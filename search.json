[{"title":"k8s grafana","url":"//linux/k8s/grafana/","content":"\n## install\n\n\n\n<!--more-->\n\n\n\n### db\n\n默认sqlite3转换成mysql\n\n```\npip install sqlite3-to-mysql\n❯ sqlite3mysql -f  /media/ssd/nfs/k8s/grafana/pv/grafana.db -d k8s_grafana -ugrafana -p -P 3305 -h localhost\n```\n\n>....\n>\n>2023-10-11 23:03:05 INFO     Adding unique index to column \"title, parent_uid\" in table folder\n>2023-10-11 23:03:05 INFO     Adding unique index to column \"uid, org_id\" in table folder\n>2023-10-11 23:03:05 INFO     Adding index to column \"parent_uid, org_id\" in table folder\n>\n>2023-10-11 23:03:05 INFO     Done!\n\n\n\n##\n\n## question  \n\n\n\n### websocket\n\n#### `/api/live/ws` → status 400\n\nhttps://grafana.com/tutorials/run-grafana-behind-a-proxy/\n\n```\nupstream dashboard{\n     server k8s01:443;\n     server k8s02:443;\n     server k8s03:443;\n     server k8s04:443;\n     server k8s05:443;\n     server k8s06:443;\n \n}\n\nmap $http_upgrade $connection_upgrade {\n  default upgrade;\n  '' close;\n}\n\nserver {\n       listen       443 ssl;\n       server_name  grafana.ui.k8s.cn;\n\n        ssl_certificate      conf.d/ssl/ui.k8s.cn.crt;\n        ssl_certificate_key  conf.d/ssl/ui.k8s.cn.key;\n\n        ssl_session_cache    shared:SSL:1m;\n        ssl_session_timeout  5m;\n\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers  on;\n  location / {\n            proxy_set_header Host $http_host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass https://dashboard;\n        }\n       location /api/live/ws {\n        \tproxy_http_version 1.1;\n        \tproxy_set_header Upgrade $http_upgrade;\n        \tproxy_set_header Connection \"Upgrade\";\n        \tproxy_set_header Host $http_host;\n        \tproxy_pass https://grafana.ui.k8s.cn;\n        }\n}\n```\n\n> 安装文档配置后\n>\n> method=GET path=/api/live/ws status=-1 \n>\n> 浏览器 101 Switching Protocols\n\n```yaml\n traefik.http.routers.grafana.rule: Host(`grafana.ui.k8s.cn`)\n```\n\n\n\n","tags":["k8s","xxx","grafana"],"categories":["linux","k8s","monitor"]},{"title":"monitor","url":"//linux/k8s/monitor/","content":"\n## monitor\n\n监控系统有 pull 和 push 两种模式:\n\npull 模式比较适合数据中心的场景\n\npush 模式更适合 iot 的场景\n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n```\n❯ kubectl apply -f /home/cs/oss/k8s-1.26/helm-charts-main/charts/kube-prometheus-stack/charts/crds/crds/crd-podmonitors.yaml\ncustomresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com created\n```\n\n> no matches for kind \"PodMonitor\" in version \"monitoring.coreos.com/v1\"\n\n\n\nserviceAnnotations 添加供pull抓取\n\n```\n  annotations:\n    meta.helm.sh/release-name: jenkins\n    meta.helm.sh/release-namespace: monitor\n    prometheus.io/path: /prometheus\n    prometheus.io/port: '8080'\n    prometheus.io/scheme: http\n    prometheus.io/scrape: 'true'\n```\n\n\n\nwrite to WAL: log samples: write /data/wal/00000157: stale NFS file handle\"\n\n\n\n\n\n","tags":["xxx","xx","monitor"],"categories":["linux","k8s","monitor"]},{"title":"istio","url":"//linux/k8s/istio/","content":"\n## istio\n\n\n\n[k8s版本支持列表](https://preliminary.istio.io/latest/zh/docs/releases/supported-releases/)\n\n<!--more-->\n\n\n\n### [ Istio Operator 安装](https://istio.io/latest/zh/docs/setup/install/operator/)\n\n\n\n\n\n### [Istioctl 安装](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n\n\n ./istio-1.19.1/manifests/profiles/default.yaml\n\n\n\n[profile=demo配置组合](https://istio.io/latest/zh/docs/setup/additional-setup/config-profiles/)\n\n\n\n```\nistioctl install --manifests=manifests/\n```\n\n> 如果使用 `istioctl` 1.19.1 版本的二进制文件，此命令将得到和独立运行 `istioctl install` 相同的结果\n\n\n\n```\n❯ ./bin/istioctl install --set hub=k8s.org/istio\nThis will install the Istio 1.19.1 \"default\" profile (with components: Istio core, Istiod, and Ingress gateways) into the cluster. Proceed? (y/N) y\n✔ Istio core installed                                                          \n- Processing resources for Istiod. Waiting for Deployment/istio-system/istiod \n```\n\n> 0/6 nodes are available: 3 Insufficient memory, 3 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/6 nodes are available: 3 No preemption victims found for incoming pod, 3 Preemption is not helpful for scheduling..\n>\n> 默认 istiod-xxx-xx request 内存2G\n\n\n\n[定制安装配置](https://istio.io/latest/zh/docs/setup/additional-setup/customize-installation/)\n\n\n\n```\n istioctl install -f samples/operator/pilot-k8s.yaml\n```\n\n> apiVersion: install.istio.io/v1alpha1\n> kind: IstioOperator\n> spec:\n>   components:\n>     pilot:\n>       k8s:\n>         resources:\n>           requests:\n>             cpu: 1000m # override from default 500m\n>             memory: 4096Mi # ... default 2048Mi\n>         hpaSpec:\n>           maxReplicas: 10 # ... default 5\n>           minReplicas: 2  # ... default 1\n\n\n\n\n\n```\n❯ ./bin/istioctl install --set hub=k8s.org/istio -f ./pilot-k8s-size.yaml\n```\n\n\n\n[samples/bookinfo/platform/kube/bookinfo.yaml](https://raw.githubusercontent.com/istio/istio/release-1.19/samples/bookinfo/platform/kube/bookinfo.yaml)\n\n```\nzgrep \"docker.io/istio\"  /samples/bookinfo/platform/kube/* | awk  '{print $3}' | sort -u | uniq | sed 's/docker.io/k8s.org/'\n#替换\nsed -i 's/docker.io/k8s.org/' `zgrep \"docker.io/istio\"  * | awk -F \":\" '{print $1}' | sort -u | uniq`\n#检查\n zgrep \"k8s.org/istio\"  * | awk  '{print $3}' | sort -u | uniq\n```\n\n\n\n### 注入 Sidecar\n\n#### 自动注入-打标签\n\n```\n#Istio 默认自动注入 Sidecar. 请为 default 命名空间打上标签 istio-injection=enabled：\n❯ kubectl label namespace default istio-injection=enabled\nnamespace/default labeled\n#查看\n❯ kubectl get ns -L istio-injection\n#修改\n❯ kubectl label namespace default istio-injection=disabled  --overwrite=true\nnamespace/default labeled\n#删除 标签后加上一个-号,如：istio-injection-\n❯ kubectl label namespace default istio-injection-\nnamespace/default unlabeled\n```\n\n\n\n#### 手动注入 [`istioctl kube-inject`](https://istio.io/latest/zh/docs/reference/commands/istioctl/#istioctl-kube-inject)\n\n```\n$  istioctl kube-inject -f samples/sleep/sleep.yaml | kubectl apply -f -\n\n$ kubectl apply -f <(istioctl kube-inject -f samples/bookinfo/platform/kube/bookinfo.yaml)\n```\n\n\n\n[使用 Ingress Gateway 服务的 Node Port验证](https://istio.io/latest/zh/docs/tasks/traffic-management/ingress/ingress-control/#using-node-ports-of-the-ingress-gateway-service)\n\n\n\n```\nexport INGRESS_NAME=istio-ingressgateway\nexport INGRESS_NS=istio-system\n\n❯ export INGRESS_HOST=$(kubectl get po -l istio=ingressgateway -n \"${INGRESS_NS}\" -o jsonpath='{.items[0].status.hostIP}')\n❯ export INGRESS_PORT=$(kubectl -n \"${INGRESS_NS}\" get service \"${INGRESS_NAME}\" -o jsonpath='{.spec.ports[?(@.name==\"http2\")].nodePort}')\n❯ echo \"INGRESS_HOST=$INGRESS_HOST, INGRESS_PORT=$INGRESS_PORT\"\nINGRESS_HOST=192.168.122.14, INGRESS_PORT=31634\n\n\n\n\n```\n\n\n\n```\ncurl -s -I -HHost:httpbin.example.com \"http://$INGRESS_HOST:$INGRESS_PORT/status/200\"\n```\n\n> HTTP/1.1 503 Service Unavailable\n> date: Fri, 06 Oct 2023 12:22:14 GMT\n> server: istio-envoy\n> transfer-encoding: chunked\n>\n> #https://istio.io/latest/zh/docs/ops/common-problems/network-issues/#route-rules-have-no-effect-on-ingress-gateway-requests\n\n\n\n```\ncurl -s -I -HHost:httpbin.example.com \"http://$INGRESS_HOST:$INGRESS_PORT/headers\"\n```\n\n>HTTP/1.1 404 Not Found\n>date: Fri, 06 Oct 2023 12:22:11 GMT\n>server: istio-envoy\n>transfer-encoding: chunked\n\n\n\n\n\n\n\n### [Helm 安装](https://istio.io/latest/zh/docs/setup/install/helm/)\n\n\n\n```\n❯ helm repo add istio https://istio-release.storage.googleapis.com/charts\n\n❯ helm search repo istio  | grep istio/\nistio/istiod                1.19.1       \t1.19.1     \tHelm chart for istio control plane               \nistio/base                  1.19.1       \t1.19.1     Helm chart for deploying Istio cluster resource...\nistio/cni                    1.19.1       \t1.19.1     \tHelm chart for istio-cni components             \nistio/gateway             1.19.1       \t1.19.1     \tHelm chart for deploying Istio gateways     \nistio/ztunnel               1.19.1       \t1.19.1     \tHelm chart for istio ztunnel components         \n\n❯ helm pull istio/base --untar\n❯ helm pull istio/gateway --untar\n❯ helm pull istio/istiod --untar\n❯ helm pull istio/ztunnel --untar\n❯ helm pull istio/cni --untar\n\n```\n\n\n\n```\n helm install istio-base istio/base -n istio-system --set defaultRevision=default\n helm install istiod istio/istiod -n istio-system --wait\n #（可选）安装 Istio 的入站网关：\n$ kubectl create namespace istio-ingress\n$ helm install istio-ingress istio/gateway -n istio-ingress --wait\n```\n\n\n\n\n\n","tags":["xxx","istio","Service-Mesh"],"categories":["linux","k8s","istio"]},{"title":"磁盘 fdisk","url":"//linux/shell/fdisk/","content":"\n### fdisk\n\n\n\n```\n❯ sudo fdisk  /dev/nvme0n1 -l\nDisk /dev/nvme0n1: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors\nDisk model: KINGSTON SNV2S2000G                     \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: 567141B0-39E4-467E-B67D-61B05D225406\n\nDevice              Start        End   Sectors   Size Type\n/dev/nvme0n1p1       2048  117186559 117184512  55.9G Linux filesystem\n/dev/nvme0n1p2  117186560  234373119 117186560  55.9G Linux filesystem\n/dev/nvme0n1p3  234373120  644530175 410157056 195.6G Linux filesystem\n/dev/nvme0n1p4  644530176 1386717183 742187008 353.9G Linux filesystem\n/dev/nvme0n1p5 1386717184 1402341375  15624192   7.5G Linux swap\n/dev/nvme0n1p6 1402341376 1403473919   1132544   553M EFI System\n/dev/nvme0n1p7 1403473920 1571248127 167774208    80G Microsoft basic data\n\n```\n\n<details>\n  <summary>创建新分区</summary>\n  <pre><a>分配未使用的分区</a><code>\nCommand (m for help): F\nUnpartitioned space /dev/nvme0n1: 1.09 TiB, 1195919875584 bytes, 2335781007 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\n</br>\n     Start        End    Sectors  Size\n1571248128 3907029134 2335781007  1.1T\n</br>\nCommand (m for help): n\nPartition number (8-128, default 8): \nFirst sector (1571248128-3907029134, default 1571248128): \nLast sector, +/-sectors or +/-size{K,M,G,T,P} (1571248128-3907029134, default 3907029134): +80G\n</br>\nCreated a new partition 8 of type 'Linux filesystem' and of size 80 GiB.\n  </code></pre>\n</details>\n\nuuid\n\n<!--more-->\n\n```\n❯ sudo blkid /dev/nvme0n1p8\n/dev/nvme0n1p8: PARTUUID=\"18fd9320-fea9-404c-817f-e4d401f9f453\"\n```\n\n####  mkfs.ext4\n\n```\n❯ sudo mkfs.ext4 /dev/nvme0n1p8\nmke2fs 1.46.6 (1-Feb-2023)\nDiscarding device blocks: done                            \nCreating filesystem with 20971520 4k blocks and 5242880 inodes\nFilesystem UUID: f55f67da-11b0-4085-8dce-b49f9c8322e4\nSuperblock backups stored on blocks: \n\t32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, \n\t4096000, 7962624, 11239424, 20480000\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (131072 blocks): done\nWriting superblocks and filesystem accounting information: done   \n\n```\n\n\n\n\n\n#### 删除\n\n\n\n```\n❯ sudo fdisk  /dev/sdb\n```\n\n>Welcome to fdisk (util-linux 2.36.1).\n>Changes will remain in memory only, until you decide to write them.\n>Be careful before using the write command.\n>\n>Command (m for help): **p**\n>Disk /dev/sdb: 238.47 GiB, 256060514304 bytes, 500118192 sectors\n>Disk model:                 \n>Units: sectors of 1 * 512 = 512 bytes\n>Sector size (logical/physical): 512 bytes / 4096 bytes\n>I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n>Disklabel type: gpt\n>Disk identifier: F4388C00-21CE-418F-86AA-3A1CD95B1CF3\n>\n>Device         Start       End   Sectors  Size Type\n>**/dev/sdb6**  304701440 500117503 195416064 93.2G Linux filesystem\n>**/dev/sdb7**  167002112 194111487  27109376 12.9G Linux filesystem\n>\n>Partition table entries are not in disk order.\n>Command (m for help): **d**\n>Partition number (6,7, default 7): **6**\n>\n>Partition 6 has been deleted.\n>Command (m for help): **d**\n>Selected partition 7\n>Partition ***7*** has been deleted.\n>\n>Command (m for help): **p**\n>Disk /dev/sdb: 238.47 GiB, 256060514304 bytes, 500118192 sectors\n>Disk model:                 \n>Units: sectors of 1 * 512 = 512 bytes\n>Sector size (logical/physical): 512 bytes / 4096 bytes\n>I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n>Disklabel type: gpt\n>Disk identifier: F4388C00-21CE-418F-86AA-3A1CD95B1CF3\n>\n>Command (m for help): **w**\n>The partition table has been altered.\n>Syncing disks.\n\n#### 创建\n\n```\n❯ sudo fdisk  /dev/sdb\n```\n\n>Welcome to fdisk (util-linux 2.36.1).\n>Changes will remain in memory only, until you decide to write them.\n>Be careful before using the write command.\n></br>\n>Command (m for help): **n**\n>Partition number (1-128, default 1): **1**\n>First sector (34-500118158, default 2048): \n>Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-500118158, default 500118158): **+120G**\n></br>\n>Created a new partition 1 of type 'Linux filesystem' and of size 120 GiB.\n></br>\n>Command (m for help): **n**\n>Partition number (2-128, default 2): **2**\n>First sector (251660288-500118158, default 251660288): \n>Last sector, +/-sectors or +/-size{K,M,G,T,P} (251660288-500118158, default 500118158): \n></br>\n>Created a new partition 2 of type 'Linux filesystem' and of size 118.5 GiB.\n></br>\n>Command (m for help): **w**\n>The partition table has been altered.\n>Calling ioctl() to re-read partition table.\n>Syncing disks.\n\n\n\n#### 挂载\n\n```\nsudo mkfs.ext4 /dev/sdb1\nsudo mkfs.ext4 /dev/sdb2\n\n❯ sudo lsblk -o name,uuid | grep sdb\nsdb         \n├─sdb1      08f1efd4-5d29-4755-bf00-6d9fb634d219\n└─sdb2      af969762-0e0b-4e34-a0c8-47c05ef085f1\n```\n\n\n\n/etc/fstab\n\n```\n$ cat /etc/fstab | grep  -A 1 /mnt/data\n#/mnt/data\nUUID=f55f67da-11b0-4085-8dce-b49f9c8322e4 /mnt/data           ext4    defaults        0       2\n\n$ sudo mount -a\n```\n\n\n\n脚本挂载，u盘怕误拨导致无法开机\n\n```\n❯ sudo ln -s /etc/rc.local  /opt/tools/init/rc.local\n❯ sudo chown :cs /etc/rc.local\n❯ sudo chmod g+wr /etc/rc.local\n❯ sudo chmod +x /etc/rc.local\n\n```\n\n\n\n\n\n### gparted\n\n\n\n```\nsudo apt-get install gparted\n```\n\n\n\n\n\n","tags":["xxx","xx","磁盘 fdisk"],"categories":["linux","shell","fdisk"]},{"title":"promethus PromQL","url":"//linux/k8s/PromQL/","content":"\n### 二元算术运算符\n\n- `+` 加法\n- `-` 减法\n- `*` 乘法\n- `/` 除法\n- `%` 模\n- `^` 幂等\n\nhttps://prometheus.io/docs/prometheus/latest/querying/functions/\n\n\n\n查询过去 5 分钟的***\\*平均请求持续时间\\****：(平均的时间/平均的数量)\n\n```\nrate(demo_api_request_duration_seconds_sum{job=\"demo\"}[5m])\n/\nrate(demo_api_request_duration_seconds_count{job=\"demo\"}[5m])\n```\n\n<!--more-->\n\n\n\n### 一对一\n\n\n\n```\n# TYPE foo gauge\nfoo{color=\"red\", size=\"small\"} 4\nfoo{color=\"green\", size=\"medium\"} 8\nfoo{color=\"blue\", size=\"large\"} 16\n# TYPE bar gauge\nbar{color=\"green\", size=\"xlarge\"} 2\nbar{color=\"blue\", size=\"large\"} 7\nbar{color=\"red\", size=\"small\"} 5\n```\n\n***\\*对于向量左边的每一个元素，操作符都会尝试在右边里面找到一个匹配的元素\\****，***\\*匹配是通过比较所有的标签来完成的，没有匹配的元素会被丢弃\\****\n\n>`foo{} + bar{}`\n>\n>{color=\"red\", size=\"small\"} 9  #4+5\n>\n>bar{color=\"blue\", size=\"large\"} 23 # 16+7\n\n***\\*使用 `on` 或者 `ignoring` 修饰符来指定用于匹配的标签进行计算\\****，基于该标签（`on (color)`）或者忽略其他的标签（`ignoring (size)`）进行计算\n\n>`foo{} + on(color) bar{}` \n>\n>{color=\"red\"} 9 \n>\n>{color=\"green\"} 10\n>\n>{color=\"blue\"} 23\n\n\n\n\n\n### 一对多\n\n***\\*必须使用 group 修饰符\\****：`group_left` 或者 `group_right` 来确定哪一个向量具有更高的基数（充当`多`的角色）(也就是说那个元素是多的那一边，左侧元素比较多需要添加group left，右侧元素多就是group right，让其明确指定一下，***\\*注意是基于标签维度的多少\\****)除了 `on()` 之外，还可以使用相反的 `ignoring()` 修饰符，可以用来将一些标签维度从二元运算操作匹配中忽略掉，如果在操作符的右侧有额外的维度，则应该使用 `group_right`（表示右边的向量具有更高的基数）修饰符。\n\n```\nrate(demo_cpu_usage_seconds_total{job=\"demo\"}[5m])\n/ ignoring(mode) group_left\ndemo_num_cpus{job=\"demo\"}\n```\n\n\n\n\n\n","tags":["query","promethus","PromQL"],"categories":["linux","k8s","monitor"]},{"title":"promethus","url":"//linux/k8s/prometheus/","content":"\n## Prometheus\n\n\n\nPrometheus实现自动采集业务指标数据\n\n业务侧实现一个接口，返回Prometheus规范化数据\n\n```\n\ntraefik_entrypoint_requests_total{app=\"traefik\", code=\"200\", entrypoint=\"metrics\", instance=\"121.21.48.198:9100\", job=\"kubernetes-service-endpoints\", method=\"GET\", namespace=\"default\", node=\"k8s06\", protocol=\"http\", service=\"traefik\"}\ntraefik_entrypoint_requests_total{app=\"traefik\", code=\"200\", entrypoint=\"websecure\", instance=\"121.21.48.198:9100\", job=\"kubernetes-service-endpoints\", method=\"GET\", namespace=\"default\", node=\"k8s06\", protocol=\"http\", service=\"traefik\"}\ntraefik_entrypoint_requests_total{app=\"traefik\", code=\"400\", entrypoint=\"websecure\", instance=\"121.21.48.198:9100\", job=\"kubernetes-service-endpoints\", method=\"GET\", namespace=\"default\", node=\"k8s06\", protocol=\"http\", service=\"traefik\"}\ntraefik_entrypoint_requests_total{app=\"traefik\", code=\"404\", entrypoint=\"traefik\", instance=\"121.21.48.198:9100\", job=\"kubernetes-service-endpoints\", method=\"GET\", namespace=\"default\", node=\"k8s06\", protocol=\"http\", service=\"traefik\"}\ntraefik_entrypoint_requests_total{app=\"traefik\", code=\"404\", entrypoint=\"web\", instance=\"121.21.48.198:9100\", job=\"kubernetes-service-endpoints\", method=\"GET\", namespace=\"default\", node=\"k8s06\", protocol=\"http\", service=\"traefik\"}\ntraefik_entrypoint_requests_total{app=\"traefik\", code=\"404\", entrypoint=\"websecure\", instance=\"121.21.48.198:9100\", job=\"kubernetes-service-endpoints\", method=\"GET\", namespace=\"default\", node=\"k8s06\", protocol=\"http\", service=\"traefik\"}\n\n```\n\n运维侧部署的时候，在svc上带上3个标签\n\n```\n  annotations:\n    prometheus.io/scrape: 'true'\n    prometheus.io/path: '/monitor'\n    prometheus.io/port: '9100'  \n```\n\n>- prometheus.io/scrape：\n>- 自动采集指标数据开关，默认为false；Prometheus会在k8s集群中自动检测哪些svc是打开了这个开关\n>\n>- prometheus.io/path：\n>  采集指标数据路径，默认为 /metrics\n>- prometheus.io/port：\n>  采集指标端口，默认为pod暴露的端口\n\n<!--more-->\n\n\n\n静态\n\n部署在非Kubernetes中的服务。Alertmanager是没有部署在Kubernetes里面的。\n\n1、业务侧实现接口，返回格式化监控数据。Alertmanager也自带监控接口，路径就是 /metrics\n\n2、修改Prometheus-Server配置文件，新增加一个job_name静态配置。\n\n```\n- job_name: \"alertmanager\"\n    static_configs:\n    - targets: ['alertmanager.xxxx.com:80']\n```\n\n\n\n## 组件\n\nhttps://github.com/prometheus-community/helm-charts\n\n\n\n```\n$ helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n\n$ helm pull prometheus-community/prometheus --untar\n```\n\n\n\n\n\n### Kube-state-metrics\n\nhttps://github.com/kubernetes/kube-state-metrics#helm-chart\n\nKubernetes 集群上 Pod、DaemonSet、Deployment、Job、CronJob 等各种资源对象的状态的监控\n\n\n\n### metric-server\n\n- metric-server（或heapster）是从api-server中获取cpu、内存使用率这种监控指标，并把他们发送给存储后端，如influxdb或云厂商，他当前的核心作用是：为HPA等组件提供决策指标支持。\n\n\n\n### Pushgateway\n\n该部件不是将数据push到prometheus,而是作为一个中间组件*收集*外部push来的数据指标，供prometheus进行pull\n\n![](/pics/prometheus-pushgateway.png)\n\n\n\nFlink可通过配置此reporter直接将数据写入Prometheus   \n\n**使用Flink ?**\n\n> 通过Pushgateway方式,Prometheus无法直接检测到监控源服务的状态,故此种方式不适用于监控服务的存活状态等场景 \n>\n> Pushgateway属于静态代理,它接收的指标不存在过期时间,故会一直保留直到该指标被更新或删除 此种情况下,不再使用的指标可能存在于网关中 \n>\n> 如上所言,Pushgateway并不算是完美的解决方案,在监控中更多做为辅助方案存在,用于解决Prometheus无法直接获取数据的场景\n\n\n\n\n\n1. 举例中删除{job=“some_job”}数据的语句并不会删除{job=“some_job”,instance=“some_instance”}的数据。因为属于不同的Group。如需要删除{job=“some_job”,instance=“some_instance”}下的数据，需要使用\n\n   ```shell\n   curl -X DELETE http://pushgateway.example.org:9091/metrics/job/some_job/instance/some_instance\n   1\n   ```\n\n2. 删除所有group下的所有metrics,启动pushgateway时需加上命令行参数–web.enable-admin-api\n\n   ```\n   curl -X PUT http://pushgateway.example.org:9091/api/v1/admin/wipe\n   ```\n\n   \n\n\n\n\n\n\n\n### node-exporter\n\n\n\n采集服务器的运行指标如CPU, 内存，磁盘等信息\n\n\n\n\n\n### grafana\n\n```\ngrafana cli admin reset-admin-password pwdxxx\n然后重启pod(前提需要将grafana核心数据持久化到本地存储)\n```\n\n> Deprecation warning: The standalone 'grafana-cli' program is deprecated and will be removed in the future. Please update all uses of 'grafana-cli' to 'grafana cli'\n\n\n\n\n\n\n\n\n\n####  添加模板id\n\n13824\n\n13332-kube-state-metrics-v2\n\n14981  cordns\n\n14518 Kubernetes Cluster Overall Dashboard\n\n\n\n\n\n### thanos\n\n主要组件：\n\n边车组件（Sidecar）：连接 Prometheus，并把 Prometheus 暴露给查询网关（Querier/Query），以供实时查询，并且可以上传 Prometheus 数据给云存储，以供长期保存(相当于可以连接本地prometheus以及查询器的)\n查询网关（Querier/Query）：实现了 Prometheus API，与汇集底层组件（如边车组件 Sidecar，或是存储网关 Store Gateway）的数据（可以去查询sidecar里面的数据，或者是程查询存储网关里面的一个数据，有一部分的数据可能还在本地，因为sidecar还没有将数据上传上去，这个时候去查询的时候会根据查询时间会去路由到本地的sidecar，如果数据在远程存储上面，那么就会从存储网关上面去读取）\n存储网关（Store Gateway）：将云存储中的数据内容暴露出来\n压缩器（Compactor）：将云存储中的数据进行压缩和下采样\n接收器（Receiver）：从 Prometheus 的 remote-write WAL（Prometheus 远程预写式日志）获取数据，暴露出去或者上传到云存储（和sidecar是两种不同的方式）\n规则组件（Ruler）：针对监控数据进行评估和报警\nBucket：主要用于展示对象存储中历史数据的存储情况，查看每个指标源中数据块的压缩级别，解析度，存储时段和时间长度等信息。\n查询前端：实现Prometheus的api，将其代理给query，同时缓存响应\n\n从使用角度来看有两种方式去使用 Thanos，sidecar模式（remote read API，与 Prometheus server 部署于同一个 pod或主机 中）和 receiver 模式（ [Prometheus Remote Write API](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write)）。\n\n\n\n- [Thanos](https://github.com/thanos-io/thanos): read and write\n\nhttps://artifacthub.io/packages/helm/banzaicloud-stable/thanos\n\n```\n```\n\n\n\n![](/pics/thanos-receive.png)\n\nThanos Receive 模式是 Thanos 响应社区用户 Remote Write 的需求新增的模式，其原理是：\n\n- Prometheus 或 Prometheus Agent 通过 Remote Write 将监控数据发送到 Thanos Receive Router；\n- Thanos Receive Router 根据租户信息将数据发送给响应的 Thanos Receive Ingestor，其中 Router 是无状态的，Ingestor 是有状态的；\n- Thanos Receive Ingestor 相当于在一个没有数据抓取能力和告警能力的 Prometheus 之上增加了 Store API 的支持用于和 Thanos Query/Thanos Ruler 交互，增加了 Shipper 组件将落盘 Block 上传对象存储；\n- Thanos Query 可以统一查询 Thanos Ingestor、Thanos Store Gateway；\n- 其他组件作用和 Thanos Sidecar 模式类似。\n\n\n\n\n\n\n\n### minio\n\n\n\n\n\n>minio  | EXAMPLES:\n>minio  |   1. Start MinIO server on \"/home/shared\" directory.\n>minio  |      $ minio server /home/shared   单机\n>minio  | \n>minio  |   2. Start single node server with 64 local drives \"/mnt/data1\" to \"/mnt/data64\".\n>minio  |      $ minio server /mnt/data{1...64}  集群\n>minio  | \n>minio  |   3. Start distributed MinIO server on an 32 node setup with 32 drives each, run following command on all the nodes\n>minio  |      $ minio server http://node{1...32}.example.com/mnt/export{1...32}\n>\n>.......\n\n\n\n\n\n```\n    type: s3\n    config:\n      bucket: \"tsdb\"\n      endpoint: \"https://minio.k8s.cn:9000\"\n      region: \"\"\n      access_key: \"blGDf93r2z7JI7LHpfop\"\n      insecure: false  #false开启https\n      signature_version2: false  #默认v4\n      secret_key: \"TJUl16aHrjMdFGHx1oId6ZQBDPBSzdhbFWyFRmEN\"\n      # put_user_metadata: {}\n      http_config:\n        idle_conn_timeout: 1m30s\n        response_header_timeout: 2m\n        insecure_skip_verify: true\n      trace:\n        enable: false\n      list_objects_version: \"\"\n      part_size: 134217728\n      # sse_config:\n      #   type: \"\"\n      #   kms_key_id: \"\"\n      #   kms_encryption_context: {}\n      #   encryption_key: \"\"\n\n```\n\n\n\n## error\n\n\n\nprometheus一旦启动占用大量内存，原因是pushgateway积累了大量的数据会push到prometheus，需要手动清除pushgateway中的数据。\n\nprometheus中日志会出现\n\n‘level=info ts=2020-04-08T11:40:55.581381661Z caller=head.go:526 component=tsdb msg=“head GC completed” duration=286.757915ms’\n\n其中duration正常的数值应该是1～2ms。\n\n清除数据可以参考prometheus git的readme中的\n\n```\ncurl -X PUT http://pushgateway.example.org:9091/api/v1/admin/wipe\n```\n\n> 是指删除pushgateway中的数据，跟promethues没有关系\n","tags":["promethus","TSDB","monitor"],"categories":["linux","k8s","monitor"]},{"title":"常见问题","url":"//linux/k8s/question/","content":"\n### mount\n\nstorageClassName: <storageClass> 名称不同匹配不到\n\n####  Permission denied  远程目录权限\n\n\n\n[securityContext.fsGroup](https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/security-context/#%E4%B8%BA-pod-%E9%85%8D%E7%BD%AE%E5%8D%B7%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E5%92%8C%E5%B1%9E%E4%B8%BB%E5%8F%98%E6%9B%B4%E7%AD%96%E7%95%A5)\n\n```yaml\n securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n    fsGroupChangePolicy: \"OnRootMismatch\"   #1.22以上，首次启动时才会执行chmod或chown操作\n```\n\n\n\n#### PVC不能安装两次\n\n> Unable to attach or mount volumes: unmounted volumes=[**storage-volume**], unattached volumes=[kube-api-access-jrz96 **storage-volume config-volume**]: timed out waiting for the condition\n>\n> /var/lib/kubelet/pods/eb4c9f58-b7c7-4663-8f9a-1cc447c51fe6/volumes/kubernetes.io~nfs/prometheus-pv0 Output: mount.nfs: mounting 192.168.122.6:/opt/data/k8s/prometheus/pv0 failed, reason given by server: No such file or directory\n\n检查权限\n\n\n\n####  Connection refused\n\n① 首先看nfs服务是否开启\n② 其次看rpcbind是否开启\n\n\n\n<!--more-->\n\n\n\n### /etc/kubernetes/manifests\n\nnode 没有这个目录\n\n```\n--pod-manifest-path=/etc/kubernetes/manifests   #StaticPodPath\n```\n\n> file_linux.go:61] \"Unable to read config path\" err=\"path does not exist, ignoring\" path=\"/etc/kubernetes/manifests\"\n\n解决方法，手动创建\n\n\n\n#### pvc\n\n```\nkubectl describe  pv grafana-pv1\n \nkubectl describe pvc grafana -n monitor\n```\n\n> Warning  ProvisioningFailed  8s (x17 over 4m5s)  persistentvolume-controller  storageclass.storage.k8s.io \"grafana-data\" not found\n\nhttps://kubernetes.io/zh-cn/docs/concepts/storage/dynamic-provisioning/\n\n```\napiVersion: ceph.rook.io/v1beta1\nkind: Pool\nmetadata:\n  name: replicapool\n  namespace: rook-ceph\nspec:\n  replicated:\n    size: 3\n---\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: block-service\nprovisioner: ceph.rook.io/block\nparameters:\n  pool: replicapool\n  #The value of \"clusterNamespace\" MUST be the same as the one in which your rook cluste\n  clusterNamespace: rook-ceph\n```\n\n\n\n### nfs\n\nkubernetes集群所有节点需要安装nfs客户端\n\n\n\n```\nhelm install -f ./nfs-subdir-external-provisioner/values.yaml  ./nfs-subdir-external-provisioner \\\n-n nfs-provisioner \\\n --set storageClass.name=nfs-client \\\n  --set storageClass.defaultClass=true \\\n--generate-name\n```\n\n>通过该配置自动创建\n>\n>  --set global.storageClass=nfs-client \n\n删除后如何重新挂载原来的卷？？？\n\n\n\n```\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm pull bitnami/tomcat --untar\n\nhelm install tomcat bitnami/tomcat \\\n  --namespace=apps \\\n  --create-namespace \\\n  --set global.storageClass=nfs-client \\\n  --set replicaCount=2 \\\n  --set service.type=NodePort \\\n  --set service.nodePort=30809\n```\n\n","tags":["xxx","xx","常见问题"],"categories":["linux","k8s"]},{"title":"dnsmasq","url":"//linux/debian/dnsmasq/","content":"\n## \n\n四行的含义：\n\n- resolv-file：从文件读取 DNSMasq 上游的 DNS [服务器](https://cloud.tencent.com/act/pro/promotion-cvm?from_column=20065&from=20065)配置。\n- strict-order：resolv-file 文件中如果指定了多个 DNS 服务器，严格安装 DNS 服务器的先后顺序查询域名。\n- listen-address：监听地址，配置为本机 IP 即可。\n- addn-hosts：从文件读取本地 DNS 域名和 IP 的对应关系，格式为 `<IP> <Domain name>`。其实可以把 IP 和域名的对应关系写在 */etc/hosts* 文件中，DNSMasq 默认从那里读取，但如果要支持一个域名对应多个 IP，就必须使用 **addn-hosts** 选项了。\n\n```\nresolv-file=/etc/resolv.conf\nstrict-order\nlisten-address=192.168.122.1\naddn-hosts=/opt/tools/dns/hosts\n```\n\n<!--more-->\n\n\n\n````\nsystemctl start dnsmasq.service 启动\n\nsystemctl enable dnsmasq.service # 开机启动\n\nnetstat -lnp|grep dnsmasq \n````\n\n\n\n\n\n\n\n````\ncat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-\n    - --cluster-cidr=121.21.0.0/16\n    - --cluster-name=cs\n    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt\n    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key\n    - --service-cluster-ip-range=10.96.0.0/12\n\n\n cat /var/lib/kubelet/config.yaml | grep -A 1 cluster\nclusterDNS:\n- 10.96.1.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\n\n\n\nkubectl edit cm kube-proxy -n kube-system\n````\n\n\n\n```\n修改每个Node上kubelet的启动参数，在其中加上以下两个参数：\n\n--cluster-dns=169.169.0.100：为DNS服务的ClusterIP地址。\n--cluster-domain=cluster.local：为在DNS服务中设置的域名。\n然后重启kubelet服务。\n```\n\n\n\n\n\n### nslookup\n\n````\n❯ kubectl debug -it vault-0  -n vault  --image=k8s.org/cs/netshoot   -- sh\nDefaulting debug container name to debugger-8z7lk.\nIf you don't see a command prompt, try pressing enter.\n/root $ nslookup  vault-internal\nServer:\t\t10.96.1.10\nAddress:\t10.96.1.10#53\n\nName:\tvault-internal.vault.svc.cluster.local\nAddress: 121.21.64.141\nName:\tvault-internal.vault.svc.cluster.local\nAddress: 121.21.80.152\nName:\tvault-internal.vault.svc.cluster.local\nAddress: 121.21.48.135\n\n````\n\n\n\n##\n\n\n\n\n\n","tags":["xxx","xx","dnsmasq"],"categories":["linux","debian","dnsmasq"]},{"title":"k8s cert manager","url":"//linux/k8s/cert-manager/","content":"\n\n\n## cert-manager\n\n它支持从Let’s Encrypt，HashiCorp Vault，Venafi等颁发证书\n\n**Issuer/ClusterIssuer**\n\n**Certificate**\n\n**ACME Orders and Challenges**\n\n**Webhook**\n\n**CA Injector**\n\n```\n\n              +-------------+\n              |   Ingress/  |\n              | annotations |\n              +------+------+\n                     |\n                     | watch ingress change\n                     |\n                     v\n              +-------------+\n              |   Issuer/   |\n              | ClusterIssuer |\n              +------+------+\n                     |\n                     | Create CertificateRequest\n                     |\n                     v\n              +------+------+\n              |CertificateRequest|\n              +------+------+\n                     |\n                     | Create Order\n                     |\n                     v\n              +------+------+\n              |      Order  |\n              +------+------+\n                     |\n                     | Create Challenges\n                     |\n                     v\n              +------+------+\n              |  Challenge  |\n              +------+------+\n                     |\n                     | Respond to Challenge\n                     |\n                     v\n              +------+------+\n              |ChallengeResponse|\n              +------+------+\n                     |\n                     | Issue Certificate\n                     |\n                     v\n              +------+------+\n              |     Secret  |\n              +------+------+\n```\n\n\n\n\n\n### [doc cert-manager](https://cert-manager.io/docs/installation/helm/)\n\nhttps://cert-manager.io/docs/installation/helm/\n\n\n\n```\n❯ helm repo add jetstack https://charts.jetstack.io\n\"jetstack\" has been added to your repositories\n❯ helm pull jetstack/cert-manager --untar\n❯ kubectl apply -f ./cert-manager.crds.yaml   #--set installCRDs=true\ncustomresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\ncustomresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\ncustomresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created\ncustomresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created\ncustomresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created\ncustomresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created\n```\n\n\n\n```\nhelm install -f ./cert-manager/values.yaml \\\n  -name cert-manager \\\n  --namespace cert-manager  \\\n  ./cert-manager  \\\n  --create-namespace  \\\n   --version v1.12.4 \\\n  # --set installCRDs=true\n  --set prometheus.enabled=false \\  # Example: disabling prometheus using a Helm parameter\n  --set webhook.timeoutSeconds=4   # Example: changing the webhook timeout using a Helm parameter\n```\n\n\n\n```\nhelm install -f ./cert-manager/values.yaml -name cert-manager --namespace cert-manager  ./cert-manager  --create-namespace --set webhook.timeoutSeconds=4 --set installCRDs=true\n\n❯ helm uninstall  -name cert-manager --namespace cert-manager\nrelease \"cert-manager\" uninstalled\n\n```\n\n\n\n<!--more-->\n\n### kpi\n\n![](/pics/cert-manager-ca.png)\n\n\n\n[Vault Binary download for Linux](https://developer.hashicorp.com/vault/downloads)\n\n\n\n```\n❯  helm repo add hashicorp https://helm.releases.hashicorp.com\n\"hashicorp\" has been added to your repositories\n❯ helm pull hashicorp/vault --untar\n\n helm install  -f ./vault/values.yaml  vault --namespace vault  ./vault  --create-namespace\n \n helm uninstall   vault --namespace vault\n```\n\n\n\n* **failed to initialize barrier: failed to persist keyring: mkdir /vault/data/core: permission denied** \n\n  >检查nfs配置权限 /etc/exports   rw\n  >\n  >**no_root_squash** 选项会确保在 NFS 客户端上使用根用户（UID 为 0）\n  >\n  > 容器中vault用户（属于other的权限），nfs宿主机目录权限设置  chmod go+rw -R ./vault/*\n\n```\n❯ kubectl exec vault-0 -n vault -- vault operator init \\\n    -key-shares=1 \\\n    -key-threshold=1 \\\n    -format=json >> ./vault/cluster-keys.json\n❯ jq -r \".unseal_keys_b64[]\" ./vault/cluster-keys.json\n0pnsR3Z5j+lDXes6y6LaS0wh0IwuNn9FI/AMjsrR6w8=\n❯ kubectl exec vault-0 -n vault -- vault operator unseal 0pnsR3Z5j+lDXes6y6LaS0wh0IwuNn9FI/AMjsrR6w8=\n```\n\n>Key                     Value\n>\\---                     \\-----\n>Seal Type               shamir\n>Initialized             true\n>Sealed                  false\n>Total Shares            1\n>Threshold               1\n>Version                 1.14.0\n>Build Date              2023-06-19T11:40:23Z\n>Storage Type            raft\n>Cluster Name            vault-cluster-e7311051\n>Cluster ID              b481f479-636b-44de-0133-0358e278547d\n>HA Enabled              true\n>HA Cluster              n/a\n>HA Mode                 standby\n>Active Node Address     <none>\n>Raft Committed Index    31\n>Raft Applied Index      31\n\n\n\n\n\n```\nvault operator init -key-shares=5 -key-threshold=3 \n# -key-shares：指定密钥的总股数， \n# -key-threshold：指定需要几股可解锁 \n# 以上参数为默认，可不设置\n```\n\n\n\n```\nkubectl exec vault-0 -n vault -- vault status\n```\n\nhttps://developer.hashicorp.com/vault/tutorials/kubernetes/kubernetes-minikube-tls\n\n\n\n```\n kubectl exec -ti vault-1 -n vault -- vault operator raft join -address=http://vault-1.vault-internal:8200\n\n\n```\n\n\n\nhttps://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/security-and-compliance/use-vault-as-a-key-management-service#3a460810ef6sd\n\n\n\nvault全部都需要解封\n\n```\n❯ kubectl debug -it vault-2  -n vault  --image=k8s.org/cs/netshoot   -- sh\nDefaulting debug container name to debugger-p6d5h.\nIf you don't see a command prompt, try pressing enter.\n/root $ telnet vault-0.vault-internal:8201\ntelnet: can't connect to remote host (121.21.80.178): Connection refused\n/root $ telnet vault-1.vault-internal:8201\nConnected to vault-1.vault-internal:8201\n/root $ telnet vault-2.vault-internal:8201\nConnected to vault-2.vault-internal:8201\n\n```\n\n> [ERROR] storage.raft: failed to heartbeat to: peer=vault-0.vault-internal:8201 backoff time=2.5s error=\"dial tcp 121.21.80.178:8201: connect: connection refused\"\n>\n>2023-09-20T06:41:19.836Z [INFO] storage.raft: pipelining replication: peer=\"{Voter vault-0 vault-0.vault-internal:8201}\"\n\n每次重启都要手动解封所有 vault 实例，自动解封[autounseal-transit](https://developer.hashicorp.com/vault/tutorials/auto-unseal/autounseal-transit)\n\n\n\n实现 vault 配置的自动化管理\n\nhttps://github.com/pulumi/pulumi-vault\n\n\n\n````\npath \"local/*\" {\n  capabilities = [\"read\", \"list\"]\n}\n\n// 允许创建 child token\npath \"auth/token/create\" {\n  capabilities = [\"create\", \"read\", \"update\", \"delete\", \"list\"]\n}\n````\n\n\n\n\n\n### traefik\n\nhttps://www.boysec.cn/boy/393ed77e.html#%E6%96%B9%E6%B3%95%E4%BA%8C%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89\n\n\n\n### ingress\n\n\n\n```\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging\nspec:\n  acme:\n    # The ACME server URL   pro https://acme-v02.api.letsencrypt.org/directory\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    # Email address used for ACME registration \n    email: xxx@xx.com\n    # Name of a secret used to store the ACME account private key\n    privateKeySecretRef:\n      name: letsencrypt-staging\n    # Enable the HTTP-01 challenge provider\n    solvers:\n      - http01:\n          ingress:\n            class:  nginx\n```\n\n","tags":["ca","cert","kpi"],"categories":["linux","k8s"]},{"title":"kubectl commands","url":"//linux/k8s/kubectl/","content":"\n## commands\n\nhttps://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#rollout\n\n<!--more-->\n\n\n\n### crd\n\n```\n❯ kubectl get crd | grep traefik.containo.us | awk '{print $1}'\ningressroutes.traefik.containo.us\ningressroutetcps.traefik.containo.us\ningressrouteudps.traefik.containo.us\nmiddlewares.traefik.containo.us\nmiddlewaretcps.traefik.containo.us\n\n$ kubectl delete customresourcedefinition `kubectl get crd | grep traefik.containo.us | awk '{print $1}'| tr '\\n' ' '`\n\n```\n\n\n\n\n\n\n\n### pod\n\n\n\n#### 重启\n\n```\nkubernetes-dashboard   kubernetes-dashboard-6495566f7b-9p5mq         0/1     ImagePullBackOff   0              9m43s\n❯ kubectl rollout  restart  kubernetes-dashboard-6495566f7b-9p5mq -n kubernetes-dashboard\nerror: the server doesn't have a resource type \"kubernetes-dashboard-6495566f7b-9p5mq\"\n❯ kubectl rollout  restart deployment/kubernetes-dashboard -n kubernetes-dashboard\ndeployment.apps/kubernetes-dashboard restarted\n\n```\n\n> rollout  restart\n\n\n\n\n\n### logs\n\n\n\n```\n❯ kubectl logs --tail=10 kubernetes-dashboard-6495566f7b-9p5mq -n kubernetes-dashboard\n```\n\n","tags":["xxx","xx","kubectl commands"],"categories":["linux","k8s","kubectl"]},{"title":"Dashboard UI","url":"//linux/k8s/dashboard/","content":"\n### install \n\n\n\nhttps://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\n\n<details>\n  <summary>dashboard</summary>\n  <pre><a>kubectl apply -f recommended.yaml</a><code>\n# Copyright 2017 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n</br>\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: kubernetes-dashboard\n</br>\n---\n</br>\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\n</br>\n---\n</br>\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 443\n      targetPort: 8443\n  selector:\n    k8s-app: kubernetes-dashboard\n</br>\n---\n</br>\napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard-certs\n  namespace: kubernetes-dashboard\ntype: Opaque\n</br>\n---\n</br>\napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard-csrf\n  namespace: kubernetes-dashboard\ntype: Opaque\ndata:\n  csrf: \"\"\n</br>\n---\n</br>\napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard-key-holder\n  namespace: kubernetes-dashboard\ntype: Opaque\n</br>\n---\n</br>\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard-settings\n  namespace: kubernetes-dashboard\n</br>\n---\n</br>\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nrules:\n  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.\n  - apiGroups: [\"\"]\n    resources: [\"secrets\"]\n    resourceNames: [\"kubernetes-dashboard-key-holder\", \"kubernetes-dashboard-certs\", \"kubernetes-dashboard-csrf\"]\n    verbs: [\"get\", \"update\", \"delete\"]\n    # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map.\n  - apiGroups: [\"\"]\n    resources: [\"configmaps\"]\n    resourceNames: [\"kubernetes-dashboard-settings\"]\n    verbs: [\"get\", \"update\"]\n    # Allow Dashboard to get metrics.\n  - apiGroups: [\"\"]\n    resources: [\"services\"]\n    resourceNames: [\"heapster\", \"dashboard-metrics-scraper\"]\n    verbs: [\"proxy\"]\n  - apiGroups: [\"\"]\n    resources: [\"services/proxy\"]\n    resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\", \"dashboard-metrics-scraper\", \"http:dashboard-metrics-scraper\"]\n    verbs: [\"get\"]\n</br>\n---\n</br>\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\nrules:\n  # Allow Metrics Scraper to get metrics from the Metrics server\n  - apiGroups: [\"metrics.k8s.io\"]\n    resources: [\"pods\", \"nodes\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</br>\n---\n</br>\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: kubernetes-dashboard\nsubjects:\n  - kind: ServiceAccount\n    name: kubernetes-dashboard\n    namespace: kubernetes-dashboard\n</br>\n---\n</br>\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: kubernetes-dashboard\nsubjects:\n  - kind: ServiceAccount\n    name: kubernetes-dashboard\n    namespace: kubernetes-dashboard\n</br>\n---\n</br>\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      securityContext:\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n        - name: kubernetes-dashboard\n          image: kubernetesui/dashboard:v2.7.0\n          imagePullPolicy: Always\n          ports:\n            - containerPort: 8443\n              protocol: TCP\n          args:\n            - --auto-generate-certificates\n            - --namespace=kubernetes-dashboard\n            # Uncomment the following line to manually specify Kubernetes API server Host\n            # If not specified, Dashboard will attempt to auto discover the API server and connect\n            # to it. Uncomment only if the default does not work.\n            # - --apiserver-host=http://my-address:port\n          volumeMounts:\n            - name: kubernetes-dashboard-certs\n              mountPath: /certs\n              # Create on-disk volume to store exec logs\n            - mountPath: /tmp\n              name: tmp-volume\n          livenessProbe:\n            httpGet:\n              scheme: HTTPS\n              path: /\n              port: 8443\n            initialDelaySeconds: 30\n            timeoutSeconds: 30\n          securityContext:\n            allowPrivilegeEscalation: false\n            readOnlyRootFilesystem: true\n            runAsUser: 1001\n            runAsGroup: 2001\n      volumes:\n        - name: kubernetes-dashboard-certs\n          secret:\n            secretName: kubernetes-dashboard-certs\n        - name: tmp-volume\n          emptyDir: {}\n      serviceAccountName: kubernetes-dashboard\n      nodeSelector:\n        \"kubernetes.io/os\": linux\n      # Comment the following tolerations if Dashboard must not be deployed on master\n      tolerations:\n        - key: node-role.kubernetes.io/master\n          effect: NoSchedule\n</br>\n---\n</br>\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: dashboard-metrics-scraper\n  name: dashboard-metrics-scraper\n  namespace: kubernetes-dashboard\nspec:\n  ports:\n    - port: 8000\n      targetPort: 8000\n  selector:\n    k8s-app: dashboard-metrics-scraper\n</br>\n---\n</br>\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  labels:\n    k8s-app: dashboard-metrics-scraper\n  name: dashboard-metrics-scraper\n  namespace: kubernetes-dashboard\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: dashboard-metrics-scraper\n  template:\n    metadata:\n      labels:\n        k8s-app: dashboard-metrics-scraper\n    spec:\n      securityContext:\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n        - name: dashboard-metrics-scraper\n          image: kubernetesui/metrics-scraper:v1.0.8\n          ports:\n            - containerPort: 8000\n              protocol: TCP\n          livenessProbe:\n            httpGet:\n              scheme: HTTP\n              path: /\n              port: 8000\n            initialDelaySeconds: 30\n            timeoutSeconds: 30\n          volumeMounts:\n          - mountPath: /tmp\n            name: tmp-volume\n          securityContext:\n            allowPrivilegeEscalation: false\n            readOnlyRootFilesystem: true\n            runAsUser: 1001\n            runAsGroup: 2001\n      serviceAccountName: kubernetes-dashboard\n      nodeSelector:\n        \"kubernetes.io/os\": linux\n      # Comment the following tolerations if Dashboard must not be deployed on master\n      tolerations:\n        - key: node-role.kubernetes.io/master\n          effect: NoSchedule\n      volumes:\n        - name: tmp-volume\n          emptyDir: {}  </code></pre>\n</details>\n\n\n\n```\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\n```\n\n>❯ grep \"image: kubernetesui\" ./recommended.yaml\n>    image: kubernetesui/dashboard:v2.7.0\n>    image: kubernetesui/metrics-scraper:v1.0.8\n\n<!--more-->\n\n\n\n### long-lived Bearer Token for ServiceAccount\n\n[create doc](https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md)\n\n\n\n<details>\n  <summary>访问</summary>\n  <pre><a>kubectl apply -f admin.yaml</a><code>\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kubernetes-dashboard\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kubernetes-dashboard\n---  \napiVersion: v1\nkind: Secret\nmetadata:\n  name: admin-user\n  namespace: kubernetes-dashboard\n  annotations:\n    kubernetes.io/service-account.name: \"admin-user\"   \ntype: kubernetes.io/service-account-token  </code></pre>\n</details>\n\n获取\n\n```\nkubectl get secret admin-user -n kubernetes-dashboard -o jsonpath={\".data.token\"} | base64 -d\n```\n\n\n\n\n\n","tags":["dashboard","ui","Kubeconfig"],"categories":["linux","k8s","dashboard"]},{"title":"k8s mysql cluster","url":"//linux/k8s/mysql/","content":"\n## install\n\n\n\n\n\n```\n─❯ helm install -f ./mysql-operator/values.yaml -name mysql-operator --namespace mysql-operator  --create-namespace  ./mysql-operator\n\n\n\n❯ helm install mycluster ./mysql-innodbcluster \\\n        --namespace mysql-operator \\\n        --set tls.useSelfSigned=true \\\n        --set credentials.root.user='root' \\\n        --set credentials.root.password='cs@123456' \\\n        --set credentials.root.host='%' \\\n        --set serverInstances=3 \\\n        --set routerInstances=1\n\n\n\n❯ helm uninstall  -name mycluster --namespace mysql-operator\nrelease \"mycluster\" uninstalled\n❯ helm uninstall  -name mysql-operator --namespace mysql-operator\nrelease \"mysql-operator\" uninstalled\n\n```\n\n>❯ kubectl logs mysql-operator-9d99d7fb4-slm2p  -n mysql-operator\n>2023-08-31 10:45:24: Info: mysqlsh   Ver 8.1.0 for Linux on x86_64 - for MySQL 8.1.0 (MySQL Community Server (GPL)) - build 11806291 - commit_id aa072a78647c21a540e40b8bdd04420e6efbe677\n>2023-08-31 10:45:24: Info: Using credential store helper: /usr/bin/mysql-secret-store-login-path\n>2023-08-31 10:45:24: Info: Loading startup files...\n>2023-08-31 10:45:24: Info: Loading plugins...\n>[2023-08-31 10:45:26,726] root                 [WARNING ] Failed to detect cluster domain. Reason: [Errno 2] Host name lookup failure\n>....\n>[2023-08-31 10:45:54,977] root                 [WARNING ] Failed to detect cluster domain. Reason: [Errno 2] Host name lookup failure\n>[2023-08-31 10:45:56,979] root                 [ERROR   ] Failed to automatically identify the cluster domain. If this\n>  persists try setting MYSQL_OPERATOR_K8S_CLUSTER_DOMAIN via environment.\n\n\n\n\n\n<!--more-->\n\n\n\n## radondb-mysql-kubernetes\n\n\n\n```\n❯ helm repo add radondb https://radondb.github.io/radondb-mysql-kubernetes/\n\"radondb\" has been added to your repositories\n❯ helm pull radondb/mysql-operator  --untar\n```\n\n\n\n>Error: INSTALLATION FAILED: unable to build kubernetes objects from release manifest: [resource mapping not found for name: \"radondb-mysql-certificate\" namespace: \"default\" from \"\": no matches for kind \"Certificate\" in version \"cert-manager.io/v1\"\n>ensure CRDs are installed first, resource mapping not found for name: \"radondb-mysql-issuer\" namespace: \"default\" from \"\": no matches for kind \"Issuer\" in version \"cert-manager.io/v1\"\n>ensure CRDs are installed first]\n\n\n\n\n\n\n\n\n\n\n\n","tags":["k8s","mysql","cluster"],"categories":["linux","k8s","mysql"]},{"title":"gogoprotobuf grpc","url":"//tool/codetool/protobuf/","content":"\n## 安装转换\n\n\n\n```\n❯ sudo apt-get install gogoprotobuf\n```\n\n>❯ protoc --version\n>libprotoc 3.12.4\n\n\n\nhttps://www.codenong.com/57700860/\n\n\n\n\n\ngo get -u github.com/golang/protobuf/{proto,protoc-gen-go,protoc-gen-go-grpc}\n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n","tags":["xxx","gogoprotobuf","grpc"],"categories":["tool","codetool","protobuf"]},{"title":"kafka介绍","url":"//services/kafka/kafka/","content":"\n###  基础架构\n\n\n\n![](/pics/kafka-all-001.png)\n\n**producer**  生产者，消息产生\n\n**broker**  实例对应服务器的节点，每个cluster集群内的broker都有不重复的编号\n\n**topic**  消息主题，分类\n\n**partition** topic的分区，用作*负载*，提高吞吐量，对应的是一个个文件\n\n**replication** 分区副本，作用是*备份*，主leader故障，follower进行选主，副本数不大于broker数，主备不在同一个机器，同一机器对同一分区也只放一个副本\n\n<!--more-->\n\n**message**  消息的主体\n\n**consumer** 消费者\n\n**consumer group** 消费者组  同一个分区只能被某一组消费者消费\n\n\n\n### 主题 分区 集群\n\n\n\n增加分区partition，提高消费效率\n\n![](/pics/kafka-pc-001.png)\n\n\n\n多实例broker,在但节点故障时增加容错率\n\n![](/pics/kafka-pc-002.png)\n\n\n\n**retention** 消息的保留机制 \n\n- log.retention.hours\n- log.retention.minutes\n- log.retention.ms     优先级最高\n\n```stylus\ngrep -i 'log.retention.[hms].*\\=' config/server.properties\nlog.retention.hours=72\n```\n\n\n\n\n\n### 效率\n\n磁盘顺序读写\n\n","tags":["partition","kafka","topic"],"categories":["services","mq"]},{"title":"Crossplane控制面板","url":"//linux/k8s/Crossplane/","content":"\n\n\n###  Install Crossplane\n\nhttps://docs.crossplane.io/latest/software/install/\n\n\n\n#### Prerequisites \n\n- An actively [supported Kubernetes version](https://kubernetes.io/releases/patch-releases/#support-period)\n- [Helm](https://helm.sh/docs/intro/install/) version `v3.2.0` or later\n\n\n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n","tags":["xxx","Crossplane","control-planes"],"categories":["linux","k8s"]},{"title":"grafana 安装配置","url":"//services/monitor/grafana/","content":"\n## Dependencies\n\nMake sure you have the following dependencies installed before setting up your developer environment:\n\n- [Git](https://git-scm.com/)\n- [Go](https://golang.org/dl/) (see [go.mod](https://github.com/grafana/grafana/blob/dfc7a98d87c93860545033c9a37d81352c2caf70/go.mod#L3) for minimum required version)\n- [Node.js (Long Term Support)](https://nodejs.org/)\n- [Yarn](https://yarnpkg.com/)\n\n\n\nhttps://github.com/grafana/grafana/blob/dfc7a98d87c93860545033c9a37d81352c2caf70/contribute/developer-guide.md\n\n<!--more-->\n\n\n\n```\n❯ npm config get registry\nhttps://registry.npm.taobao.org/\n```\n\n\n\n```\nyarn install --immutable\n\nyarn start\n```\n\n...\n\n\n\n## 安装\n\n下载二进制包 https://grafana.com/grafana/download/9.5.3?edition=oss\n\n\n\n```\n❯ tree ./grafana-9.5.3 -L 1\n ./grafana-9.5.3\n├──  bin\n├──  conf\n├──  LICENSE\n├──  NOTICE.md\n├──  plugins-bundled\n├──  public\n├──  README.md\n└──  VERSION\n```\n\n\n\n### configure\n\nhttps://grafana.com/docs/grafana/latest/setup-grafana/configure-grafana/\n\n\n\n\n\n### plugins\n\n\n\n#### zabbix\n\nhttps://grafana.com/grafana/plugins/alexanderzobnin-zabbix-app/\n\n\n\nsqlite3替换成\n\n```\ncreate database grafana;\ncreate user grafana@'%' identified by 'grafana@123';\ngrant all on grafana.* to grafana@'%';\nflush privileges;\n```\n\n>type = mysql\n>host = 127.0.0.1:3305\n>name = grafana\n>user = grafana\n>password = grafana@123\n\n\n\nAdministration->Default preferences->Preferences(Language)->中文\n\n\n\n\n\nhttps://grafana.com/docs/grafana/latest/cli/#plugins-commands\n\n```\n./grafana-cli --pluginsDir \"/opt/monitor/grafana/plugins\" plugins install alexanderzobnin-zabbix-app\n```\n\n\n\n\n\n","tags":["zabbix","grafana","prometheus"],"categories":["services","monitor"]},{"title":"zabbix 安装配置","url":"//services/monitor/zabbix-sources/","content":"\n## zabbix \n\nhttps://www.zabbix.com/download_sources\n\n\n\n### 编译\n\n Documentation: [Zabbix 6.4 Installation from sources](https://www.zabbix.com/documentation/6.4/manual/installation/install)\n\n\n\n```\n❯ sudo addgroup --system --quiet zabbix\n\n❯ sudo adduser --quiet --system --disabled-login --ingroup zabbix --home /var/lib/zabbix --no-create-home zabbix\n\n\n./configure  --prefix=/opt/zabbix  --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2 --with-openipmi\n```\n\n> Running `make install` will by default install the daemon binaries (zabbix_server, zabbix_agentd, zabbix_proxy) in /usr/local/sbin and the client binaries (zabbix_get, zabbix_sender) in /usr/local/bin.\n\n#### 缺依赖\n\nhttps://packages.debian.org/search?searchon=contents&keywords=libssl.so\n\n<!--more-->\n\n<details>\n  <summary>依赖库文件</summary>\n  <pre><a>各种报错缺依赖情况</a><code>\nconfigure: error: Unable to use libevent (libevent check failed)\nconfigure: error: Curl library not found\n</br>\ncs@debian:apt-get install -y libevent-dev\ncs@debian:apt install -y libghc-curl-dev\n</br>\n</br>\nNo package 'libxml-2.0' found\nchecking for xmlReadMemory in -lxml2... no\nconfigure: error: Not found libxml2 library\ncs@debian: apt-get install -y libxml2-dev\n</br>\nchecking for net-snmp-config... no\nconfigure: error: Invalid Net-SNMP directory - unable to find net-snmp-config\ncs@debian:sudo apt install libsnmp-dev\n</br>\nchecking for OPENIPMI support... no\nconfigure: error: Invalid OPENIPMI directory - unable to find ipmiif.h\ncs@debian: sudo apt install libopenipmi-dev\n</br>\nchecking for libevent support... no\nconfigure: error: Unable to use libevent (libevent check failed)\ncs@debian: sudo apt install libevent-dev\n</br>\nchecking for curl-config... no\nconfigure: error: Curl library not found\ncs@debian: sudo apt install  libcurl4-openssl-dev=7.88.1-7~bpo11+2\n</br>\n</br>\nchecking pkg-config is at least version 0.9.0... yes\nconfigure: error: cannot find pkg-config package for libpcre\ncs@debian: sudo apt-get install libpcre3-dev  #other os >pcre-devel\n</br>\n</br>\nmake  ###报错\n/usr/bin/ld: warning: libcrypto.so.1.0.2, needed by /usr/lib/x86_64-linux-gnu/libnetsnmp.so, may conflict with libcrypto.so.1.1\n/usr/bin/ld: warning: libssl.so.1.0.2, needed by /usr/lib/x86_64-linux-gnu/libcurl.so, may conflict with libssl.so.1.1\n/usr/local/mysql/lib/libmysqlclient.so: undefined reference to `SSL_CTX_set_ciphersuites@OPENSSL_1_1_1'\n/usr/local/mysql/lib/libmysqlclient.so: undefined reference to `BIO_set_callback_ex@OPENSSL_1_1_1'\ncollect2: error: ld returned 1 exit status\n</br>\n## ldconfig -p | grep  libcrypto  或 locate xxx\ncs@debian:/opt/zabbix-6.0.2$ locate libcrypto.so\n/opt/kingsoft/wps-office/office6/libcrypto.so\n/opt/kingsoft/wps-office/office6/libcrypto.so.1.1\n/opt/mysql/lib/private/libcrypto.so\n/opt/mysql/lib/private/libcrypto.so.1.1\n/opt/vagrant/embedded/lib64/libcrypto.so\n/opt/vagrant/embedded/lib64/libcrypto.so.1.1\n/usr/lib/x86_64-linux-gnu/libcrypto.so\n/usr/lib/x86_64-linux-gnu/libcrypto.so.1.0.2\n/usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\ncs@debian:/opt/zabbix-6.0.2$ locate libssl.so\n/opt/kingsoft/wps-office/office6/libssl.so\n/opt/kingsoft/wps-office/office6/libssl.so.1.1\n/opt/mysql/lib/private/libssl.so\n/opt/mysql/lib/private/libssl.so.1.1\n/opt/vagrant/embedded/lib64/libssl.so\n/opt/vagrant/embedded/lib64/libssl.so.1.1\n/usr/lib/x86_64-linux-gnu/libssl.so\n/usr/lib/x86_64-linux-gnu/libssl.so.1.0.2\n/usr/lib/x86_64-linux-gnu/libssl.so.1.1\n</br>\ncs@debian:/opt/zabbix-6.0.2$ locate libmysqlclient.so\n/opt/mysql/lib/libmysqlclient.so\n/opt/mysql/lib/libmysqlclient.so.21\n/opt/mysql/lib/libmysqlclient.so.21.1.21\n</br>\n</br>\n</br>\n#找到动态链接库的路径\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\n#找到静态库的路径\nexport LIBRARY_PATH=$LIBRARY_PATH:/usr/local/lib\n</br>\n</br>\ncs@debian:/opt/zabbix-6.0.2$ make \nmake[1]: Leaving directory '/opt/zabbix-6.0.2'\ncs@debian:/opt/zabbix-6.0.2$ make install\nmake[1]: Leaving directory '/opt/zabbix-6.0.2\n编译成功  </code></pre>\n</details>\n\n\n\n\n```\n./configure  --prefix=/opt/zabbix   --enable-proxy  --with-mysql    --enable-agent2\n```\n\n> No database selected for Zabbix server/proxy. Use --with-mysql or --with-oracle or --with-postgresql or --with-sqlite3.\n\n\n\n\n\n\n\n### sql\n\n Must be at least (8.00.30) [mysql](/services/database/mysql/install/#install-mysql)\n\nhttps://www.zabbix.com/documentation/6.4/en/manual/appendix/install/db_scripts\n\nmysql -uroot -p<password>      \n```\nmysql> create database zabbix character set utf8mb4 collate utf8mb4_bin;\nmysql> create user 'zabbix'@'localhost' identified by 'zabbix';\nmysql> grant all privileges on zabbix.* to 'zabbix'@'localhost';\nmysql> SET GLOBAL log_bin_trust_function_creators = 1;\nmysql> quit;\n```\n\n>❯ mysql -uzabbix  -p -P3305  zabbix <schema.sql\n>Enter password: \n>\n>\\#proxy节点的数据库无需倒入下面的。\n>\n>❯ mysql -uzabbix  -P3305 -p  zabbix <images.sql\n>Enter password: \n>❯ mysql -uzabbix  -P3305 -p  --default-character-set=utf8mb4 zabbix <data.sql\n>Enter password: \n\n\n\n`log_bin_trust_function_creators` 当二进制日志启用后，这个变量就会启用。它控制是否可以信任存储函数创建者，不会创建写入二进制日志引起不安全事件的存储函数。如果设置为`0（默认值）`，用户不得创建或修改存储函数，除非它们具有除CREATE ROUTINE或ALTER ROUTINE特权之外的SUPER权限。 设置为0还强制使用DETERMINISTIC特性或READS SQL DATA或NO SQL特性声明函数的限制。 如果变量设置为`1`，MySQL不会对创建存储函数实施这些限制。 \n\n```\nmysql -uroot -p<password>\n       \nmysql> SET GLOBAL log_bin_trust_function_creators = 0;\nmysql> quit;\n```\n\n\n\n如果Zabbix server和proxy安装在同一个主机上，那么它们的数据库必须用不同的名称创建！\n\n```\nMySQL root@localhost:none>  create database zabbix_proxy character set utf8mb4 collate utf8mb4_bin;\nMySQL root@localhost:none>   grant all privileges on zabbix_proxy.* to 'zabbix'@'localhost';\n\n\n```\n\n>\\# For a Zabbix proxy database, only `schema.sql` should be imported (no images.sql nor data.sql).\n>\n>❯ mysql -uzabbix  -p -P3305  zabbix_proxy <schema.sql\n>Enter password: \n\n\n\n### agent\n\n[本地包方式](/linux/debian/apt#yum-local)\n\n```\nrpm -Uvh https://repo.zabbix.com/zabbix/6.4/rhel/7/x86_64/zabbix-release-6.4-1.el7.noarch.rpm\nyum install zabbix-agent\n```\n\n\n\n```\n# sed '/^#/d;/^$/d' /etc/zabbix/zabbix_agentd.conf \nPidFile=/run/zabbix/zabbix_agentd.pid\nLogFile=/var/log/zabbix/zabbix_agentd.log\nLogFileSize=0\nServer=127.0.0.1\nServerActive=127.0.0.1\nHostname=Zabbix server\nInclude=/etc/zabbix/zabbix_agentd.d/*.conf\n\n```\n\nhttps://blog.csdn.net/weixin_45880055/article/details/115330224\n\n\n\nagent\n\n no active checks on server [192.168.122.1:10051]: host [test] not found\n\n**在zabbix web页面Monitoring->Configuration->Hosts 页面更改Host name和zabbix_agentd.conf里面的Hostname一样**\n\n```\n[root@test ~]# ss -antl | grep 10050\nLISTEN     0      128          *:10050                    *:*                  \nLISTEN     0      128         :::10050                   :::*   \n```\n\n\n\n\n\nserver\n\ncannot send list of active checks to \"192.168.122.8\": host [test] not found\n\n\n\n```\n❯ netstat -tanlp | grep -I  10051\n(Not all processes could be identified, non-owned process info\n will not be shown, you would have to be root to see it all.)\ntcp        0      0 0.0.0.0:10051           0.0.0.0:*               LISTEN      4070/zabbix_server  \n\n```\n\n\n\nReceived empty response from Zabbix Agent at [127.0.0.1]. Assuming that agent dropped connection because of access permissions.\n\n\n\n\n\n## ui\n\n\n\n### php\n\nhttps://www.php.net/manual/zh/install.unix.debian.php\n\n#### 编译\n\n```\n./configure --prefix=/opt/php/php8.2.6 \\\n    --with-config-file-path=/opt/php/php8.2.6/etc \\\n    --enable-mysqlnd \\\n    --with-pdo-mysql \\\n    --with-pdo-mysql=mysqlnd \\\n    -with-mysqli  \\\n    --enable-bcmath \\\n    --enable-fpm \\\n    --with-fpm-user=www-data \\\n    --with-fpm-group=www-data \\\n    --enable-mbstring \\\n    --enable-phpdbg \\\n    --enable-shmop \\\n    --enable-sockets \\\n    --enable-sysvmsg \\\n    --enable-sysvsem \\\n    --enable-sysvshm \\\n     --enable-gd   \\\n    --with-ldap  \\\n    --with-jpeg  \\\n    --with-freetype  \\\n    -with-gettext \\\n    --with-zlib \\\n    --with-curl \\\n    --with-pear \\\n    --with-openssl \\\n    --enable-pcntl \\\n    --with-readline\n   \n```\n\n>+--------------------------------------------------------------------+\n>| License:                                                           |\n>| This software is subject to the PHP License, available in this     |\n>| distribution in the file LICENSE. By continuing this installation  |\n>| process, you are bound by the terms of this license agreement.     |\n>| If you do not agree with the terms of this license, you must abort |\n>| the installation process at this point.                            |\n>+--------------------------------------------------------------------+\n>\n>Thank you for using PHP.\n\n\n\n\n<details>\n  <summary>php编译</summary>\n  <pre><a>configure依赖</a><code>\nhttps://packages.debian.org/search?suite=default&section=all&arch=any&searchon=contents&keywords=ldap.h\n=====sqlite3\nNo package 'sqlite3' found\n</br>\nConsider adjusting the PKG_CONFIG_PATH environment variable if you\ninstalled software in a non-standard prefix.\n</br>\nAlternatively, you may set the environment variables SQLITE_CFLAGS\nand SQLITE_LIBS to avoid the need to call pkg-config.\nSee the pkg-config man page for more details.\n######安装sqlite3,依旧提示找不到包 ,pkg-config列表会没有,必须安装libsqlite3-dev\n</br>\nsudo apt-get install sqlite3 libsqlite3-dev\n</br>\nyum -y install sqlite-devel\n</br>\n</br>\n=====ldap\nchecking if we're at 64-bit platform... yes\nconfigure: error: Cannot find ldap.h\n</br>\ndebian\nsudo apt install libldap-dev\n</br>\n</br>\ncentos\nyum  -y install openldap openldap-devel\n</br>\n=====gb\nNo package 'libpng' found\nNo package 'freetype2' found\n</br>\n sudo apt install libjpeg-dev  libpng-dev  libfreetype-dev\n</br>\n=====oniguruma\nNo package 'oniguruma' found\n</br>\nsudo apt install libonig-dev\n</br>\n=====readline.h\n  iconfigure: error: Please reinstall readline - I cannot find readline.h\nsudo apt-get install libreadline-dev\n</br>\n=====zip\nconfigure: WARNING: unrecognized options: --enable-zip, --with-libzip\nsudo apt-get install  libzip-dev libzip4 \n=====libreadline.so.7\nerror while loading shared libraries: libreadline.so.7: cannot open shared \n</br>\nsudo ln -s /lib/x86_64-linux-gnu/libreadline.so.8.1  /lib/x86_64-linux-gnu/libreadline.so.7\n</br>\n$ pkg-config --list-all | grep oniguruma\noniguruma     oniguruma - Regular expression library\n</code></pre>\n</details>\n[php.ini development,*php.ini-production*](https://github.com/php/php-src/blob/master/php.ini-production)\n\n#### 配置\n\n```\n❯ cp php.ini-production $PHP_HOME/etc/php.ini\n❯ cp php-fpm.conf.default php-fpm.conf\n❯ sed -i '/^;/d;/^$/d' php.ini\n❯ cd  ./php-fpm.d && cp www.conf.default www.conf\n```\n\n#### 启动\n\n```\n./sbin/php-fpm\n```\n\n>Starting............ [04-Jun-2023 18:03:24] NOTICE: [pool www] 'user' directive is ignored when FPM is not running as root\n>[04-Jun-2023 18:03:24] NOTICE: [pool www] 'group' directive is ignored when FPM is not running as root\n\n#### 检查端口\n\n```\nlsof -i tcp:9000\n```\n\n>COMMAND   PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n>php-fpm 10006     root    7u  IPv4 288286      0t0  TCP localhost:9000 (LISTEN)\n>php-fpm 10007 www-data    5u  IPv4 288286      0t0  TCP localhost:9000 (LISTEN)\n>php-fpm 10008 www-data    5u  IPv4 288286      0t0  TCP localhost:9000 (LISTEN)\n\n\n\n#### nginx\n\n`include   conf.d/http/*.conf;`\n\n<details>\n  <summary>zabbix.conf</summary>\n  <pre><a>zabbix.conf</a><code>\nupstream zabbix{\n     server 127.0.0.1:9000;\n }\n</br> \nlog_format  zabbix  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n</br> \nserver {\n       listen       8081;\n       server_name  localhost;\n</br> \n        index index.php index.html index.html;\n        root /opt/zabbix/ui;\n        access_log  logs/zabbix.log  zabbix;\n</br> \n       location /zabbix {\n                try_files $uri $uri/ /index.php?$args;\n        }\n </br>        \n        location ~ .*\\.(php)?$ {\n                expires -1s;\n                try_files $uri =404;\n                fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n                include fastcgi_params;\n                fastcgi_param PATH_INFO $fastcgi_path_info;\n                fastcgi_index index.php;\n                fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n                fastcgi_pass zabbix;\n                include fastcgi.conf;\n        }\n}\n  </code></pre>\n</details>\n\n\nzabbix前端已经安装完成！超级用户名是Admin，密码是zabbix\n\n","tags":["xxx","xx","zabbix 安装配置"],"categories":["services","monitor","zabbix-sources"]},{"title":"MySQL AutoCompletion","url":"//linux/tool/mycli/","content":"\n## mycli\n\n### Quick Start\n\n\n\nhttp://mycli.net/docs\n\nYou might need sudo on linux.\n\n```\n$ pip install -U mycli\n```\n\nor\n\n```\n$ brew update && brew install mycli  # Only on macOS\n```\n\nor\n\n```\n$ sudo apt-get install mycli # Only on debian or ubuntu\n```\n\n<!--more-->\n\n\n\n### 配置\n\nuser settings are configured via the file located at `~/.myclirc`, which is a hidden file in your home folder in Linux and macOS. On Windows it is located at `C:\\Users\\<username>\\.myclirc`.\n\n<details>\n  <summary>~/.myclirc</summary>\n  <pre><a>myclirc</a><code>\n# vi: ft=dosini\n[main]\n</br>\n# Enables context sensitive auto-completion. If this is disabled the all\n# possible completions will be listed.\nsmart_completion = True\n</br>\n# Multi-line mode allows breaking up the sql statements into multiple lines. If\n# this is set to True, then the end of the statements must have a semi-colon.\n# If this is set to False then sql statements can't be split into multiple\n# lines. End of line (return) is considered as the end of the statement.\nmulti_line = False\n</br>\n# Destructive warning mode will alert you before executing a sql statement\n# that may cause harm to the database such as \"drop table\", \"drop database\"\n# or \"shutdown\".\ndestructive_warning = True\n</br>\n# log_file location.\nlog_file = ~/.mycli/mycli.log\n</br>\n# Default log level. Possible values: \"CRITICAL\", \"ERROR\", \"WARNING\", \"INFO\"\n# and \"DEBUG\". \"NONE\" disables logging.\nlog_level = INFO\n</br>\n# Log every query and its results to a file. Enable this by uncommenting the\n# line below.\naudit_log = ~/.mycli/mycli-audit.log\n</br>\n# Timing of sql statements and table rendering.\ntiming = True\n</br>\n# Beep after long-running queries are completed; 0 to disable.\nbeep_after_seconds = 0\n</br>\n# Table format. Possible values: ascii, double, github,\n# psql, plain, simple, grid, fancy_grid, pipe, orgtbl, rst, mediawiki, html,\n# latex, latex_booktabs, textile, moinmoin, jira, vertical, tsv, csv.\n# Recommended: ascii\ntable_format = ascii\n</br>\n# Syntax coloring style. Possible values (many support the \"-dark\" suffix):\n# manni, igor, xcode, vim, autumn, vs, rrt, native, perldoc, borland, tango, emacs,\n# friendly, monokai, paraiso, colorful, murphy, bw, pastie, paraiso, trac, default,\n# fruity.\n# Screenshots at http://mycli.net/syntax\n# Can be further modified in [colors]\nsyntax_style = perldoc\n</br>\n# Keybindings: Possible values: emacs, vi.\n# Emacs mode: Ctrl-A is home, Ctrl-E is end. All emacs keybindings are available in the REPL.\n# When Vi mode is enabled you can use modal editing features offered by Vi in the REPL.\nkey_bindings = vi\n</br>\n# Enabling this option will show the suggestions in a wider menu. Thus more items are suggested.\nwider_completion_menu = False\n</br>\n# MySQL prompt\n# \\D - The full current date\n# \\d - Database name\n# \\h - Hostname of the server\n# \\m - Minutes of the current time\n# \\n - Newline\n# \\P - AM/PM\n# \\p - Port\n# \\R - The current time, in 24-hour military time (0-23)\n# \\r - The current time, standard 12-hour time (1-12)\n# \\s - Seconds of the current time\n# \\t - Product type (Percona, MySQL, MariaDB, TiDB)\n# \\A - DSN alias name (from the [alias_dsn] section)\n# \\u - Username\n# \\x1b[...m - insert ANSI escape sequence\nprompt = '\\t \\u@\\h:\\d> '\nprompt_continuation = '->'\n</br>\n# Skip intro info on startup and outro info on exit\nless_chatty = False\n</br>\n# Use alias from --login-path instead of host name in prompt\nlogin_path_as_host = False\n</br>\n# Cause result sets to be displayed vertically if they are too wide for the current window,\n# and using normal tabular format otherwise. (This applies to statements terminated by ; or \\G.)\nauto_vertical_output = False\n</br>\n# keyword casing preference. Possible values \"lower\", \"upper\", \"auto\"\nkeyword_casing = auto\n</br>\n# disabled pager on startup\nenable_pager = True\n</br>\n# Choose a specific pager\npager = 'less'\n</br>\n# Custom colors for the completion menu, toolbar, etc.\n[colors]\ncompletion-menu.completion.current = 'bg:#ffffff #000000'\ncompletion-menu.completion = 'bg:#008888 #ffffff'\ncompletion-menu.meta.completion.current = 'bg:#44aaaa #000000'\ncompletion-menu.meta.completion = 'bg:#448888 #ffffff'\ncompletion-menu.multi-column-meta = 'bg:#aaffff #000000'\nscrollbar.arrow = 'bg:#003333'\nscrollbar = 'bg:#00aaaa'\nselected = '#ffffff bg:#6666aa'\nsearch = '#ffffff bg:#4444aa'\nsearch.current = '#ffffff bg:#44aa44'\nbottom-toolbar = 'bg:#222222 #aaaaaa'\nbottom-toolbar.off = 'bg:#222222 #888888'\nbottom-toolbar.on = 'bg:#222222 #ffffff'\nsearch-toolbar = 'noinherit bold'\nsearch-toolbar.text = 'nobold'\nsystem-toolbar = 'noinherit bold'\narg-toolbar = 'noinherit bold'\narg-toolbar.text = 'nobold'\nbottom-toolbar.transaction.valid = 'bg:#222222 #00ff5f bold'\nbottom-toolbar.transaction.failed = 'bg:#222222 #ff005f bold'\n</br>\n# style classes for colored table output\noutput.header = \"#00ff5f bold\"\noutput.odd-row = \"\"\noutput.even-row = \"\"\noutput.null = \"#808080\"\n</br>\n# SQL syntax highlighting overrides\n# sql.comment = 'italic #408080'\n# sql.comment.multi-line = ''\n# sql.comment.single-line = ''\n# sql.comment.optimizer-hint = ''\n# sql.escape = 'border:#FF0000'\n# sql.keyword = 'bold #008000'\n# sql.datatype = 'nobold #B00040'\n# sql.literal = ''\n# sql.literal.date = ''\n# sql.symbol = ''\n# sql.quoted-schema-object = ''\n# sql.quoted-schema-object.escape = ''\n# sql.constant = '#880000'\n# sql.function = '#0000FF'\n# sql.variable = '#19177C'\n# sql.number = '#666666'\n# sql.number.binary = ''\n# sql.number.float = ''\n# sql.number.hex = ''\n# sql.number.integer = ''\n# sql.operator = '#666666'\n# sql.punctuation = ''\n# sql.string = '#BA2121'\n# sql.string.double-quouted = ''\n# sql.string.escape = 'bold #BB6622'\n# sql.string.single-quoted = ''\n# sql.whitespace = ''\n</br>\n# Favorite queries.\n[favorite_queries]\n</br>\n# Use the -d option to reference a DSN.\n# Special characters in passwords and other strings can be escaped with URL encoding.\n[alias_dsn]\n# example_dsn = mysql://[user[:password]@][host][:port][/dbname]\nlocalhost = mysql://root@localhost  </code></pre>\n</details>\n\n\n\n**NOTE:** Mycli does not read the `[mysql]` section of MySQL's option files. It only reads the `[client]` section.\n\n\n\nycli also reads the `[client]` section of MySQL's option file, `~/.my.cnf` (on Windows: `C:\\Users\\<username>\\.my.cnf`)\n\n\n\n<details>\n  <summary>~/.my.cnf</summary>\n  <pre><a>client</a><code>\n[client]\n# The client section is read by mycli and all MySQL applications.\n</br>\n# Default connection information\nuser = root\npassword = 123456\nhost = localhost\ndatabase = test\nport = 3305\n</br>\n</br>\n# Use the UTF-8 character set\ndefault-character-set = utf8mb4\n</br>\n# SSL options - see the MySQL documentation for more information.\n# https://dev.mysql.com/doc/refman/5.7/en/secure-connection-options.html#option_general_ssl-ca\n# ssl-ca\n# ssl-cert\n# ssl-key\n# ssl-cipher\n# ssl-verify-server-cert\n</br>\n# Turn on the LOAD DATA INFILE statement\nlocal-infile = on\n</br>\n# Another local infile alias.\n# Use it if the previous one clashes with other MySQL tools.\nloose-local-infile = on\n</br>\n# Configure the pager\n#pager = 'vim -'\npager  =  grcat ~/.grcat  </code></pre>\n</details>\n\n\n\n\n\n![](/pics/mycli-localhost.gif)\n\n\n\n## other \n\n### MySQL Prompt (mysqlsh)\n\nhttps://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-install-linux-quick.html\n\n```\nsudo apt-get install mysql-shell\n```\n\n\n\nhttps://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-active-language.html\n","tags":["mysql","xxx","mycli"],"categories":["linux","tool"]},{"title":"psensor 监控","url":"//linux/tool/psensor/","content":"\n\n\n##安装\n\n``` prettyprint\n sudo apt-get install lm-sensors hddtemp psensor\n```\n\n  \n\n**lm_sensors 配置**\n\n<!--more-->\n\n``` prettyprint\nsudo sensors-detect\n```\n\n<details>\n  <summary>sensors-detect</summary>\n  <pre><a>sensors-detect</a><code>\n# sensors-detect revision 6209 (2014-01-14 22:51:58 +0100)\n# System: Notebook P65xHP [Not Applicable] (laptop)\nThis program will help you determine which kernel modules you need\nto load to use lm_sensors most effectively. It is generally safe\nand recommended to accept the default answers to all questions,\nunless you know what you're doing.\nSome south bridges, CPUs or memory controllers contain embedded sensors.\nDo you want to scan for them? This is totally safe. (YES/no): yes\nModule cpuid loaded successfully.\nSilicon Integrated Systems SIS5595...                       No\nVIA VT82C686 Integrated Sensors...                          No\nVIA VT8231 Integrated Sensors...                            No\nAMD K8 thermal sensors...                                   No\nAMD Family 10h thermal sensors...                           No\nAMD Family 11h thermal sensors...                           No\nAMD Family 12h and 14h thermal sensors...                   No\nAMD Family 15h thermal sensors...                           No\nAMD Family 15h power sensors...                             No\nAMD Family 16h power sensors...                             No\nIntel digital thermal sensor...                             Success!\n    (driver `coretemp')\nIntel AMB FB-DIMM thermal sensor...                         No\nVIA C7 thermal sensor...                                    No\nVIA Nano thermal sensor...                                  No\nSome Super I/O chips contain embedded sensors. We have to write to\nstandard I/O ports to probe them. This is usually safe.\nDo you want to scan for Super I/O sensors? (YES/no): yes\nProbing for Super-I/O at 0x2e/0x2f\nTrying family `National Semiconductor/ITE'...               Yes\nFound unknown chip with ID 0x8587\nProbing for Super-I/O at 0x4e/0x4f\nTrying family `National Semiconductor/ITE'...               No\nTrying family `SMSC'...                                     No\nTrying family `VIA/Winbond/Nuvoton/Fintek'...               No\nTrying family `ITE'...                                      No\nSome hardware monitoring chips are accessible through the ISA I/O ports.\nWe have to write to arbitrary I/O ports to probe them. This is usually\nsafe though. Yes, you do have ISA I/O ports even if you do not have any\nISA slots! Do you want to scan the ISA I/O ports? (YES/no): yes\nProbing for `National Semiconductor LM78' at 0x290...       No\nProbing for `National Semiconductor LM79' at 0x290...       No\nProbing for `Winbond W83781D' at 0x290...                   No\nProbing for `Winbond W83782D' at 0x290...                   No\nLastly, we can probe the I2C/SMBus adapters for connected hardware\nmonitoring devices. This is the most risky part, and while it works\nreasonably well on most systems, it has been reported to cause trouble\non some systems.\nDo you want to probe the I2C/SMBus adapters now? (YES/no): yes\nFound unknown SMBus adapter 8086:a123 at 0000:00:1f.4.\nSorry, no supported PCI bus adapters found.\nNext adapter: SMBus I801 adapter at f040 (i2c-0)\nDo you want to scan it? (YES/no/selectively): yes\nNow follows a summary of the probes I have just done.\nJust press ENTER to continue: \nDriver `coretemp':\n  * Chip `Intel digital thermal sensor' (confidence: 9)\nTo load everything that is needed, add this to /etc/modules:\n#----cut here----\n# Chip drivers\ncoretemp\n#----cut here----\nIf you have some drivers built into your kernel, the list above will\ncontain too many modules. Skip the appropriate ones!\nDo you want to add these lines automatically to /etc/modules? (yes/NO)yes\nSuccessful!\nMonitoring programs won't work until the needed modules are\nloaded. You may want to run '/etc/init.d/kmod start'\nto load them.\nUnloading cpuid... OK  </code></pre>\n</details>\n\n\n\n\n\n``` prettyprint\ncs@debian:~$ sudo /etc/init.d/kmod start\n[sudo] password for cs: \n[ ok ] Starting kmod (via systemctl): kmod.service.\n```\n\n![](/pics/psensor-1488665626.png)\n\n\n\n### hddtemp 监控硬盘  \n\n/dev/*\n\n``` prettyprint\nsudo hddtemp -d /dev/sba   #检测\n```\n\n  \n\n### speedtest  测网速\n\n```\nwget -o speedtest  https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py\nchmod +x speedtest\nsudo mv speedtest /usr/local/bin/speedtest\n```\n\nspeedtest  --h \n\n```\ncs@debian:~/tools$ speedtest\nRetrieving speedtest.net configuration...\nTesting from China Telecom (59.41.125.225)...\nRetrieving speedtest.net server list...\nSelecting best server based on ping...\nHosted by CTM Internet Services (Macau) [106.48 km]: 184.538 ms\nTesting download speed................................................................................\nDownload: 6.55 Mbit/s\nTesting upload speed....................................................................................................\nUpload: 3.32 Mbit/s\n```\n\n简单显示\n\n```\ncs@debian:~/tools$ speedtest --simple\nPing: 21.101 ms\nDownload: 11.72 Mbit/s\nUpload: 3.08 Mbit/s\n```\n\n\n\n### network\n\n\n\n```\nsudo apt-get install  network-manager-gnome\n```\n\n\n\n\n\n","tags":["xxx","psensor","hddtemp"],"categories":["linux","tool"]},{"title":"vim 配置","url":"//linux/tool/vim/","content":"\n### vim \n\n\n\n\n\n依赖  vim-runtime\n\ngui  依赖   libruby2.1 libyaml-0-2 vim-gui-common\n\n\n\n\n\n将会安装下列额外的软件包：\n\n libruby2.1 libyaml-0-2 vim-gui-common\n\n建议安装的软件包：\n\n cscope vim-doc\n\n下列【新】软件包将被安装：\n\n libruby2.1 libyaml-0-2 vim-athena vim-gui-common\n\n<!--more-->\n\n```\nsudo apt-get install  vim-gtk\nsudo apt-get -f install\n```\n\n卸载gvim\n\n\n\n```\nsudo apt-get remove  vim-gtk\nsudo apt-get autoremove\n```\n\nvimcdoc-1.5.0.tar.gz\n\n[中文下载地址] http://nchc.dl.sourceforge.net/sourceforge/vimcdoc/vimcdoc-1.5.0.tar.gz\n\n\n\n```\n cd vimcdoc-1.5.0\n sudo ./vimcdoc.sh -i\n```\n\n进入编辑 :help  就可以查看中文帮助了\n\n**java补全**\n\n下载[[javacomplete0.77.1.2.zip](http://www.vim.org/scripts/download_script.php?src_id=14914)]http://www.vim.org/scripts/script.php?script_id=1785\n\n```\nmkdir  ~/.vim/\ntar -xvzf  javacomplete*.tar.gz\nmv  autoload  ~/.vim/autoload\nmv  doc  ~/.vim/doc\n\n```\n\n进入 ~/.vim/autoload 目录，执行 javac Reflection.java 然后会在该目录内生成 Java 的字节码文件 Reflection.class\n\n把 :~/.vim/autoload 添加到CLASSPATH环境变量\n\necho $CLASSPATH 查看是否正确\n\n```\nsudo mousepad  /etc/vim/vimrc\n#添加到文件末尾\nsetlocal omnifunc=javacomplete#Complete\nautocmd FileType java set omnifunc=javacomplete#Complete\nautocmd FileType java set completefunc=javacomplete#CompleteParamsInf\n```\n\nSy 按 Ctrl+p  自动补全\n\n\n\n单词字符间隔\n\n```\n#gvim 调试字体 看效果      空格转换\n# 英\nset guifont=Nimbus\\ Mono\\ L\\ 12\n#中\nset guifontwide=幼圆:b:h13:cGB2312 \n```\n\n\n\n\n\n~/.vimrc\n\n```\n\"打开语法高亮\nsyntax on\n\"使用配色方案\ncolorscheme desert\n\"打开文件类型检测功能\nfiletype on\n\"不同文件类型采用不同缩进\nfiletype indent on\n\"允许使用插件\nfiletype plugin on\nfiletype plugin indent on\n\"关闭vi模式\nset nocp\n\"与windows共享剪贴板\nset clipboard+=unnamed\n\"取消VI兼容，VI键盘模式不易用\nset nocompatible\n\"显示行号, 或set number\nset nu\n\"历史命令保存行数 \nset history=100 \n\"当文件被外部改变时自动读取\nset autoread \n\"取消自动备份及产生swp文件\nset nobackup\nset nowb\nset noswapfile\n\"允许使用鼠标点击定位\nset mouse=a\n\"允许区域选择\nset selection=exclusive\nset selectmode=mouse,key\n\"高亮光标所在行\nset cursorline\n\"取消光标闪烁\nset novisualbell\n\"总是显示状态行\nset laststatus=2\n\"状态栏显示当前执行的命令\nset showcmd\n\"标尺功能，显示当前光标所在行列号\nset ruler\n\"设置命令行高度为3\nset cmdheight=3\n\"粘贴时保持格式\nset paste\n\"高亮显示匹配的括号\nset showmatch\n\"在搜索的时候忽略大小写\nset ignorecase\n \n\"高亮被搜索的句子\nset hlsearch\n \n\"在搜索时，输入的词句的逐字符高亮（类似firefox的搜索）\nset incsearch\n\"继承前一行的缩进方式，特别适用于多行注释\nset autoindent\n\"为C程序提供自动缩进\nset smartindent\n\"使用C样式的缩进\nset cindent\n\"制表符为4\nset tabstop=4\n\"统一缩进为4\nset softtabstop=4\nset shiftwidth=4\n\"允许使用退格键，或set backspace=2\nset backspace=eol,start,indent\nset whichwrap+=<,>,h,l\n\"取消换行\nset nowrap\n\"启动的时候不显示那个援助索马里儿童的提示\nset shortmess=atI\n\"在被分割的窗口间显示空白，便于阅读\nset fillchars=vert:\\ ,stl:\\ ,stlnc:\\\n\"光标移动到buffer的顶部和底部时保持3行距离, 或set so=3\nset scrolloff=3\n\"设定默认解码\nset fenc=utf-8\nset fencs=utf-8,usc-bom,euc-jp,gb18030,gbk,gb2312,cp936\n\"设定字体\nset guifont=Courier_New:h11:cANSI\nset guifontwide=新宋体:h11:cGB2312\n \n\"设定编码\nset enc=utf-8\nset fileencodings=ucs-bom,utf-8,chinese\nset langmenu=zh_CN.UTF-8\nlanguage message zh_CN.UTF-8\nsource $VIMRUNTIME/delmenu.vim\nsource $VIMRUNTIME/menu.vim\n\"自动补全\nfiletype plugin indent on\nset completeopt=longest,menu\n\"自动补全命令时候使用菜单式匹配列表\nset wildmenu\nautocmd FileType ruby,eruby set omnifunc=rubycomplete#Complete\nautocmd FileType python set omnifunc=pythoncomplete#Complete\nautocmd FileType javascript set omnifunc=javascriptcomplete#CompleteJS\nautocmd FileType html set omnifunc=htmlcomplete#CompleteTags\nautocmd FileType css set omnifunc=csscomplete#CompleteCSS\nautocmd FileType xml set omnifunc=xmlcomplete#CompleteTags\nautocmd FileType java set omnifunc=javacomplete#Complet\n```\n\n\n\n\n\n\n\n","tags":["xxx","xx","vim 配置"],"categories":["linux","tool","vim"]},{"title":"X session error","url":"//linux/debian/Xsession/","content":"\n## Xsession :warning:unable to write to /tmp; X session may exit with an error \n\n![](/pics/x-okay.png)\n\n 登陆进入不了界面，可以进入命令行`ctrl+alt+f1` \n\n###  磁盘\n\n```\ndf -lh\n\n#1777权限\nls -ld /tmp\n\nsudo du --max-depth=1 -h\n \n du -k |sort -n |tail -10\n```\n\n> 磁盘目录满了清目录 \n>\n> https://www.experts-exchange.com/questions/26782995/Xsession-warning-unable-to-write-to-tmp.html\n\n\n\n\n\n### user@\n\n<!--more-->\n\n点击okay提示 启动user@xxxxx.service失败\n\n```\n#tab补充uid\nsystemctl status user@\n```\n\n>systemctl status user@xxxxx.service\n\n\n\n![](/pics/x-okay-user.png)\n\n`/usr/bin/xxx`文件权限被修改导致，具体那个文件待确认\n\n~`sudo chmod u+s /usr/bin/*  导致`~\n\n\n\n```\n❯ su root\n密码：\nsu: 鉴定故障\n❯ ls -ld /usr/bin/su\n-rwxr-xr-x 1 root root 71912  1月 21  2022 /usr/bin/su\n\n```\n\n> ❯ ls -ld /usr/bin/sudo\n> -rwsr-xr-x 1 root root 182600  1月 14 21:29 /usr/bin/sudo\n>\n> #4755\n>\n> chmod u+s /usr/bin/su   `rwsr-xr-x`\n\n\n\n\n\n## 屏幕亮度\n\n### 背光\n\n#### 临时修改\n\n```\n❯ xrandr\nScreen 0: minimum 8 x 8, current 1920 x 1080, maximum 32767 x 32767\nHDMI-0 disconnected (normal left inverted right x axis y axis)\nDP-0 connected 1920x1080+0+0 (normal left inverted right x axis y axis) 344mm x 194mm\n   1920x1080     60.02*+\nDP-1 disconnected (normal left inverted right x axis y axis)\nDP-2 disconnected (normal left inverted right x axis y axis)\nDP-3 disconnected (normal left inverted right x axis y axis)\nDP-4 disconnected (normal left inverted right x axis y axis)\n❯ xrandr --output DP-0  --brightness 0.6\n❯ xrandr --output DP-0  --brightness 0.96\n\n```\n\n> xrandr --output DISPLAY --brightness MONITOR\n>\n> \"DISPLAY\"和\"MONITOR\"替换为您的实际值\n\n\n\n#### 永久\n\n默认是100\n\n```\n#acpi_video0或acpi_video1或 nvidia_0\nls  /sys/class/backlight/\n \necho 88 | tee /sys/class/backlight/nvidia_0/brightness\n```\n\n>sudo update-rc.d  custom-init  defaults 90  #添加开机自启\n>\n>sudo update-rc.d -f custom-init remove  #移除\n\n<details>\n  <summary>/etc/init.d</summary>\n  <pre><a>custom-init</a><code>\n❯ cat /etc/rc1.d/K01custom-init\n#!/bin/sh\n### BEGIN INIT INFO\n# Provides:          custom-init   \n# Required-Start:    $local_fs $network $remote_fs $syslog\n# Required-Stop:     $local_fs $network $remote_fs $syslog\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-Description: starts the custom-init daemon\n# Description:   custom script    \n### END INIT INFO\n</br>\n#屏幕亮度\n##sudo update-rc.d  custom-init  defaults 90\n## sudo update-rc.d -f custom-init remove\n[ -f \"/sys/class/backlight/nvidia_0/brightness\" ] && { echo 72 | sudo tee /sys/class/backlight/nvidia_0/brightness ; }\n</br>\n  </code></pre>\n</details>\n\n\n\n### 调节伽马值\n\n```\n#默认值为1.0，越高则越亮，越低则越暗。\nxgamma -gamma 0.9\nxgamma -bgamma 0.9\n```\n\n>-gamma f.f Gamma Value\n>\n>-rgamma f.f Red Gamma Value\n>\n>-ggamma f.f Green Gamma Value\n>\n>-bgamma f.f Blue Gamma Value\n","tags":["error","Xsession","tmp"],"categories":["linux","debian"]},{"title":"grub主题样式","url":"//linux/debian/grub/","content":"\n## grub2\n\n主题网址 \n\nhttps://www.pling.com/p/1603282/\n\nhttps://www.box-look.org/browse?cat=109&page=2&ord=latest\n\n### 安装\n\n#### Copy the theme directory\n\n```\n/usr/share/grub/themes\n```\n\n\n\n#### Make changes to the GRUB config file.\n\n```\nsudo mousepad  /etc/default/grub\n```\n\n> Find the line `GRUB_THEME=` then change it to `GRUB_THEME=\"/usr/share/grub/themes/xxxx/theme.txt\"`\n\n\n\n### 预览\n\n https://pypi.org/project/grub2-theme-preview/\n\n<!--more-->\n\n```\n pip install --user grub2-theme-preview\n```\n\n>Please make sure to install these *non-PyPI dependencies* as well:\n>\n>- `grub-mkrescue` of [GRUB 2](https://www.gnu.org/software/grub/) (package `grub-common` on Debian and Ubuntu)\n>- [QEMU](https://wiki.qemu.org/Main_Page) — *hypervisor that performs hardware virtualization*\n>- [OVMF](https://github.com/tianocore/tianocore.github.io/wiki/OVMF) — EFI bios image for use with QEMU\n>- [mtools](https://www.gnu.org/software/mtools/) — *collection of utilities to access MS-DOS*\n>- `xorriso` of [libisoburn](https://dev.lovelyhq.com/libburnia/libisoburn) — *frontend which enables creation and expansion of the ISO format*\n>\n>\n\n\n\n#### Usage\n\n```\ngrub2-theme-preview --help\n```\n\n>默认\n>\n>positional arguments:\n>  PATH                  path of theme directory (or PNG/TGA image file) to\n>                        preview\n>\n>optional arguments:\n>  -h, --help            show this help message and exit\n>  --grub-cfg PATH       path of custom grub.cfg file to use (default:\n>                        /boot/grub{2,}/grub.cfg)\n>  --resolution WxH      set a custom resolution, e.g. 800x600\n>  --timeout SECONDS     set GRUB timeout in whole seconds  (default: 30 seconds)\n>  --add TARGET=/SOURCE  make grub2-mkrescue add file(s) from /SOURCE to\n>                        /TARGET in the rescue image (can be passed multiple\n>                        times)\n>\n>command location arguments:\n>  --grub2-mkrescue COMMAND\n>                        grub2-mkrescue command (default: auto-detect)\n>  --qemu COMMAND        KVM/QEMU command (default: qemu-system-<machine>)\n>  --xorriso COMMAND     xorriso command (default: xorriso)\n>\n>\n\n\n\n```\n❯ grub2-theme-preview  /usr/share/grub/themes/breeze\n```\n\n>INFO: Appending to fonts to load: Hack-12.pf2\n>INFO: Appending to fonts to load: Hack-14.pf2\n>INFO: Appending to fonts to load: Hack-16.pf2\n>INFO: Appending to fonts to load: Hack-18.pf2\n>INFO: Appending to fonts to load: Hack-22.pf2\n>INFO: Appending to fonts to load: Hack-24.pf2\n>INFO: Appending to fonts to load: Hack-32.pf2\n>INFO: Appending to fonts to load: Hack-36.pf2\n>INFO: Found OVMF image at '/usr/share/OVMF/OVMF_CODE.fd'.\n>INFO: Please give GRUB a moment to show up in QEMU...\n\n![](/home/cs/oss/hexo/themes/spfk/source/pics/grub2-theme-preview.png)\n\n\n\n\n\n\n\n\n\n\n\n## old grub\n\n旧机器debian8,Ubuntu11.10,grub1\n\n### 安装burg\n\n```\nsudo apt-get install burg burg-themes\n```\n\n\n\n1. burg-common_1.98+20100623-1_amd64.deb\n2. burg-emu_1.98+20100623-1_amd64.deb\n3. burg-pc_1.98+20100623-1_amd64.deb  \n\n安装过程  \n\n![img](/pics/20230530-1428201466.png)\n\n![img](/pics/20230530-254554797.png)\n\n![img](/pics/20230530-680244002.png)\n\n空格选择\n\n![img](/pics/20230530-616937850.png)\n\n4. burg-themes-common_1.98+20100623-1_all.deb \n\n\n\n5.burg-themes_1.98+20100623-1_all.deb\n\n6.burg_1.98+20100623-1_amd64.deb\n\n\n\n### 执行更新  \n\n```\nsudo update-burg\n```\n\n安装完成 ,重启看效果\n\n\n\n### 开始 DIY主题\n\nhttp://www.deviantart.com/挑选一个主题下载（本文以[Metro](http://luxieblack.deviantart.com/art/Metro-burg-theme-336505408?offset=30#comments)主题为例），将下载的文件解压复制到/boot/burg/themes/中,终端执行sudo update-burg\n\n\n\n**调试模式**\n\n终端输入sudo burg-emu打开\n\n\n\n![img](/pics/20230530-362346960.png)\n\n按F2(\"t\")选择主题Metro，F3是调节分辨率的，需要在真实的显示环境下调节\n\n\n\n添加图标  分别改名为hover_linuxmint和normal_linuxmint\n\n<center class=\"half\">\n      <img src=\"/pics/20230530-749cdb37dfdf.png\" width=\"130\">\n     <img src=\"/pics/20230530-4ce00a9f0164.png\" width=\"130\">\n</center>\n\n​     \n\n复制到/boot/burg/themes/Metro/icons/中。并修改同目录的文件icons，加入下面的命令：\n\n```\n-linuxmint { image = \"$$/normal_linuxmint.png:$$/hover_linuxmint.png\" }\n```\n\n\n\n### 删除 burg\n\n```\nsudo apt-get remove burg burg-themes burg-emu\n```\n\n> 注意：采用wubi（Ubuntu Installer for Windows）安装的请勿尝试\n\n\n\n\n\n\n\n","tags":["xxx","xx","grub主题样式"],"categories":["linux","debian","grub"]},{"title":"influxdb存放zabbix监控数据","url":"//services/database/influxdb/influxdb-zabbix/","content":"\n### influxdb\n\nhttps://www.zabbix.com/cn/integrations/influxdb\n\n```\n docker run -d -p 8086:8086  influxdb:2.7.1 \\\n-v /home/cs/data/influxdb:/var/lib/influxdb \\\n--name my-db  \n\n\ndocker stop my-db\ndocker rm my-db\n```\n\n \n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n","tags":["xxx","influxdb","zabbix"],"categories":["services","database"]},{"title":"grub配置详解","url":"//linux/debian/grub-cfg/","content":"\n\n\nGRUB2 配置文件详解\n============\n\n1\\. GRUB2配置文件\n\nGRUB2 的配置文件通常为 `/boot/grub2/grub.cfg`，虽然此文件很灵活，但是我们并不需要手写所有内容。可以通过程序自动生成，或是直接修改生成之后的文件。\n\n2\\. 简单配置\n\n通常情况下简单配置文件 `/etc/default/grub` ，然后用程序 `grub-mkconfig` 来产生文件 `grub.cfg`。  \n文件 `/etc/default/grub` 是一个 shell 脚本，通常仅是 `KEY=value` 这样的连续行。如果值包含空格或特殊字符，必须用 `\"` 引用。详看 [GRUB Manual: Simple configuration](https://www.gnu.org/software/grub/manual/grub/html_node/Simple-configuration.html#Simple-configuration)。其常用关键字如下：\n\n2.1. GRUB\\_DEFAULT\n------------------\n\n默认菜单项。默认值为 `0`。可选值有：\n\n| 值       | 说明                                            |\n| -------- | ----------------------------------------------- |\n| <number> | 菜单项的数字序号，从 `0` 开始                   |\n| saved    | 被 `GRUB_SAVEDEFAULT` 保存的上次选择项          |\n| <id>     | 菜单项的唯一标识（menuentry ... --id **xxxx**） |\n\n2.2. GRUB\\_TIMEOUT\n------------------\n\n自启超时时间。默认值为 `5`。可选值有：\n\n| 值   | 说明       |\n| ---- | ---------- |\n| 0    | 不等待     |\n| \\-1  | 永久等待   |\n| 其他 | 等待对应秒 |\n\n2.3. GRUB\\_TIMEOUT\\_STYLE\n-------------------------\n\n倒计时显示风格。默认值为 `menu`。可选值有：\n\n| 值        | 说明       |\n| --------- | ---------- |\n| menu      | 显示菜单   |\n| countdown | 显示倒计时 |\n| hidden    | 隐藏       |\n\n2.4. GRUB\\_DISTRIBUTOR\n----------------------\n\n被用于生成菜单项的更多信息。\n\n2.5. GRUB\\_TERMINAL\n-------------------\n\n设置输入、输出终端类型。可选值有：\n\n| 值             | 说明           |\n| -------------- | -------------- |\n| console        | 控制台         |\n| serial         | 串口           |\n| serial\\_<port> | 具体串口号     |\n| gfxterm        | 图形模式输出   |\n| vga\\_text      | `VGA` 文本输出 |\n\n2.6. GRUB\\_CMDLINE\\_LINUX\n-------------------------\n\n添加到菜单项中的启动 `linux` 的命令行参数。\n\n2.7. GRUB\\_DISABLE\\_RECOVERY\n----------------------------\n\n设置此选项为 `true`，禁止产生恢复模式菜单项。\n\n2.8. GRUB\\_DISABLE\\_SUBMENU\n---------------------------\n\n默认情况下，`grub-mkconfig` 会将低版本内核放在高版本内核子菜单里。设置此选项为 `true`，所有菜单项都将出现在顶层。\n\n2.9. GRUB\\_DISABLE\\_OS\\_PROBER\n------------------------------\n\n默认情况下，`grub-mkconfig` 会使用外部程序 `os-prober` 检测其他已安装的操作系统，并产生菜单项。设置此选项为 `true`来禁止它。\n\n3\\. 直接修改\n\n我们也可以直接修改由 `grub-mkconfig` 生成之后的 `grub.cfg` ，其由 GRUB 内建的脚本语言组成，和 `GNU bash` 语法非常相似，比如定义函数、判断语句等。以下列出一些可调用的命令，详看 [GRUB Manual: Commands](https://www.gnu.org/software/grub/manual/grub/html_node/Commands.html#Commands)。\n\n> 注意：\n>\n> 1.  命令\n>\n>     其中个别命令只能在 `grub.cfg` 中使用，不能在命令行模式使用。比如 `menuentry`等。\n>\n> 2.  指定设备\n>\n>     定位一个文件，需要指定它所在设备分区与路径。[指定设备](https://www.gnu.org/software/grub/manual/grub/html_node/Device-syntax.html#Device-syntax)的语法如下：\n>\n>     ```\n>     (<device-type><device-number>,<partition-number>)\n>     \n>     ```\n>\n>     > 注解：\n>     >\n>     > 1.  <device-type>\n>     >\n>     >     设备类型，有如下几种常用类型：\n>     >\n>     >     | 类型 | 说明         |\n>     >     | ---- | ------------ |\n>     >     | hd   | 硬盘         |\n>     >     | fd   | 3.5 英寸软盘 |\n>     >     | nd   | 网络         |\n>     >     | cd   | CD/DVD等     |\n>     >\n>     > 2.  <device-number>\n>     >\n>     >     BIOS能够识别的设备号，下标从 `0` 开始计数。比如 `hd0` 表示主硬盘，等价于 linux 的 `/dev/hda`。\n>     >\n>     > 3.  <partition-number>\n>     >\n>     >     分区号，比如 `modos2` 表示第 `2` 个分区。下标从 `1` 开始计数。\n>     >\n>\n\n3.1. menuentry\n--------------\n\n定义 GRUB 的菜单项。当选中菜单项时，GRUB 将执行括号内的命令。如果最后的命令返回`成功`，并且内核被加载时，将自动执行 `boot` 命令。此命令不能在命令行模式执行。语法格式如下：\n\n```\nmenuentry <title> [--class=<class> …] [--users=<users>] \n\t[--unrestricted] [--hotkey=<key>] [--id=<id>] [<arg> …] { <command>; … }\n\n```\n\n> 注解：\n>\n> 1.  <title>\n>\n> 菜单项的显示名称。\n>\n> 2.  \\[--class=<class> …\\]\n>\n>     将菜单项指定为某一类。可指定多个类别。不同的菜单主题可能会显示不同的菜单类别。\n>\n> 3.  \\[--users=<users>\\]\n>\n>     授予指定用户访问菜单项的权利。\n>\n> 4.  \\[--unrestricted\\]\n>\n>     允许所有用户访问此菜单项。\n>\n> 5.  \\[--hotkey=<key>\\]\n>\n>     给菜单项指定一个快捷键。\n>\n> 6.  \\[--id=<id>\\]\n>\n>     给菜单项指定一个唯一的 `ASCII` 字符串标识。\n>\n> 7.  \\[<arg> …\\]\n>\n>     和 <title> 一起作为参数，传递给大括号里将要执行的命令。<title> 总是被指定为 `$1`。\n>\n\n3.2. boot\n---------\n\n启动已加载的内核。\n\n3.3. help\n---------\n\n显示内建命令的帮助信息。语法格式如下：\n\n```\nhelp [<pattern> …]\n\n```\n\n> 注解：\n>\n> 1.  \\[<pattern> …\\]\n>\n>     如果省略，则显示所有命令的简短描述。否则，显示指定命令的详细描述。\n>\n\n3.4. linux\n----------\n\n从指定文件加载内核，并传递启动参数。任何 `initrd` 必须在此命令后重加载。语法格式如下：\n\n```\nlinux <file> …\n\n```\n\n3.5. initrd\n-----------\n\n为 `linux` 内核加载初始的 `ramdisk`，并在 `linux` 启动的内存区域，设置恰当的参数。语法格式如下：\n\n```\ninitrd <file>\n\n```\n\n3.6. search\n-----------\n\n查找设备。语法格式如下：\n\n```\nsearch [--file|--label|--fs-uuid] [--set [<var>]] [--no-floppy] <name>\n\n```\n\n> 注解：\n>\n> 1.  \\[--file|--label|--fs-uuid\\]\n>\n>     分别表示按文件、文件系统标志、文件系统 `UUID` 查找设备。\n>\n> 2.  \\[--set \\[<var>\\]\\]\n>\n>     第一个找到的设备会被设置为环境变量 `var` 的值。默认变量是 `root`。\n>\n> 3.  \\[--no-floppy\\]\n>\n>     防止搜索软盘。\n>\n\n3.7. set\n--------\n\n设置环境变量。语法格式如下：\n\n```\nset [<envvar>=<value>]\n\n```\n\n> 注解：\n>\n> 1.  \\[<envvar>=<value>\\]\n>\n>     如果省略此参数，打印所有变量。\n>\n> 2.  根目录标识\n>\n>     指定根目录后，可以像 `linux` 的绝对路径的方式去定位一个文件。语法格式如下：\n>\n>     ```\n>     set root=(<device-type><device-number>,<partition-number>)\n>     \n>     ```\n>\n\n3.8. cat\n--------\n\n显示文件内容。\n\n3.9. ls\n-------\n\n列出设备或文件。语法格式如下：\n\n```\nls [<arg> …]\n\n```\n\n> 注解：\n>\n> 1.  \\[<arg> …\\]\n>\n>     如果没有参数，则显示所有 GRUB 已知的设备。否则根据参数显示设备或者文件。\n>\n\n3.10. lsmod和insmod\n------------------\n\n显示或插入指定的动态模块。语法格式如下：\n\n```\nlsmod\ninsmod <module>\n\n```\n\n\n\n","tags":["xxx","grub配置详解","cfg"],"categories":["linux","debian"]},{"title":"revAnimated models","url":"//lang/stable-diffusion/models/revAnimated/","content":"\n## revAnimated_v122.safetensors\n\n\n\n#### Negative Prompts TI  消极提示\n\n- [EasyNegative](https://huggingface.co/embed/EasyNegative/tree/main)\n- [Deep Negative](https://civitai.com/models/4629/deep-negative-v1x)\n- [bad_prompt_version2](https://huggingface.co/embed/bad_prompt/blob/main/bad_prompt_version2.pt)\n- [bad-artist](https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist.pt)\n- [bad-artist-anime](https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist-anime.pt)\n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n","tags":["xxx","xx","revAnimated models"],"categories":["lang","stable-diffusion","models","revAnimated"]},{"title":"解除限制小魔法","url":"//tool/crack/unfreeze/","content":"\n### 工具\n\n无法输入中文，查看 **  libfcitxplatforminputcontextplugin.so **\n\n```\n/usr/lib/x86_64-linux-gnu/qt5/plugins/platforminputcontexts/libfcitxplatforminputcontextplugin.so\n```\n\n\n\n### sublime text\n\nhttps://www.pythonblogs.com/sublime-text-license-key/\n\n\n\n二进制破解\n\nhttps://hexed.it/\n\n\n\n```\n打开文件将sublime_text.exe导入\n\nCtrl+F`搜索查找`97 94 0D`，替换为`00 00 00\n```\n\n\n\n#### typora\n\n##### win\n\nwinmm.dll\n\n##### linux\n\nhttps://2dph.com/archives/typora-crack-linux.html \n\n<!--more-->\n\n\n\n### 网站\n\n#### csdn\n\n如果确实不想登录账号的话，这边有个超级简单的方法解决。\n**1、在书签栏加一个书签**\n**2、在网址输入框中填入如下代码**\n**3、以后每次想要复制之前点击一下这个书签，就可以自由复制CSDN的代码啦**\n\n```\njavascript:window.oncontextmenu=document.oncontextmenu=document.oncopy=null; [...document.querySelectorAll('body')].forEach(dom => dom.outerHTML = dom.outerHTML); [...document.querySelectorAll('body, body *')].forEach(dom => {['onselect', 'onselectstart', 'onselectend', 'ondragstart', 'ondragend', 'oncontextmenu', 'oncopy'].forEach(ev => dom.removeAttribute(ev)); dom.style['user-select']='auto';});\n```\n\n\n\n\n\n\n\n","tags":["xxx","unfreeze","crack"],"categories":["tool","crack"]},{"title":"Kcptun安装使用","url":"//network/Kcptun/","content":"\n\n\n### kupun\n\n\n\nhttps://github.com/xtaci/kcptun/releases/download/v20230214/kcptun-linux-amd64-20230214.tar.gz\n\n![](/pics/ss-kupun.png)\n\n<!--more-->\n\n\n\nc\n\n```\n{\n    \"localaddr\": \"10801\",\n    \"remoteaddr\": \"23.94.137.155:29981\",\n    \"key\": \"cP=!i10221L$;\",\n    \"crypt\": \"aes\",\n    \"mode\": \"fast3\",\n    \"mtu\": 1350,\n    \"sndwnd\": 1024,\n    \"rcvwnd\": 1024,\n    \"datashard\": 10,\n    \"parityshard\": 3,\n    \"dscp\": 46,\n    \"nocomp\": true\n}\n\n\n{\n  \"server\":\"127.0.0.1\",                                     \n  \"server_port\":10801,#对应本地localaddr\n  \"local_port\":1080,\n  \"password\":\"csP!=10221;\",          \n  \"timeout\":300,               \n  \"method\":\"aes-256-gcm\",\n   \"plugin\":\"kcptun\",\n    \"plugin_opts\": \"client;/home/cs/oss/ss/kcptun.json\",\n   \"remarks\": \"/home/cs/.local/bin/sslocal -c /home/cs/oss/ss.json\"\n}\n\n```\n\n\n\nhttps://www.taterli.com/4760/\n\n![](/pics/kup-udp2raw.png)\n\nhttps://github.com/wangyu-/udp2raw-tunnel\n\n\n\n\n\n### proxychains\n\nproxychains curl -I https://www.youtube.com/\n\n\n\n/etc/proxychains4.conf\n\n\n\n#### git代理\n\n\n\ncat  ~/.gitconfig\n\n```\n[https]\n\tproxy = socks5://127.0.0.1:1080\n[http]\n\tproxy = socks5://127.0.0.1:1080\n```\n\n>取消\n>\n>```bash\n>unset http_proxy\n>unset https_proxy\n>```\n\n","tags":["xxx","Kcptun","ss"],"categories":["network","Kcptun"]},{"title":"picture processing models","url":"//lang/stable-diffusion/models/processing/","content":"\n### LDSR\n\nextensions-builtin/LDSR/scripts/ldsr_model.py\n\n```\nproject.yaml\nmodel.ckpt\n```\n\n>  self.model_url = \"https://heibox.uni-heidelberg.de/f/578df07c8fc04ffbadf3/?dl=1\"\n>  self.yaml_url = \"https://heibox.uni-heidelberg.de/f/31a76b13ea27482981b4/?dl=1\"\n\n<!--more-->\n\n\n\n### ScuNET\n\nextensions-builtin/ScuNET/scripts/scunet_model.py\n\n```\n self.name = \"ScuNET\"\n        self.model_name = \"ScuNET GAN\"\n        self.model_name2 = \"ScuNET PSNR\"\n```\n\n>​        self.model_url = \"https://github.com/cszn/KAIR/releases/download/v1.0/scunet_color_real_gan.pth\"\n>\n>​        self.model_url2 = \"https://github.com/cszn/KAIR/releases/download/v1.0/scunet_color_real_psnr.pth\"\n>\n>\n\n\n\n\n\n","tags":["xxx","xx","picture processing models"],"categories":["lang","stable-diffusion","models","processing"]},{"title":"zimfw shell","url":"//linux/shell/zimfw/","content":"\n## zsh\n\n\n\n```\nsudo apt install zsh\n\n#zsh替换为你的默认shell\nchsh -s $(which zsh)\n```\n\n\n\n\n\n\n\n## zimfw\n\n### Automatic installation\n\nhttps://ghproxy.com/https://raw.githubusercontent.com/zimfw/install/master/install.zsh\n\n<!--more-->\n\n```\ncurl -fsSL https://raw.githubusercontent.com/zimfw/install/master/install.zsh | zsh\n```\n\n>) Using Zsh version 5.8\n>) ZIM_HOME not set, using the default one.\n>密码：\n>) Changed your default shell to /usr/bin/zsh\n>! You seem to be already calling compinit in /etc/zsh/zshrc. Please remove it, because Zim's completion module will call compinit for you.\n>) Downloaded the Zim script to /home/cs/.zim/zimfw.zsh\n>) Prepended Zim template to /home/cs/.zimrc\n>) Prepended Zim template to /home/cs/.zshrc\n>\n>.\n>\n>.\n>\n>.\n\n\n\n### Manual installation\n\n`~/.zshrc`\n\n```\nZIM_HOME=~/.zim\n\nhttps://github.com/zimfw/zimfw/releases/latest/download/zimfw.zsh\n```\n\n>$ cat ~/.zshrc  | grep zstyle\n>#zstyle ':zim:zmodule' use 'degit'\n>#zstyle ':zim:git' aliases-prefix 'g'\n>#zstyle ':zim:input' double-dot-expand yes\n>#zstyle ':zim:termtitle' format '%1~'\n\n\n\n`~/.zimrc`\n\n<p id=\"zim-modules\" >~/.zim/modules/</p>\n\n>$ cat ~/.zimrc  | grep zmodule\n>zmodule environment\n>zmodule git\n>zmodule input\n>zmodule termtitle\n>zmodule utility\n>zmodule duration-info\n>zmodule git-info\n>zmodule asciiship\n>zmodule zsh-users/zsh-completions --fpath src\n>zmodule completion\n>zmodule zsh-users/zsh-syntax-highlighting\n>zmodule zsh-users/zsh-history-substring-search\n>zmodule zsh-users/zsh-autosuggestions\n\n\n\n### Uninstalling\n\n\n\n```\n#rm -rf ~/.zim ~/.zimrc\n```\n\n>$ ls -l ~/.z*\n>-rw------- 1 cs cs 1574  4月  8 18:54 /home/cs/.zimrc\n>-rw------- 1 cs cs 3587  4月  8 18:54 /home/cs/.zshrc\n>\n>/home/cs/.zim:\n>总用量 40\n>drwxr-xr-x 15 cs cs  4096  4月  8 19:23 modules\n>-rw-r--r--  1 cs cs 36117  4月  8 18:54 zimfw.zsh\n\n\n\n## modules\n\n[zimrc add zmodule](#zim-modules)\n\n### autojump\n\nhttps://github.com/wting/autojump\n\n```\nsudo apt install autojump\n```\n\n> /usr/share/doc/autojump/README.Debian\n\nautojump 将只跳到先前 `cd` 命令到过的目录\n\nj\n\n```\n❯ j k8s\n/home/cs/oss/k8s-1.26\n❯ j w k8s   #权限小的目录\n/home/cs/data/VM/k8s\n\n```\n\n\n\n\n\n\n\n#### stat \n\n选项可以查看访问过的目录权重\n\n```\n❯ j --stat\n10.0:\t/home/cs/data/VM/k8s\n14.1:\t/home/cs/oss/k8s-1.26\n14.1:\t/opt/tools\n20.0:\t/home/cs/oss/hexo\n________________________________________\n\n58:\t total weight\n4:\t number of entries\n10.00:\t current directory weight\n\ndata:\t /home/cs/.local/share/autojump/autojump.txt  #统计存储日志\n\n```\n\n\n\n### fzf\n\nhttps://github.com/junegunn/fzf#examples\n\n```\ngit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf\n~/.fzf/install\n```\n\n>Downloading bin/fzf ...\n>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n>                                 Dload  Upload   Total   Spent    Left  Speed\n>  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n>100 1340k  100 1340k    0     0   5941      0  0:03:50  0:03:50 --:--:--  7241\n>  - Checking fzf executable ... 0.39.0\n>Do you want to enable fuzzy auto-completion? ([y]/n) y\n>Do you want to enable key bindings? ([y]/n) y\n>\n>Generate /home/cs/.fzf.bash ... OK\n>Generate /home/cs/.fzf.zsh ... OK\n>\n>Do you want to update your shell configuration files? ([y]/n) y\n>\n>Update /home/cs/.bashrc:\n>  - [ -f ~/.fzf.bash ] && source ~/.fzf.bash\n>    + Added\n>\n>Update /home/cs/.zshrc:\n>  - [ -f ~/.fzf.zsh ] && source ~/.fzf.zsh\n>    + Added\n>\n>Finished. Restart your shell or reload config file.\n>   source ~/.bashrc  # bash\n>   source ~/.zshrc   # zsh\n>\n>Use uninstall script to remove fzf.\n>\n>For more information, see: https://github.com/junegunn/fzf\n\n\n\n### fzf-tab\n\n~/.zimrc\n\n```\ngit clone --depth 1 https://github.com/Aloxaf/fzf-tab.git  /.zim/modules/fzf-tab\n#fzf-tab ALSO needs fzf installed\nzmodule Aloxaf/fzf-tab\n```\n\n\n\n```\n# disable sort when completing `git checkout`\nzstyle ':completion:*:git-checkout:*' sort false\n# set descriptions format to enable group support\nzstyle ':completion:*:descriptions' format '[%d]'\n# set list-colors to enable filename colorizing\nzstyle ':completion:*' list-colors ${(s.:.)LS_COLORS}\n# preview directory's content with exa when completing cd\nzstyle ':fzf-tab:complete:cd:*' fzf-preview 'exa -1 --color=always $realpath'\n# switch group using `,` and `.`\nzstyle ':fzf-tab:*' switch-group ',' '.'\n```\n\nhttps://github.com/Aloxaf/fzf-tab/wiki/Configuration\n\n\n\n\n\n### powerlevel10k\n\ndoc https://github.com/romkatv/powerlevel10k#installation\n\n```\n#add ~/.zimrc\nzmodule romkatv/powerlevel10k\n```\n\n>/home/cs/.zim/modules/powerlevel10k\n\n\n\n#### p10k安装\n\n```\np10k configure\n```\n\n> New config: ~/.p10k.zsh.\n> Backup of ~/.zshrc: /tmp/.zshrc.JO4Ns3iulN.\n>\n> See ~/.zshrc changes:\n>\n>   diff /tmp/.zshrc.JO4Ns3iulN ~/.zshrc\n>\n> File feature requests and bug reports at\n> https://github.com/romkatv/powerlevel10k/issues\n\n\n\n\n\n\n\n\n\n#### font\n\nhttps://www.nerdfonts.com/font-downloads\n\nhttps://github.com/ryanoasis/nerd-fonts/releases/tag/v2.3.3\n\n\n\n\n\n\n\n#### icons\n\nhttps://www.nerdfonts.com/cheat-sheet\n\n~/.p10k.zsh\n\n````\nPOWERLEVEL9K_BATTERY_CHARGING='yellow'\nPOWERLEVEL9K_BATTERY_CHARGED='green'\nPOWERLEVEL9K_BATTERY_DISCONNECTED='$DEFAULT_COLOR'\nPOWERLEVEL9K_BATTERY_LOW_THRESHOLD='10'\nPOWERLEVEL9K_BATTERY_LOW_COLOR='red'\nPOWERLEVEL9K_BATTERY_ICON='\\uf1e6 '\nPOWERLEVEL9K_MULTILINE_FIRST_PROMPT_PREFIX=''\nPOWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX='\\uf0da'\n#POWERLEVEL9K_VCS_GIT_ICON='\\ue60a'\n\nPOWERLEVEL9K_VCS_MODIFIED_BACKGROUND='yellow'\nPOWERLEVEL9K_VCS_UNTRACKED_BACKGROUND='yellow'\n#POWERLEVEL9K_VCS_UNTRACKED_ICON='?'\n\nPOWERLEVEL9K_SHORTEN_STRATEGY=\"truncate_middle\"\nPOWERLEVEL9K_SHORTEN_DIR_LENGTH=4\n\n#POWERLEVEL9K_CUSTOM_TIME_FORMAT=\"%D{\\uf017 %H:%M:%S}\"\nPOWERLEVEL9K_TIME_FORMAT=\"%D{\\uf017 %H:%M \\uf073 %d.%m.%y}\"\n\nPOWERLEVEL9K_STATUS_VERBOSE=false\n\nPOWERLEVEL9K_PROMPT_ON_NEWLINE=true\n````\n\n\n\n\n\n### exa\n\n代替ls\n\nhttps://github.com/ogham/exa/releases/tag/v0.10.1\n\n```\n❯ exa -lh -T --icons ./\n```\n\n> - **-T**, **--tree**: 递归到树视图中的子目录\n> - **--icons**: 显示图标\n\n\n\n```\n❯ exa -lh -T  --icons ./   -L 1\n```\n\n>- **-L**, **--level=(depth)**: 限制递归的深度\n>- **-D**, **--only-dirs**: 只列出目录\n\n\n\n\n\n```\ndebian# ln -s /home/cs/.zshrc /root/.zshrc\ndebian# ln -s /home/cs/.zimrc /root/.zimrc\n\ndebian# ln -s /home/cs/.fzf.zsh /root/.fzf.zsh     \ndebian# ln -s /home/cs/.p10k.zsh /root/.p10k.zsh\ndebian#\ndebian# ln -s /home/cs/.zim/modules  /root/.zim/modules\n\n```\n\n>lrwxrwxrwx 1 root root     15  4月 15 20:05 /root/.zimrc -> /home/cs/.zimrc\n>lrwxrwxrwx 1 root root     15  4月 15 20:05 /root/.zshrc -> /home/cs/.zshrc\n>\n>lrwxrwxrwx 1 root root  18  4月 15 20:07 /root/.p10k.zsh -> /home/cs/.p10k.zsh\n\n\n\n### thefuck\n\nhttps://github.com/nvbn/thefuck\n\n```\npip3 install thefuck --user\n```\n\n>❯ pip show thefuck\n>Name: thefuck\n>Version: 3.32\n>Summary: Magnificent app which corrects your previous console command\n>Home-page: https://github.com/nvbn/thefuck\n>Author: Vladimir Iakovlev\n>Author-email: nvbn.rm@gmail.com\n>License: MIT\n>Location: /home/cs/.local/lib/python3.9/site-packages\n>Requires: colorama, decorator, psutil, pyte, six\n>Required-by: \n>\n>❯ ls -l /home/cs/.local/bin | grep fuck\n>-rwxr-xr-x 1 cs   cs        233  7月 16 23:28 fuck\n>-rwxr-xr-x 1 cs   cs        223  7月 16 23:28 thefuck\n\n\n\n```\n❯ sudo ln -s /home/cs/.local/bin/thefuck /usr/local/bin/thefuck\n[sudo] cs 的密码：\n❯ sudo ln -s /home/cs/.local/bin/fuck /usr/local/bin/fuck\n\n\n```\n\n> .zshrc   \n>\n> eval \"$(/home/cs/.local/bin/thefuck --alias fuck)\"\n\n\n\n## other\n\n对于Zsh，这是一个语言级别的错误；对于Bash，这是一个外部命令执行的错误。这差别很重要，因为它意味着后者可以被轻易地catch，而前者不能。\n\n\n\n### zsh: no matches found:\n\n`find` 命令\n\n在`~/.zshrc`中加入:`setopt no_nomatch`\n\n\n\n### 带%\n\n解决zsh不完全行会多%号的问题\n\n`unsetopt prompt_cr prompt_sp`\n\n\n\n### zsh: 文件已存在:\n\n**默认情况下，Zsh不允许直接覆盖已存在的文件**\n\n```\n# >! 都行\nxsel -o -b >| /tmp/output.txt\n```\n\n> `>!`的作用是强制覆盖已存在的文件`/tmp/output.txt` \n","tags":["shell","zimfw","zsh"],"categories":["linux","shell","zimfw"]},{"title":"lora models说明","url":"//lang/stable-diffusion/models/lora/","content":"\n### 身体模型\n\nhttps://huggingface.co/tt-doang69/loras\n\n![](/home/cs/%E5%9B%BE%E7%89%87/si/2023-04-06_20-00.png)\n\n lora:breastinclassbetter_v141:0.5\n\n\n\nlora:inniesbettervaginas_v11:1.0\n\n\n\nbetterBodyBetterFace_mayukiV1:\n\n\n\n<!--more-->\n\n### Doing something / Pose\n\n![](/home/cs/%E5%9B%BE%E7%89%87/si/shirt%20lift.jpg)\n\nlora:shirtliftALORAFor_shirtliftv1:0.5   Trigger words : shirtlift\n\n\n\n\n\n\n\n","tags":["private-cs","lora","models"],"categories":["lang","stable-diffusion","models","lora"]},{"title":"Stable diffusion概念","url":"//lang/stable-diffusion/deep/","content":"\n## stable-diffusion-webui\n\n[stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n\n\n\n```\nstable-diffusion-webui ❯ ./webui.sh\n################################################################\nInstall script for stable-diffusion + Web UI\nTested on Debian 11 (Bullseye)\n################################################################\n\n################################################################\nRunning on cs user\n################################################################\n\n################################################################\nClone stable-diffusion-webui\n################################################################\n正克隆到 'stable-diffusion-webui'...\nremote: Enumerating objects: 25633, done.\nremote: Counting objects: 100% (20/20), done.\nremote: Compressing objects: 100% (13/13), done.\nremote: Total 25633 (delta 7), reused 18 (delta 7), pack-reused 25613\n接收对象中: 100% (25633/25633), 31.61 MiB | 54.00 KiB/s, 完成.\n处理 delta 中: 100% (17963/17963), 完成.\n\n################################################################\nCreate and activate python venv\n```\n\n\n\n\n\n\n\n只记录关键步骤\n\n### 跳过下载检查\n\nv1.0  \n\n ~/stable-diffusion-webui/launch.py\n\n```\nskip_install = True\n```\n\nv1.2\n\n～/stable-diffusion-webui/webui.sh\n\n```\n/sbin/ldconfig\n```\n\n\n\n```\ngit fetch --all //只是下载代码到本地，不进行合并操作\ngit reset --hard v1.2.1  //把HEAD指向最新下载的版本\n```\n\n\n\n\n\n使用代理下载7个github的库https://ghproxy.com/\n\nhttps://github.com/Stability-AI/stablediffusion/archive/refs/heads/main.zip\n\n```\n\nhttps://github.com/salesforce/BLIP\nhttps://github.com/sczhou/CodeFormer\nhttps://github.com/crowsonkb/k-diffusion\nhttps://github.com/Stability-AI/stablediffusion\nhttps://github.com/CompVis/taming-transformers\n\n#/stable-diffusion-webui/venv/lib/python3.9/site-packages/\nhttps://github.com/TencentARC/GFPGAN\nhttps://github.com/openai/CLIP\nhttps://github.com/mlfoundations/open_clip\n```\n\n<!--more-->\n\n### [pip源](/lang/python/pip#pip-source)下载\n\nhttps://pypi.org/project/xformers/\n\n```\npip config set global.index-url https://mirrors.aliyun.com/pypi/simple/\nsource  ~/stable-diffusion-webui/venv/bin/activate\npip  install facexlib\n\nxformers\nlpips\n.\n.\n.\n```\n\n\n\n### 目录\n\n#### repositories\n\n~/stable-diffusion-webui/modules/paths.py\n\n```\n$ tree -L 1 ~/stable-diffusion-webui/repositories\n/home/cs/stable-diffusion-webui/repositories\n├── BLIP\n├── CodeFormer\n├── k-diffusion\n├── stable-diffusion-stability-ai\n└── taming-transformers\n\n5 directories, 0 files\n\n```\n\n\n\n##### CodeFormer\n\n仓库代码https://github.com/sczhou/CodeFormer/releases/tag/v0.1.0\n\n～/stable-diffusion-webui/modules/codeformer_model.py\n\n```\n#CodeFormer版本v0.1.0\nsend_model_to（）\n```\n\nCodeFormer 预训练模型下载到～/stable-diffusion-webui/repositories/CodeFormer/weights\n\n```\n$ tree ~/stable-diffusion-webui/repositories/CodeFormer/weights -L 2\n/home/cs/stable-diffusion-webui/repositories/CodeFormer/weights\n├── CodeFormer\n│   └── codeformer.pth\n├── dlib\n│   ├── mmod_human_face_detector-4cb19393.dat\n│   └── shape_predictor_5_face_landmarks-c4b1e980.dat\n├── facelib\n│   ├── detection_Resnet50_Final.pth\n│   └── parsing_parsenet.pth\n└── README.md\n\n3 directories, 6 files\n\n```\n\n\n\n##### ESRGAN 放大\n\nhttps://github.com/xinntao/Real-ESRGAN/blob/master/README_CN.md\n\n1. realesrgan-x4plus（默认）\n2. reaesrnet-x4plus\n3. realesrgan-x4plus-anime（针对动漫插画图像优化，有更小的体积）\n4. realesr-animevideov3 (针对动漫视频)\n\n ~/stable-diffusion-webui/modules/realesrgan_model.py\n\n\n\n##### clip\n\nDownloading: \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth\" to /home/cs/stable-diffusion-webui/models/BLIP/model_base_caption_capfilt_large.pth\n\n\n\nhttps://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n\nViT-L-14\n\nhttps://huggingface.co/laion/CoCa-ViT-L-14-laion2B-s13B-b90k/tree/main\n\nwget ‐‐continue\n\n\n\nCannot locate TCMalloc (improves CPU memory usage)\n\n```\n/sbin/ldconfig\n```\n\n\n\n```\nexport COMMANDLINE_ARGS=\"--xformers  --medvram  --listen\"\n```\n\n\n\n\n\n\n\n### 启动参数\n\n16XX启动（图片分辨率最大方图为576×576）：--medvram --precision full --no-half --always-batch-cond-uncond --deepdanbooru --xformers\n\n2G启动：--lowvram --always-batch-cond-uncond --deepdanbooru --xformers\n\n4G启动（图片分辨率最大方图为576×576）：--medvram --always-batch-cond-uncond --deepdanbooru --xformers\n\n6G启动（最大方图分辨率自行测试）：--medvram --always-batch-cond-uncond --deepdanbooru --xformers\n\n8G及以上：--always-batch-cond-uncond --deepdanbooru --xformers\n\nCPU启动（控制台不动可能需要回车）：--use-cpu all --no-half --skip-torch-cuda-test --deepdanbooru\n\n>deepdanbooru：这是一个用来给二次元图跑训练时提取信息的插件，需要额外安装，如果用了别人的pt训练包，一定要加上这个参数，不然效果天差地别，因为别人大概率是用了这个插件进行训练的\n>\n>always-batch-cond-uncond：不清楚，不过推测应该是自动整理显存碎片的\n>\n>xformers：优化显存占用情况的插件，需要额外安装，不支持CPU，不启用这个参数就要把4G及16XX中的medvram改为lowvram\n>\n>precision full和no-half：完全精度和非半精度，也就是使用32位浮点运算而不是使用16位浮点运算，开启这两个参数会让显存占用增加，但图的质量会更好，但是cpu和16XX显卡必须开启，不然黑图或者\n>\n>\n\n\n\n\n\n### 文生图（`text2img`）\n\n| 参数            | 说明                                                         |\n| --------------- | ------------------------------------------------------------ |\n| Prompt          | 提示词（正向）                                               |\n| Negative prompt | 消极的提示词（反向）                                         |\n| Width & Height  | 要生成的图片尺寸。尺寸越大，越耗性能，耗时越久。             |\n| CFG scale       | AI 对描述参数（Prompt）的倾向程度。值越小生成的图片越偏离你的描述，但越符合逻辑；值越大则生成的图片越符合你的描述，但可能不符合逻辑。 |\n| Sampling method | 采样方法。有很多种，但只是采样算法上有差别，没有好坏之分，选用适合的即可。 |\n| Sampling steps  | 采样步长。太小的话采样的随机性会很高，太大的话采样的效率会很低，拒绝概率高(可以理解为没有采样到,采样的结果被舍弃了)。 |\n| Seed            | 随机数种子。生成每张图片时的随机种子，这个种子是用来作为确定扩散初始状态的基础。不懂的话，用随机的即可。 |\n\n\n\n\n\nSampling Steps 你可以理解让AI推演多少步，一般来说超过17基本就能看了，步数越多，画面中的细节就越多，但需要的时间也就越久，一般20~30是一个比较稳妥的设定。这个数不会改变画面内容，只会让内容更加精细，比如20的项链就是一个心形钻石，而50的项链还是同样的心形钻石，只是钻石上会有更加复杂的线条\n\nSampling method 你可以理解成AI推演的算法，一般Euler a，Euler ，DDIM，都是不错的，任选一个就行。\n\n图片分辨率 这个就是拼显卡显存的，自己调吧，低于512X512可能画面就不会有太多细节了，越大的分辨率AI能发挥的地方就越多。\n\n下边是3个扩展选项，一般不需要勾选。\nRestore faces：勾选后可以生成更真实的脸，第一次勾选使用时，需要先下载几个G的运行库。\nTiling：让图片可以平铺（类似瓷砖，生成的图案左右上下都可以无缝衔接上自己）\nHighres. fix：超分辨率，让AI用更高的分辨率填充内容，但生成的最终尺寸还是你上边设定的尺寸。\n\n生成几次，每次多少张\nBatch count：是一次运行几次\nBatch size： 是同时生成多少张\n比如：Batch count设置为4,用时N分钟*4，生成4张图；Batch count设置为4,用时N分钟，生成4张图，但是同时需要的显存也是4倍。512X512大概需要3.75GB显存，4倍就是15GB显存了。\n\nCFG Scale AI有多参考你的Prompt与Negative prompt\n开得越高，AI越严格按照你的设定走，但也会有越少的创意\n开的越低，AI就越放飞自我，随心所欲的画。\n一般7左右就行。\n\nSeed 随机数种子，AI作画从原理上其实就是用一个随机的噪声图，反推回图像。但因为计算机里也没有真随机嘛，所以实际上，AI作画的起始噪声，是可以量化为一个种子数的。\n\nGenerate 开始干活按钮，这个就不用说了吧，点了AI就开始干活了。\n\nStable Diffusion checkpoint 在最左上角，是选择模型的\n\n\n\n### 汉化\n\n[下载本 git 仓库](https://codeload.github.com/dtlnor/stable-diffusion-webui-localization-zh_CN/zip/refs/heads/main)为 zip 档案，解压，并把文件夹放置在 webui 根目录下的 `extensions` 文件夹中\n\n\n\nhttps://github.com/dtlnor/stable-diffusion-webui-localization-zh_CN#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8\n\n\n\n##\n\n\n\n````\n模型：ChilloutMix（基于Stable Diffusion 1.5）\n\n关键词：<lora:koreanDollLikeness_v10:0.3>,<lora:taiwanDollLikeness_v10:0.2>(8k, RAW photo, best quality, masterpiece:1.2), (realistic, photo-realistic:1.37), ultra-detailed, 1 girl,cute, solo,beautiful detailed sky,detailed cafe,night,sitting,dating,(nose blush),(smile:1.1),(closed mouth) medium breasts,beautiful detailed eyes,(collared shirt:1.1), bowtie,pleated skirt,(short hair:1.2),floating hair\n\n参数：Steps: 40, Sampler: DPM++ 2M Karras, CFG scale: 7, Seed: 3131560428, Size: 768x1024（不同的图片参数有些许差异）\n````\n\n![](/home/cs/oss/hexo/themes/spfk/source/pics/2023-04-02_15-26.png)\n\n\n\n\n\n\n\n```\n例如配置如下：\n\n<lora:koreanDollLikeness_v10:0.5> <lora:lora-hanfugirl-v1-5:0.5>,hanfu,medium breasts, glasses,\n\nNegative prompt: ng_deepnegative_v1_75t,EasyNegative, paintings, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, glans,extra fingers,fewer fingers,disabled body,DeepNegative,tatoo\n\nSize: 512x960, Seed: 872093151, Model: chilloutmix_NiPrunedFp32Fix, Steps: 26, Sampler: DPM++ 2M Karras, CFG scale: 10.5, Model hash: fc2511737a\n```\n\n![](/home/cs/oss/hexo/themes/spfk/source/pics/2023-04-02_15-28.png)\n","tags":["Stable","diffusion","text2img","picture"],"categories":["lang","python","deep"]},{"title":"GPU CUDA安装","url":"//tool/gpu/","content":"\n### GPU\n\nhttps://developer.nvidia.com/cuda-gpus\n\n<p id=\"gpu\" hidden />\n\n#### 版本\n\n下载 https://www.nvidia.cn/geforce/drivers/\n\n![](/pics/nvidia-select.png)\n\n```\n$  uname -srm\nLinux 5.10.0-21-amd64 x86_64\n\n# dpkg-query -s linux-headers-$(uname -r)\n```\n\n> Driver Version 要是 51x\n\n![](/pics/nvidia-download.png)\n\n\n\n```\n$ lspci | grep -i vga\n01:00.0 VGA compatible controller: NVIDIA Corporation GP106M [GeForce GTX 1060 Mobile] (rev a1)\n```\n\n>Nvidia 卡信息的末尾是 rev a1，表示已经开启。\n>\n>末尾是 rev ff，表示独显已经关闭\n\n支持列表 https://developer.nvidia.com/cuda-gpus\n\n\n\n\n\n#### X server\n\n \n\n```\n#切换到文本界面\n/sbin/init 3 \n\n#切换到图形界面\n/sbin/init 5\n```\n\n>Using: nvidia-installer ncurses v6 user interface\n>-> Detected 8 CPUs online; setting concurrency level to 8.\n>-> The file '/tmp/.X0-lock' exists and appears to contain the process ID '773' of a running X server.\n>ERROR: You appear to be running an X server; please exit X before installing.  For further details, please see the section INSTALLING THE NVIDIA DRIVER in the README available on the Linux driver download page at www.nvidia.com.\n>ERROR: Installation has failed.  Please see the file '/var/log/nvidia-installer.log' for details.  You may find suggestions on fixing installation problems in the README available on the Linux driver download page at www.nvidia.com.\n\n\n\n#### driver\n\n```\ncat <<EOF | sudo tee /usr/lib/modprobe.d/dist-blacklist.conf\nblacklist nouveau\noptions nouveau modeset=0\nEOF\n\n\nsudo update-initramfs -u\n\n#reboot \nlsmod | grep nouveau\n```\n\n>ERROR: The Nouveau kernel driver is currently in use by your system.  This driver is incompatible with the NVIDIA driver, and must be disabled before proceeding.  Please consult the NVIDIA driver README and your Linux distribution's documentation for details on how to correctly disable the Nouveau kernel driver.\n\n\n\n#### kernel-source  \n\n会提示安装\n\n```\n#根据/var/log/nvidia-installer.log 报错情况安装缺失包\nsudo apt install  dkms\n```\n\n>--kernel-source-path   问题 安装linux-headers\n\n\n\n\n\n```\n#关闭X server 图形界面后执行\nsh  NVIDIA-Linux-x86_64-*.run\n\n```\n\n\n\n\n\n#### 驱动版本\n\n```\ncat /proc/driver/nvidia/version\n```\n\n![](/pics/nvidia-version.png)\n\n\n\n#### 显卡编号\n\n```\nls -l /dev/nvidia*\n```\n\n![](/pics/nvidia-1.png)\n\n多块\n\n![2](/pics/nvidia-2.png)\n\n\n\n\n\n```\nsudo nvidia-smi\n```\n\n![](/pics/nvidia.png)\n\n\n\n温度\n\n```\nsudo nvidia-smi -q -d TEMPERATURE\n```\n\n10s 一次\n\n```\nwatch -n 10 nvidia-smi\n```\n\n\n\n#### 卸载 \n\n```\n sh  NVIDIA*.run  --uninstall  \n```\n\n> 高版本可以卸载低版本的 525卸载515\n\n\n\n<!--more-->\n\n\n\n### CUDA\n\nhttps://developer.nvidia.com/cuda-toolkit-archive\n\n![](/pics/cuda-download.png)\n\n```\nsudo sh cuda_*.run\n\n#accept/decline/quit:accept\n#Install NVIDIA Accelerated Graphics Driver no不选择安装\nnvidia-fs 如果你需要在容器中使用NVIDIA GPU资源,需要安装nvidia-fs\n```\n\n> ===========\n>\n> = Summary =\n>\n> ===========\n>\n> Driver:   Not Selected\n> Toolkit:  Installed in /usr/local/cuda-11.7/\n>\n> Please make sure that\n>  -   PATH includes /usr/local/cuda-11.7/bin\n>  -   LD_LIBRARY_PATH includes /usr/local/cuda-11.7/lib64, or, add /usr/local/cuda-11.7/lib64 to /etc/ld.so.conf and run ldconfig as root\n>\n> To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.7/bin\n> ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 515.00 is required for CUDA 11.7 functionality to work.\n> To install the driver using this installer, run the following command, replacing <CudaInstaller> with the name of this run file:\n>    sudo <CudaInstaller>.run --silent --driver\n>\n> Logfile is /var/log/cuda-installer.log\n>\n> \n\n#### nvidia-fs\n\nhttps://github.com/NVIDIA/gds-nvidia-fs\n\n>[INFO]: previous version of nvidia-fs is not installed, nvidia-fs version: 2.14.14 will be installed.\n>[INFO]: getting mofed Status\n>[INFO]: installation status shows that mofed is not installed,please install mofed before continuing nvidia_fs install.\n>[ERROR]: Install of nvidia-fs failed, quitting\n\n\n\ndownload https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/\n\n\n\n\n\n#### nvcc\n\n```\n$ /usr/local/cuda-11.7/bin/nvcc -V\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Jun__8_16:49:14_PDT_2022\nCuda compilation tools, release 11.7, V11.7.99\nBuild cuda_11.7.r11.7/compiler.31442593_0\n```\n\n\n\n\n\n```\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"\nexport CUDA_HOME=\"/usr/local/cuda\"\n```\n\n> Check failed: s.ok() could not find cudnnCreate in cudnn DSO xxxxx undefined symbol: cudnnCreate\n\n\n\n\n\n### CUDNN\n\n下载地址：https://developer.nvidia.com/cudnn\n\n\n\n```\ntar -zxvf cudnn-8.0-linux-*.tgz\nsudo cp cuda/include/cudnn.h /usr/local/cuda/include/\nsudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/\nsudo chmod a+r /usr/local/cuda/include/cudnn.h\nsudo chmod a+r /usr/local/cuda/lib64/libcudnn*\n\n```\n\n>a+r所有人加上可执行权限，包括所有者，所属组，和其他人\n>o+x 只是给其他人加上可执行权限\n\n\n\n\n\n### 卸载内核\n\n```\ndpkg --get-selections |grep linux-image\n```\n\n>linux-image-5.10.0-21-amd64\t\t\tinstall\n>linux-image-6.1.0-0.deb11.6-amd64\t\tinstall\n>linux-image-amd64\t\t\t\tinstall\n\n\n\n```\ndpkg -l 'linux-image-*' | grep '^ii'\n```\n\n>ii  linux-image-5.10.0-21-amd64                5.10.162-1       amd64        Linux 5.10 for 64-bit PCs (signed)\n>ii  linux-image-6.1.0-0.deb11.6-amd64          6.1.15-1~bpo11+1 amd64        Linux 6.1 for 64-bit PCs (signed)\n>ii  linux-image-amd64                          6.1.15-1~bpo11+1 amd64        Linux for 64-bit PCs (meta-package)\n\n\n\n\n\n```\nsudo apt-get purge  linux-image-5.10.0-21-amd64\n```\n\n>正在清除 linux-image-5.10.0-21-amd64 (5.10.162-1) 的配置文件 ...\n>rmdir: 删除 '/lib/modules/5.10.0-21-amd64' 失败: 目录非空\n\n/lib/modules/5.10.0-21-amd64/\n","tags":["install","GPU CUDA","CUDA"],"categories":["tool","gpu"]},{"title":"venv虚拟环境","url":"//lang/python/venv/","content":"\n### venv\n\n\n\nhttps://docs.python.org/zh-cn/3/library/venv.html\n\n创建\n\n```\npython -m venv -h\n\npython -m venv /path/to/new/virtual/environment\n\nsource <venv>/bin/activate\n```\n\n激活\n\n```\npython3 -m venv /opt/stable-diffusion/sd-venv\n\n#激活虚拟环境\nsource /opt/stable-diffusion/sd-venv/bin/activate\n```\n\n>(sd-venv) cs@debian:/opt/stable-diffusion/\n\n\n\n```\n#查看当前pip源\npip config list\n#pip config set global.index-url 源网址\n\npip install -r requirements.txt\n\n#已经安装的包以requirements的格式\npip freeze\n\n\n\npip wheel -w ./tmp_dir -r requirements.txt\npip download  -d ./tmp_dir -r requirements.txt\npip install -no-index --find-links=./tmp_dir   -r requirements.txt\n```\n\n\n\n停止\n\n```\n#停止使用虚拟环境\nsource /opt/stable-diffusion/sd-venv/bin/deactivate\n```\n\n\n\n<!--more-->\n\nlist\n\n```\npip list | grep gradio\n```\n\n> gradio                   3.23.0\n\n\n\nshow\n\n```\npip show gradio\n```\n\n>Name: gradio\n>Version: 3.23.0\n>Summary: Python library for easily interacting with trained machine learning models\n>Home-page: None\n>Author: None\n>Author-email: Abubakar Abid <team@gradio.app>, Ali Abid <team@gradio.app>, Ali Abdalla <team@gradio.app>, Dawood Khan <team@gradio.app>, Ahsen Khaliq <team@gradio.app>, Pete Allen <team@gradio.app>, Ömer Faruk Özdemir <team@gradio.app>\n>License: None\n>Location: /home/cs/oss/sd/venv/lib/python3.9/site-packages\n>Requires: websockets, fastapi, markupsafe, fsspec, pydantic, huggingface-hub, altair, orjson, python-multipart, aiohttp, ffmpy, markdown-it-py, pillow, semantic-version, uvicorn, pyyaml, typing-extensions, pandas, huggingface-hub, httpx, numpy, aiofiles, matplotlib, requests, pydub, mdit-py-plugins, jinja2\n>Required-by: \n\n\n\n\n\n\n\n    if torch.cuda.is_available():\n      device = torch.device('cuda')\n    else:\n      device = torch.device('cpu')\n      \n    #等价  \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n\n加载cuda异常\n\n```\n>>> import torch\n>>> torch.cuda.is_available()\n/home/cs/.local/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n  return torch._C._cuda_getDeviceCount() > 0\nFalse\n>>> torch.cuda.is_available()\nFalse\n\n```\n\n>nvidia-modprobe 版本过低或未安裝，与显卡驱动的版本不匹配，将nvidia-modprobe更新至与显卡驱动的版本一致即可。  apt-get install nvidia-modprobe\n>\n>重装pytorch和CUDA也无济于事，后面查到是因为ubuntu在[suspend](https://so.csdn.net/so/search?q=suspend&spm=1001.2101.3001.7020)出现的问题，重启服务器**物理机**就可以了。  \n\n\n\n\n\n```\nsource /home/cs/data/sd-venv/bin/activate\n\nsudo python setup.py install --prefix /home/cs/.local\n\npython setup.py install --prefix /home/cs/stable-diffusion-webui/venv\n```\n\n\n\n7z x yajiu.7z \n\n\n\n\n\n#### python wheel 安装包的制作与安装\n\nhttp://coolpython.net/informal_essay/20-09/python-wheel-make-and-install.html\n","tags":["environment","venv","virtual"],"categories":["lang","python","venv"]},{"title":"nfs介绍","url":"//linux/tool/nfs/","content":"\n### NFS\n\nhttps://nfs.sourceforge.net/\n\n```\n#debian\nsudo apt-get install nfs-common   nfs-kernel-server  -y\n\n#centos\nsudo yum install nfs-utils   rpcbind   -y\n```\n\n>#下载安装包\n>\n>sudo apt-get install  nfs-common   nfs-kernel-server  -y  --download-only \n>\n>sudo yum install nfs-utils rpcbind   -y --downloadonly --downloaddir /opt/nfs\n\n![nfs](/pics/nfs-src.png)\n\n1. 首先服务器端启动RPC服务，并开启111端口；启动NFS服务，并向RPC注册端口信息\n2. 客户端启动RPC（portmap服务），向服务端的RPC(portmap)服务请求服务端的NFS端口（由程序在NFS客户端发起存取文件的请求，客户端本地的RPC(rpcbind)服务会通过网络向NFS服务端的RPC的111端口发出文件存取功能的请求。）\n3. 服务端的RPC(portmap)服务反馈NFS端口信息给客户端。\n4. 客户端通过获取的NFS端口来建立和服务端的NFS连接并进行数据的传输。（客户端获取正确的端口，并与NFS daemon联机存取数据。）\n5. 存取数据成功后，返回前端访问程序，完成一次存取操作。\n\n<!--more-->\n\n\n\n### 安装\n\n```\nsudo rpm -ivh  /opt/nfs/*.rpm --force --nodeps \n\n#debian\nsudo dpkg -i   /opt/nfs/*.deb\n```\n\n\n\n#### 服务端\n\n设置共享目录\n\n```\n#开启\nsystemctl enable nfs\nsystemctl restart nfs\nsystemctl status nfs\n#debian\nsystemctl status nfs-kernel-server\n\nmkdir -p /opt/data/k8s/redis/{pv{1..6},srcipt}\n\ncat  <<EOF |  tee -a  /etc/exports\n/opt/data/k8s/redis/pv1  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv2  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv3  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv4  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv5  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv6  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/srcipt  192.168.122.0/24(rw,sync,no_root_squash)\nEOF\n\ncat  <<EOF |  tee -a  /etc/exports\n/opt/data/k8s/mysql/pv1  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/mysql/pv2  192.168.122.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/mysql/pv3  192.168.122.0/24(rw,sync,no_root_squash)\nEOF\n\n\n#加载\nexportfs -arv\n\n#查看本机NFS共享目录\nshowmount -e\n```\n\n\n\n<details>\n  <summary>exports配置</summary>\n  <pre><a>/etc/exports</a><code>\n# /etc/exports: the access control list for filesystems which may be exported\n#\t\tto NFS clients.  See exports(5).\n#\n# Example for NFSv2 and NFSv3:\n# /srv/homes       hostname1(rw,sync,no_subtree_check) hostname2(ro,sync,no_subtree_check)\n#\n# Example for NFSv4:\n# /srv/nfs4        gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check)\n# /srv/nfs4/homes  gss/krb5i(rw,sync,no_subtree_check)\n#\n#/opt/data     ip地址为客户端的地址或网段(rw,sync,no_root_squash,insecure)\n/opt/data/k8s/redis/pv1  192.168.56.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv2  192.168.56.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv3  192.168.56.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv4  192.168.56.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv5  192.168.56.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/pv6  192.168.56.0/24(rw,sync,no_root_squash)\n/opt/data/k8s/redis/srcipt  192.168.56.0/24(rw,sync,no_root_squash)\n  </code></pre>\n</details>\n\n\n\n\n>exportfs: /etc/exports [3]: Neither 'subtree_check' or 'no_subtree_check' specified for export \"192.168.122.0/24:/home/cs/data/k8s/mysql/pv3\".\n>Assuming default behaviour ('no_subtree_check').\n>NOTE: this default has changed since nfs-utils version 1.0.x\n>\n>#即使输出目录是一个子目录,nfs服务器也不检查其父目录的权限\n>\n>/home/cs/data/k8s/mysql/pv3  192.168.122.0/24(rw,sync,no_root_squash,no_subtree_check)\n\n\n\n```\n❯ sudo exportfs -arv\nexporting 192.168.122.0/24:/mnt/data/k8s\n❯ sudo chown :cs -R //mnt/data/k8s\n❯ sudo chmod g+wr /mnt/data/k8s\n\n```\n\n\n\n\n\n\n#### 客户端\n\n\n\n```\n#服务端ip,查看服务端里面可以挂载的目录\nshowmount -e 192.168.122.6\n\n#挂载\nmount -t nfs 192.168.122.6:/opt/data/k8s/redis/srcipt   /opt/srcipt\n\nsudo mount -t nfs 192.168.122.6:/opt/data/k8s/mysql/pv3 /home/cs/oss/bak/pv3\n\n```\n\n>[root@base opt]# df -Th /opt/data/k8s/mysql/pv3\n>文件系统                类型  容量  已用  可用 已用% 挂载点\n>/dev/mapper/centos-root xfs    19G  2.6G   17G   14% /\n\n\n\n[开机自启挂载fstab](/linux/storage/fstab)\n\n```\necho \"192.168.122.6:/data /opt    nfs  default 0 0\" >>/etc/fstab\n```\n\n\n\n\n\n\n\n```\n$ showmount -e 192.168.122.8\n```\n\n>clnt_create: RPC: Port mapper failure - Unable to receive: errno 113 (No route to host)\n\n服务端防火墙\n\n```\nsystemctl status firewalld\n```\n\n>[root@test opt]# firewall-cmd --add-service=nfs\n>success\n>[root@test opt]# firewall-cmd --add-service=rpc-bind\n>success\n>[root@test opt]# firewall-cmd --add-service=mountd\n>success\n\n\n\n### 卸载\n\n\n\n```\n❯ sudo apt remove  --purge nfs-common   nfs-kernel-server\n\n❯ sudo apt autoremove\n\n```\n\n\n\n","tags":["nfs","rpc","storage"],"categories":["linux","tool","nfs"]},{"title":"regular expression","url":"//lang/regular-expression/","content":"\n## 基本规则\n\n| 字符  | 描述                                                         |\n| ----- | ------------------------------------------------------------ |\n| \\|    | 当有多个选项的使用，选项之间用”\\|“进行隔离。例如：匹配abc和DEF中的任意一项：abc\\|DEF。                             |\n| ()    | 匹配括号内容的内容。例如：(abc\\|DEF)可以匹配abc或者DEF。                           |\n| []    | 匹配括号中的任一字符，例如[abc]，可以匹配字符\"a\"，或者匹配字符\"b\"，或者匹配字符\"c\"。 |\n| \\*    | 匹配前面的子表达式零次或多次。例如，\"ab*\"能匹配 \"a\" 以及 \"abb\"。* 等价于{0,}。 |\n| \\+    | 匹配前面的子表达式一次或多次。例如，\"ab+\"能匹配 \"ab\" 以及 \"abb\"，但不能匹配 \"a\"。+ 等价于 {1,}。 |\n| ?     | 匹配前面的子表达式零次或一次。例如，\"a(b)?\"能匹配 \"a\"以及\"ab\"。? 等价于 {0,1}。 |\n| {n}   | 是一个非负整数。匹配确定的 n 次。例如，'a{2}' 能匹配 \"baac\" 中的两个 a， 但是不能匹配bac中的一个a。 |\n| {n,}  | 是一个非负整数。至少匹配n 次。例如，'a{2,}' 不能匹配 \"bac\" 中的一个a，但能匹配 \"baaaac\" 中的全部a。 |\n| {n,m} | 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。例如，\"a{1,3}\" 将匹配 \"baaaaaac\"中的前三个a。注意：在逗号和两个数之间不能有空格。 |\n\n\n|\t当有多个选项的使用，选项之间用”|“进行隔离。例如：匹配abc和DEF中的任意一项：abc|DEF。\n()\t匹配括号内容的内容。例如：(abc|DEF)可以匹配abc或者DEF。\n[]\t匹配括号中的任一字符，例如[abc]，可以匹配字符\"a\"，或者匹配字符\"b\"，或者匹配字符\"c\"。\n\\*\t匹配前面的子表达式零次或多次。例如，\"ab*\"能匹配 \"a\" 以及 \"abb\"。* 等价于{0,}。\n\\+\t匹配前面的子表达式一次或多次。例如，\"ab+\"能匹配 \"ab\" 以及 \"abb\"，但不能匹配 \"a\"。+ 等价于 {1,}。\n?\t匹配前面的子表达式零次或一次。例如，\"a(b)?\"能匹配 \"a\"以及\"ab\"。? 等价于 {0,1}。\n{n}\tn 是一个非负整数。匹配确定的 n 次。例如，'a{2}' 能匹配 \"baac\" 中的两个 a， 但是不能匹配bac中的一个a。\n{n,}\tn 是一个非负整数。至少匹配n 次。例如，'a{2,}' 不能匹配 \"bac\" 中的一个a，但能匹配 \"baaaac\" 中的全部a。\n{n,m}\tm 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。例如，\"a{1,3}\" 将匹配 \"baaaaaac\"中的前三个a。注意：在逗号和两个数之间不能有空格。\n\n\n<!--more-->\n\n\n\n### 多个匹配\n\n匹配token或image存在前面就加#####\n\n```\nsed -n \"s/\\(token\\|image\\)/######&/\"p  ./kubeadm-config.yaml\n```\n\n>  ######token: \"9a08jv.c0izixklcxtmnze7\"\n>  description: \"kubeadm bootstrap ######token\"\n>      system:bootstrappers:kubeadm:default-node-######token\n>  ######token: uxzaiw.1ar6vc7zi0r16rt6\n>   ######imagePullPolicy: IfNotPresent\n>    ######imageRepository: \"k8s.org/k8s\"\n>    ######imageTag: \"3.5.6-0\"\n>   ######imageRepository: k8s.org/k8s\n\n\n\n\n\n\n\n","tags":["regular","replace","match"],"categories":["lang","regular"]},{"title":"ansible playbook","url":"//linux/tool/ansible1/","content":"\n## Roles\n\nRoles 就是通过分别将变量、文件、任务、模块及处理器放置于单独的目录中，并可以便捷地 include 它们\n\nhttp://www.ansible.com.cn/docs/playbooks_roles.html#roles\n\n```\n└── roles\n    └── k8s\n        ├── files  用来存放由 copy 模块或 script 模块调用的文件\n        ├── library\n        ├── tasks 包含一个 main.yml 文件，用于定义此角色的任务列表，此文件可以使用 include 包含其它的位于此目录的 task 文件\n        └── vars  包含一个 main.yml 文件，用于定义此角色用到的变量\t\n \t\t└──templates\t用来存放正则模板，template 模块会自动在此目录中寻找正则模板文件\n\t\t └──handlers\t此目录应当包含一个 main.yml 文件，用于定义此角色中触发条件时执行的动作\n\t\t └──defaults\t此目录应当包含一个 main.yml 文件，用于为当前角色设定默认变量\n\t \t└──meta\t此目录应当包含一个 main.yml 文件，用于定义此角色的特殊设定及其依赖关系\n\t.......\n```\n\n>根据情况删减目录\n\n\n\n目录\n\n>cni /opt/cni/bin\n>\n>cni config /etc/cni/net.d\n>\n>containerd /etc/containerd/config.toml\n>\n>crictl /etc/crictl.yaml\n\n<!--more-->\n\n\n\n### copy\n\n\n\n```\ncs@debian:~$ ansible k8s-img -m copy -a \"src=/opt/kubernetes/cni/net.d/10-flannel.conflist dest=/etc/cni/net.d/ mode=0644\"\n```\n\n>src参数 ：用于指定需要copy的文件或目录。\n>\n>dest参数 ：用于指定文件将被拷贝到远程主机的哪个目录中，dest为必须参数。\n>\n>content参数 ：当不使用src指定拷贝的文件时，可以使用content直接指定文件内容，src与content两个参数必有其一，否则会报错。\n>\n>force参数 : 当远程主机的目标路径中已经存在同名文件，并且与ansible主机中的文件内容不同时，是否强制覆盖，可选值有yes和no，默认值为yes，表示覆盖，如果设置为no，则不会执行覆盖拷贝操作，远程主机中的文件保持不变。\n>\n>backup参数 : 当远程主机的目标路径中已经存在同名文件，并且与ansible主机中的文件内容不同时，是否对远程主机的文件进行备份，可选值有yes和no，当设置为yes时，会先备份远程主机中的文件，然后再将ansible主机中的文件拷贝到远程主机。\n>\n>owner参数 : 指定文件拷贝到远程主机后的属主，但是远程主机上必须有对应的用户，否则会报错。\n>\n>group参数 : 指定文件拷贝到远程主机后的属组，但是远程主机上必须有对应的组，否则会报错。\n>\n>mode参数 : 指定文件拷贝到远程主机后的权限，如果你想将权限设置为”rw-r--r--“，则可以使用mode=0644表示，如果你想要在user对应的权限位上添加执行权限，则可以使用mode=u+x表示。\n\n\n\n","tags":["xxx","xx","ansible","playbook"],"categories":["linux","tool","ansible1"]},{"title":"ansible安装使用入门","url":"//linux/tool/ansible/","content":"\n\n\n## 安装\n\n### 准备\n\n下载地址\n\n<https://github.com/ansible/ansible/releases>\n\n设置源\n\ncs\\@debian:~\\$ cat  ~/.pip/pip.conf\n\\[global]\ntrusted-host=mirrors.aliyun.com\nindex-url=<http://mirrors.aliyun.com/pypi/simple/>\n\n### `get-pip.py`\n\nThis is a Python script that uses some bootstrapping logic to install pip.\n\n- Download the script, from https://bootstrap.pypa.io/get-pip.py.\n\n- Open a terminal/command prompt, `cd` to the folder containing the `get-pip.py` file and run:\n\n  Linux\n\n  ```\n  $ python get-pip.py\n  ```\n\n>No module named 'distutils.cmd'    #依赖 python3.x-distutils \n>\n>export PATH=\"$HOME/.local/bin:$PATH\"\n\n### 开始\n\ncd   ansible-2.10.0\n\n#### 安装依赖\n\npip install --user -r ./requirements.txt\n\n#### 正式安装\n\npython setup.py install\n\nansible --version\n\n> pkg\\_resources.DistributionNotFound: The 'jinja2'\n>\n> pip list 查看，执行用户没有安装该模板\n\n<!--more-->\n\n## 使用\n\n*   [Control node](https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html#control-node)\n*   [Managed nodes](https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html#managed-nodes)\n*   [Inventory](https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html#inventory)\n*   [Modules](https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html#modules)\n*   [Tasks](https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html#tasks)\n*   [Playbooks](https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html#playbooks)\n\n### 示例\n\n**使用root用户执行命令**\n\n*   \\-m  模块\n\n*   \\-a  命令\n\n*   –become 或 -b\n\n*   –become-method    \\[ sudo | su | pbrun | pfexec | doas | dzdo | ksu | runas | machinectl ]\n\n*   –become-user\n\n*   –ask-become-pass 或 -K\n\n```shell\nansible  node  -m shell -a \"cat /etc/docker/key.json\"    -b --become-method su --become-user root  -K\n```\n\n> BECOME password: 输入密码\n\n\n\n#### copy\n\n```\nansible test -m copy -a \"src=/opt/zabbix/etc/zabbix_agentd.conf.d/agent.conf dest=/etc/zabbix/zabbix_agentd.d/\"  -b --become-method sudo --become-user root\n\n```\n\n\n\n\n\n#### 加密文件\n\n对密码等保密信息进行加密\n\n##### [创建加密文件 ](#create_yaml)\n\n设置文件密码,调用vi 编辑器,写入保密信息\n\n```shell\nansible-vault create  node-pass.yaml\n```\n\n> cs\\@debian:/opt/ansible`$cat node-pass.yaml $`ANSIBLE\\_VAULT;1.1;AES256\n> 39336263626462323665333364313465343437613332656562383532366436363036373662336630\n> 6666313066386532663833623237633833356235633765660a666631396236636136656239613062\n> 62363333373961363239333735343061656638366537323332353335353861623137666232393037\n> 3164633166613864360a383833386538343337326335636135323435313532346665336562356464\n> 31363663633930653434633564656231663566303538393066346236363731386132\n\n##### 解密 已加密文件\n\n```shell\nansible-vault decrypt  node-pass.yaml\n```\n\n> cs\\@debian:/opt/ansible\\$ cat node-pass.yaml\n> \\---\n> password: 123456\n\n##### 加密 解密后的文件\n\n```shell\nansible-vault encrypt  node-pass.yaml\n```\n\n> cs\\@debian:/opt/ansible`$ ansible-vault encrypt  node-pass.yaml \n> New Vault password: \n> Confirm New Vault password: \n> Encryption successful\n> cs@debian:/opt/ansible$` cat node-pass.yaml\n> \\$ANSIBLE\\_VAULT;1.1;AES256\n> 64383861626430373864316636386430306463656436623238386238303537313964396238343133\n> 3763333630643336333930333934653466393863366365390a386637343761376430613465333233\n> 33643364633930346466646233356637333862653730663063636332653436353635643535376164\n> 3061396164616266380a656239313837353632386562613531633539313461343764376139373838\n> 38616631616565316264366436326665646665663866306161396132303236313234\n\n##### 编辑加密文件\n\n```shell\nansible-vault edit  node-pass.yaml \n```\n\n> cs\\@debian:/opt/ansible\\$ ansible-vault edit  node-pass.yaml\n> Vault password:\n\n##### 查看加密文件\n\n仅查看的内容而不进行编辑\n\n```shell\nansible-vault view  node-pass.yaml \n```\n\n> cs\\@debian:/opt/ansible\\$ ansible-vault view  node-pass.yaml\n> Vault password:\n> \\---\n> password: 123456\n\n##### [加密字符串](#create_string)\n\n```shell\nansible-vault encrypt_string --vault-id dev@a_password_file  '123456' --name 'become_pass'\n```\n\n> cs\\@debian:/opt/ansible`$ansible-vault encrypt_string --vault-id dev@a_password_file  '123456' --name 'become_pass'\n> become_pass: !vault |\n>       $`ANSIBLE\\_VAULT;1.2;AES256;dev\n> 36636239393163616238326666343263613830363731333662373136313462613138356136616166\n> 3264613139643933333663303938613539653963633038370a383961343836633937316362633437\n> 33393836383734633838656130366666353838306234303762623966323764613465373865633865\n> 6630323763396663300a303135353765613539306465363837653566613139353265373833613830\n> 6135\n> Encryption successful\n\n*   dev 代表标签\n\n*   a\\_password\\_file  一个文件,里面是`--vault-id @prompt ` 的值\n\n*   '123456'  字符串的明文,即密码,不推荐这样操作\n\n*   \\--name  指定变量名\n\n推荐\n\n```shell\n ansible-vault encrypt_string --vault-id dev@a_password_file --stdin-name 'become_pass'\n```\n\n> Reading plaintext input from stdin. (ctrl-d to end input)\n> 123456\n\n\\### <span id=\"jump1\">1. 目录1</span>\n\n####  ansible-playbook\n\n\n\n##### 引用加密文件\n\n```shell\n ansible-playbook  /opt/ansible/yaml/local-b.yaml       --vault-id @prompt\n```\n\n> cs\\@debian:\\~\\$ ansible-playbook  /opt/ansible/yaml/local-b.yaml       --vault-id @prompt\n> Vault password (default): 输入保护文件的密码,解密文件内容\n\n<span id=\"create_yaml\">node-pass.yaml</span>见创建加密文件\n\n```yaml\n# /opt/ansible/yaml/local-b.yaml\n---\n- hosts: node\n  vars_files:\n    - /opt/ansible/node-pass.yaml\n  tasks:\n  - name: Run a command\n    become: yes\n    become_method: su\n    vars:\n       ansible_become_pass: \"{{ password }}\"\n    file:   \n      state: absent \n      path: /opt/kubernetes/amd64/kube-apiserver\n```\n\n> vars\\_files 引入文件\n>\n> file 操作文件的模块\n\nfile模块主要用于远程主机上的文件操作\n\n*   force：需要在两种情况下强制创建软链接，一种是源文件不存在但之后会建立的情况下；另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no\n*   group：定义文件/目录的属组\n*   mode：定义文件/目录的权限\n*   owner：定义文件/目录的属主\n*   path：必选项，定义文件/目录的路径\n*   recurse：递归的设置文件的属性，只对目录有效\n*   src：要被链接的源文件的路径，只应用于state=link的情况\n*   dest：被链接到的路径，只应用于state=link的情况\n*   state： directory：如果目录不存在，创建目录\n    file：即使文件不存在，也不会被创建\n    link：创建软链接\n    hard：创建硬链接\n    touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间\n    absent：删除目录、文件或者取消链接文件\n\n##### 引用文件内加密变量\n\n```shell\nansible-playbook /opt/ansible/yaml/local-b.yaml  --vault-password-file /opt/ansible/a_password_file \n```\n\n<span id=\"create_string\">custom.yaml</span>  见创建加密变量\n\n```yaml\n# 加密变量\n---\ncustom_vars:\n    become_pass: !vault |\n          $ANSIBLE_VAULT;1.2;AES256;dev\n          66383637343038636234353234353062633966663738616666653931353730333839653362373935\n          6632343665313561333435323366376661343065636133340a373866373835303731383034653663\n          31633938616330343535393339626163656630323233316566393264306462666434303434383263\n          6333386535323666330a623965623436373464653734383736663464356664343439343837613039\n          3635\n```\n\nlocal-b.yaml\n\n```yaml\n---\n- hosts: node\n  vars_files:\n    - /opt/ansible/custom.yaml\n  tasks:\n  - name: Run a command\n    become: yes\n    #become_user: root\n    become_method: su\n    vars:\n       ansible_become_pass: \"{{ custom_vars.become_pass }}\"\n    file:   \n      state: absent \n      path: /opt/kubernetes/amd64/kube-apiserver\n```\n\n\n\n\n\n","tags":["install","xxx","ansible"],"categories":["linux","tool","ansible"]},{"title":"自定义cmd命令","url":"//linux/shell/customcmd/","content":"\ntypora没有details快捷的插入标签功能，对xml这种折叠不行，其他文本还可以\n\n![](/pics/details-gif.gif)\n\n## 脚本\n\n/home/cs/.local/custom/details.sh\n\n```\nxdetails_helpdoc(){\n    cat <<EOF\nDescription:\n   处理文档，方便粘贴到typora,实现折叠效果\nUsage:\n   xdetails  file\neg:\n  xdetails  /home/cs/data/kvm/default.xml\n--------------------------------------------------\n<details>\n  <summary>折叠代码块</summary>\n  <pre><a>xxxx</a><xmp>\n<network>\n  <input type='tablet' bus='usb'>\n    <address type='usb' bus='0' port='1'/>\n  </input>\n</network>\n  </xmp></pre>\n</details>\n------------------------------------------------------\nEOF\n}\n\n\n\nxdetails_space(){\n\tcat >$2<<EOF\n<details>\n  <summary>折叠代码块</summary>\n  <pre><a>xxxx</a><code>\nEOF\n  \n  sed  \"s/^$/<\\/br>/\" $1 >>$2\n\n\tcat >>$2<<EOF\n  </code></pre>\n</details>\nEOF\n\necho \"对${1##*.}文本使用</br>替换标签。。。\" \n\n}\n\n\n\nxdetails_xml(){\n\n\tcat >$2<<EOF\n<details>\n  <summary>折叠代码块</summary>\n  <pre><a>xxxx</a><xmp>\nEOF\n\n  sed  \"/^$/d\" $1 >>$2\n\n\tcat >>$2<<EOF\n  </xmp></pre>\n</details>\nEOF\n\necho \"对xml文本使用xmp标签处理。。。\"\n\n}\n\n\ndetails(){\n  target=\"/tmp/${1##*/}.new\"\n if [ -f \"$1\" ] \n then\n      [  \"xml\" = \"${1##*.}\" ] || { echo \"开始对：${1##*/} 处理。。。\" && xdetails_space $1 $target ;}\n      [  \"xml\" != \"${1##*.}\" ] || { echo \"开始对：${1##*/} 处理。。。\"  && xdetails_xml $1 $target;}\n      cat $target | xsel -i -b  && echo \"已复制到剪贴板中\" \n      echo  \"新文件路径：$target\"\n else\n       xdetails_helpdoc\n  fi\n}\n```\n\n把定义脚本统一放到custom目录\n\n<!--more-->\n\n## 引入\n\n\n\n```\ncs@debian:~/oss/hexo$ cat ~/.bashrc  |grep  -A 25 custom\n######### custom start###########\nCMD(){\n  url=~/.local/custom/$1\n  [ -f \"$url\" ] && source $url\n}\n\nif [ -n \"$(command -v xsel)\" ] ; then\n  CMD details.sh\n  alias xdetails='details $@'\nfi\n\n######### custom end###########\n```\n\n\n\n## 使用\n\n刷新，开始使用\n\n```\ncs@debian:~/oss/hexo$ source ~/.bashrc \ncs@debian:~/oss/hexo$ xdetails \nDescription:\n   处理文档，方便粘贴到typora,实现折叠效果\nUsage:\n   xdetails  file\neg:\n  xdetails  /home/cs/data/kvm/default.xml\n--------------------------------------------------\n<details>\n  <summary>折叠代码块</summary>\n  <pre><a>xxxx</a><xmp>\n<network>\n  <input type='tablet' bus='usb'>\n    <address type='usb' bus='0' port='1'/>\n  </input>\n</network>\n  </xmp></pre>\n</details>\n------------------------------------------------------\ncs@debian:~/oss/hexo$ xdetails /home/cs/data/kvm/default.xml\n开始对：default.xml 处理。。。\n对xml文本使用xmp标签处理。。。\n已复制到剪贴板中\n新文件路径：/tmp/default.xml.new\n```\n\n\n\n\n\n\n\n<details>\n  <summary>折叠xml</summary>\n  <pre><a>折叠xml文本typora不显示，网页会正常</a><xmp>\n<!--\nWARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE\nOVERWRITTEN AND LOST. Changes to this xml configuration should be made using:\n  virsh net-edit default\nor other application using the libvirt API.\n-->\n<network>\n  <name>default</name>\n  <uuid>f527b455-06b2-4bd2-87cd-7c4c84ef899d</uuid>\n  <forward mode='nat'/>\n  <bridge name='virbr0' stp='on' delay='0'/>\n  <mac address='52:54:00:b5:1f:85'/>\n  <ip address='192.168.122.1' netmask='255.255.255.0'>\n    <dhcp>\n      <range start='192.168.122.2' end='192.168.122.254'/>\n      <host mac='52:54:00:ed:75:fc' name='centos7-01' ip='192.168.122.11'/>\n    </dhcp>\n  </ip>\n</network>\n  </xmp></pre>\n</details>\n\n\n\n<details>\n  <summary>折叠普通文本</summary>\n  <pre><a>peek一个生成gif软件</a><code>\ncs@debian:~/下载$ sudo dpkg -i /home/cs/下载/peek_1.5.1-1_amd64.deb\n[sudo] cs 的密码：\n正在选中未选择的软件包 peek。\n(正在读取数据库 ... 系统当前共安装有 112082 个文件和目录。)\n准备解压 .../下载/peek_1.5.1-1_amd64.deb  ...\n正在解压 peek (1.5.1-1) ...\n......\n正在设置 libcdio-cdda2:amd64 (10.2+2.0.0-1+b2) ...\n正在设置 libcdio-paranoia2:amd64 (10.2+2.0.0-1+b2) ...\n正在设置 libavdevice58:amd64 (7:4.3.5-0+deb11u1) ...\n正在设置 ffmpeg (7:4.3.5-0+deb11u1) ...\n正在设置 peek (1.5.1-1) ...\n正在处理用于 libc-bin (2.31-13+deb11u5) 的触发器 ...\n正在处理用于 man-db (2.9.4-2) 的触发器 ...\n  </code></pre>\n</details>\n","tags":["cmd","bashrc","custom"],"categories":["linux","shell"]},{"title":"截取分割","url":"//linux/shell/split/","content":"\n## #$%\n\n| 格式                       | 说明                                                         |\n| -------------------------- | ------------------------------------------------------------ |\n| ${string: start :length}   | 从 string 字符串的左边第 start 个字符开始，向右截取 length 个字符。 |\n| ${string: start}           | 从 string 字符串的左边第 start 个字符开始截取，直到最后。    |\n| ${string: 0-start :length} | 从 string 字符串的右边第 start 个字符开始，向右截取 length 个字符。 |\n| ${string: 0-start}         | 从 string 字符串的右边第 start 个字符开始截取，直到最后。    |\n| ${string#*chars}           | 从 string 字符串第一次出现 *chars 的位置开始，截取 *chars 右边的所有字符。 |\n| ${string##*chars}          | 从 string 字符串最后一次出现 *chars 的位置开始，截取 *chars 右边的所有字符。 |\n| ${string%*chars}           | 从 string 字符串第一次出现 *chars 的位置开始，截取 *chars 左边的所有字符。 |\n| ${string%%*chars}          | 从 string 字符串最后一次出现 *chars 的位置开始，截取 *chars 左边的所有字符。 |\n\n\n\n\n\n```\nvar=https://github.com/csyuancode/csyuancode.github.io/tree/master/js\n```\n\n\n\n### `#` \n\n从左边开始截取删除保留匹配剩下字符\n\n\n\n```\ncs@debian:~/oss/hexo$ var=https://github.com/csyuancode/csyuancode.github.io/tree/master/js\n\n#一次匹配\ncs@debian:~/oss/hexo$ echo ${var#*cs}\nyuancode/csyuancode.github.io/tree/master/js\n\n##最后一次匹配\ncs@debian:~/oss/hexo$ echo ${var##*cs}\nyuancode.github.io/tree/master/js\n\n```\n\n![](/pics/split-zifu-q.png)\n\n\n\n\n\n### `%`\n\n从末尾开始往前删除保留匹配剩下字符\n\n```\ncs@debian:~/oss/hexo$ var=https://github.com/csyuancode/csyuancode.github.io/tree/master/js\n\n#截取从后面开始第一次cs前字符\ncs@debian:~/oss/hexo$ echo ${var%cs*}\nhttps://github.com/csyuancode/\n\n#截取从后面开始最一次cs前字符\ncs@debian:~/oss/hexo$ echo ${var%%cs*}\nhttps://github.com/\n```\n\n<!--more-->\n\n![](/pics/split-zifu-h.png)\n\n\n\n\n\n\n\n## tr\n\n去除空行\n\n```\ncat file.txt |tr -s ‘\\n’\n\ncat file.txt |sed '/^$/d'\n```\n\n\n\n\n\n\n\n","tags":["sed","split","partition"],"categories":["linux","shell","split"]},{"title":"containerd安装","url":"//linux/k8s/containerd/","content":"\n\n\n## Installing containerd \n\nhttps://github.com/containerd/containerd/releases   \n\n<p id=\"containerd\" hidden/>\n\n```\n$ tar -zxvf  ../containerd-1.6.19-linux-amd64.tar.gz\nscp ./bin/*  root@k8s01:/usr/local/bin\n```\n\n>Warning: Permanently added 'k8s01,192.168.122.11' (ECDSA) to the list of known hosts.\n>containerd                                    100%   50MB 172.4MB/s   00:00    \n>containerd-shim                               100% 7180KB 167.3MB/s   00:00    \n>containerd-shim-runc-v1                       100% 9248KB 161.9MB/s   00:00    \n>containerd-shim-runc-v2                       100% 9264KB 169.7MB/s   00:00    \n>containerd-stress                             100%   22MB 146.9MB/s   00:00    \n>ctr                                           100%   26MB 193.4MB/s   00:00  \n\n<!--more-->\n\n### containerd.service\n\n/usr/local/lib/systemd/system/containerd.service\n\n```\ncat  <<EOF >/etc/systemd/system/containerd.service\n[Unit]\nDescription=containerd container runtime\nDocumentation=https://containerd.io\nAfter=network.target local-fs.target\n\n[Service]\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/local/bin/containerd\n\nType=notify\nDelegate=yes\nKillMode=process\nRestart=always\nRestartSec=5\n# Having non-zero Limit*s causes performance problems due to accounting overhead\n# in the kernel. We recommend using cgroups to do container-local accounting.\nLimitNPROC=infinity\nLimitCORE=infinity\nLimitNOFILE=1048576\n# Comment TasksMax if your systemd version does not supports it.\n# Only systemd 226 and above support this version.\nTasksMax=infinity\nOOMScoreAdjust=-999\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n>- `Delegate`: 这个选项允许 containerd 以及运行时自己管理自己创建容器的 cgroups。如果不设置这个选项，systemd 就会将进程移到自己的 cgroups 中，从而导致 containerd 无法正确获取容器的资源使用情况。\n>- `KillMode` 这个选项用来处理 containerd 进程被杀死的方式。默认情况下，systemd 会在进程的 cgroup 中查找并杀死 containerd 的所有子进程。KillMode 字段可以设置的值如下。\n>  - `control-group`（默认值）：当前控制组里面的所有子进程，都会被杀掉\n>  - `process`：只杀主进程,可以确保升级或重启 containerd 时不杀死现有的容器\n>  - `mixed`：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号\n>  - `none`：没有进程会被杀掉，只是执行服务的 stop 命令\n>\n>\n\n\n\n\n\n### config.toml\n\n/etc/containerd/config.toml\n\n```\ncontainerd config default > ../containerd/config.toml\nscp  -r ./containerd  root@k8s01:/etc\n```\n\n>Warning: Permanently added 'k8s01,192.168.122.11' (ECDSA) to the list of known hosts.\n>config.toml                                   100% 7154     6.8MB/s   00:00 \n\n#### pause\n\nsandbox_image = \"k8s.org/k8s/pause:3.6\"\n\n#### Systemd\n\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n\n```\n SystemdCgroup = true\n```\n\n\n\n#### 配置源\n\n[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n\n          [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.org\"]\n            endpoint = [\"https://k8s.org\"]\n\nhttps://github.com/containerd/containerd/blob/main/docs/cri/config.md\n\n```\ncat > hosts.toml <<EOF\nserver = \"https://k8s.org\"\n\n[host.\"https://k8s.org\"]\n  ca = \"/opt/k8s.org/ca.crt\"\n  client = [\"/opt/k8s.org/k8s.org.cert\", \"/opt/k8s.org/k8s.org.key\"]\nEOF\n```\n\nhttps://github.com/containerd/containerd/blob/main/docs/hosts.md\n\n\n\n\n\n#### 启动\n\n```\nsystemctl daemon-reload && systemctl restart containerd.service\nsystemctl enable --now containerd\n```\n\n\n\n#### ctr\n\n\n\n```\n# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nk8s.org        \n```\n\n\n\nx509 报错\n\n```\n# ctr i pull   k8s.org/k8s/pause:3.9    -k\n```\n\n>k8s.org/k8s/pause:3.9:                                                            resolved       |++++++++++++++++++++++++++++++++++++++| \n>manifest-sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4: done           |++++++++++++++++++++++++++++++++++++++| \n>layer-sha256:61fec91190a0bab34406027bbec43d562218df6e80d22d4735029756f23c7007:    done           |++++++++++++++++++++++++++++++++++++++| \n>config-sha256:e6f1816883972d4be47bd48879a08919b96afcd344132622e4d444987919323c:   done           |++++++++++++++++++++++++++++++++++++++| \n>elapsed: 1.9 s                                                                    total:   0.0 B (0.0 B/s)                                         \n>unpacking linux/amd64 sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4...\n>done: 430.599969ms\t\n\n\n\n```\n# ctr i ls \n```\n\n>REF                   TYPE                                                 DIGEST                                                                  SIZE      PLATFORMS   LABELS \n>k8s.org/k8s/pause:3.9 application/vnd.docker.distribution.manifest.v2+json sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4 311.6 KiB linux/amd64 -      \n\n\n\nrm\n\n```\n# ctr i  rm  registry.aliyuncs.com/google_containers/pause:3.6\nregistry.aliyuncs.com/google_containers/pause:3.6\n```\n\n\n\n\n\n#### crictl\n\nhttps://github.com/kubernetes-sigs/cri-tools/releases\n\n\n\n```\ncat > ./crictl.yaml <<EOF\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 10\ndebug: false\npull-image-on-create: false\nEOF\n```\n\n\n\n```\ntar -zxvf ../crictl-v1.26.0-linux-amd64.tar.gz\nscp ./crictl root@k8s01:/usr/local/bin\n```\n\n>Warning: Permanently added 'k8s01,192.168.122.11' (ECDSA) to the list of known hosts.\n>crictl                                        100%   50MB 172.6MB/s   00:00\n\n\n\n## Installing runc\n\n https://github.com/opencontainers/runc/releases\n\n```\n$ scp runc.amd64   root@k8s01:/opt\n```\n\n>Warning: Permanently added 'k8s01,192.168.122.11' (ECDSA) to the list of known hosts.\n>runc.amd64                                    100% 9210KB 146.6MB/s   00:00 \n\n\n\n```\n# install -m 755 runc.amd64 /usr/local/sbin/runc\n# ll /usr/local/sbin/runc\n-rwxr-xr-x. 1 root root 9431456 3月   1 21:33 /usr/local/sbin/runc\n\n```\n\n\n\n\n\n## Installing CNI plugins\n\n\n\nhttps://github.com/containernetworking/plugins/releases/download/v1.2.0/cni-plugins-linux-amd64-v1.2.0.tgz\n\n\n\n```\ntar -zxvf  ../cni-plugins-linux-amd64-v1.2.0.tgz  -C ./cni/bin\n\n#/opt/cni/bin\nscp -r ./cni  root@k8s01:/opt\n```\n\n>Warning: Permanently added 'k8s01,192.168.122.11' (ECDSA) to the list of known hosts.\n>ptp                                           100% 4064KB 121.7MB/s   00:00    \n>vlan                                          100% 3900KB 175.7MB/s   00:00    \n>tuning                                        100% 3357KB 168.7MB/s   00:00    \n>macvlan                                       100% 3935KB 165.2MB/s   00:00    \n>bandwidth                                     100% 3769KB 171.7MB/s   00:00    \n>loopback                                      100% 3274KB 169.4MB/s   00:00    \n>bridge                                        100% 4198KB 164.9MB/s   00:00    \n>dhcp                                          100% 9929KB 176.3MB/s   00:00    \n>portmap                                       100% 3658KB 169.1MB/s   00:00    \n>ipvlan                                        100% 3906KB 128.2MB/s   00:00    \n>firewall                                      100% 4282KB 127.3MB/s   00:00    \n>host-device                                   100% 3780KB 160.8MB/s   00:00    \n>dummy                                         100% 3893KB 162.8MB/s   00:00    \n>host-local                                    100% 3210KB 160.2MB/s   00:00    \n>sbr                                           100% 3467KB 167.2MB/s   00:00    \n>static                                        100% 2779KB 161.2MB/s   00:00    \n>vrf                                           100% 3502KB 166.9MB/s   00:00   \n\n\n\n\n\n\n\nlevel=error msg=\"failed to load cni during init, please check CRI plugin status before setting up network for pods\" error=\"cni config load failed: no network config found in /etc/cni/net.d: cni plugin not initialized: failed to load cni config\"\n","tags":["xxx","xx","containerd安装"],"categories":["linux","k8s","containerd"]},{"title":"scp上传下载","url":"//linux/shell/scp/","content":"\n## \n\n```\nscp [可选参数] file_source file_target\n```\n\n>- -F ssh_config： 指定一个替代的ssh配置文件，此参数直接传递给ssh。\n>- -i identity_file： 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。\n>- -P port：注意是大写的P, port是指定数据传输用到的端口号\n>- -q： 不显示传输进度条。\n>- -r： 递归复制整个目录。\n>- -v：详细方式显示输出。\n>\n>\n\n<!--more-->\n\n\n\n## 上传\n\n\n\n```\ncs@debian:~/下载/k8s$ ls -l ./kube*\n-rwxr-xr-x 1 cs cs  47554560  2月 28 17:10 ./kubeadm\n-rwxr-xr-x 1 cs cs  48644096  2月 28 17:10 ./kubectl\n-rwxr-xr-x 1 cs cs 122036984  2月 28 17:10 ./kubelet\n\nscp ./kube* root@192.168.122.11:/usr/local/bin/\n```\n\n>Warning: Permanently added '192.168.122.11' (ECDSA) to the list of known hosts.\n>root@192.168.122.11's password: \n>kubeadm                                       100%   45MB 113.6MB/s   00:00    \n>kubectl                                       100%   46MB  87.2MB/s   00:00    \n>kubelet                                       100%  116MB 136.2MB/s   00:00    \n\n\n\nscp -r ./lib root@121.41.40.138:/data/www/test\n\nscp -i ~/.ssh/aliyun-tcs.pem ./dist.tar.gz root@121.41.40.138:/data/www/test\n\n\n\n## 下载\n\n\n\n```\nscp root@121.41.40.138:/data/www/test/image.json ./photos/\n```\n\n\n\n```\nscp -r root@121.41.40.138:/data/www/test/image ./\n```\n\n","tags":["xxx","xx","scp上传下载"],"categories":["linux","shell","scp"]},{"title":"harbor容器仓库","url":"//linux/tool/harbor/","content":"\n## 仓库安装\n\n[安装](/linux/k8s/harbor#harbor-install)\n\n<!--more-->\n\n```\n<details>\n  <summary>折叠代码块</summary>\n  <pre><code> \n     System.out.println(\"虽然可以折叠代码块\");\n     System.out.println(\"但是代码无法高亮\");\n  </code></pre>\n</details>\n\n<details>\n  <summary>折叠代码块</summary>\n  <pre><xmp> \n     System.out.println(\"不渲染\");\n     <input />\n  </xmp></pre>\n</details>\n```\n\n\n\n\n\n## containerd\n\n/etc/containerd/config.toml\n\n<details>\n  <summary>config.toml</summary>\n  <pre><a>/etc/containerd/config.toml</a><code>\n  disabled_plugins = []\nimports = []\noom_score = 0\nplugin_dir = \"\"\nrequired_plugins = []\nroot = \"/var/lib/containerd\"\nstate = \"/run/containerd\"\ntemp = \"\"\nversion = 2\n</br>\n[cgroup]\n  path = \"\"\n</br>\n[debug]\n  address = \"\"\n  format = \"\"\n  gid = 0\n  level = \"\"\n  uid = 0\n</br>\n[grpc]\n  address = \"/run/containerd/containerd.sock\"\n  gid = 0\n  max_recv_message_size = 16777216\n  max_send_message_size = 16777216\n  uid = 0\n</br>\n[metrics]\n  address = \"\"\n  grpc_histogram = false\n</br>\n[plugins]\n</br>\n  [plugins.\"io.containerd.gc.v1.scheduler\"]\n    deletion_threshold = 0\n    mutation_threshold = 100\n    pause_threshold = 0.02\n    schedule_delay = \"0s\"\n    startup_delay = \"100ms\"\n</br>\n  [plugins.\"io.containerd.grpc.v1.cri\"]\n    device_ownership_from_security_context = false\n    disable_apparmor = false\n    disable_cgroup = false\n    disable_hugetlb_controller = true\n    disable_proc_mount = false\n    disable_tcp_service = true\n    enable_selinux = false\n    enable_tls_streaming = false\n    enable_unprivileged_icmp = false\n    enable_unprivileged_ports = false\n    ignore_image_defined_volumes = false\n    max_concurrent_downloads = 3\n    max_container_log_line_size = 16384\n    netns_mounts_under_state_dir = false\n    restrict_oom_score_adj = false\n    sandbox_image = \"k8s.org/k8s/pause:3.9\"\n    selinux_category_range = 1024\n    stats_collect_period = 10\n    stream_idle_timeout = \"4h0m0s\"\n    stream_server_address = \"127.0.0.1\"\n    stream_server_port = \"0\"\n    systemd_cgroup = false\n    tolerate_missing_hugetlb_controller = true\n    unset_seccomp_profile = \"\"\n</br>\n    [plugins.\"io.containerd.grpc.v1.cri\".cni]\n      bin_dir = \"/opt/cni/bin\"\n      conf_dir = \"/etc/cni/net.d\"\n      conf_template = \"\"\n      ip_pref = \"\"\n      max_conf_num = 1\n</br>\n    [plugins.\"io.containerd.grpc.v1.cri\".containerd]\n      default_runtime_name = \"runc\"\n      disable_snapshot_annotations = true\n      discard_unpacked_layers = false\n      ignore_rdt_not_enabled_errors = false\n      no_pivot = false\n      snapshotter = \"overlayfs\"\n</br>\n      [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime]\n        base_runtime_spec = \"\"\n        cni_conf_dir = \"\"\n        cni_max_conf_num = 0\n        container_annotations = []\n        pod_annotations = []\n        privileged_without_host_devices = false\n        runtime_engine = \"\"\n        runtime_path = \"\"\n        runtime_root = \"\"\n        runtime_type = \"io.containerd.runtime.v1.linux\"\n</br>\n        [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options]\n</br>\n      [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes]\n</br>\n        [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n          base_runtime_spec = \"\"\n          cni_conf_dir = \"\"\n          cni_max_conf_num = 0\n          container_annotations = []\n          pod_annotations = []\n          privileged_without_host_devices = false\n          runtime_engine = \"\"\n          runtime_path = \"\"\n          runtime_root = \"\"\n          runtime_type = \"io.containerd.runc.v2\"\n</br>\n          [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n            BinaryName = \"\"\n            CriuImagePath = \"\"\n            CriuPath = \"\"\n            CriuWorkPath = \"\"\n            IoGid = 0\n            IoUid = 0\n            NoNewKeyring = false\n            NoPivotRoot = false\n            Root = \"\"\n            ShimCgroup = \"\"\n            SystemdCgroup = true\n</br>\n      [plugins.\"io.containerd.grpc.v1.cri\".containerd.untrusted_workload_runtime]\n        base_runtime_spec = \"\"\n        cni_conf_dir = \"\"\n        cni_max_conf_num = 0\n        container_annotations = []\n        pod_annotations = []\n        privileged_without_host_devices = false\n        runtime_engine = \"\"\n        runtime_path = \"\"\n        runtime_root = \"\"\n        runtime_type = \"\"\n</br>\n        [plugins.\"io.containerd.grpc.v1.cri\".containerd.untrusted_workload_runtime.options]\n</br>\n    [plugins.\"io.containerd.grpc.v1.cri\".image_decryption]\n      key_model = \"node\"\n</br>\n    [plugins.\"io.containerd.grpc.v1.cri\".registry]\n      config_path = \"\"\n</br>\n      [plugins.\"io.containerd.grpc.v1.cri\".registry.auths]\n</br>\n      [plugins.\"io.containerd.grpc.v1.cri\".registry.configs]\n         [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"k8s.org\".tls]\n           insecure_skip_verify = true\n           ca_file = \"/opt/k8s.org/ca.crt\"   # CA 证书\n           cert_file = \"/opt/k8s.org/k8s.org.cert\"    # harbor 证书\n           key_file  = \"/opt/k8s.org/k8s.org.key\"  # harbor 私钥\n         [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"k8s.org\".auth]\n           username = \"admin\"\n           password = \"cs123456\"\n      [plugins.\"io.containerd.grpc.v1.cri\".registry.headers]\n</br>\n      [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n         [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.org\"]\n            endpoint = [\"https://k8s.org\"]\n</br>\n  [plugins.\"io.containerd.internal.v1.opt\"]\n    path = \"/opt/containerd\"\n</br>\n  [plugins.\"io.containerd.internal.v1.restart\"]\n    interval = \"10s\"\n</br>\n  [plugins.\"io.containerd.internal.v1.tracing\"]\n    sampling_ratio = 1.0\n    service_name = \"containerd\"\n</br>\n  [plugins.\"io.containerd.metadata.v1.bolt\"]\n    content_sharing_policy = \"shared\"\n</br>\n  [plugins.\"io.containerd.monitor.v1.cgroups\"]\n    no_prometheus = false\n</br>\n  [plugins.\"io.containerd.runtime.v1.linux\"]\n    no_shim = false\n    runtime = \"runc\"\n    runtime_root = \"\"\n    shim = \"containerd-shim\"\n    shim_debug = false\n</br>\n  [plugins.\"io.containerd.runtime.v2.task\"]\n    platforms = [\"linux/amd64\"]\n    sched_core = false\n</br>\n  [plugins.\"io.containerd.service.v1.diff-service\"]\n    default = [\"walking\"]\n</br>\n  [plugins.\"io.containerd.service.v1.tasks-service\"]\n    rdt_config_file = \"\"\n</br>\n  [plugins.\"io.containerd.snapshotter.v1.aufs\"]\n    root_path = \"\"\n</br>\n  [plugins.\"io.containerd.snapshotter.v1.btrfs\"]\n    root_path = \"\"\n</br>\n  [plugins.\"io.containerd.snapshotter.v1.devmapper\"]\n    async_remove = false\n    base_image_size = \"\"\n    discard_blocks = false\n    fs_options = \"\"\n    fs_type = \"\"\n    pool_name = \"\"\n    root_path = \"\"\n</br>\n  [plugins.\"io.containerd.snapshotter.v1.native\"]\n    root_path = \"\"\n</br>\n  [plugins.\"io.containerd.snapshotter.v1.overlayfs\"]\n    root_path = \"\"\n    upperdir_label = false\n</br>\n  [plugins.\"io.containerd.snapshotter.v1.zfs\"]\n    root_path = \"\"\n</br>\n  [plugins.\"io.containerd.tracing.processor.v1.otlp\"]\n    endpoint = \"\"\n    insecure = false\n    protocol = \"\"\n</br>\n[proxy_plugins]\n</br>\n[stream_processors]\n</br>\n  [stream_processors.\"io.containerd.ocicrypt.decoder.v1.tar\"]\n    accepts = [\"application/vnd.oci.image.layer.v1.tar+encrypted\"]\n    args = [\"--decryption-keys-path\", \"/etc/containerd/ocicrypt/keys\"]\n    env = [\"OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf\"]\n    path = \"ctd-decoder\"\n    returns = \"application/vnd.oci.image.layer.v1.tar\"\n</br>\n  [stream_processors.\"io.containerd.ocicrypt.decoder.v1.tar.gzip\"]\n    accepts = [\"application/vnd.oci.image.layer.v1.tar+gzip+encrypted\"]\n    args = [\"--decryption-keys-path\", \"/etc/containerd/ocicrypt/keys\"]\n    env = [\"OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf\"]\n    path = \"ctd-decoder\"\n    returns = \"application/vnd.oci.image.layer.v1.tar+gzip\"\n</br>\n[timeouts]\n  \"io.containerd.timeout.bolt.open\" = \"0s\"\n  \"io.containerd.timeout.shim.cleanup\" = \"5s\"\n  \"io.containerd.timeout.shim.load\" = \"5s\"\n  \"io.containerd.timeout.shim.shutdown\" = \"3s\"\n  \"io.containerd.timeout.task.state\" = \"2s\"\n</br>\n[ttrpc]\n  address = \"\"\n  gid = 0\n  uid = 0\n  </code></pre>\n</details>\n\n替换pause镜像，Cgroup及添加密钥文件\n\n```\nsed -n '/sandbox_image/s/= .*/= \"k8s.org\\/k8s\\/pause:3.6\"/'p /etc/containerd/config.toml\t\n#替换 sed -i '/sandbox_image/s/= .*/= \"k8s.org\\/k8s\\/pause:3.9\"/' /etc/containerd/config.toml\n\nsed -n '/SystemdCgroup/s/= .*/= true/'p /etc/containerd/config.toml\t\n```\n\n> sandbox_image = \"k8s.org/k8s/pause:3.9\"\n>\n> SystemdCgroup = true\n\n\n\n### 密钥配置\n\n```toml\n [plugins.\"io.containerd.grpc.v1.cri\".registry.configs]\n         [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"k8s.org\".tls]\n           insecure_skip_verify = true\n           ca_file = \"/opt/k8s.org/ca.crt\"   # CA 证书\n           cert_file = \"/opt/k8s.org/k8s.org.cert\"    # harbor 证书\n           key_file  = \"/opt/k8s.org/k8s.org.key\"  # harbor 私钥\n         [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"k8s.org\".auth]\n           username = \"admin\"\n           password = \"cs123456\"\n  \n  [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n         [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.org\"]\n            endpoint = [\"https://k8s.org\"] \n```\n\n> 配置私库域名k8s.org，及配置证书 \n>\n> **insecure_skip_verify** 设置true,ctr拉取一样x509,使用-k ` ctr i pull  k8s.org/k8s/pause:3.6  -k`\n\n","tags":["harbor","containerd","crt"],"categories":["linux","tool","harbor"]},{"title":"k8s1.26.1编译部署","url":"//linux/k8s/k8s-compile/","content":"\nk8s去docker,1.24版本移除 Dockershim https://kubernetes.io/zh-cn/blog/2022/02/17/dockershim-faq/\n\n## kubernetes\n\n### 准备\n\n1.26.1  需要>=go1.19 [go env](/lang/go/environment#go_env)\n\n```\nmkdir -p $GOPATH/src/k8s.io\ncd $GOPATH/src/k8s.io\ngit clone https://github.com/kubernetes/kubernetes\ncd kubernetes\nmake\n```\n\n>#编译指定组件\n>\n>$ make WHAT=cmd/kubelet\n>+++ [0325 21:01:36] Building go targets for linux/amd64\n>    k8s.io/kubernetes/cmd/kubelet (non-static)\n>\n>\n>\n>$ make kubectl kubeadm kubelet  \n>+++ [0325 21:19:43] Building go targets for linux/amd64\n>    k8s.io/kubernetes/cmd/kubectl (static)\n>\n>+++ [0325 21:21:23] Building go targets for linux/amd64\n>    k8s.io/kubernetes/cmd/kubeadm (static)\n>\n>+++ [0325 21:19:45] Building go targets for linux/amd64\n>    k8s.io/kubernetes/cmd/kubelet (non-static)\n\n#### network\n\n<!--more-->\n\n\n\n```\ncat <<EOF | sudo tee /etc/modules-load.d/k8s.conf\noverlay\nbr_netfilter\nEOF\n\nsudo modprobe overlay\nsudo modprobe br_netfilter\n\n# 设置所需的 sysctl 参数，参数在重新启动后保持不变\ncat <<EOF | sudo tee /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.ipv4.ip_forward                 = 1\nEOF\n\n# 应用 sysctl 参数而不重新启动\nsudo sysctl --system\n```\n\n\n\n#### swap/firewalld\n\n```\nswapoff -a\nsed -n '/swap/s/^/#/'p /etc/fstab\nsed -i '/swap/s/^/#/' /etc/fstab\nsed  -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\nsystemctl stop firewalld.service && systemctl disable firewalld.service \n```\n\n\n\n\n\n\n\n```\nstr=$(./bin/kubeadm  --image-repository registry.aliyuncs.com/google_containers config images list)\narr=${str//registry.aliyuncs.com\\/google_containers/k8s.org\\/k8s}\n\nfor i in ${arr}; do  docker push $i ;done\n```\n\n> for i in $(docker images | grep 'v1.26.1' | awk 'BEGIN{OFS=\":\"}{print $1,$2}'); do echo docker push $i ;done\n\n\n\n### CRI\n\nhttps://kubernetes.io/zh-cn/docs/setup/production-environment/container-runtimes/\n\n\n\n#### containerd\n\n[containerd 安装](/linux/k8s/containerd#containerd)\n\n\n\n\n\n### kubelet\n\n\n\n\n\n```\ncat > /opt/kubernetes/kubelet.env <<EOF\n KUBELET_OPTIONS=\" --hostname-override=k8s01  \\\\\n --pod-infra-container-image=k8s.org/k8s/pause:3.9 \\\\\n --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf    \\\\\n --kubeconfig=/etc/kubernetes/kubelet.conf    \\\\\n --config=/var/lib/kubelet/config.yaml     \\\\\n --container-runtime-endpoint=unix:///run/containerd/containerd.sock \\\\\n --runtime-cgroups=/systemd \"\nEOF\n```\n\n\n\n```\ncat >/usr/lib/systemd/system/kubelet.service <<EOF\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=containerd.service\nRequires=containerd.service\n\n[Service]\nWorkingDirectory=/var/lib/kubelet\nEnvironmentFile=/opt/kubernetes/kubelet.env\nExecStart=/usr/local/bin/kubelet  \\$KUBELET_OPTIONS\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n\n\n```\nsystemctl daemon-reload &&  systemctl enable kubelet\n```\n\n\n\n### 使用自定义的镜像\n\n```\n kubeadm config print init-defaults>kubeadm.yaml \n\n# images pull  \nkubeadm config images pull --config /opt/kubeadm.yaml\n```\n\n\n\n### 初始化\n\n#### 依赖\n\n![](/pics/conntrack.png)\n\n```\nyum install --downloadonly --downloaddir=/tmp/pages  conntrack-tools \nyum install --downloadonly --downloaddir=/tmp/pages socat\n```\n\n\n\n##### socat\n\n```\n# rpm -ivh /tmp/pages/socat-1.7.3.2-2.el7.x86_64.rpm \nwarning: /tmp/pages/socat-1.7.3.2-2.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\nPreparing...                          ################################# [100%]\nUpdating / installing...\n   1:socat-1.7.3.2-2.el7              ################################# [100%]\n```\n\n>特点就是在两个数据流之间建立通道\n>\n>http://mirror.centos.org/centos/7/os/x86_64/Packages/socat-1.7.3.2-2.el7.x86_64.rpm\n\n\n\n##### conntrack\n\n```\n# rpm -ivh /tmp/pages/libnetfilter_*.rpm\nwarning: /tmp/pages/libnetfilter_cthelper-1.0.0-11.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\nPreparing...                          ################################# [100%]\nUpdating / installing...\n   1:libnetfilter_queue-1.0.2-2.el7_2 ################################# [ 33%]\n   2:libnetfilter_cttimeout-1.0.0-7.el################################# [ 67%]\n   3:libnetfilter_cthelper-1.0.0-11.el################################# [100%]\n   \n# rpm -ivh /tmp/pages/conntrack-tools-1.4.4-7.el7.x86_64.rpm \nwarning: /tmp/pages/conntrack-tools-1.4.4-7.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\nPreparing...                          ################################# [100%]\nUpdating / installing...\n   1:conntrack-tools-1.4.4-7.el7      ################################# [100%]\n```\n\n\n\n>跟踪并且记录连接状态　\n>\n>conntrack-tools　http://mirror.centos.org/centos/7/os/x86_64/Packages/conntrack-tools-1.4.4-7.el7.x86_64.rpm\n>\n>依赖\n>\n>http://mirror.centos.org/centos/7/os/x86_64/Packages/libnetfilter_cttimeout-1.0.0-7.el7.x86_64.rpm\n>\n>http://mirror.centos.org/centos/7/os/x86_64/Packages/libnetfilter_cthelper-1.0.0-11.el7.x86_64.rpm\n>\n>http://mirror.centos.org/centos/7/os/x86_64/Packages/libnetfilter_queue-1.0.2-2.el7_2.x86_64.rpm\n\n\n\n#### init \n\n自定义初始化\n\n https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file\n\nhttps://kubernetes.io/zh-cn/docs/reference/config-api/kubeadm-config.v1beta3/\n\n```\n#主节点\nkubeadm config print init-defaults >init.yaml\n\nkubeadm init --config=/opt/init-kubeadm.yaml\n```\n\n\n\n<details>\n  <summary>init-kubeadm.yaml折叠</summary>\n  <pre><a>/opt/init-kubeadm.yaml</a><code>\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: ujogs9.ntea26wujtca8fjb\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.122.11\n  bindPort: 6443\ncertificateKey: 228bfe0e01e9456c981455b81abad41a067b9ca31bf9f91a692a778115cb9b7a\nnodeRegistration:\n  criSocket: unix:///var/run/containerd/containerd.sock\n  imagePullPolicy: IfNotPresent\n  name: k8s01\n  taints: null\n---\napiServer:\n  extraArgs:\n    etcd-servers: https://192.168.122.11:2379,https://192.168.122.12:2379,https://192.168.122.13:2379\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: cs\ncontrollerManager:\n  extraArgs:\n    \"allocate-node-cidrs\": \"true\"\n    \"cluster-cidr\": \"121.21.0.0/16\"\n    \"node-cidr-mask-size\": \"20\"\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: k8s.org/k8s\nkind: ClusterConfiguration\nkubernetesVersion: 1.26.1\ncontrolPlaneEndpoint: k8s.org:6443\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\n  podSubnet: 121.21.0.0/16\nscheduler:\n  extraArgs:\n    log-flush-frequency: 6s\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd\nclusterDNS:\n- 121.21.0.0\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging:\n  flushFrequency: 0\n  options:\n    json:\n      infoBufferSize: \"0\"\n  verbosity: 0\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nbindAddress: 0.0.0.0\nbindAddressHardFail: false\nclientConnection:\n  acceptContentTypes: \"\"\n  burst: 0\n  contentType: \"\"\n  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf\n  qps: 0\nclusterCIDR: \"121.21.0.0\"\nAllocateNodeCIDRs: true\nconfigSyncPeriod: 0s\nconntrack:\n  maxPerCore: null\n  min: null\n  tcpCloseWaitTimeout: null\n  tcpEstablishedTimeout: null\ndetectLocal:\n  bridgeInterface: \"\"\n  interfaceNamePrefix: \"\"\ndetectLocalMode: \"\"\nenableProfiling: false\nhealthzBindAddress: \"\"\nhostnameOverride: \"\"\niptables:\n  localhostNodePorts: null\n  masqueradeAll: false\n  masqueradeBit: null\n  minSyncPeriod: 0s\n  syncPeriod: 0s\nipvs:\n  excludeCIDRs: null\n  minSyncPeriod: 0s\n  scheduler: \"rr\"\n  strictARP: false\n  syncPeriod: 30s\n  tcpFinTimeout: 0s\n  tcpTimeout: 0s\n  udpTimeout: 0s\nkind: KubeProxyConfiguration\nmetricsBindAddress: \"\"\nmode: \"ipvs\"\nnodePortAddresses: null\noomScoreAdj: null\nportRange: \"\"\nshowHiddenMetricsForVersion: \"\"\nwinkernel:\n  enableDSR: false\n  forwardHealthCheckVip: false\n  networkName: \"\"\n  rootHnsEndpointName: \"\"\n  sourceVip: \"\"\n  </code></pre>\n</details>\n\n\n\n<details>\n  <summary>初始化详情</summary>\n  <pre><a>初始化过程</a><code>\n[root@base ~]# kubeadm init --config /opt/kubeadm.yaml \n[init] Using Kubernetes version: v1.26.1\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [base kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.122.6]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [base localhost] and IPs [192.168.122.6 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [base localhost] and IPs [192.168.122.6 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 26.502067 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node base as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node base as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]\n[bootstrap-token] Using token: abcdef.0123456789abcdef\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n</br>\nYour Kubernetes control-plane has initialized successfully!\n</br>\nTo start using your cluster, you need to run the following as a regular user:\n</br>\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n</br>\nAlternatively, if you are the root user, you can run:\n</br>\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n</br>\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n</br>\nThen you can join any number of worker nodes by running the following on each as root:\n</br>\nkubeadm join 192.168.122.6:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:a5b9ef128064a6c279cd2dc0d738ae2b4d4d8d993ccead6f7e2e9b8ec0d2d9d7   </code></pre>\n</details>\n\n\n\n\n\n### 运行 kubectl\n\nhttps://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/\n\n\n\nhttps://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\n\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?  需要配置\n\n非root用户\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n\n\nroot用户\n\n```\n# echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> /etc/profile\n# source /etc/profile\n# kubectl get node\nNAME    STATUS     ROLES           AGE   VERSION\nk8s01   NotReady   control-plane   27m   v1.26.1\n```\n\n\n\n### 密钥\n\nhttps://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-token/#cmd-token-create\n\n>kubeadm join k8s.org:6443 --token $1 \\\n>\n>--discovery-token-ca-cert-hash sha256:$2  \\\n>\n>--control-plane --certificate-key $3\n\n\n\n#### token\n\n```\nkubeadm token generate\n```\n\n> \n>\n> kubeadm token  list  #查看token\n\n\n\n#### discovery-token-ca-cert-hash\n\n```\nopenssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa \\\n-pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n```\n\n\n\n\n\n#### certificate-key\n\n```\n#--upload-certs  certificateKey\n# kubeadm certs certificate-key\n228bfe0e01e9456c981455b81abad41a067b9ca31bf9f91a692a778115cb9b7a\n\n##更新\nkubeadm init phase upload-certs --upload-certs\n```\n\n> W0314 19:18:31.841138    5585 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n> W0314 19:18:31.841320    5585 version.go:105] falling back to the local client version: v1.26.1\n> [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n> [upload-certs] Using certificate key:\n> 58c8e04a2e479d3f10274eff43988d626f627e49ecc1ebb3463f8aedf50ccfda\n>\n> \n>\n> sed -n \"/certificateKey/s/:.*/: 58c8e04a2e479d3f10274eff43988d626f627e49ecc1ebb3463f8aedf50ccfda/\"p /opt/join.yaml\n\n\n\n```\nkubeadm init phase upload-certs --upload-certs --config=SOME_YAML_FILE\n```\n\n\n\n\n\n\n\n### join \n\n#### command\n\n#####  master\n\n```\nkubeadm join k8s.org:6443 --token $1 \\\n--discovery-token-ca-cert-hash sha256:$2  \\\n--control-plane --certificate-key $3\n```\n\n>kubeadm join k8s.org:6443 --token l860je.2f4ox4tb166kui7l --discovery-token-ca-cert-hash sha256:4533b6361be151af712c014c0b1c2eb52f902f52ff292f63ccc258c58d9e59be  --control-plane --certificate-key 56a92754164260b76bbe525f0e60059b6eea38d2ef07f42231a2c3bebfd18bbf\n\n\n\n\n#####  node\n\n```\n#重新生成\nkubeadm token create    --print-join-command\n```\n\n> kubeadm join k8s.org:6443 --token q3paz2.w5zohvudzrsltrh3 --discovery-token-ca-cert-hash sha256:8f1ac78f64629c049a2e0e8a8e8fa83f29e92e6801ca1a1d27cc3e06ecef9943\n> \n\n\n\n\n\nhttps://kubernetes.io/zh-cn/docs/reference/config-api/kubeadm-config.v1beta3/#kubeadm-k8s-io-v1beta3-ClusterConfiguration\n\n\n\n##### controlPlane\n\n```\n#第一个主节点\nkubeadm config print init-defaults >init.yaml\n\n#后续控制面板 controlPlane\nkubeadm config print join-defaults >join.yaml\nkubeadm config print join-defaults --component-configs KubeletConfiguration\n```\n\n\n\n初始化文件\n\n<details>\n  <summary>init-kubeadm.yaml</summary>\n  <pre><a>cat  /opt/init-kubeadm.yaml</a><code>\napiVersion: kubeadm.k8s.io/v1beta3\ncaCertPath: /etc/kubernetes/pki/ca.crt\ndiscovery:\n  bootstrapToken:\n    apiServerEndpoint: k8s.org:6443\n    token: yl0hvd.mv683yn2rljdrigk\n    unsafeSkipCAVerification: true\n  timeout: 5m0s\n  tlsBootstrapToken: yl0hvd.mv683yn2rljdrigk\nkind: JoinConfiguration\nnodeRegistration:\n  criSocket: unix:///var/run/containerd/containerd.sock\n  imagePullPolicy: IfNotPresent\n  name: k8s01\n  taints: null\ncontrolPlane:\n  localAPIEndpoint:\n    advertiseAddress: 192.168.122.11\n    bindPort: 6443\n  certificateKey: 66b4704450dd461f02f56c81b9c323363c0e2a077a1a5619aaab7b58eb953be9\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: k8s.org/k8s\nkind: ClusterConfiguration\nkubernetesVersion: 1.26.1\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\ncontrolPlaneEndpoint: k8s.org:6443  #集群\nscheduler: {}\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\ncgroupDriver: systemd\nfailSwapOn: false\n# clusterDNS:\n# - 10.96.0.10\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nipvs:\n  minSyncPeriod: 0s\n  scheduler: \"rr\"\n  syncPeriod: 30s\nmode: \"ipvs\"  </code></pre>\n</details>\n\n\n\n<details>\n  <summary>控制面板初始化详情</summary>\n  <pre><a>kubeadm join --config /opt/join.yaml</a><code>\nW0319 19:08:00.540407   31325 initconfiguration.go:305] error unmarshaling configuration schema.GroupVersionKind{Group:\"kubeproxy.config.k8s.io\", Version:\"v1alpha1\", Kind:\"KubeProxyConfiguration\"}: strict decoding error: unknown field \"AllocateNodeCIDRs\"\nW0319 19:08:00.541712   31325 configset.go:177] error unmarshaling configuration schema.GroupVersionKind{Group:\"kubeproxy.config.k8s.io\", Version:\"v1alpha1\", Kind:\"KubeProxyConfiguration\"}: strict decoding error: unknown field \"AllocateNodeCIDRs\"\nW0319 19:08:00.543375   31325 utils.go:69] The recommended value for \"clusterCIDR\" in \"KubeProxyConfiguration\" is: 121.21.0.0/16; the provided value is: 121.21.0.0\nW0319 19:08:00.543398   31325 utils.go:69] The recommended value for \"clusterDNS\" in \"KubeletConfiguration\" is: [10.96.0.10]; the provided value is: [121.21.0.0]\n[init] Using Kubernetes version: v1.26.1\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s.org k8s01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.122.11]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s01 localhost] and IPs [192.168.122.11 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s01 localhost] and IPs [192.168.122.11 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 18.528146 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node k8s01 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s01 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]\n[bootstrap-token] Using token: ujogs9.ntea26wujtca8fjb\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n</br>\nYour Kubernetes control-plane has initialized successfully!\n</br>\nTo start using your cluster, you need to run the following as a regular user:\n</br>\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n</br>\nAlternatively, if you are the root user, you can run:\n</br>\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n</br>\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n</br>\nYou can now join any number of control-plane nodes by copying certificate authorities\nand service account keys on each node and then running the following as root:\n</br>\n  kubeadm join k8s.org:6443 --token ujogs9.ntea26wujtca8fjb \\\n\t--discovery-token-ca-cert-hash sha256:a51e48270ff979d72adbedc004ba7aad363623120ed9e24e9a6409e2ba5fde37 \\\n\t--control-plane --certificate-key 228bfe0e01e9456c981455b81abad41a067b9ca31bf9f91a692a778115cb9b7a\n</br>\nThen you can join any number of worker nodes by running the following on each as root:\n</br>\nkubeadm join k8s.org:6443 --token ujogs9.ntea26wujtca8fjb \\\n\t--discovery-token-ca-cert-hash sha256:a51e48270ff979d72adbedc004ba7aad363623120ed9e24e9a6409e2ba5fde37 \n  </code></pre>\n</details>\n\n直接在其他控制面板执行报错\n\n> error execution phase control-plane-prepare/download-certs: error downloading certs: error downloading the secret: secrets \"kubeadm-certs\" is forbidden: User \"system:bootstrap:ujogs9\" cannot get resource \"secrets\" in API group \"\" in the namespace \"kube-system\"\n\n执行命令生成certificatekey,用新生成的替换原有值在其他控制面板执行加入\n\n```\nkubeadm init phase upload-certs --upload-certs\n```\n\n>W0319 19:11:21.959770   32656 version.go:104] could not fetch a Kubernetes version from the internet: unable to get URL \"https://dl.k8s.io/release/stable-1.txt\": Get \"https://dl.k8s.io/release/stable-1.txt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n>W0319 19:11:21.960020   32656 version.go:105] falling back to the local client version: v1.26.1\n>[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n>[upload-certs] Using certificate key:\n>0240fc6ba87ada32042b73469103b5577df42603289429ea38f0c5789fc6f9c7\n\n\n\n<details>\n  <summary>join 控制模板初始化详情</summary>\n  <pre><a>kubeadm join k8s.org:6443 --token ujogs9.ntea26wujtca8fjb \\\n   --discovery-token-ca-cert-hash sha256:a51e48270ff979d72adbedc004ba7aad363623120ed9e24e9a6409e2ba5fde37 \\\n  --control-plane --certificate-key 228bfe0e01e9456c981455b81abad41a067b9ca31bf9f91a692a778115cb9b7a\n[preflight] Running pre-flight checks\n</a><code>\n[preflight] Running pre-flight checks\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\nW0319 19:10:37.146702   22564 utils.go:69] The recommended value for \"clusterCIDR\" in \"KubeProxyConfiguration\" is: 121.21.0.0/16; the provided value is: 121.21.0.0\nW0319 19:10:37.146747   22564 utils.go:69] The recommended value for \"clusterDNS\" in \"KubeletConfiguration\" is: [10.96.0.10]; the provided value is: [121.21.0.0]\n[preflight] Running pre-flight checks before initializing the new control plane instance\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[download-certs] Downloading the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\nerror execution phase control-plane-prepare/download-certs: error downloading certs: error downloading the secret: secrets \"kubeadm-certs\" is forbidden: User \"system:bootstrap:ujogs9\" cannot get resource \"secrets\" in API group \"\" in the namespace \"kube-system\"\nTo see the stack trace of this error execute with --v=5 or higher\n[root@k8s03 ~]# kubeadm join k8s.org:6443 --token ujogs9.ntea26wujtca8fjb --discovery-token-ca-cert-hash sha256:a51e48270ff979d72adbedc004ba7aad363623120ed9e24e9a6409e2ba5fde37 --control-plane --certificate-key 0240fc6ba87ada32042b73469103b5577df42603289429ea38f0c5789fc6f9c7\n[preflight] Running pre-flight checks\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\nW0319 19:11:33.434784   22613 utils.go:69] The recommended value for \"clusterCIDR\" in \"KubeProxyConfiguration\" is: 121.21.0.0/16; the provided value is: 121.21.0.0\nW0319 19:11:33.434827   22613 utils.go:69] The recommended value for \"clusterDNS\" in \"KubeletConfiguration\" is: [10.96.0.10]; the provided value is: [121.21.0.0]\n[preflight] Running pre-flight checks before initializing the new control plane instance\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[download-certs] Downloading the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[download-certs] Saving the certificates to the folder: \"/etc/kubernetes/pki\"\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s03 localhost] and IPs [192.168.122.13 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s03 localhost] and IPs [192.168.122.13 127.0.0.1 ::1]\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s.org k8s03 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.122.13]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Valid certificates and keys now exist in \"/etc/kubernetes/pki\"\n[certs] Using the existing \"sa\" key\n[kubeconfig] Generating kubeconfig files\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[check-etcd] Checking that the etcd cluster is healthy\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n[etcd] Announced new etcd member joining to the existing etcd cluster\n[etcd] Creating static Pod manifest for \"etcd\"\n[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s\nThe 'update-status' phase is deprecated and will be removed in a future release. Currently it performs no operation\n[mark-control-plane] Marking the node k8s03 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s03 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]\n</br>\nThis node has joined the cluster and a new control plane instance was created:\n</br>\n* Certificate signing request was sent to apiserver and approval was received.\n* The Kubelet was informed of the new secure connection details.\n* Control plane label and taint were applied to the new node.\n* The Kubernetes control plane instances scaled up.\n* A new etcd member was added to the local/stacked etcd cluster.\n</br>\nTo start administering your cluster from this node, you need to run the following as a regular user:\n</br>\n\tmkdir -p $HOME/.kube\n\tsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\tsudo chown $(id -u):$(id -g) $HOME/.kube/config\n</br>\nRun 'kubectl get nodes' to see this node join the cluster.\n  </code></pre>\n</details>\n\n\n#### yaml \n\n截止v1.26都是beta版本\n\nhttps://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-join/\n\n![](/pics/config-beta.png)\n\n\n\n##### controlPlane\n\n```\n#后续控制面板 controlPlane\nkubeadm config print join-defaults >join.yaml\nkubeadm config print join-defaults --component-configs KubeletConfiguration\n```\n\n\n\n配置中需要有controlPlane\n\n待补充\n\n\n\n\n##### worker\n\n<details>\n  <summary>join-worker.yaml</summary>\n  <pre><a>join-worker</a><code>\napiVersion: kubeadm.k8s.io/v1beta3\ncaCertPath: /etc/kubernetes/pki/ca.crt\ndiscovery:\n  bootstrapToken:\n    apiServerEndpoint: kube-apiserver:6443\n    token: abcdef.0123456789abcdef\n    unsafeSkipCAVerification: true\n  timeout: 5m0s\n  tlsBootstrapToken: abcdef.0123456789abcdef\nkind: JoinConfiguration\nnodeRegistration:\n  criSocket: unix:///var/run/containerd/containerd.sock\n  imagePullPolicy: IfNotPresent\n  name: debian\n  taints: null\n  </code></pre>\n</details>\n\n\n\n\n\n\n### 运行 kubectl\n\nhttps://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/\n\n\n\nhttps://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\n\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?  需要配置\n\n非root用户\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n\n\nroot用户\n\n```\n# echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> /etc/profile\n# source /etc/profile\n# kubectl get node\nNAME    STATUS     ROLES           AGE   VERSION\nk8s01   NotReady   control-plane   27m   v1.26.1\n```\n\n\n\n\n\n### etcd\n\n\n\n\n\n>find /tmp/  -name ca.key -type f \n>/tmp/pki/etcd/ca.key\n>/tmp/pki/ca.key\n\n\n\n### flannel\n\n\n\nContainerCreating\n\n\n\n\n\n### edit\n\n\n\n```\nkubectl edit cm kube-proxy -n kube-system\n\n#删除pod\nkubectl get pod  -n  kube-system | grep kube-proxy | awk '{system(\"kubectl delete pod \"$1\" -n kube-system\")}'\n```\n\n\n\n\n\n\n\n### 删除pod\n\n- • k8s garbage-collection\n- • k8s finalizers\n\n![](/pics/k8s-terminated-del.png)\n\n\n\n```\n kubectl delete pod xxx  -n kube-system --grace-period=0 --force\n```\n\n\n\n```\n$ kubectl proxy  #127.0.0.1:8001\nname=xx\nnamespace=xxx\n$ kubectl get pod $name -n $namespace -o json >tmp.json\n4.执行生效\ncurl -k -H “Content-Type: application/json” -X PUT --data-binary @tmp.json http://127.0.0.1:8001/api/v1/namespaces/$name/finalize\n```\n\n[Terminating状态](https://support.huaweicloud.com/cce_faq/cce_faq_00277.html)\n\n\n\n\n\n```\n❯ kubectl get pod -n mysql-operator\nNAME          READY   STATUS        RESTARTS   AGE\nmycluster-1   0/2     Terminating   0          17h\n❯ kubectl patch pod mycluster-1   -n mysql-operator -p '{\"metadata\":{\"finalizers\":null}}'\npod/mycluster-1 patched\n```\n\n[finalizers](https://cloudmessage.top/archives/k8s-wu-fa-shan-chu-zhuang-tai-wei-terminatingde-podjie-jue-fang-fa)\n\n\n\n\n\n\n### 卸载清理\n\n```bash\nkubeadm reset -f\nrm -rf /var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni /etc/kubernetes\n```\n\n\n\n\n\n\n\n### 证书过期\n\n```\n\n$ cd /etc/kubernetes/pki/\n$ mv {apiserver.crt,apiserver-etcd-client.key,apiserver-kubelet-client.crt,front-proxy-ca.crt,front-proxy-client.crt,front-proxy-client.key,front-proxy-ca.key,apiserver-kubelet-client.key,apiserver.key,apiserver-etcd-client.crt} ~/\n$ kubeadm init phase certs all\n$ cd /etc/kubernetes/\n$ mv {admin.conf,controller-manager.conf,kubelet.conf,scheduler.conf} ~/\n$ kubeadm init phase kubeconfig all\n$ reboot\n$ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n```\n\n\n\n\n\n```\nkubeadm    join  k8s.org:6443   --config /opt/join.yaml\n\nsystemctl  status  kubelet\n\n\n```\n\n\n\n```\n\n\n```\n\n>Failed to get system container stats\" err=\"failed to get cgroup stats for \\\"/systemd\\\": failed to get container info for \\\"/systemd\\\": unknown container \\\"/systemd\\\"\" containerName=\"/systemd\"\n>\n>https://github.com/kubernetes/kubernetes/issues/56850\n>https://github.com/kubermatic/machine-controller/pull/476\n>https://github.com/kubernetes/kubernetes/issues/56850#issuecomment-406241077\n\n\n\n\n\n\n\n\n\n```\nkube-dns查看token\n#查看所有账号\nkubectl -n kube-system get sa\n\n取得secrets\nkubectl -n kube-system get sa kube-dns -o yaml 取得secrets\n#secrets值为kube-dns-token-rst6j\n\n取得token\nkubectl get secrets kube-dns-token-rst6j -n kube-system -o yaml\n\n取得token值\nkubectl get secret kube-dns-token-rst6j -n kube-system -o jsonpath={\".data.token\"}\n\ntokne转码\nkubectl get secret kube-dns-token-rst6j -n kube-system -o jsonpath={\".data.token\"}| base64 -d\n\n```\n\n\n\n[使用 kubeadm 进行证书管理](https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/)\n\n\n\n\n\n```\nkubectl get secrets  -n kube-system\nNAME                     TYPE                            DATA   AGE\nbootstrap-token-uxzaiw   bootstrap.kubernetes.io/token   6      28m\n\n[root@k8s01 ~]# kubectl describe  secrets  -n kube-system\nName:         bootstrap-token-uxzaiw\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  <none>\n\nType:  bootstrap.kubernetes.io/token\n\nData\n====\nauth-extra-groups:               47 bytes\nexpiration:                      20 bytes\ntoken-id:                        6 bytes\ntoken-secret:                    16 bytes\nusage-bootstrap-authentication:  4 bytes\nusage-bootstrap-signing:         4 bytes\n\n```\n\n>\n>\n>[download-certs] Downloading the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n>error execution phase control-plane-prepare/download-certs: error downloading certs: error downloading the secret: secrets \"kubeadm-certs\" is forbidden: User \"system:bootstrap:uxzaiw\" cannot get resource \"secrets\" in API group \"\" in the namespace \"kube-system\"\n>To see the stack trace of this error execute with --v=5 or higher\n\n\n\nvirsh 关闭vm\n\n```\nfor i in $(sudo virsh list --name);do sudo virsh shutdown $i;done\n```\n\n","tags":["xxx","xx","k8s1.26.1编译部署"],"categories":["linux","k8s","k8s-compile"]},{"title":"go环境配置","url":"//lang/go/environment/","content":"\n\n\nhttps://github.com/golang/go\n\n## 编译\n\nGOPATH之下主要包含三个目录: \n\nbin  编译后可的执行文件的存放路径\n\npkg  编译包时，生成的.a文件的存放路径\n\nsrc 源码路径\n\n\n\n升级或编译源码，需要旧的二进制版本来编译 \n\n<p id=\"go_env\" hidden/>\n\n```\nexport GOROOT=/opt/go/1.18.1\nexport PATH=$PATH:$GOROOT/bin\nexport GOROOT_BOOTSTRAP=/opt/go/1.18.1\n\ngit clone https://github.com/golang/go.git\ncd go\ngit checkout go1.20.1\ncd ./src\n./make.bash\n\n```\n\n> Set $GOROOT_BOOTSTRAP to a working Go tree >= Go 1.17.13\n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n","tags":["xxx","go","environment"],"categories":["lang","go","environment"]},{"title":"ruby从git拉取编译安装","url":"//lang/ruby/compile/","content":"\nhttps://github.com/ruby/ruby/blob/master/doc/contributing/building_ruby.md\n\n## build\n\n\n\n### Dependencies\n\n1. Install the prerequisite dependencies for building the CRuby interpreter:\n\n   - C compiler\n\n   For RubyGems, you will also need:\n\n   - OpenSSL 1.1.x or 3.0.x / LibreSSL\n   - libyaml 0.1.7 or later\n   - zlib\n\n   If you want to build from the git repository, you will also need:\n\n   - autoconf - 2.67 or later\n   - bison - 3.0 or later\n   - gperf - 3.1 or later\n     - Usually unneeded; only if you edit some source files using gperf\n   - ruby - 2.2 or later\n     - We can upgrade this version to system ruby version of the latest Ubuntu LTS.\n\n2. Install optional, recommended dependencies:\n\n   - readline/editline (libedit, to build readline)\n   - libffi (to build fiddle)\n   - gmp (if you with to accelerate Bignum operations)\n   - libexecinfo (FreeBSD)\n   - rustc - 1.58.0 or later (if you wish to build [YJIT](https://github.com/ruby/ruby/blob/master/doc/yjit/yjit.md))\n\n   If you installed the libraries needed for extensions (openssl, readline, libyaml, zlib) into other than the OS default place, typically using Homebrew on macOS, add `--with-EXTLIB-dir` options to `CONFIGURE_ARGS` environment variable.\n\n   ```\n   export CONFIGURE_ARGS=\"\"\n   for ext in openssl readline libyaml zlib; do\n     CONFIGURE_ARGS=\"${CONFIGURE_ARGS} --with-$ext-dir=$(brew --prefix $ext)\"\n   done\n   ```\n\n<!--more-->\n\n\n\n##\n\n\n\n```\n$ ./configure --prefix=/opt/ruby  --disable-install-doc\nchecking for ruby... /usr/bin/ruby\ndownloading config.guess ... done\ndownloading config.sub ... done\nchecking build system type... x86_64-pc-linux-gnu\nchecking host system type... x86_64-pc-linux-gnu\nchecking target system type... x86_64-pc-linux-gnu\nchecking for gcc... no\nchecking for clang... no\nchecking for cc... no\nchecking for gcc... no\nchecking for cc... no\nchecking for cl.exe... no\nconfigure: error: in `/home/cs/下载/ruby-3_2_1':\nconfigure: error: no acceptable C compiler found in $PATH\nSee `config.log' for more details\n\n```\n\n\n\n### 源\n\n\n\n```\ngem sources\ngem sources -a url地址\ngem sources -r url地址\ngem sources -u\n```\n\n\n\n\n\nsudo gem install nokogiri\n","tags":["git","compile","ruby"],"categories":["lang","ruby","compile"]},{"title":"用户组命令","url":"//linux/shell/user-group/","content":"\n## user\n\nadduser 与 useradd 指令为同一指令\n\n```\n[root@localhost ~]# useradd user1\n[root@localhost ~]# useradd user2\n```\n\n- -c<备注> 　加上备注文字。备注文字会保存在passwd的备注栏位中。\n- -d<登入目录> 　指定用户登入时的起始目录。\n- -D 　变更预设值．\n- -e<有效期限> 　指定帐号的有效期限。\n- -f<缓冲天数> 　指定在密码过期后多少天即关闭该帐号。\n- -g<群组> 　指定用户所属的群组。\n- -G<群组> 　指定用户所属的附加群组。\n- -m 　制定用户的登入目录。\n- -M 　不要自动建立用户的登入目录。\n- -n 　取消建立以用户名称为名的群组．\n- -r 　建立系统帐号。\n- -s<shell>　 　指定用户登入后所使用的shell。\n- -u<uid> 　指定用户ID。\n\n\n\n```\n#添加一个不能登录的用户\nuseradd -d /usr/local/apache -g apache -s /bin/false apache\n```\n\n\n\n```\n# -r 删除用户登入目录以及目录中所有文件。\nuserdel -r name \n```\n\n\n\n\n\n## group\n\n- /etc/group 组账户信息。\n- /etc/gshadow 安全组账户信息。\n- /etc/login.defs Shadow密码套件配置。\n\n\n\n```\n[root@localhost ~]# groupadd group1\n\ngroupdel group_name\n```\n\n\n\n\n\n\n\n## gpasswd\n\n\n\n```\ngpasswd [-a user][-d user][-A user,...][-M user,...][-r][-R] groupname\n```\n\n- -a：添加用户到组；\n- -d：从组删除用户；\n- -A：指定管理员；\n- -M：指定组成员和-A的用途差不多；\n- -r：删除密码；\n- -R：限制用户登入组，只有组中的成员才可以用newgrp加入该组。\n\n<!--more-->\n\n```\n[root@localhost ~]# gpasswd -a user1 group1\n正在将用户“user1”加入到“group1”组中\n\n[root@localhost ~]# gpasswd -a user2 group1\n\n[root@localhost ~]# cat /etc/group\ngroup1:x：1011:user1,user2 \n\n```\n\n> usermod -G group_name user_name 这个命令可以添加一个用户到指定的组，但是以前添加的组就会清空掉。\n\n\n\n```\n#从原组中用户，删除其中一个用户。\n[root@localhost ~]# grep group1 /etc/group\ngroup1:x：1011:user3,user1,user2\n[root@localhost ~]# gpasswd -d user1 group1\n正在将用户“user1”从“group1”组中删除\n[root@localhost ~]# grep group1 /etc/group\ngroup1:x：1011:user3,user2\n```\n\n\n\n##\n\n\n\n\n\n","tags":["gpasswd","user","group"],"categories":["linux","shell"]},{"title":"svg.js示例","url":"//tool/text/process/svg/","content":"\n## \n\n\n\nhttps://github.com/svgdotjs/svg.js\n\n\n\ngithub https://github.com/svgdotjs/svg.js\n\n轻量的js库，操作svg和定义动画\n\n## 安装\n\n\n\n```\nNpm:\nnpm install @svgdotjs/svg.js\n\nYarn:\nyarn add @svgdotjs/svg.js\n\nCDNs:\nhttps://cdnjs.com/libraries/svg.js\nhttps://cdn.jsdelivr.net/npm/@svgdotjs/svg.js\nhttps://unpkg.com/@svgdotjs/svg.js\n```\n\n\n\n<!--more-->\n\n\n\n## doc\n\n\n\nhttps://svgjs.dev/docs/3.0/getting-started/\n\n\n\n","tags":["xxx","xx","svgjs"],"categories":["tool","text","process"]},{"title":"md语法示例","url":"//tool/text/markdown/test/","content":"\n## \n\n<!--more-->\n\n## 引入\n\n\n\n\n\n### 图片\n\n\n\n```\n![图片](/pics/xxxx.png)\n\nsudo ln -s /home/cs/oss/hexo/themes/spfk/source/pics /pics\n```\n\n> ![](/pics/xxxx.png)\n\n\n\n并列\n\n```\n<center class=\"half\">\n    <img src=\"http://xxx.jpg\" width=\"100\"/>\n    <img src=\"http://yyy.jpg\" width=\"100\"/>\n</center>\n```\n\n\n\n\n\n\n\n### 跳转\n\n#### 站内文章跳转\n\nA文章跳到B文章的某处\n\n```\n[A文章](路径#id-service)\n\n\nB文章<p id=\"id-service\" hidden/>\n\n\n```\n\n> eg: [跳转到](/linux/k8s/kubelet#id-service)\n\n\n\n#### 页面内跳转\n\nA文章  \n\n```\n<a id=\"zim-modules\">跳到这里</a>\n\n[点击这里](#zim-modules)\n```\n\n> typora 按住ctrl再点击\n\n\n\n### 折叠\n\n```\n<details>\n  <summary>折叠文本</summary>\n  此处可书写文本\n  嗯，是可以书写文本的\n</details>\n\n\n<details>\n  <summary>折叠代码块</summary>\n  <pre><code> \n     System.out.println(\"虽然可以折叠代码块\");\n     System.out.println(\"但是代码无法高亮\");\n  </code></pre>\n</details>\n\n<details>\n  <summary>折叠代码块</summary>\n  <pre><xmp> \n     System.out.println(\"不渲染\");\n     <input />\n  </xmp></pre>\n</details>\n\n```\n\n示例\n\n<details>\n  <summary>折叠文本</summary>\n  此处可书写文本\n  嗯，是可以书写文本的\n</details>\n<details>\n  <summary>折叠代码块</summary>\n  <pre><code> \n     System.out.println(\"虽然可以折叠代码块\");\n     System.out.println(\"但是代码无法高亮\");\n  </code></pre>\n</details>\n","tags":["xxx","markdown","example"],"categories":["tool","text","markdown"]},{"title":"linux开启wifi","url":"//linux/tool/create_ap/","content":"\n## iwlwifi\n\n```\nsudo apt-get install firmware-iwlwifi\n\nmodprobe  iwlwifi\n\n \n\n```\n\n\n\n```\n#ifconfig\n$ sudo apt install net-tools  \n$ ifconfig\n```\n\n>enp109s0f1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n>        inet 192.168.5.141  netmask 255.255.255.0  broadcast 192.168.5.255\n>        inet6 fe80::82fa:5bff:fe3e:b84c  prefixlen 64  scopeid 0x20<link>\n>        ether 80:fa:5b:3e:b8:4c  txqueuelen 1000  (Ethernet)\n>        RX packets 9829  bytes 5164328 (4.9 MiB)\n>        RX errors 0  dropped 0  overruns 0  frame 0\n>        TX packets 10728  bytes 2469498 (2.3 MiB)\n>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n>\n>lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n>        inet 127.0.0.1  netmask 255.0.0.0\n>        inet6 ::1  prefixlen 128  scopeid 0x10<host>\n>        loop  txqueuelen 1000  (Local Loopback)\n>        RX packets 24  bytes 2540 (2.4 KiB)\n>        RX errors 0  dropped 0  overruns 0  frame 0\n>        TX packets 24  bytes 2540 (2.4 KiB)\n>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n>\n>wlp110s0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500\n>        ether b2:6f:32:64:0a:75  txqueuelen 1000  (Ethernet)\n>        RX packets 0  bytes 0 (0.0 B)\n>        RX errors 0  dropped 0  overruns 0  frame 0\n>        TX packets 0  bytes 0 (0.0 B)\n>        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nenp109s0f1  eth0\n\nwlp110s0   wlan0\n\n```\nsed -n '/GRUB_CMDLINE_LINUX=/s/\"\"/\"net.ifnames=0 biosdevname=0\"/'p  /etc/default/grub\nGRUB_CMDLINE_LINUX=\"net.ifnames=0 biosdevname=0\"\n\nsudo sed -i '/GRUB_CMDLINE_LINUX=/s/\"\"/\"net.ifnames=0 biosdevname=0\"/'  /etc/default/grub\n```\n\ngrub-mkconfig -o /boot/grub/grub.cfg  ?\n\n\n\n## create_ap\n\nhttps://github.com/oblique/create_ap\n\n```\ngit clone https://github.com/oblique/create_ap\ncd create_ap\nmake install\n```\n\n>install -Dm755 create_ap /usr/bin/create_ap\n>install -Dm644 create_ap.conf /etc/create_ap.conf\n>[ ! -d /lib/systemd/system ] || install -Dm644 create_ap.service /usr/lib/systemd/system/create_ap.service\n>[ ! -e /sbin/openrc-run ] || install -Dm755 create_ap.openrc /etc/init.d/create_ap\n>install -Dm644 bash_completion /usr/share/bash-completion/completions/create_ap\n>install -Dm644 README.md /usr/share/doc/create_ap/README.md\n\n<!--more-->\n\n```\ncreate_ap$ create_ap --version\n0.4.6\n```\n\n\n\n\n\n\n\n## hostapd\n\n\n\n```\ncp   defconfig   .config\n```\n\n> CONFIG_LIBNL32=y  #放开此行注释\n\n\n\n\n\n```\nmake\nmake install\n```\n\n>install -D hostapd /usr/local/bin//hostapd\n>install -D hostapd_cli /usr/local/bin//hostapd_cli\n\n\n\n```\n\n$ sudo ln -s /opt/hot-wifi/hostapd-2.10/hostapd/hostapd  /usr/local/bin/hostapd\n$ sudo ln -s /opt/hot-wifi/hostapd-2.10/hostapd/hostapd_cli  /usr/local/bin/hostapd_cli\n\n$ sudo mkdir /etc/hostapd\n$ sudo ln -s /opt/hot-wifi/hostapd-2.10/hostapd/hostapd.accept /etc/hostapd/hostapd.accept\n\nsudo ln -s /opt/hot-wifi/hostapd-2.10/hostapd/hostapd.deny /etc/hostapd/hostapd.deny\nsudo ln -s /opt/hot-wifi/hostapd-2.10/hostapd/hostapd.conf /etc/hostapd/hostapd.conf\n```\n\n\n\n\n\n\n\n## 查看 wifi 热点连接情况\n\n```\n#查看当前无线网的ID\n$ create_ap --list-running\nList of running create_ap instances:\n\n1969 wlan0 (ap0)\n\n\n$ create_ap --list-clients  1969\n```\n\n\n\n","tags":["linux","wifi","create_ap","x"],"categories":["linux","tool"]},{"title":"ssh远程登陆工具","url":"//linux/tool/ssh-tool/","content":"\n\n\n### lcrt\n\nlcrt 1.1.2\n\nhttps://packages.debian.org/stretch/lcrt\n\n```\nsudo dpkg -i /home/cs/下载/lcrt_1.1.2-2+b1_amd64.deb\n```\n\n> sudo apt --fix-broken install   #修复依赖\n\n<!--more-->\n\n\n\n### electerm\n\n[Terminal/ssh/sftp client(linux, mac, win) ](https://github.com/electerm/electerm)\n\n\n\nhttps://electerm.github.io/electerm/\n\n```\nhttps://github.com/electerm/electerm/releases/download/v1.25.30/electerm-1.25.30-linux-amd64.deb\n```\n\n>https://ghproxy.com/\n\n\n\n","tags":["ssh","tool","remote"],"categories":["linux","tool"]},{"title":"kvm安装入门","url":"//linux/virtualization/kvm/","content":"\n##  kvm\n\n### 安装\n\n```\nsudo apt install  libvirt-clients libvirt-daemon-system bridge-utils virtinst libvirt-daemon libvirt-dev  -y\n```\n\n\n\n<!--more-->\n\n```\nsudo apt install virt-manager -y\n```\n\n\n\n检查组是否已经存在\n\nsudo getent group | grep libvirt\n\n如果不存在，请将其添加为系统组\n\nsudo groupadd --system libvirt\n\n#sudo adduser $USER libvirt\n\nsudo usermod -a -G libvirt $(whoami)\n\nnewgrp libvirt\n\n\n\n```\n$ sudo cat /etc/libvirt/libvirtd.conf | egrep  \"unix_sock_group|unix_sock_rw_perms\" \n#unix_sock_group = \"libvirt\"\n#unix_sock_rw_perms = \"0770\"\n\nsudo sed -i 's/^#\\(unix_sock_group\\)/\\1/' /etc/libvirt/libvirtd.conf\nsudo sed -i 's/^#\\(unix_sock_rw_perms\\)/\\1/' /etc/libvirt/libvirtd.conf\n```\n\n\n\nsudo systemctl restart libvirtd.service\n\nsudo usermod -aG kvm $USER  ?\n\n\n\n### 目录\n\n默认存储池默认存储池 /var/lib/libvirt/images\n\n> cat  /etc/libvirt/storage/default.xml | grep path\n>\n> <path>/var/lib/libvirt/images</path>\n\n虚拟网络配置文件作为XML文件存储在**/etc/libvirt/qemu/networks**\n\n> /etc/libvirt/qemu/networks/default.xml\n\n\n\n```\nsudo sed -i \"s#/home/cs/data#/mnt#\" `ls /etc/libvirt/qemu/k8s*.xml`\n```\n\n\n\n### 导入qcow2\n\n#### define 根据xml文件创建\n\n```\nsudo virsh define /mnt/kvm/qcow/k8s01.xml\n```\n\n>❯ sudo virsh list  --all\n>\n>Id   名称    状态\n>\n>-    k8s01   关闭\n>\n>\n\n\n\n### 创建系统\n\n```\nvirt-install \\\n--virt-type kvm \\\n--os-type=linux \\\n--os-variant debian9 \\\n--name test \\\n--ram 1024  \\\n--vcpus=1  \\\n--disk /home/cs/data/kvm/qcow/debian9.qcow2,size=20,bus=virtio,format=qcow2 \\\n--cdrom  /home/cs/data/VM/debian-9.8.0-amd64-netinst.iso    \\\n--network=bridge=br0,model=virtio \\\n--graphics vnc,listen=0.0.0.0 \\\n--noautoconsole\n--autostart\n```\n\n> --connect 默认为qemu:///system, qemu+ssh://192.168.35.10/system\n>\n> –name 这个参数就是取名字\n> –ram 这个参数就是分配内存以MB计数 16834就是16G\n> –vcpus 这个就是分配CPU的个数\n> –cdrom 这个就是选择镜像位置\n> –network=bridge 这个就是选择桥接网卡的接口 ,nat network=default/net-br\n> –disk path 这个参数就是为了配置虚拟机的硬盘大小 size=40 就是40G format为qcow2 \n>\n> --os-variant  查询 osinfo-query os（ apt -y install libosinfo-bin ）\n>\n> --autostart   自动开启\n\n\n\n#### 添加网桥\n\n网桥是一种在链路层实现中继，对帧进行转发的技术，根据MAC分区块，可隔离碰撞，将网络的多个网段在数据链路层连接起来的网络设备。\n\n![](/pics/kvm-brctl-vm.png)\n\n\n\n```\n yum install bridge-utils -y\n \napt-get  install bridge-utils -y\n```\n\n\n\n\n\n```\nsudo  brctl addbr br0\n```\n\n> ERROR    无法在 'br0' 获取接口 MTU: 没有那个设备\n\n\n\n```\n❯  brctl show | grep br0\nvirbr0\t\t8000.525400b51f85\tyes\t\tvnet0\n```\n\n>配置ip地址\n>\n>ifconfig virbr0 192.168.122.1 netmask 255.255.255.0 \n>\n> ip addr | grep -A 3 \"`brctl show | grep br0 | awk '{print $1}'`:\"\n\n\n\n容器\n\n![](/pics/kvm-brctl-docker.png)\n\n\n\n#### 创建centos7 \n\n[mirrors集合](https://www.centos.org/download/mirrors/ )\n\n\n\n[阿里CentOS-7-x86_64](http://mirrors.aliyun.com/centos/7.9.2009/isos/x86_64/CentOS-7-x86_64-Minimal-2009.iso?spm=a2c6h.25603864.0.0.736a6aeaa9kHJB )\n\n```\n$ sudo virt-install   --virt-type kvm --os-type=linux --os-variant centos7 --name centos7-01 --ram 2048  --vcpus=2  --disk /home/cs/data/kvm/qcow/centos7.qcow2,size=20,bus=virtio,format=qcow2 --cdrom  /home/cs/data/kvm/iso/CentOS-7-x86_64-Minimal-1810.iso    --network=bridge=br0,model=virtio --graphics vnc,listen=0.0.0.0 --noautoconsole\n\n开始安装......\n正在分配 'debian9.qcow2'        0% [                 ]    0 B/s | 1.2 MB  --:-- 正在分配 'debian9.qcow2'        0% [                 ] 5.7 MB/s | 9.2 MB  59:31 正在分配 'debian9.qcow2'        0% [                 ] 6.3 MB/s |  18 MB  53:49 正在分配 'debian9.qcow2'        0% [                 ] 6.7 MB/s |  27 MB  51:00 正在分配 'debian9.qcow2'        0% [                 ] 6.9 MB/s |  35 MB  49:24 正在分配 'debian9.qcow2'        0% [                 ] 7.1 MB/s |  42 MB  48:12 正在分配 'debian9.qcow2'                                        |  20 GB  00:05     \n\n域仍在运行。安装可能正在进行中。\n可以重新连接到控制台以完成安装过程。\n```\n\n> qemu:///system\n\n\n\n### 磁盘格式\n\nraw立即分配空间,裸格式，占用空间比较大，不适合远程传输,不支持快照功能，性能较好\n\nqcow2只有需要时才会分配空间,cow(copy on write)占用空间小，适合传输，支持快照，性能比 raw 稍差\n\n\n\n```\n#创建虚拟磁盘\nqemu-img create test.raw  10G\nqemu-img create -f qcow2 test.qcow2 10G\n \n#查看虚拟磁盘信息\nqemu-img info test.raw\n \n#调整虚拟磁盘容量大小\nqemu-img resize test.raw +5G\n \n#磁盘格式转换\nqemu-img convert -f raw -O qcow2 test.raw test.qcow2\n```\n\n\n\n### 快照\n\n\n\n```\nraw不支持快照\n\n创建快照\nvirsh snapshot-create-as vm02 vm02.snap02\n\n查看快照\nvirsh snapshot-list vm02\n\n关闭虚拟机，恢复快照\nvirsh snapshot-revert vm02 vm02.snap02\n\n删除快照\nvirsh snapshot-delete --snapshotname vm02.snap02 vm02\n```\n\n\n\n### 网络\n\n#### brctl\n\n```\nbrctl [参数] <bridge>\n```\n\n| 参数                      | 说明                   | 示例                      |\n| ------------------------- | ---------------------- | ------------------------- |\n| `addbr <bridge>`          | 创建网桥               | **brctl** addbr br10      |\n| `delbr <bridge>`          | 删除网桥               | **brctl** delbr br10      |\n| `addif <bridge> <device>` | 将网卡接口接入网桥     | **brctl** addif br10 eth0 |\n| `delif <bridge> <device>` | 删除网桥接入的网卡接口 | **brctl** delif br10 eth0 |\n| `show <bridge>`           | 查询网桥信息           | **brctl** show br10       |\n| `stp <bridge> {on|off}`   | 启用禁用 STP           | **brctl** stp br10 off/on |\n| `showstp <bridge>`        | 查看网桥 STP 信息      | **brctl** showstp br10    |\n| `setfd <bridge> <time>`   | 设置网桥延迟           | **brctl** setfd br10 10   |\n| `showmacs <bridge>`       | 查看 mac 信息          | **brctl** showmacs br10   |\n\n\n\nhttps://www.cnblogs.com/hukey/p/6436211.html\n\n\n\n\n\n#### 桥接\n\n\n\n```\n#创建桥接网络\nvirsh iface-bridge eth0 br0\n```\n\n> --network bridge=br0\n\n\n\nsudo brctl addif br0 eth0\n\nsudo brctl stp br0 on\n\nbrctl show\n\n\n\n#### net\n\n\n\n```\n$ sudo virsh net-list --all\n 名称      状态     自动开始   持久\n-------------------------------------\n default   不活跃   否         是\n\n$ sudo virsh net-autostart default\n网络default标记为自动启动\n\n$ sudo virsh net-start default\n网络 default 已开始\n\n$ sudo virsh net-list --all\n 名称      状态   自动开始   持久\n-----------------------------------\n default   活动   是         是\n\n$ sudo virsh net-destroy default\n网络 default 被删除\n\n```\n\n> 网络 'default' 未激活\n\n\n\nhttps://tqdev.com/2020-kvm-network-static-ip-addresses\n\n```\n$ sudo virsh net-dumpxml default\n```\n\n><network>\n><name>default</name>\n><uuid>f527b455-06b2-4bd2-87cd-7c4c84ef899d</uuid>\n><forward mode='nat'>\n><nat>\n><port start='1024' end='65535'/>\n></nat>\n></forward>\n><bridge name='virbr0' stp='on' delay='0'/>\n><mac address='52:54:00:b5:1f:85'/>\n><ip address='192.168.122.1' netmask='255.255.255.0'>\n><dhcp>\n><range start='192.168.122.2' end='192.168.122.254'/>  #ip-dhcp-range\n></dhcp>\n></ip>\n></network>\n\n宿主机操作default.xml\n\n```\n##更新dhcp范围\n# virsh net-update default delete ip-dhcp-range \"<range start='192.168.122.2' end='192.168.122.254'/>\" --live --config\n# virsh net-update default add ip-dhcp-range \"<range start='192.168.122.100' end='192.168.122.254'/>\" --live --config\n\n#获取name\n$ sudo virsh list \n Id   名称         状态\n----------------------------\n 3    centos7-01   running\n \n #获取mac\n$ sudo virsh dumpxml centos7-01  | grep \"mac address\"\n      <mac address='52:54:00:ed:75:fc'/>\n\n#分配ip\nsudo virsh net-update default add-last ip-dhcp-host \"<host mac='52:54:00:ed:75:fc' name='centos7-01' ip='192.168.122.11'/>\" --live --config\nsudo virsh net-dumpxml default\n```\n\n><network>\n><name>default</name>\n><uuid>f527b455-06b2-4bd2-87cd-7c4c84ef899d</uuid>\n><forward mode='nat'>\n><nat>\n><port start='1024' end='65535'/>\n></nat>\n></forward>\n><bridge name='virbr0' stp='on' delay='0'/>\n><mac address='52:54:00:b5:1f:85'/>\n><ip address='192.168.122.1' netmask='255.255.255.0'>\n><dhcp>\n><range start='192.168.122.2' end='192.168.122.254'/>\n><host mac='52:54:00:ed:75:fc' name='centos7-01' ip='192.168.122.11'/>\n></dhcp>\n></ip>\n></network>\n\n\n\n在虚机上重新发送DHCP请求\n\n```\nsudo dhclient -r && sudo dhclient\ndhclient -r &&  dhclient\n```\n\nping\n\n```\n$ arp -a | grep 52:54:00:ed:75:fc\n? (192.168.122.11) at 52:54:00:ed:75:fc [ether] on virbr0\n\n$ ping 192.168.122.11\nPING 192.168.122.11 (192.168.122.11) 56(84) bytes of data.\n64 bytes from 192.168.122.11: icmp_seq=1 ttl=64 time=0.279 ms\n64 bytes from 192.168.122.11: icmp_seq=2 ttl=64 time=0.311 ms\n^C\n--- 192.168.122.11 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1022ms\nrtt min/avg/max/mdev = 0.279/0.295/0.311/0.016 ms\n```\n\n\n\n重启自动获取ip\n\n```\n[root@centos7-01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 | grep BOOT\nBOOTPROTO=dhcp\nONBOOT=no\n\n[root@centos7-01 ~]# sed -n '/^ONBOOT=/s/no/yes/'p /etc/sysconfig/network-scripts/ifcfg-eth0\nONBOOT=yes\n[root@centos7-01 ~]# sed -i '/^ONBOOT=/s/no/yes/' /etc/sysconfig/network-scripts/ifcfg-eth0\n\n[root@centos7-01 ~]# systemctl restart network\n```\n\n\n\nssh\n\n```\nsystemctl status sshd.service\nsystemctl restart sshd.service\n\n\n# sed -n \"s/^#\\(Port\\|Listen\\|PermitRoo\\)/水&/\"p /etc/ssh/sshd_config\n#Port 22\n#ListenAddress 0.0.0.0\n#ListenAddress ::\n#PermitRootLogin yes\n\n\n#取消 sed 's/^#\\(bbb\\)/\\1/' z.txt\n```\n\n\n\n\n\n\n\n\n\n```\n$ sudo virsh net-edit default\n```\n\n>Select an editor.  To change later, run 'select-editor'.\n>\n>    1. /bin/nano        <---- easiest\n>    2. /usr/bin/vim.tiny\n>\n>Choose 1-2 [1]: 2\n\n\n\n#### ifcfg-eth0\n\nhost /etc/libvirt/qemu/networks/default.xml\n\n>  <ip address='192.168.122.1' netmask='255.255.255.0'>\n>     <dhcp>\n>       <range start='192.168.122.2' end='192.168.122.254'/>\n>       <host mac='52:54:00:ed:75:fc' name='centos7-01' ip='192.168.122.11'/>\n>       <host mac='52:54:00:ed:5f:02' name='centos7-01' ip='192.168.122.12'/>\n>     </dhcp>\n>   </ip>\t\n\n\n\nvm  /etc/sysconfig/network-scripts/ifcfg-eth0\n\n>TYPE=Ethernet\n>PROXY_METHOD=none\n>BROWSER_ONLY=no\n>BOOTPROTO=dhcp\n>DEFROUTE=yes\n>IPV4_FAILURE_FATAL=no\n>IPV6INIT=yes\n>IPV6_AUTOCONF=yes\n>IPV6_DEFROUTE=yes\n>IPV6_FAILURE_FATAL=no\n>IPV6_ADDR_GEN_MODE=stable-privacy\n>NAME=eth0\n>UUID=5ab88b14-d03b-4469-8dfa-d98872b7c97b\n>DEVICE=eth0\n>ONBOOT=yes\n\n\n\n```\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nIPV6_ADDR_GEN_MODE=stable-privacy\nNAME=eth0\nDEVICE=eth0\nONBOOT=yes\nIPADDR=192.168.122.1\nNETMASK=255.255.255.0\nGATEWAY=192.168.122.1\nDNS1=192.168.1.1\n```\n\n> IPADDR=192.168.122.1  #固定静态ip\n\n\n\n\n### libguestfs\n\nhttps://libguestfs.org/\n\n该工具包内包含的工具有virt-cat、virt-df、virt-ls、virt-copy-in、virt-copy-out、*virt-edit*....\n\n```\nsudo yum install libguestfs-tools      # Fedora/RHEL/CentOS\nsudo apt-get install libguestfs-tools  # Debian/Ubuntu\n```\n\n\n\n#### virt-edit\n\nhttps://libguestfs.org/virt-edit.1.html\n\n```\ncs@debian:~/data/kvm$ sudo virt-edit -d base /etc/sysconfig/network-scripts/ifcfg-eth0 -e \"s/dhcp/static/\" \ncs@debian:~/data/kvm$ sudo virt-cat base /etc/sysconfig/network-scripts/ifcfg-eth0\n```\n\n> TYPE=Ethernet\n> PROXY_METHOD=none\n> BROWSER_ONLY=no\n> BOOTPROTO=static\n> DEFROUTE=yes\n> IPV4_FAILURE_FATAL=no\n> IPV6INIT=yes\n> IPV6_AUTOCONF=yes\n> IPV6_DEFROUTE=yes\n> IPV6_FAILURE_FATAL=no\n> IPV6_ADDR_GEN_MODE=stable-privacy\n> NAME=eth0\n> UUID=65a51a6b-e278-4066-8d60-f7537080cc68\n> DEVICE=eth0\n> ONBOOT=yes\n\n\n\n不支持  \"/^BOOTPROTO/s/static/dhcp/\"\n\n```\ncs@debian:~/data/kvm$ sudo virt-edit -d base /etc/sysconfig/network-scripts/ifcfg-eth0 -e \"/^BOOTPROTO/s/static/dhcp/\"\nsyntax error at (eval 1) line 1, at EOF\n\t...propagated at -e line 1, <STDIN> line 1.\n```\n\n\n### 镜像模板配置\n\n#### hosts\n\n<details>\n  <summary>/etc/hosts</summary>\n127.0.0.1   localhost k8s01\n::1         localhost\n192.168.122.11 k8s01\n192.168.122.12 k8s02\n192.168.122.13 k8s03\n192.168.122.14 k8s04\n192.168.122.15 k8s05\n192.168.122.16 k8s06\n</details>\n\n\n#### ifcfg-eth0\n\n<details>\n  <summary>/etc/sysconfig/network-scripts/ifcfg-eth0</summary>\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nIPV6_ADDR_GEN_MODE=stable-privacy\nNAME=eth0\nDEVICE=eth0\nONBOOT=yes\nNETMASK=255.255.255.0\nGATEWAY=192.168.122.1\nDNS1=192.168.1.1\n</details>\n\n\n#### 批量创建\n\n基于已有镜像系统\n\n```\n/etc/libvirt/qemu\n├── base.xml\n├── k8s01.xml\n├── k8s02.xml\n├── k8s03.xml\n├── k8s04.xml\n├── k8s05.xml\n├── k8s06.xml\n├── networks\n│   ├── autostart\n│   │   └── default.xml -> /etc/libvirt/qemu/networks/default.xml\n│   └── default.xml\n└── test.xml\n\n2 directories, 10 files\n\n```\n\n  virsh defline --validate k8s01.xml\n\n\n\n<details>\n  <summary>k8s01.xml</summary>\n<pre><a>/etc/libvirt/qemu/k8s01.xml</a><xmp>\n <!--\nWARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE\nOVERWRITTEN AND LOST. Changes to this xml configuration should be made using:\n  virsh edit k8s01\nor other application using the libvirt API.\n-->\n<domain type='kvm'>\n  <name>k8s01</name>\n  <uuid>f2e97f2f-583d-4ada-a7be-f18f42053374</uuid>\n  <title>192.168.1.1</title>\n  <metadata>\n    <libosinfo:libosinfo xmlns:libosinfo=\"http://libosinfo.org/xmlns/libvirt/domain/1.0\">\n      <libosinfo:os id=\"http://centos.org/centos/7.0\"/>\n    </libosinfo:libosinfo>\n  </metadata>\n  <memory unit='KiB'>2097152</memory>\n  <currentMemory unit='KiB'>2097152</currentMemory>\n  <vcpu placement='static'>2</vcpu>\n  <os>\n    <type arch='x86_64' machine='pc-q35-5.2'>hvm</type>\n    <boot dev='hd'/>\n  </os>\n  <features>\n    <acpi/>\n    <apic/>\n  </features>\n  <cpu mode='host-model' check='partial'/>\n  <clock offset='utc'>\n    <timer name='rtc' tickpolicy='catchup'/>\n    <timer name='pit' tickpolicy='delay'/>\n    <timer name='hpet' present='no'/>\n  </clock>\n  <on_poweroff>destroy</on_poweroff>\n  <on_reboot>restart</on_reboot>\n  <on_crash>destroy</on_crash>\n  <pm>\n    <suspend-to-mem enabled='no'/>\n    <suspend-to-disk enabled='no'/>\n  </pm>\n  <devices>\n    <emulator>/usr/bin/qemu-system-x86_64</emulator>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='qcow2'/>\n      <source file='/home/cs/data/kvm/qcow/centos7.qcow2'/>\n      <target dev='vda' bus='virtio'/>\n      <address type='pci' domain='0x0000' bus='0x04' slot='0x00' function='0x0'/>\n    </disk>\n    <disk type='file' device='cdrom'>\n      <driver name='qemu' type='raw'/>\n      <target dev='sda' bus='sata'/>\n      <readonly/>\n      <address type='drive' controller='0' bus='0' target='0' unit='0'/>\n    </disk>\n    <controller type='usb' index='0' model='qemu-xhci' ports='15'>\n      <address type='pci' domain='0x0000' bus='0x02' slot='0x00' function='0x0'/>\n    </controller>\n    <controller type='sata' index='0'>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x1f' function='0x2'/>\n    </controller>\n    <controller type='pci' index='0' model='pcie-root'/>\n    <controller type='pci' index='1' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='1' port='0x10'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0' multifunction='on'/>\n    </controller>\n    <controller type='pci' index='2' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='2' port='0x11'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x1'/>\n    </controller>\n    <controller type='pci' index='3' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='3' port='0x12'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x2'/>\n    </controller>\n    <controller type='pci' index='4' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='4' port='0x13'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x3'/>\n    </controller>\n    <controller type='pci' index='5' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='5' port='0x14'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x4'/>\n    </controller>\n    <controller type='pci' index='6' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='6' port='0x15'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x5'/>\n    </controller>\n    <controller type='pci' index='7' model='pcie-root-port'>\n      <model name='pcie-root-port'/>\n      <target chassis='7' port='0x16'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x6'/>\n    </controller>\n    <controller type='virtio-serial' index='0'>\n      <address type='pci' domain='0x0000' bus='0x03' slot='0x00' function='0x0'/>\n    </controller>\n    <interface type='network'>\n      <mac address='52:54:00:ed:75:fc'/>\n      <source network='default'/>\n      <model type='virtio'/>\n      <address type='pci' domain='0x0000' bus='0x01' slot='0x00' function='0x0'/>\n    </interface>\n    <serial type='pty'>\n      <target type='isa-serial' port='0'>\n        <model name='isa-serial'/>\n      </target>\n    </serial>\n    <console type='pty'>\n      <target type='serial' port='0'/>\n    </console>\n    <channel type='unix'>\n      <target type='virtio' name='org.qemu.guest_agent.0'/>\n      <address type='virtio-serial' controller='0' bus='0' port='1'/>\n    </channel>\n    <input type='tablet' bus='usb'>\n      <address type='usb' bus='0' port='1'/>\n    </input>\n    <input type='mouse' bus='ps2'/>\n    <input type='keyboard' bus='ps2'/>\n    <graphics type='vnc' port='-1' autoport='yes' listen='0.0.0.0'>\n      <listen type='address' address='0.0.0.0'/>\n    </graphics>\n    <video>\n      <model type='vga' vram='16384' heads='1' primary='yes'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x0'/>\n    </video>\n    <memballoon model='virtio'>\n      <address type='pci' domain='0x0000' bus='0x05' slot='0x00' function='0x0'/>\n    </memballoon>\n    <rng model='virtio'>\n      <backend model='random'>/dev/urandom</backend>\n      <address type='pci' domain='0x0000' bus='0x06' slot='0x00' function='0x0'/>\n    </rng>\n  </devices>\n</domain>\n </xmp></pre>\n</details>\n\n\n##### 网络 \n\n<details>\n  <summary>default.xml</summary>\n  <pre><a>/etc/libvirt/qemu/networks/default.xml</a><xmp> \n  <!--\nWARNING: THIS IS AN AUTO-GENERATED FILE. CHANGES TO IT ARE LIKELY TO BE\nOVERWRITTEN AND LOST. Changes to this xml configuration should be made using:\n  virsh net-edit default\nor other application using the libvirt API.\n-->\n<network>\n  <name>default</name>\n  <uuid>f527b455-06b2-4bd2-87cd-7c4c84ef899d</uuid>\n  <forward mode='nat'/>\n  <bridge name='virbr0' stp='on' delay='0'/>\n  <mac address='52:54:00:b5:1f:85'/>\n  <ip address='192.168.122.1' netmask='255.255.255.0'>\n    <dhcp>\n      <range start='192.168.122.2' end='192.168.122.254'/>\n      <host mac='52:54:00:ed:75:fc' name='centos7-01' ip='192.168.122.11'/>\n    </dhcp>\n  </ip>\n</network>\n</xmp></pre>\n</details>\n##### 批量脚本\n\nbatch.sh\n\n```shell\n#!/bin/env bash\nstart=4\nend=6\n\n#基础镜像和配置\nbaseimg=/home/cs/data/kvm/images/centos-base.qcow2\nsqemu=/home/cs/data/kvm/k8s01.xml\n\n#qemu=/etc/libvirt/qemu\nqemu=/home/cs/data/kvm/qcow\n\n#网络\nnet=/etc/libvirt/qemu/networks/default.xml\n#名称domain\nname=k8s0\n#ip起始\nbip=\"192.168.122.1\"\n\ncopy_xml(){\n\tcp_xml=$qemu/$name$1.xml\n\tcp $sqemu $cp_xml\n\tuuid=$(cat /proc/sys/kernel/random/uuid)\n\tmac1=`openssl rand -base64 8 |md5sum |cut -c1-2`\n\tmac2=`openssl rand -base64 8 |md5sum |cut -c1-2`\n\n\tsed -n \"/<name>/s/>.*</>$name$1</\"p $cp_xml\n\tsed -i \"/<name>/s/>.*</>$name$1</\" $cp_xml\n\n\tsed -n \"/<uuid>/s/>.*</>$uuid</\"p  $cp_xml\n\tsed -i \"/<uuid>/s/>.*</>$uuid</\" $cp_xml\n\n\tsed -n \"/<title>/s/>.*</>$bip$1</\"p  $cp_xml\n\tsed -i \"/<title>/s/>.*</>$bip$1</\" $cp_xml\n\n\t# mac <mac address='52:54:00:ed:xx:xx'/>\n\tmac=\"/<mac/s/address=.*'/address='52:54:00:ed:$mac1:$mac2'/\"\n\tsed -n ${mac}p  $cp_xml\n\tsed -i ${mac} $cp_xml\n\n\t#磁盘名称\n\tfile=\"/<source/s/file=.*'/file='\\/home\\/cs\\/data\\/kvm\\/qcow\\/$name$i.qcow2'/\"\n\tsed -n ${file}p  $cp_xml\n\tsed -i  ${file} $cp_xml\n\n\t\n}\n\n#复制img文件\ncopy_qcow2(){\n\tfor i in `seq $start $end`\n\tdo\n\t{\n\t\ttemp=/home/cs/data/kvm/qcow/$name$i.qcow2\n\t\t[ -f \"$temp\" ] && { echo \"file:$temp is exist,exit shell\" && exit 0;} \n\t\techo \">>>start copy...$name$i.qcow2\"\n\t\tcp $baseimg  $temp\n\t    wait\n\t\techo \"copy qcow2 end\"\n        \n        echo \">>>start copy...xml\"\n        copy_xml $i\n        echo \"copy xml end\"\t\n\n\t}\n\tdone\n\n}\n\n#/etc/libvirt/qemu/networks/default.xml\nallcote_ip(){\n   for i in `seq $start $end`\n\tdo\n\t{\n        echo \">>>start allcote ip...\"\n        temp=$qemu/$name$i.xml\n        mac=$(cat $temp | grep \"<mac\" | sed  \"s/.*\\(52.*\\)'\\/>/\\1/\")\n        sed -n \"/$name$i/s/mac=.* n/mac='$mac' n/\"p $net\n        sed -i \"/$name$i/s/mac=.* n/mac='$mac' n/\" $net\n\n        virsh define $temp\n        [ -n \"$(command virt-edit -V)\" ] || { echo \"tool virt-edit is not exist,please download https://libguestfs.org/\" && exit ; }\n        ar=\"IPADDR=192.168.122.1$i\"\n        virt-edit -d $name$i /etc/sysconfig/network-scripts/ifcfg-eth0 -e \"s/.*ADDR=192.*/$ar/\"\n        wait\n        changeip=$(virt-cat $name$i /etc/sysconfig/network-scripts/ifcfg-eth0 | grep IPADDR)\n        echo \"NAME=$name$i MAC=$mac $changeip\"\n        echo \"end allcote ip\\n\"\n\t}\n\tdone\n\t\n}\n\ncopy_qcow2\n\nallcote_ip\n\n:<<EOF\nqemu-img info base.qcow2 \nimage: base.qcow2\nfile format: qcow2\nvirtual size: 20 GiB (21474836480 bytes)\ndisk size: 3.72 GiB\ncluster_size: 65536\nFormat specific information:\n    compat: 1.1\n    compression type: zlib\n    lazy refcounts: true\n    refcount bits: 16\n    corrupt: false\n    extended l2: false\n    \nsudo yum install libguestfs-tools      # Fedora/RHEL/CentOS\nsudo apt-get install libguestfs-tools  # Debian/Ubuntu\n\n[ \"${USER}\" = \"root\" ] || { echo \"user:$USER \" && copy_qcow2  ;}\n[ \"${USER}\" = \"root\" ] && { echo \"user:$USER \" && allcote_ip ;}\n\nEOF\n```\n\n\n\n## virsh\n\n\n\n### list\n\n```\nsudo virsh list --all\n```\n\n\n\n### start\n\n```\nlist=$(sudo virsh list  --all --name  | grep k8s)\nfor i in $(list);do sudo virsh start $i;done\n```\n\n\n\n\n\n### shutdown\n\n批量关机\n\n```\nlist=($(sudo virsh list --name | grep k8s))    #zsh\nfor i in $list;do sudo virsh shutdown $i;done\n```\n\n\n\n\n\n\n\n\n## vagrant\n\n [vagrant 虚拟工具](/tool/vagrant)\n\n\n\n```\n$ sudo ln -sf /opt/vagrant/bin/vagrant  /usr/local/bin/vagrant\n\n```\n\n> #存储全局状态的默认目录\n>\n> $ ls  ~/.vagrant.d\n\n\n\n\nmetadata.json\n\n```\nvagrant box add name metadata.json\ncat >metadata.json<<EOF\n{\n    \"name\": \"名称\", \n    \"versions\": [{\n        \"version\": \"版本\", \n        \"providers\": [{\n            \"name\": \"虚拟机类型\", \n            \"url\": \"file:///home/cs/data/VM/xxx.box\"\n        }]\n    }]\n}\nEOF\n```\n\n>{\n>    \"name\": \"centos/7\",\n>    \"versions\": [{\n>        \"version\": \"7.1.0\",\n>        \"providers\": [{\n>            \"name\": \"libvirt\",\n>            \"url\": \"file:///home/cs/data/VM/centos/CentOS-7-x86_64-Vagrant-2004_01.LibVirt.box\"\n>        }]\n>    }]\n>}\n\n\n\n### add\n\n```\n vagrant box add centos/7 /home/cs/data/VM/centos/metadata.json\n \n```\n\n>==> box: Loading metadata for box '/home/cs/data/VM/centos/metadata.json'\n>box: URL: file:///home/cs/data/VM/centos/metadata.json\n>==> box: Adding box 'centos/7' (v7.1.0) for provider: libvirt\n>box: Unpacking necessary files from: file:///home/cs/data/VM/centos/CentOS-7-x86_64-Vagrant-2004_01.LibVirt.box\n>==> box: Successfully added box 'centos/7' (v7.1.0) for 'libvirt'!\n\n\n\n### list\n\n```\n$ vagrant box list\ncentos/7 (libvirt, 7.1.0)\ncentos/7 (virtualbox, 7.1.0)\n\n```\n\n\n\n\n\n### plugin\n\n\n\nvagrant plugin expunge --reinstall\n\n\n\n#插件列表\nvagrant plugin list\n\n\n\n\n\n\n\n命令行界面之 Plugin https://blog.51cto.com/luciferliu/3432079\n","tags":["xxx","xx","kvm安装入门"],"categories":["linux","virtualization","kvm"]},{"title":"docker二进制安装","url":"//linux/virtualization/container/docker-bit/","content":"\n## 下载\n\ndocker二进制包获取地址：https://download.docker.com/linux/static/stable/x86_64/\n\n```\n$ tar -zxvf docker*.tgz\n$ cp docker/* /usr/bin\n```\n\n\n\n## json\n\ndaemon.json\n\n```\ncat >> /etc/docker/daemon.json <<EOF\n{\n    \"data-root\": \"/home/cs/data/docker\",\n   \"registry-mirrors\" : [\n    \"http://hub-mirror.c.163.com\"\n  ],\n\"insecure-registries\":[\n  \"https://k8s.org\"\n  ],\n  \"debug\" : true,\n  \"experimental\" : true\n}\nEOF\n```\n\n\n\n<!--more-->\n\n\n\n## service\n\n\n\n```\ncat >>/usr/lib/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service\nWants=network-online.target\n\n[Service]\nType=notify\nExecStart=/usr/bin/dockerd\nExecReload=/bin/kill -s HUP $MAINPID\nLimitNOFILE=infinity\nLimitNPROC=infinity\nTimeoutStartSec=0\nDelegate=yes\nKillMode=process\nRestart=on-failure\nStartLimitBurst=3\nStartLimitInterval=60s\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n\n\n## 开始\n\n```\nsystemctl daemon-reload\nsystemctl enable --now docker\n\ncat /etc/group | grep ^docker  #不存在\nsudo groupadd docker  #存在忽略，创建组\nsudo gpasswd -a ${USER} docker   #添加当前用户到组\nsudo restart  #重启生效\n```\n\n\n\n\n\n## compose\n\n\n\nhttps://ghproxy.com/\n\n```\n$ curl -L https://github.com/docker/compose/releases/download/v2.15.1/docker-compose-linux-x86_64\n$ docker compose version\nDocker Compose version v2.15.1\n\n```\n\n> 当前用户 docker-compose` and copy it to `$HOME/.docker/cli-plugins\n>\n> 所有用户 /usr/local/lib/docker/cli-plugins/docker-compose\n>\n> 原有的“docker-compose 命令不再使用\n\n\n\n## 私库\n\n[harbor安装](/linux/tool/harbor)\n\nsudo bash /opt/ansible/bak/harbor.sh \n\n\n\n````\n$ sudo mkdir -p /etc/docker/certs.d/k8s.org\n$ sudo cp /opt/kubernetes/harbor/k8s.org/{k8s.org*,ca.crt} /etc/docker/certs.d/k8s.org\n$ ls -l /etc/docker/certs.d/k8s.org\n总用量 12\n-rw-r--r-- 1 root root 1968  2月 28 21:22 ca.crt\n-rw-r--r-- 1 root root 2004  2月 28 21:22 k8s.org.cert\n-rw------- 1 root root 3243  2月 28 21:22 k8s.org.key\n$ sudo systemctl status docker\n````\n\n","tags":["docker","virtualization","binary"],"categories":["linux","container","docker-bit"]},{"title":"fstab挂盘","url":"//linux/storage/fstab/","content":"\n### 格式化\n\n原盘\n\n```\n❯ lsblk -o name,uuid,FSTYPE,size\nNAME        UUID                                 FSTYPE   SIZE\nsda                                                     931.5G\n├─sda1      70BE7BF5BE7BB1E8                     ntfs     250G\n├─sda2      0FE407890FE40789                     ntfs   200.5G\n├─sda3      62711307D9630248                     ntfs   108.6G\n├─sda4      b519f517-5f11-4108-8601-e456e3da4fd1 xfs    100.9G\n├─sda5      0CFA1DD20CFA1DD2                     ntfs   150.8G\n└─sda6      2006966506963BAA                     ntfs   120.7G\nnvme0n1                                                   1.8T\n├─nvme0n1p1 8aef5178-364f-47de-9016-3b3bb254aadd ext4    55.9G\n├─nvme0n1p2 ff3aedfa-1448-4161-95fb-3b43fddf4506 ext4    55.9G\n├─nvme0n1p3 8c8a753d-b3f4-45ee-b2a8-629c13f4c18e ext4   195.6G\n├─nvme0n1p4 a40908d9-e0e9-4d17-8aad-d7e1a1f90730 ext4   353.9G\n├─nvme0n1p5 bb259291-c221-4e34-b422-663e0bea289e swap     7.5G\n├─nvme0n1p6 E509-52C5                            vfat     553M\n└─nvme0n1p7 7A1276B712767849                     ntfs      80G\n\n```\n\n格式xfs\n\n```\nsudo apt-get install xfsprogs\n```\n\n\n\n```\n❯ sudo mkfs.xfs /dev/sda3 -f\nmeta-data=/dev/sda3              isize=512    agcount=4, agsize=7117869 blks\n         =                       sectsz=4096  attr=2, projid32bit=1\n         =                       crc=1        finobt=1, sparse=1, rmapbt=0\n         =                       reflink=1    bigtime=0\ndata     =                       bsize=4096   blocks=28471475, imaxpct=25\n         =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0, ftype=1\nlog      =internal log           bsize=4096   blocks=13902, version=2\n         =                       sectsz=4096  sunit=1 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\n\n```\n\n>/dev/sda3 contains a mounted filesystem   需要是非挂载状态\n>/dev/sda3 appears to contain an existing filesystem (ntfs).  其他格式使用-f强制\n\n生成新的uuid\n\n```\n❯ sudo blkid /dev/sda3\n/dev/sda3: UUID=\"f8354fa6-cc44-4591-8995-b9cbdbd3c2a9\" BLOCK_SIZE=\"4096\" TYPE=\"xfs\" PARTLABEL=\"Basic data partition\" PARTUUID=\"ce05cf5a-d347-4101-98d1-fc27e7659c5b\"\n\n```\n\n挂载到/etc/fstab\n\n```\n❯ sudo mv  /home/cs/data/kvm  /home/cs/data/kvms\n❯ sudo mousepad /etc/fstab\n❯ sudo mount -a\n❯ sudo mv  /home/cs/data/kvms/*  /home/cs/data/kvm\n\n```\n\n> \\#/data was on /dev/sda3 during installation\n>\n> UUID=f8354fa6-cc44-4591-8995-b9cbdbd3c2a9 /home/cs/data/kvm            xfs    defaults        0       2\n\n\n\n```\nsudo systemctl stop libvirtd\nsudo systemctl start libvirtd\n```\n\n\n\n\n\n### 挂盘\n\n/etc/fstab\n\n```\n#cat /etc/fstab\n# /boot/efi was on /dev/sda2 during installation\nUUID=FF6E-1E1A  /boot/efi       vfat    umask=0077      0       1\n# /home was on /dev/sda6 during installation\nUUID=abca56cf-7ab5-4c4a-a5ab-f4b2ebdc0c82 /home           ext4    defaults        0       2\n```\n\n> **<file system>**\n>\n> **<dir>**\n>\n> **<type>**  ext3、ext4、xfs、swap\n>\n> **<options>**  \n>\n>    auto - 在启动时或键入了 mount -a 命令时自动挂载\n>\n>    exec - 允许执行此分区的二进制文件。\n>\n>    ro - 以只读模式挂载文件系统。\n>    rw - 以读写模式挂载文件系统。\n>\n>    suid - 允许 suid 操作和设定 sgid 位 临时提权操作\n>\n>    defaults - 使用文件系统的默认挂载参数，例如 ext4 的默认参数为:rw, suid, dev, exec, auto, nouser, async.\n>\n> **<dump>**  dump 工具通过它决定何时作备份. dump 会检查其内容，允许的数字是 0 和 1 。0 表示忽略， 1 则进行备份\n>\n> **<pass>**  数值来决定需要检查的文件系统的检查顺序。允许的数字是0, 1, 和2。 根目录应当获得最高的优先权 1, 其它所有需要被检查的设备设置为 2. 0 表示设备不会被 fsck 所检查。\n\n<!--more-->\n\n```\n$ sudo mount -a\nmount: /etc/fstab: parse error at line 24 -- ignored\n```\n\n> **cat -v /etc/fstab**   将显示出任何虚假字符/不显示乱0xa0码造成任何问题\n\n\n\n\n\n\n\n\n\n","tags":["xxx","fstab","挂盘"],"categories":["linux","storage","fstab"]},{"title":"os信息备份","url":"//linux/debian/os/","content":"\n## 系统版本\n\n```\ncat /etc/redhat-release\nCentOS Linux release 7.6.1810 (Core) \n\n\n# uname -r\n3.10.0-957.el7.x86_64\n```\n\n>el7是RHEL7系列的,centos7看到\n\n\n\n```\n❯ uname -r\n6.1.0-0.deb11.7-amd64\n```\n\n> debian11\n\n\n\n## 图形界面\n\nxface\n\n```\n#查看当前启动模式\nsystemctl get-default\n\n#由命令行模式更改为图形界面模式\nsystemctl set-default graphical.target\n\n#由图形界面模式更改为命令行模式\nsystemctl set-default multi-user.target\n```\n\n\n\n命令行界面—>图形界面\n\n执行startx命令\n\n图形界面—>命令行界面\n\nCtrl+Alt+F2\n\n\n\n## 引导\n\n### 启动\n\n```\n#选择系统图\n/usr/share/grub/themes/breeze\n#themes配置\n/usr/share/grub/themes/breeze/theme.txt\n\n\n#启动图\n/usr/share/images/desktop-base/desktop-grub.png\n```\n\n\n\n\n\n### 双系统boot\n\n```\ncs@debian:~$ sudo tree /boot/efi/EFI -L 2\n/boot/efi/EFI\n├── Boot\n│   └── bootx64.efi\n├── debian\n│   ├── BOOTX64.CSV\n│   ├── fbx64.efi\n│   ├── grub.cfg\n│   ├── grubx64.efi\n│   ├── mmx64.efi\n│   └── shimx64.efi\n└── Microsoft\n    └── Boot\n\n4 directories, 7 files\n\n```\n\n\n\n```\ncs@debian:~$ sudo update-grub\nGenerating grub configuration file ...\nFound background image: /usr/share/images/desktop-base/desktop-grub.png\nFound linux image: /boot/vmlinuz-5.10.0-21-amd64\nFound initrd image: /boot/initrd.img-5.10.0-21-amd64\nWarning: os-prober will be executed to detect other bootable partitions.\nIts output will be used to detect bootable binaries on them and create new boot entries.\nFound Windows Boot Manager on /dev/sda2@/EFI/Microsoft/Boot/bootmgfw.efi\nAdding boot menu entry for UEFI Firmware Settings ...\ndone\n```\n\nhttps://www.cnblogs.com/coding-my-life/p/12817690.html\n\n<!--more-->\n\n\n\n\n\n## 备份\n\n\n\n### 步骤\n\n#### 新盘先装系统分好盘\n\n新系统内核与老系统版本一致\n\n```\n❯ uname -r\n6.1.0-0.deb11.6-amd64\n```\n\n\n\n\n\n#### 进入原系统\n\n备份目录，解压到新系统目录\n\n```\n#用户目录配置信息文件\n/home/cs$ tar cvpzf cs.tar.gz --exclude=.cache  --exclude=cs.tar.gz  ./.*\n\n/media/cs/xx/cs$  tar xvpfz cs.tar.gz -C  ./\n\ntar -cvpzf ./var.tar.gz    --exclude=/var/tmp --exclude=/var/log  /var\ntar xvpfz var.tar.gz -C  /media/cs/xx/var  --strip-components 1\n\ntar -cvpzf ./usr.tar.gz  /usr\ntar xvpfz usr.tar.gz -C  /media/cs/xx/usr  --strip-components 1\n\ntar -cvpzf ./etc.tar.gz  --exclude=/etc/fstab  /etc\ntar xvpfz etc.tar.gz -C  /media/cs/xx/etc  --strip-components 1\n```\n\n>  --exclude  权限问题无法或无需备份的进行过滤文件目录\n>\n>提前备份新旧系统的2个文件\n>\n>**/etc/fstab**（fstab 盘符uuid不一样）\n>\n>**/boot/grub/grub.cfg**  （grub.cfg  盘符uuid不一样）\n\n\n\n#### 登陆新系统验证\n\n\n\n\n\n### grub\n\n#### win \n\nwin os u盘修复win引导在esp盘\n\n\n\n#### linux\n\n##### 无法进入grub\n\nlinux u盘 引导修复 ，主要是挂载目录到shell环境\n\n##### grub>\n\n在救援模式下只有很少的命令可以用：set , ls , insmod , root , prefix\n\n- ls  查看设备\n- set 查看环境变量，这里可以查看启动路径和分区。 \n- root 指定用于启动系统的分区,在救援模式下设置grub启动分区 \n- prefix 设定grub启动路径\n- insmod 加载模块normal\n\n\n\n![](/pics/grub-rescue.jpeg)\n\n\n\n```\ngrub rescue>set root=(hd0,gpt4) \n\ngrub rescue>set prefix=(hd0,gpt4)/boot/grub \n\ngrub rescue>insmod normal              #启动normal启动 \n\ngrub rescue>normal  #之后你就会看到熟悉的启动菜单栏了\n```\n\n出现选择界面，进入系统\n\n![](/pics/nv-grub.png)\n\n```\n❯ update-grub\nGenerating grub configuration file ...\nFound theme: /usr/share/grub/themes/breeze/theme.txt\nFound background image: /usr/share/images/desktop-base/desktop-grub.png\nFound linux image: /boot/vmlinuz-6.1.0-0.deb11.6-amd64\nFound initrd image: /boot/initrd.img-6.1.0-0.deb11.6-amd64\nWarning: os-prober will be executed to detect other bootable partitions.\nIts output will be used to detect bootable binaries on them and create new boot entries.\nFound Windows Boot Manager on /dev/nvme0n1p6@/EFI/Microsoft/Boot/bootmgfw.efi\nAdding boot menu entry for UEFI Firmware Settings ...\ndone\n\n```\n\n直接操作 **update-grub** 会导致每次都是 **grub>** ,重新设置启动 grub-install\n\n ` grub-install /dev/nvme0n1p1`\n\n![](/pics/grub-install.jpg)\n\n在进入系统之后，通过grub-install脚本进行安装grub，原先在/boot/grub下的stage文件都删除也没关系，该脚本每次执行都会删除这些文件的。\n\n| 参数（可省略）   | 含义                       |\n| ---------------- | -------------------------- |\n| --root-directory | 在指定目录安装GRUB镜像     |\n| --grub-shell     | 使用指定文件作为GRUB Shell |\n| --no-floppy      | 不探测任何软盘驱动器       |\n\nhttps://www.cnblogs.com/zhengah/p/4238396.html\n\n#### new\n\n\n\n#### old\n\n\n\n\n\n\n\n### 盘/etc/fstab\n\n```\n❯ sudo lsblk -o name,uuid\nNAME        UUID\nsda         \n├─sda1      70BE7BF5BE7BB1E8\n├─sda2      0FE407890FE40789\n├─sda3      b519f517-5f11-4108-8601-e456e3da4fd1\n├─sda4      0CFA1DD20CFA1DD2\n└─sda5      2006966506963BAA\nsdb         \n├─sdb1      0003DFF700005BA6\n├─sdb2      FF6E-1E1A\n├─sdb3      fe04554c-3dae-42e5-9fd5-5ddda44d2f1c\n├─sdb4      5f92ed02-f45d-49e5-b245-09f7447eac24\n├─sdb5      5cb263cd-27a3-4ab2-9090-7417f4c80536\n├─sdb6      abca56cf-7ab5-4c4a-a5ab-f4b2ebdc0c82\n└─sdb7      f26d54f8-1746-47a9-8805-3d339062ab3a\nnvme0n1     \n├─nvme0n1p1 8aef5178-364f-47de-9016-3b3bb254aadd\n├─nvme0n1p2 ff3aedfa-1448-4161-95fb-3b43fddf4506\n├─nvme0n1p3 8c8a753d-b3f4-45ee-b2a8-629c13f4c18e\n├─nvme0n1p4 a40908d9-e0e9-4d17-8aad-d7e1a1f90730\n├─nvme0n1p5 bb259291-c221-4e34-b422-663e0bea289e\n└─nvme0n1p6 E509-52C5\n```\n\n\n\n\n\n#### new\n\n```\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\n# / was on /dev/nvme0n1p1 during installation\nUUID=8aef5178-364f-47de-9016-3b3bb254aadd /               ext4    errors=remount-ro 0       1\n# /boot/efi was on /dev/nvme0n1p6 during installation\nUUID=E509-52C5  /boot/efi       vfat    umask=0077      0       1\n# /home was on /dev/nvme0n1p3 during installation\nUUID=8c8a753d-b3f4-45ee-b2a8-629c13f4c18e /home           ext4    defaults        0       2\n# /opt was on /dev/nvme0n1p4 during installation\nUUID=a40908d9-e0e9-4d17-8aad-d7e1a1f90730 /opt            ext4    defaults        0       2\n# /usr was on /dev/nvme0n1p2 during installation\nUUID=ff3aedfa-1448-4161-95fb-3b43fddf4506 /usr            ext4    defaults        0       2\n# swap was on /dev/nvme0n1p5 during installation\nUUID=bb259291-c221-4e34-b422-663e0bea289e none            swap    sw              0       0\n# /data was on /dev/sdb3 during installation\n```\n\n\n\n#### old\n\n```\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\n# / was on /dev/sda7 during installation\nUUID=f26d54f8-1746-47a9-8805-3d339062ab3a /               ext4    errors=remount-ro 0       1\n# /boot/efi was on /dev/sda2 during installation\nUUID=FF6E-1E1A  /boot/efi       vfat    umask=0077      0       1\n# /home was on /dev/sda6 during installation\nUUID=abca56cf-7ab5-4c4a-a5ab-f4b2ebdc0c82 /home           ext4    defaults        0       2\n# /opt was on /dev/sda4 during installation\nUUID=5f92ed02-f45d-49e5-b245-09f7447eac24 /opt            ext4    defaults        0       2\n# /usr was on /dev/sda5 during installation\nUUID=5cb263cd-27a3-4ab2-9090-7417f4c80536 /usr            ext4    defaults        0       2\n# swap was on /dev/sda3 during installation\nUUID=fe04554c-3dae-42e5-9fd5-5ddda44d2f1c none            swap    sw              0       0\n# /data was on /dev/sdb3 during installation\nUUID=b519f517-5f11-4108-8601-e456e3da4fd1 /home/cs/data            xfs    defaults        0       2\n```\n\n\n\n\n\n## error\n\n\n\n\n\n### mdadm: no arrays found in config file or automatically\n\n![](/pics/swap-uuid.png)\n\n```\n#debian \nsudo rm /etc/initramfs-tools/conf.d/resume\nsudo update-initramfs -u\n```\n\n> This is the initramfs configuration where mdadm.conf is copied and some magic happens to start the array. Did you create a md raid array or use btrfs array options? If you used mdadm then `mdadm --detail --scan >> /etc/mdadm/mdadm.conf` will add the array configuration and `update-initramfs -u -k all` will create a new initramfs image. The resume entry is in `/etc/initramfs-tools/conf.d/resume` if you want to change that (i had to change it to 'none' for encrypted swap).\n>\n> https://www.reddit.com/r/debian/comments/h8b0am/dell_optiplex_390_gets_stuck_on_mdadm_no_arrays/\n\n","tags":["win","bak","OS"],"categories":["linux","debian","os"]},{"title":"screenshot","url":"//tool/screenshot/","content":"\n## peek\n\nctrl+alt+r 开始/停止\n\n<!--more-->\n\n\n\n##\n\n\n\n\n\n","tags":["git","linux","screenshot"],"categories":["tool","screenshot"]},{"title":"vagrant","url":"//tool/vagrant/","content":"\ndoc https://developer.hashicorp.com/vagrant/docs\n\n## box\n\nkvm libvirt\n\nvirtualbox\n\nhttps://app.vagrantup.com/boxes/search\n\n```\n$ vagrant box list\ncentos/7 (libvirt, 7.1.0)\ncentos/7 (virtualbox, 7.1.0)\n\n```\n\n\n\n### add\n\n`**`vagrant box add metadata.json`**`\n\n```\ncat >metadata.json <<EOF\n{\n    \"name\": \"centos/7\",\n    \"versions\": [{\n        \"version\": \"7.1.0\",\n        \"providers\": [{\n            \"name\": \"virtualbox\",\n            \"url\": \"file:///home/cs/data/VM/VirtualBox/CentOS-7-x86_64-Vagrant-2004_01.VirtualBox.box\"\n        }]\n    }]\n}\nEOF\n```\n\n\n\n<!--more-->\n\n### init\n\n生成Vagrantfile模板文件 **`vagrant init centos/7`**\n\n\n\n#### Vagrantfile\n\nhttps://developer.hashicorp.com/vagrant/docs/vagrantfile/version\n\n```\nENV[\"LC_ALL\"] = \"en_US.UTF-8\"\n\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"centos/7\"\n \n  config.vm.provider :virtualbox do |v|\n    v.memory = 1024\n    v.cpus = 1\n          ##修改为具有 50% 的主机 CPU 执行上限\n    v.customize [\"modifyvm\", :id, \"--cpuexecutioncap\", \"50\"]\n  end\n\n  ##是否使用公私钥来登录,默认true\n  config.ssh.insert_key = false\n  config.ssh.private_key_path = [ \n    '~/.ssh/id_rsa', \n    '~/.vagrant.d/insecure_private_key' \n    ] \n    config.vm.provision 'file', \n    source: '~/.ssh/id_rsa.pub', \n    destination: '~/.ssh/authorized_keys' \n\n  # 激活hostmanager插件\n  config.hostmanager.enabled = true\n\n  # 在宿主机上的hosts文件中添加虚拟机的主机名解析信息\n  config.hostmanager.manage_host = true\n\n  # 在各自虚拟机中添加各虚拟机的主机名解析信息\n  config.hostmanager.manage_guest = true\n\n  #不忽略私有网络的地址\n  config.hostmanager.ignore_private_ip = false\n\n    config.vm.define \"master11\" do |node|\n            node.vm.hostname = \"master11\"\n            node.vm.network \"private_network\", ip: \"192.168.56.111\", hostname: true\n    end  \n    \n     config.vm.provision \"shell\", path: \"k8s.sh\"\n \nend\n```\n\n\n\n根据文件创建虚拟机`vagrant up`\n\n\n\nhttps://www.jianshu.com/p/120c4380c69c\n\n\n\n## plugin\n\n\n\n### vagrant-libvirt\n\nvagrant默认只支持VirtualBox，Hyper-V和Docker provider,该插件安装kvm的provider插件\n\n\n\n```\nvagrant up --provider=libvirt \n\nvagrant status\n```\n\n\n\nhttps://www.5axxw.com/wiki/content/mkqte4#29keoitdxry\n","tags":["vagrant","vm","batch"],"categories":["tool","vagrant"]},{"title":"visual studio code","url":"//tool/codetool/vscode/","content":"\n\n\n### tempCodeRunnerFile.go\n\n**方法一**\n在setting.json中添加\n\n```json\n{\n  \"code-runner.ignoreSelection\": true\n}\n```\n\n**方法二**\n在设置中搜索**selection**并勾选`Whether to ignore selection to always run entire file.`\n","tags":["visual","studio","vscode"],"categories":["tool","codetool"]},{"title":"visual studio code","url":"//tool/codetool/vs-code/","content":"\n\n\n## downlocad\n\nhttps://code.visualstudio.com/download\n\n替换成国内cdn  **vscode.cdn.azure.cn**\n\n![cdn](/pics/vscode-download-cdn.png)\n\nhttps://az764295.vo.msecnd.net/stable/704ed70d4fd1c6bd6342c436f1ede30d1cff4710/code-stable-x64-1681293081.tar.gz\n\n## 插件\n\n～/.vscode/extensions/\n\n\n\n### Code Runner\n\n运行多种语言的代码片段或代码文件，省掉保存的环节，直接可以运行\n\n\n\n### Better Comments\n\n美化注释，可以将我们的多行注释按照类别自动高亮\n\n\n\n### Bracket\n\n系统已内置\n\n 括号折线匹配高亮,让代码缩进更清晰\n\n### Bracket Pair Colorizer\n\n![bracket](/pics/vs-bracket.gif)\n\n<!--more-->\n\n\n\n### **`koroFileHeader`**\n\n用于生成文件头部注释和函数注释的插件，支持所有主流语言,功能强大，灵活方便，文档齐全，食用简单！\n\nCREL+SHIFT+P\n\n`~/.config/Code/User/settings.json`添加\n\n```\n  // 头部注释  ctrl+WIN+i\n\"fileheader.customMade\": {\n  \n  // Author字段是文件的创建者 可以在specialOptions中更改特殊属性\n  // 公司项目和个人项目可以配置不同的用户名与邮箱 搜索: gitconfig includeIf  比如: https://ayase.moe/2021/03/09/customized-git-config/\n  // 自动提取当前git config中的: 用户名、邮箱\n  //\"Author\": \"git config user.name && git config user.email\", // 同时获取用户名与邮箱\n  // \"Author\": \"git config user.name\", // 仅获取用户名\n  // \"Author\": \"git config user.email\", // 仅获取邮箱\n  \"Author\": \"Shea\", // 写死的固定值 不从git config中获取\n  \"Date\": \"Do not edit\", // 文件创建时间(不变)\n  // LastEditors、LastEditTime、FilePath将会自动更新 如果觉得时间更新的太频繁可以使用throttleTime(默认为1分钟)配置更改更新时间。\n  \"LastEditors\": \"Shea && git config user.email\", // 文件最后编辑者 与Author字段一致\n  // 由于编辑文件就会变更最后编辑时间，多人协作中合并的时候会导致merge\n  // 可以将时间颗粒度改为周、或者月，这样冲突就减少很多。搜索变更时间格式: dateFormat\n  \"LastEditTime\": \"Do not edit\", // 文件最后编辑时间\n  // 输出相对路径，类似: /文件夹名称/src/index.js\n  \"FilePath\": \"Do not edit\", // 文件在项目中的相对路径 自动更新\n  // 插件会自动将光标移动到Description选项中 方便输入 Description字段可以在specialOptions更改\n  \"Description\": \"\", // 介绍文件的作用、文件的入参、出参。\n  // custom_string_obkoro1~custom_string_obkoro100都可以输出自定义信息\n  // 可以设置多条自定义信息 设置个性签名、留下QQ、微信联系方式、输入空行等\n  \"custom_string_obkoro1\": \"\", \n  // 版权声明 保留文件所有权利 自动替换年份 获取git配置的用户名和邮箱\n  // 版权声明获取git配置, 与Author字段一致: ${git_name} ${git_email} ${git_name_email}\n  \"custom_string_obkoro1_copyright\": \"Copyright (c) ${now_year} by Shea, All Rights Reserved. \"\n  // \"custom_string_obkoro1_copyright\": \"Copyright (c) ${now_year} by 写死的公司名/用户名, All Rights Reserved. \"\n},\n// 函数注释   ctrl+WIN+t\n\"fileheader.cursorMode\": {\n\n  \"description\": \"\", // 函数注释生成之后，光标移动到这里\n  \"param\": \"[in]\", // param 开启函数参数自动提取 需要将光标放在函数行或者函数上方的空白行\n  \"return\": \"[out]\",\n}\n```\n\n\n\n\n\n","tags":["visual","studio","vscode"],"categories":["tool","codetool"]},{"title":"冒泡排序","url":"//other/sort/bubble/","content":"\n## 冒泡\n\n两个相邻位置比较,如果前面的元素比后面的元素大就换位置.每比较一次,最后一次就不用再参与比较了.相邻元素两两比较，大的往后放，第一次完毕，最大值出现在了最大索引处\n\n\n![](/pics/20180829175559005.gif)  \n\n  <!--more-->\n\njava\n\n```java\nint[] array = {3,1,6,2,5,4};\n\npublic  void bubbleSort(int[] a) {\n\n    int temp = 0;\n    int n = a.length;\n\n    //外层循环控制排序趟数，n个数排序，只用进行n-1趟\n    for(int i = 0; i < n-1; i++) {\n        boolean flag = false;\n   //内层循环控制每一趟排序多少次，从第1位开始比较直到最后一个尚未归位的数\n      for(int j = 0; j < n-i-1; j++) {\n          //比较大小并交换\n          if (a[j] < a[j+1]) {\n            temp = a[j];\n            a[j] = a[j+1];\n            a[j+1] = temp;\n              flag = true;\n          }\n      }\n        //-- 当前趟 没有发生交换,那下一趟可以不用比较了!\n        if(!flag){\n            break;\n        }\n\n    }\n   }\n```\n\n\n\ngo\n\n```go\n slice := []int{50,16,10,8,6}\n\nfunc popSort(a []int){\n\tfor i:=1;i<len(a);i++{\n\t\tindex := 0\n\t\tsorted := true\n\t\tfor j:=0;j<len(a)-i;j++{\n\t\t\tif a[j] > a[j+1]{  //冒泡排序是属于稳定排序，这里不能是>=,否则会变成不稳定\n\t\t\t\ta[j],a[j+1]=a[j+1],a[j]\n\t\t\t\tindex = j   //如果尾部的已经是排好序了，我们可以跳掉尾部已经排好的那几次循环\n\t\t\t\tsorted = false\n\t\t\t}\n\t\t}\n\t\ti = len(a)-index-1\n\t\tif sorted {\n\t\t\tbreak\n\t\t}\n\t}\n\tfmt.Println(a)\n\n```\n\n","tags":["冒泡排序","bubble"],"categories":["other","sort","bubble"]},{"title":"二叉树","url":"//other/data-structure/binary-tree/","content":"\n## 二叉树\n\n\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">树的结点（node）：包含一个数据元素及若干指向子树的分支；</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">孩子结点（child\nnode）：结点的子树的根称为该结点的孩子；</span>\n\n<span wiz-span=\"data-wiz-span\" style=\"font-size: 1.167rem;\">双亲结点：B\n结点是A 结点的孩子，则A结点是B 结点的双亲；</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">兄弟结点：同一双亲的孩子结点；\n堂兄结点：同一层上结点；</span>\n\n<span wiz-span=\"data-wiz-span\" style=\"font-size: 1.167rem;\">祖先结点:\n从根到该结点的所经分支上的所有结点</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">子孙结点：以某结点为根的子树中任一结点都称为该结点的子孙</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">结点层：根结点的层定义为1；根的孩子为第二层结点，依此类推；</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">**树的深度**：树中最大的结点层</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">**结点的度**：结点子树的个数</span>\n\n<span wiz-span=\"data-wiz-span\" style=\"font-size: 1.167rem;\">**树的度**：\n树中最大的结点度。</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">叶子结点：也叫终端结点，是度为 0\n的结点；</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">分枝结点：度不为0的结点；</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">有序树：子树有序的树，如：家族树；</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"font-size: 1.167rem;\">无序树：不考虑子树的顺序；</span>\n\n  \n\n  \n\n### 满二叉树\n\n![](/pics/0c197bb5-0d99-44b0-96d1-bca6d20fe8d1.jpg)\n\n​    <!--more-->\n\n1.  叶子只能出现在最下一层。\n2.  非叶子结点度一定是2.\n3.  在同样深度的二叉树中，满二叉树的结点个数最多，叶子树最多。\n\n  \n\n###  完全二叉树\n\n![](/pics/4fdd0b13-2a71-4147-ab35-6f0c806f1a59.jpg)\n\n1.  叶子结点只能出现在最下一层（满二叉树继承而来）\n2.  最下层叶子结点一定集中在左 部连续位置。\n3.  倒数第二层，如有叶子节点，一定出现在右部连续位置。\n4.  同样结点树的二叉树，完全二叉树的深度最小（满二叉树也是对的）。\n\n<!--more-->\n\n### BST\n\n二叉查找树 ，<span style=\"line-height: 1.7;\">树上每个结点都</span><span\nstyle=\"line-height: 1.7;\">满足：</span>\n\n<span\nstyle=\"line-height: 1.7;\"> 其左子树上所有结点数据均小于根结点；</span>\n\n<span\nstyle=\"line-height: 1.7;\">右子树所有结点数据域均大于根结点数据域。</span>\n\n<img\nsrc=\"/pics/4b4b2a7e-5c3e-4d2a-a4d1-a6664292a948.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" width=\"429\"\nheight=\"334\" />\n\n  \n\n  \n\n  \n\n### ALV\n\n平衡二叉树，在二叉平衡查找树基础上增加了 “平衡”\n\n 左子树和右子树的高度绝对差不超过 1\n\n<img\nsrc=\"/pics/e93154fd-ccaa-4659-8a10-c193bd41ee96.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n  \n\n  \n\n右旋操作\n\n  \n\n<img\nsrc=\"/pics/6cef681e-3aa4-4323-85d8-95d608edbf80.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n  \n\n左旋操作\n\n  \n\n<img\nsrc=\"/pics/afbdab28-7456-4c2f-a85a-aa8696b87bb7.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n  \n\n  \n\n<img\nsrc=\"/pics/53beb403-c902-4fd7-a5bd-57f8f5d66ff3.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\nLR型\n\n<img\nsrc=\"/pics/01692aac-97e3-4957-b2a7-fad570523649.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\nRL型\n\n<img\nsrc=\"/pics/4f97ee66-0338-4293-b013-caa2c75b9bb8.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n## 遍历\n\n\n\n### 前序遍历\n\n![](/pics/62795589-6f79-489c-b7cc-dfc4faac0c2b.jpg)\n\n <span\nstyle=\"color:rgb(51, 51, 51);font-style:normal;font-weight:400;\">先访问根结点，再先序遍历左子树，最后再先序遍历右子树即</span>根—左—右\n\n  \n\n  \n\n### <span wiz-span=\"data-wiz-span\">后序遍历</span>  \n\n<span\nwiz-span=\"data-wiz-span\">![](/pics/08d43bf9-4544-47a8-b7bc-0bf1a3efbd6b.jpg)</span>\n\n <span\nstyle=\"color:rgb(51, 51, 51);font-style:normal;font-weight:400;\">先后序遍历左子树，然后再后序遍历右子树，最后再访问根结点即<span\nwiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(255, 0, 0);\">左—右—根</span></span>\n\n\n\n### 中序遍历\n\n<span\nstyle=\"color:rgb(51, 51, 51);font-style:normal;font-weight:400;\"><span\nwiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(40, 40, 40);\">![](/pics/1b91ca9f-7cc1-428c-9d06-12e3fe3d7ddf.jpg)</span></span>\n\n<span wiz-span=\"data-wiz-span\" style=\"color: rgb(165, 42, 0);\">       \n <span wiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(255, 0, 0);\">左—根—右</span></span>\n\n<span style=\"color:rgb(79, 79, 79);font-style:normal;font-weight:400;\">B\n D C A E H G K F</span>\n\n<span\nstyle=\"color:rgb(51, 51, 51);font-style:normal;font-weight:400;\"><span\nwiz-span=\"data-wiz-span\" style=\"color: rgb(255, 0, 0);\">  \n</span></span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(255, 0, 0);\">还原二叉树知道前序<span\nwiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(0, 0, 0);\">（第一个）</span>或后序<span\nwiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(0, 0, 0);\">（最后一个）</span> 确定根节点，必须知道中序才能确定左子树或右子树</span>\n","tags":["二叉树","查找","平衡"],"categories":["other","data-structure","binary-tree"]},{"title":"explain执行计划","url":"//services/database/mysql/explain/","content":"\n## explain\n\n\n\n执行计划\n\n```\nexplain select  .....   from  .... [  where ... ]\n```\n\n\n\n![img](/pics/1882599998.png)\n\n\n\n### id\n\n- [id](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#id)  顺序标识整个查询过程 数值越大先执行，可能为空（union）\n\n\n\n### select_type\n\n- [select_type](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#select_type) 查询类型（常见几种）\n\n<!--more-->\n\n SIMPLE \n\n​    简单查询，不带条件\n\n  PRIMARY \n\n​     最外层查询，union(前面查询)\n\n UNION\n\n​    UNION第二个及后面select语句\n\n DERIVED\n\n​    嵌套select查询\n\n UNION RESULT\n\n​    一个UNION查询的结果\n\n DEPENEDNET UNION\n\n   需要满足UNION条件, 及UNION第二个及后面SELECT语句，同时该语句依赖外部查询\n\n  \n\n\n```\nselect  * from user where id in\n   (  \n           select  * from  user_info  where tel=123 \n    union \n          select * from user_info  where  age>12     \n);\n\n#  in 操作符 优化为\nselect  * from user where  exists (\n        select * from user_info tel=123 \n  union \n       select * from user_info  where age > 12 \n  and   user_info.uid=user.id  \n); \n```\n\n\n\n SUBQUERY\n\n​    子查询中的第一个SELECT查询   \n\n\n\n### table\n\n- [table](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#table)\n\n 不一名是真实表名，num代表id(执行顺序)值 <select_type[id]>\n\n   eg: <derived3>  <union2,3>\n\n   \n\n### type\n\n- [type](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#type)\n\nconst\n\n  确定只有一行匹配，通常用在主键或唯一索引上进行比较时\n\nsystem const \n\n   表仅有一行满足条件\n\neq_ref\n\n  innodb 与 syisam 有区别\n\n  被连接使用并且索引是union或primary key\n\n  使用=操作符比较带索引的列\n\nref\n\n 关联操作只使用了索引的最左前缀，或索引不是union和primary key\n\n 使用=或< = > 操作符带索引列\n\nfulltext\n\n  全文索引 （B树）\n\nref_or_null  \n\n  与ref类似，额外搜索包含null列\n\nindex_merger \n\n 使用了索引合并优化方法\n\nunique_subquery\n\n \n\nindex_subquery\n\n\n\nrange\n\n  只检索给定范围的行，使用一个索引来选择行，\n\n  key列显示使用那个索引，key_len包含所使用索引最长关键元素\n\n   使用=、<>、>、>=、<、<=、IS NULL、<=>、BETWEEN或者IN操作符，用常量比较关键列时\n\nindex  \n\n  是否使用索引进行排序\n\nALL \n\n  全表扫描 \n\n\n\n### possible_keys\n\n- [possible_keys](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#possible_keys)\n\n  使用哪个索引查找行\n\n\n\n### key\n\n- [key](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#key)\n\n显示实际使用键（索引），没有索引为null\n\n 强制或忽视索引  force index,use index或ignore index\n\n\n\n### key_len\n\n- [key_len](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#key_len)\n\n 使用的键长度。如果键是NULL，则长度为NULL ,越短越好（不损失精确度）\n\n\n\n### ref\n\n- [ref](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#ref)\n\n 使用那个列或常数 与 key 一起从表中选择行\n\n\n\n### rows\n\n- [rows](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#rows)\n\n执行查询时必须检测行数（预估值）\n\n\n\n### Extra\n\n- [Extra](http://www.cnblogs.com/magialmoon/archive/2013/11/23/3439042.html#Extra) 常用\n\n using filesort\n\n   生成有序结果（排序或索引）  【order  by，group by 默认对字段排序（order by **null禁止排序**） 】\n\n using temporary\n\n  使用了临时表，要避免临时表使用\n\n not exists\n\n  优化 left join \n\n using index\n\n 查询覆盖了索引，mysql直接从索引中过滤不需要记录并发挥命中\n\nusing index condition\n\n  索引条件推送（v5.6版），在二级索引上进行like操作\n\nusing where \n\n 表示MySQL服务器将存储引擎返回服务层以后再应用WHERE条件过滤。\n\n\n\n\n\n","tags":["xxx","xx","explain执行计划"],"categories":["services","database","mysql","explain"]},{"title":"mysql函数","url":"//services/database/mysql/function/","content":"\n\n\n## 函数\n\n\n\n### case  .... when\n\n```sql\nselect \ncount(case age when 10 then age else null end) as age_num,\ncount(case name when '张五' then name end) as name_num \nfrom test_list;\n```\n\n#### 多条件统计\n\n```\nSELECT year,\n SUM(CASE WHEN type=1 THEN value ELSE 0 END) as type1,\n SUM(CASE WHEN type=2 THEN value ELSE 0 END) as type2,\n SUM(CASE WHEN type=3 THEN value ELSE 0 END) as type3,\n FROM table_test GROUP BY year\n```\n\n#### 统计状态（sum累加）\n\n```\nsum(case when type=1 then 1 else 0 end)  t1\nsum(case when type=2 then 1 else 0 end)  t2\n```\n\n\n\n<!--more-->\n\n\n\n## 存储过程\n\n### 存储过程体\n\n\\* 局部变量\n\n声明局部变量，用来存储临时结果\n\n```\nDECLARE` `var_name[,…] type [``DEFAULT` `value]\nVar_name:指定局部变量的名称\nType:用于声明局部变量的数据类型\ndefault``子句:用于为局部变量指定一个默认值。若没有指定，默认为``null``.\n```\n\n begin  ......    end  \n\n\\* set\n\n局部变量赋值\n\n 可以是任意类型数据，包括sql 查询返回值\n\n\\* select ... into  语句\n\n把返回列的值直接存储(into)到局部变量中   **结果集只能是一条数据**\n\n\\* 异常处理\n\n### 示例\n\n多个参数彼此间用逗号分隔。输入参数、输出参数和输入/输出参数，分别用in/out/inout标识。参数的取名不要与数  据表的列名相同。\n\n```\nDROP PROCEDURE IF EXISTS `test`; -- 存在删除\n\n  DELIMITER //\n  CREATE PROCEDURE test(IN `p_id` BIGINT,OUT `v_error` VARCHAR(1000))  comment \"输入，输出参数\"\n  BEGIN\n  -- 声明变量\n  DECLARE v_status INT;-- 状态\n  -- 查询\n  select [数据库字段] into [声明变量] from  表  where 条件 ;\n  -- 判断声明变量 逻辑处理  \n  SET v_status =(SELECT  DISTINCT is_flag  FROM tm_meal_standard_set_info WHERE ORG_ID =p_id AND is_flag=1 ); \n  IF(v_status IS NULL) THEN \n  SET v_status =(SELECT DISTINCT is_flag  FROM tm_meal_standard_set_info WHERE ORG_ID =p_id AND is_flag=0 );\n            IF(v_status < 1) THEN SET v_error = '失效';\n            -- ELSE SET v_error='没有0';\n              END IF;\n        -- else SET v_error='有1';\n          END IF;\n  END //\n  DELIMITER; \n\nSELECT  is_flag  FROM tm_meal_standard_set_info WHERE ORG_ID =10001268  AND  is_flag=0 AND \n NOT EXISTS (\n     SELECT  *  FROM tm_meal_standard_set_info WHERE ORG_ID =10001268  AND is_flag=1\n );\n\n\n调用\n赋值 set @p_id;\n运行 call test(@p_id,@smg);\n查询结果 select @smg;\n```\n\n\n\n","tags":["xxx","函数","function"],"categories":["services","database","mysql"]},{"title":"mysql参数配置","url":"//services/database/mysql/my-conf/","content":"\n## \n\n### 慢查询日志\n\n```\n#查看开启状态 单位秒\nshow variables like 'slow_query_log';\n#查询日志\nshow variables like '%log%';\n```\n\n\n\n- `long_query_time`是查询执行时间的阈值，超过该阈值将被记录下来。记录花费时间超过阈值的所有查询，无论它们是否使用索引。\n\n- `log_queries_not_using_indexes`告诉MySQL另外记录所有不使用索引来限制扫描行数的查询。无论执行时间如何，都会记录此条件。\n\n  https://dev.mysql.com/doc/refman/8.0/en/slow-query-log.html\n\n<!--more-->\n\n```\n#0禁用 1启用\nslow-query-log=1\n#相对路径为 datadir 目录下\nslow_query_log_file=\"cs-slow.log\"\n#缺省10秒\nlong_query_time=2\n```\n\n\n\n\n\n### emoji表情\n\n```\n#字符存储编码\nSHOW VARIABLES LIKE 'character_set_%';\n#字符连接编码\nSHOW VARIABLES LIKE 'collation_%';\n```\n\n\n\n```shell\nmysql>  SHOW VARIABLES LIKE 'character_set_%';\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8mb4                    |\n| character_set_connection | utf8mb4                    |\n| character_set_database   | utf8                       |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8mb4                    |\n| character_set_server     | utf8mb4                    |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /opt/mysql/share/charsets/ |\n+--------------------------+----------------------------+\n8 rows in set (0.01 sec)\n\nmysql> SHOW VARIABLES LIKE 'collation_%';\n+----------------------+--------------------+\n| Variable_name        | Value              |\n+----------------------+--------------------+\n| collation_connection | utf8mb4_unicode_ci |\n| collation_database   | utf8_bin           |\n| collation_server     | utf8mb4_unicode_ci |\n+----------------------+--------------------+\n3 rows in set (0.00 sec)\n\n```\n\n\n\n```\n[client]  \ndefault-character-set = utf8mb4\n \n[mysql]  \ndefault-character-set = utf8mb4  \n \n[mysqld]  \ncharacter-set-client-handshake = FALSE  \ncharacter-set-server=utf8mb4 \ncollation-server = utf8mb4_general_ci  \ninit_connect='SET NAMES utf8mb4'\n```\n\n> <property name=\"connectionInitSqls\" value=\"set names utf8mb4;\" />\n\n\n\nERROR Lost connection to MySQL server during query\n\n```\nmax_allowed_packet=100M\n```\n\n> 默认64M\n>\n> 如果您使用大 [`BLOB`](https://dev.mysql.com/doc/refman/8.0/en/blob.html)列或长字符串，则必须增加此值。它应该与 [`BLOB`](https://dev.mysql.com/doc/refman/8.0/en/blob.html)您要使用的最大一样大。协议限制为 [`max_allowed_packet`](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_max_allowed_packet)1GB。该值应为 1024 的倍数；非倍数向下舍入到最接近的倍数。\n\n\n\n### console grc\n\n#### install\n\n1. Install grc (for debian systems: `apt-get install grc`)\n2. Copy both config files into your home directory: [.grcat](https://github.com/nitso/colour-mysql-console/blob/master/.grcat) and [.my.cnf](https://github.com/nitso/colour-mysql-console/blob/master/.my.cnf)\n3. Run mysql client `mysql -u <user> -p -h <hostname>`\n\n#### 配置 ~/.grcat\n\n```\n#default word color\n#regexp=[\\w.,\\:\\-_/]+\nregexp=.+\ncolours=green\n-\n#table borders\nregexp=[+\\-]+[+\\-]|[|]\ncolours=red\n-\n#data in ( ) and ' '\nregexp=\\([\\w\\d,']+\\)\ncolours=white\n-\n#numeric\nregexp=\\s[\\d\\.]+\\s*($|(?=\\|))\ncolours=yellow\n-\n#date\nregexp=\\d{4}-\\d{2}-\\d{2}\ncolours=cyan\n-\n#time\nregexp=\\d{2}:\\d{2}:\\d{2}\ncolours=cyan\n-\n#IP\nregexp=(\\d{1,3}\\.){3}\\d{1,3}(:\\d{1,5})?\ncolours=cyan\n-\n#schema\nregexp=`\\w+`\ncolours=yellow\n-\n#email\nregexp=[\\w\\.\\-_]+@[\\w\\.\\-_]+\ncolours=magenta\n-\n#row delimeter when using \\G key\nregexp=[*]+.+[*]+\ncount=stop\ncolours=white\n-\n#column names when using \\G key\nregexp=^\\s*\\w+:\ncolours=white\n```\n\n\n\n#### my.cnf\n\n```\n[mysql]\npager  = grcat  ~/.grcat\n```\n\n","tags":["mysql","xxx","config"],"categories":["services","database","mysql"]},{"title":"pandoc文本格式转换","url":"//tool/text/markdown/pandoc/","content":"\n###  pandoc\n\npandoc 标记语言转换工具，可实现不同标记语言间的格式转换\n\n在线转换测试 https://pandoc.org/try/\n\n下载 https://github.com/jgm/pandoc/releases/tag/2.19.2\n\n#### linux\n\n##### html 转 md\n\n```shell\n /opt/tools/pandoc-2.19.2/bin/pandoc -i  test.html  --to markdown_github -o test.md\n```\n\n别名\n\n<!--more-->\n\n```shell\n$ cat  >> ~/.bashrc <<EOF \n######### custom start###########\nCMD(){\n  url=~/.local/custom/$1\n  [ -f \"$url\" ] && source $url\n}\n\nif [ -f \"/opt/tools/pandoc-2.19.2/bin/pandoc\" ] ; then \n   CMD pandoc.sh\n   alias tom='htomd $1 $2'\nfi\n######### custom end###########\nEOF\n\n```\n\n~/.local/custom/pamdoc.sh\n\n```shell\ntomd(){\n   [ \"help\" == $1  -o -z \"$1\"  ] && { echo \"eg: tom xx.html xxx.md\" && return; }\n   echo \"pandoc from html to md\"\n  /opt/tools/pandoc-2.19.2/bin/pandoc -i  $1  --to markdown_github -o $2\n}\n```\n\n\n\n```shell\ntom   /xx/xx.html    /xxx/xxxx.md\n```\n\n\n\n\n\n#### 文档\n\nhttps://www.pandoc.org/demos.html#\n\n","tags":["format","md","html"],"categories":["markdown","pandoc"]},{"title":"mysql查询过程","url":"//services/database/mysql/mysql-query/","content":"\n## mysql查询过程\n\n<img src=\"/pics/cd88f35d-6766-4f73-8890-4b7fb44b3361.jpg\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n### 客户端与服务端通信协议\n\n“双半工”  <span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生</span>\n\n \n\n在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT\n\\*以及加上LIMIT限制的原因之一。  \n\n  <!--more-->\n\n### 查询缓存\n\n解析一个查询语句前，如果缓存是打开的，那么mysql会检查这个缓存语句是否命中缓存中的数据，如果命中，在检查用户权限后直接返回缓存中的结果，这种情况下，查询不会被解析，不会生成执行计划，更不会执行\n\n  \n\nmysql将缓存放在一个引用表 (<span\nstyle=\"font-size: 1rem; background-color: rgb(255, 255, 255);\">类似hashmap</span>)\n 利用哈希值索引\n,这个哈希值通过查询本身，数据库，客户端版本号等一些影响结果计算得到，2个查询不同（空格，注释等），不会命中\n\n<span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果都不会被缓存</span>  \n\n<span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\"><span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">函数NOW()或者CURRENT_DATE()\n       <span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">包含CURRENT_USER或者CONNECION_ID()</span></span>  \n</span>\n\n<span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\"><span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\"><span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">  \n</span></span></span>\n\n      缓存何时失效\n\n\n 查询缓存系统会跟踪查询语句中涉及的每个表，如果这些表（结构或数据）发生变化，那么和这张表相关联的所有缓存数据都将失效。\n\n\n   如何写操作都会导致缓存失效\n\n\n如果查询缓存非常大或者碎片很多，带来很大系统消耗，甚至系统僵死一会儿，查询对缓存的额外消耗不仅在写操作，读操作也不例外：\n\n1.任何查询语句开始前必须经过检查缓存，即使这条sql语句永远不会命中\n\n2.如何结果可以被缓存，那么执行完成后会将结果写入缓存，也会带来额外消耗\n\n  \n\n<span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，</span>只有缓存带来资源消耗大于本身消耗资源时，才会给系统带来性能提升  \n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"background-color: rgb(255, 255, 0);\">优化：</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"background-color: rgb(255, 255, 0);\"> \n 多个小表代替大表，避免过度设计</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"background-color: rgb(255, 255, 0);\"> 缓存空间大小设置\n，几十兆</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"background-color: rgb(255, 255, 0);\"> \n批量插入代替循环单条插入</span>\n\n<span wiz-span=\"data-wiz-span\"\nstyle=\"background-color: rgb(255, 255, 0);\"> 通过SQL_CACHE\n和SQL_NO_CACHE控制某条语句是否需要进行缓存</span>\n\n写密集型应用不要打开缓存，QUERY_CACHE_TYPE 设置 DEMAND\n ，只有加入SQL_CACHE的查询才会走缓存\n\n  \n\n缓存如何使用内存？\n\n缓存如何控制内存的碎片化？\n\n事务对查询缓存的影响？\n\n  \n\n### 语法解析和预处理\n\nmysql通过  关键字   将sql语句进行解析并生成一颗对应 解析树 \n\n过程解析器主要通过语法规则来验证和解析（关键字，关键字顺序是否正确）   \n\n预处理 会根据mysql规则进一步检查解析树是否合法 （数据表，列是否存在）\n\n  \n\n### 查询优化\n\n   经过解析和预处理的语法树被认为合法，并且有优化器将其转化成查询计划；\n\n一般一条查询有多种查询方式，返回相同结果，优化器会选择最好的执行计划\n\n  \n\n查询当前会话的 last_query_cost 值来计算当前查询的成本\n\n\n\n``` CodeMirror-line\nshow status like 'last_query_cost'\n```\n\n<span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。</span>  \n\n<span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\">  \n</span>\n\nMySQL 和我们想的不一样（我们执行时间短，mysq\n值认为选择它认为成本小的，并不意味执行时间短）\n\n<span wiz-span=\"data-wiz-span\" style=\"color: rgb(255, 0, 0);\">驱动表\n</span>：**mysql中指定了连接条件时，满足查询条件的记录行数少的表为驱动表；如未指定查询条件，则扫描行数少的为驱动表。mysql优化器就是这么粗暴以小表驱动大表的方式来决定执行顺序的**<span\nstyle=\"color:rgb(75, 75, 75);font-size:1rem;background-color:rgb(255, 255, 255);\">。</span>\n\n<span\nstyle=\"color:rgb(75, 75, 75);font-size:1rem;background-color:rgb(255, 255, 255);\"> \n STRAIGHT_JOIN功能同join类似，但能让左边的表来驱动右边的表，能改表优化器对于联表查询的执行顺序</span>  \n\n  \n\n  \n\n查询优化器是一个非常复杂的部件，它使用非常多的优化策略来生成一个最优执行计划：\n\n1.重新定义表关联<span\nstyle=\"font-size: 1rem; background-color: rgb(255, 255, 255);\">顺序（多表关联查询时，并不一定按照SQL指定顺序进行）</span>\n\n<span\nstyle=\"color:rgb(75, 75, 75);font-size:1rem;background-color:rgb(255, 255, 255);\"> \n STRAIGHT_JOIN只适用于inner join，并不使用与left join，right join</span>\n\n``` sql\nselect t1.*\nfrom Table1 t1\nSTRAIGHT_JOIN  Table2 t2\non t1.id = t2.id\nwhere t1.stu = 1\n```\n\n2.优化MIN()和MAX()函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值)  \n\n3.提前终止查询 <span\nstyle=\"font-size: 0.813rem; background-color: rgb(254, 254, 242);\"> </span>（分页limit  ）\n\n4.优化排序（单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序）\n\n\n\n### 查询执行引擎\n\n在完成解析和优化后，MySQL会生成对应执行计划，查询执行引擎根据执行计划指令依次执行得出结果。\n\n整个过程通过调用存储引擎实现接口（handler\napi）每一张表一个handler实例表示，优化器可以根据这些实例接口来获取表的相关信息，包括列名，索引统计信息\n\n  \n\n  \n\n查询过程：\n\n-   客户端向MySQL服务器发送一条查询请求\n\n-   服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段\n\n-   服务器进行SQL解析、预处理、再由优化器生成对应的执行计划\n\n-   MySQL根据执行计划，调用存储引擎的API来执行查询\n\n-   将结果通过tcp协议进行传输返回给客户端，同时缓存查询结果\n\n  \n\n\n\n  \n\n\n\n\n\n","tags":["mysql","query"],"categories":["services","database","mysql"]},{"title":"PLSQL","url":"//tool/databasetool/pl-sql/","content":"\n###   win\n\n#### 环境变量\n\n```\nORACLE_HOME=D:\\sqlplus\\instantclient_19_3\n\npath   %ORACLE_HOME%\n```\n\noci.dll  http://download.oracle.com/otn/nt/instantclient/19300/instantclient-basic-windows.x64-19.3.0.0.0dbru.zip\n\n<!--more-->\n\n#### where 条件搜索带中文  \n\n```\nselect * from v$nls_parameters where parameter like 'NLS_CH%'; \n或\nselect * from v$nls_parameters   where  parameter='NLS_CHARACTERSET';\n```\n\n![](/pics/pl-sql-4659.png)\n\n环境变量添加  `NLS_LANG = AMERICAN_AMERICA.AL32UTF8`\n\n\n\n\n\n\n\n","tags":["PL/SQL","oracle"],"categories":["tool","databasetool"]},{"title":"IDEA tool","url":"//tool/codetool/idea-tool/","content":"\n\n\n## 激活\n\n### idea64.exe.vmoptions\n\n-javaagent:C:\\Program Files\\IDEA\\jetbra\\ja-netfilter.jar=jetbrains\n\n### code\n\n[copy code ]: https://3.jetbra.in/\t\"code\"\n\n\n\n\n\n## Font\n\n### code 代码区域\n\nFile-->Settings\n\n选择Editor--> Font\n\n\n\n### console log区域\n\nFile-->Settings\n\n选择Editor-->Color Scheme-->*Console* Font\n\n\n\n### 过滤 \n\nSettings→Editor→File Types\n\n在Ignore files and folders中添加需要过滤的内容\n\n\n\n## 模板\n\n### java main\n\n **1.点击File-->Settings-->Editor-->Live Templates**\n\n **2 新增**\n\n点击右上角的\"+\"，添加\"Template Group\"，如java\n\n 点击右上角的\"+\"，添加\"Live Template\"，如main\n\n**3.填写模板内容 Template text**\n\n```Java\npublic static void main(String[] args){\n\n}\n```\n\n**4. 定义作用域  选择\"Change\",选择Java文件下的选项**\n\n\n\n \n\n## database面板\n\n### 自动生成实体类\n\n\n\n<img src=\"/pics/6fda574f-0050-43f7-84b2-e281a0b62989.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n### <span wiz-span=\"data-wiz-span\" style=\"font-size: 1rem;\">连接数据库</span>\n\n<!--more-->\n\n<img src=\"/pics/6a7e416d-f5a0-4558-8737-6a2c90ff0515.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n## Persistence面板\n\n<span\nstyle=\"color:rgb(47, 47, 47);font-family:-apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size:1rem;font-style:normal;font-weight:400;text-align:start;text-indent:0px;background-color:rgb(255, 255, 255);display:inline !important;\"><span\nstyle=\"color:rgb(47, 47, 47);font-family:-apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size:1rem;font-style:normal;font-weight:400;text-align:start;text-indent:0px;background-color:rgb(255, 255, 255);display:inline !important;\">位置是View-Tool\nWindows- Persistence （如果找不到）</span>  \n</span>\n\n<span\nstyle=\"color:rgb(47, 47, 47);font-family:-apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size:1rem;font-style:normal;font-weight:400;text-align:start;text-indent:0px;background-color:rgb(255, 255, 255);display:inline !important;\"><span\nstyle=\"color:rgb(47, 47, 47);font-family:-apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size:1rem;font-style:normal;font-weight:400;text-align:start;text-indent:0px;background-color:rgb(255, 255, 255);display:inline !important;\">-------先选中项目在点 <span\nwiz-span=\"data-wiz-span\"\nstyle=\"color: rgb(50, 205, 50);\">+</span></span></span>\n\n<img src=\"/pics/d4853c95-e416-4ffe-b0c9-e8d921971a0e.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n**spring boot  选择 jpa   选错没有 session factory**\n\n<span\nstyle=\"color: rgb(47, 47, 47); font-family: -apple-system, 'SF UI Text', Arial, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif; font-size: 1rem; font-style: normal; text-align: start; text-indent: 0px; display: inline !important; background-color: rgb(255, 255, 255);\">**hibernate\n项目选择 hibernate  **</span>\n\n### <span style=\"color:rgb(47, 47, 47);font-family:-apple-system, 'SF UI Text', Arial, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;font-size:1rem;font-style:normal;font-weight:normal;text-align:start;text-indent:0px;display:inline !important;background-color:rgb(255, 255, 255);\">Persistence<span class=\"Apple-converted-space\"> 最下面</span></span> \n\n<span\nstyle=\"color:rgb(47, 47, 47);font-family:-apple-system, 'SF UI Text', Arial, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;font-size:1rem;font-style:normal;font-weight:normal;text-align:start;text-indent:0px;display:inline !important;background-color:rgb(255, 255, 255);\"><span\nclass=\"Apple-converted-space\">hibernate</span></span>\n\n<img src=\"/pics/11d578d1-b5cf-4f49-8623-aab65adb0837.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n选择数据 ，表\n\n<img src=\"/pics/1cb72990-ff22-4fae-a1ee-3d03e9edf07c.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\njpa\n\n<img src=\"/pics/5541b376-5ba9-4fa7-bd9e-8ca929bae9e1.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n  \n\n<img src=\"/pics/30c314a6-b022-4758-9b80-a152853dd1c5.png\"\nstyle=\"vertical-align: bottom; max-width: 100%;\" />\n\n点击ok 生成 实体到指定 package\n\n \n\n\n\n\n\n","tags":["jpa","Template","Font","active"],"categories":["tool","idea"]},{"title":"Sublime设置","url":"//tool/codetool/sublime03/","content":"\n###  插件\n\n#### Sublimelint3\n\nSublimelint支持显示高亮错误代码\n\n安装路径  ~/.config/sublime-text-3/Packages/\n\nctrl+shift+p  输入 install    **sublimelinter**\n\n\n>打开 SublimeLinter 的配置文件：菜单 Preferences -> Package Settings -> SublimeLinter -> Settings - User，\n>\n>加入 \"sublimelinter\": \"save-only\"\n\n\n\n<!--more-->\n\n\n\n### 设置\n\ntoolbar -> Preferences -> Browse packages  -> open User file \n\n左侧目录字体\n\nDefault.sublime-theme 手动创建\n\n```\n[\n    {\n        \"class\": \"tab_label\",\n        \"font.size\": 18\n    },\n    {\n        \"class\": \"sidebar_label\",\n        \"font.size\": 18\n    }\n]\n```\n\n","tags":["插件","设置","xxx"],"categories":["tool","sublime"]},{"title":"Sublime运行脚本","url":"//tool/codetool/sublime02/","content":"\n### shell \n\nBuild Stytem > New Build Stytem ...\n\n```\n{    \"shell_cmd\": \"chmod a+x $file && /bin/sh $file\"}\n```\n\nctrl+s 保存 sh.sublime-build\n\n路径： ~/.config/sublime-text-3/Packages/User/sh.sublime-build\n\n执行脚本快捷键 ctrl+b\n\n<!--more-->\n\n### lua\n\n/usr/local/bin/lua\n\nlua\n\n```\n{    \"cmd\": [\"lua\", \"$file\"],    \"file_regex\": \"^(?:lua:)?[\\t ](...*?):([0-9]*):?([0-9]*)\",    \"selector\": \"source.lua\"}\n```\n\n\n\nluajit\n\n```\n{    \"cmd\": [\"luajit\", \"$file\"],    \"file_regex\": \"^(?:lua:)?[\\t ](...*?):([0-9]*):?([0-9]*)\",    \"selector\": \"source.lua\"}\n```\n\n\n\n\n\n","tags":["shell","脚本","lua"],"categories":["tool","sublime"]},{"title":"Sublime中文","url":"//tool/codetool/sublime01/","content":"\n### 无法输入中文\n\ngit<span\nstyle=\"font-size: 15px;\"> </span><a href=\"https://github.com/lyfeyaj/sublime-text-imfix\"\ndata-_src=\"https://github.com/lyfeyaj/sublime-text-imfix\"\nstyle=\"font-size: 15px; text-decoration: underline;\"><span\nstyle=\"font-size: 15px;\">https://github.com/lyfeyaj/sublime-text-imfix</span></a>\n\n忽略编译（已编译）\n\n<span style=\"font-size: 15px;\">sublime-imfix.c\n下面命令编译生成 libsublime-imfix.so</span>\n\n``` prettyprint\ngcc -shared -o libsublime-imfix.so sublime_imfix.c  `pkg-config --libs --cflags gtk+-2.0` -fPIC\n```\n\n<!--more-->\n\ncopy安装目录  \n\n``` prettyprint\nsudo mv libsublime-imfix.so /opt/sublime_text/\n```\n\n<img src=\"/pics/450575164.png\" data-border=\"0\"\ndata-_src=\"/pics/450575164.png\" />\n\n  \n\n### 命令行启动输入中文\n\n/usr/bin/subl\n\n``` prettyprint\nexec /opt/sublime_text/sublime_text \"$@\"    \n替换为\nLD_PRELOAD=/opt/sublime_text/libsublime-imfix.so exec /opt/sublime_text/sublime_text \"$@\"\n```\n\n  \n\n### 菜单栏打开输入中文\n\n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">修改文件sublime_text.desktop的内容</span>\n\n<img src=\"/pics/1133594981.png\" data-border=\"0\"/>\n\n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  将\\[Desktop\nEntry\\]中的字符串</span>  \n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n Exec=/opt/sublime_text/sublime_text %F</span>  \n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n 修改为</span>  \n\n``` prettyprint\n    Exec=bash -c \"LD_PRELOAD=/opt/sublime_text/libsublime-imfix.so exec /opt/sublime_text/sublime_text %F\"\n```\n\n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n 将\\[Desktop Action Window\\]中的字符串</span>  \n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n Exec=/opt/sublime_text/sublime_text -n</span>  \n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n 修改为</span>  \n\n``` prettyprint\n    Exec=bash -c \"LD_PRELOAD=/opt/sublime_text/libsublime-imfix.so exec /opt/sublime_text/sublime_text -n\"\n```\n\n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n 将\\[Desktop Action Document\\]中的字符串</span>  \n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n Exec=/opt/sublime_text/sublime_text --command new_file</span>  \n<span\nstyle=\"color: rgb(61, 70, 77); font-family: 'Pingfang SC', STHeiti, 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', SimSun, sans-serif; font-size: 16px; background-color: rgb(248, 248, 248);\">  \n 修改为</span>  \n\n``` prettyprint\n   Exec=bash -c \"LD_PRELOAD=/opt/sublime_text/libsublime-imfix.so exec /opt/sublime_text/sublime_text --command new_file\"\n```\n\n  \n\n中文界面\n\n<span\nstyle=\"font-size: 15px;\"> <a href=\"https://packagecontrol.io/installation#Simple\"\ndata-_src=\"https://packagecontrol.io/installation#Simple\">https://packagecontrol.io/installation#Simple</a>\n</span>\n\n<span style=\"font-size: 15px;\">下载 <span\nstyle=\"color: rgb(111, 146, 186); text-decoration: none; font-family: Consolas, 'Driod Sans Mono', monospace; font-size: 15px; white-space: normal;\"><span\nstyle=\"\"><a href=\"https://packagecontrol.io/Package%20Control.sublime-package\"\nstyle=\"color: rgb(111, 146, 186); text-decoration: none; font-family: Consolas, &#39;Driod Sans Mono&#39;, monospace; font-size: 15px; white-space: normal;\">Package\nControl.sublime-package</a> </span></span><a href=\"https://packagecontrol.io/Package%20Control.sublime-package\"\ndata-_src=\"https://packagecontrol.io/Package%20Control.sublime-package\">https://packagecontrol.io/Package%20Control.sublime-package</a>\n</span>\n\n<span\nstyle=\"color: rgb(85, 85, 85); font-family: Helvetica, Arial, Verdana, sans-serif; font-size: 15px;\"> 点击 </span><span\nclass=\"menu\"\nstyle=\"border-top-left-radius: 2px; border-top-right-radius: 2px; border-bottom-right-radius: 2px; border-bottom-left-radius: 2px; background-color: rgb(243, 243, 243); padding: 1px 4px; text-shadow: rgb(255, 255, 255) 0px 1px 0px; color: rgb(85, 85, 85); font-family: Helvetica, Arial, Verdana, sans-serif; font-size: 15px;\">Preferences *\\>* Browse\nPackages</span>\n\n进入目录软件\n\n1.  Download <a href=\"https://packagecontrol.io/Package%20Control.sublime-package\"\n    style=\"color: rgb(111, 146, 186); text-decoration: none;\">Package\n    Control.sublime-package</a> and copy it into the Installed\n    Packages/ directory\n\n2.  重启生效  \n\n3.  <span\n    style=\"color: rgb(51, 51, 51); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify;\">点击Preferences/Package\n    Control，然后输入Package Control：<span\n    style=\"color: rgb(255, 0, 0); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify;\">Install Package</span></span>\n\n4.  <span\n    style=\"color: rgb(51, 51, 51); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify;\"><span\n    style=\"color: rgb(255, 0, 0); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify;\"><span\n    style=\"color: rgb(51, 51, 51); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify; white-space: normal;\">然后在弹出的命令界面，输入Chinese，选择ChineseLocalization</span></span></span>\n\n5.  <span\n    style=\"color: rgb(51, 51, 51); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify;\"><span\n    style=\"color: rgb(255, 0, 0); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify;\"><span\n    style=\"color: rgb(51, 51, 51); font-family: 'Microsoft Yahei', 微软雅黑, arial, 宋体, sans-serif; font-size: 16px; text-align: justify; white-space: normal;\">安装成功</span></span></span>  \n\n  \n\n\n\n","tags":["中文","zh-cn","linux"],"categories":["tool","sublime"]},{"title":"前置操作/后置操作","url":"//lang/test/tests/","content":"\npostman **https://learning.postman.com/docs/writing-scripts/intro-to-scripts/**\n\n设置变量 {{变量名}}，可用于Pre-request Script，Body，request url ,Tests...\n\n\n\n### 前置操作\n\nPre-request-script\n\n![](/pics/test-2022-08-31-21-02.gif)\n\nbody 的json串在图片上仅为展示可以设置变量\n\n#### 设置变量\n\n <!--more--> \n\n##### 字符串\n\n```js\nvar url = \"scripts/pre-request-script\"; \npm.environment.set(\"example\", url.split(\"/\")[0]);\npm.environment.set(\"function\", url.split(\"/\")[1]);\n```\n\n>环境变量 environment ；例如:测试,预发,生产url\n>\n>全局变量 globals；例如:登录token\n\n##### 非字符串\n\n对于数组和对象需要 JSON.stringify() 转换成字符串\n\n###### 设置\n\n```js\nvar array = [1, 2, 3, 4];\npm.environment.set('array', JSON.stringify(array));\n\nvar obj = { a: [1, 2, 3, 4], b: { c: 'val' } };\npm.environment.set('obj', JSON.stringify(obj));\n```\n\n\n\n###### 读取\n\n```js\ntry {\n  var array = JSON.parse(pm.environment.get('array'));\n  var obj = JSON.parse(pm.environment.get('obj'));\n} catch (e) {\n  // 处理异常\n}\n```\n\n\n\n\n\n### 后置操作\n\nTests  \n\n#### 设置token\n\n返回请求头toekn写入环境变量,给其他接口调用\n\n![](/pics/test-2022-08-28-14-48.gif)\n\n```js\n//获取返回header信息,如“Authorization”,\"X-Subject-Token\"\nvar token = pm.response.headers.get(\"X-Subject-Token\");\nconsole.log(token)\npm.environment.set(\"token\",token)\n```\n\n\n\n```js\nvar tk = JSON.parse(responseBody);//pm.response.json();\npm.globals.set(\"token\", tk.data.Token)\n```\n\n>{\n>\n>   \"code\":200,\n>\n>​    \"data\":{\n>\n>​         \"Token\":\"xxxxxxxxxxxx\",\n>\n>​         \"Expired-in\":720000\n>\n>​    }\n>\n>}\n\n\n\n```js\nvar type = pm.response.headers.get(\"Content-Type\");\npm.test('返回类型', function() {\n  pm.expect(type).to.be.contain(\"text/html\");\n});\npm.test('返回结果状态码正常', function() {\n  pm.response.to.have.status(200);\n});\n```\n\n>expect  运行结果    期望结果\n>\n>","tags":["api","request","response"],"categories":["lang","test"]},{"title":"草稿","url":"//draft/","content":"\n\n\n```\npandoc -f html -t markdown_github \\\n--standalone --embed-resources --toc --number-sections --citeproc \\\n--wrap=preserve \\\n-i ./psensor.html -o ./md/p.md\n\n\n\n```\n\n\n\n\n\n```\n#发布到 source/_drafts/<title>.md\nhexo new draft <title> \n\n#正式发布\nhexo publish url  <title> \n\n\nhexo s --draft \n```\n\n\n\n\n\n```\nscp -r  ./themes   root@36.138.204.26:/opt/hexo/   #L2Dwidget;\n```\n\n\n\n```\n\t    L2Dwidget.init({\n\t\t\"model\": {\n\t　　　　　　　//jsonpath控制显示那个小萝莉模型，haru01/haru01  haru02/haru02  hibiki/hibiki  hijiki/hijiki\n\t\t    //jsonPath: \"https://xxxxx/assets/hijiki.model.json\",\n\t\t     jsonPath: \"<%- config.root %>models/haru01/haru01.model.json\",\n\t\t    \"scale\": 1\n\t\t},\n\t\t\"display\": {\n\t\t    \"position\": \"right\", //看板娘的表现位置\n\t\t    \"width\": 150,  //小萝莉的宽度\n\t\t    \"height\": 330, //小萝莉的高度\n\t\t    \"hOffset\": 0,\n\t\t    \"vOffset\": -20\n\t\t},\n\t\t\"mobile\": {\n\t\t    \"show\": true,\n\t\t    \"scale\": 0.5\n\t\t},\n\t\t\"react\": {\n\t\t    \"opacityDefault\": 0.7,\n\t\t    \"opacityOnHover\": 0.2\n\t\t}\n\t    }); \n```\n\n\n\n### 仅限于 Kubernetes:\n\nhttps://github.com/jenkins-x/jx\n\nJenkins\n\nJenkins X并非全新的一个全新的Jenkins，它依然采用Jenkins 2.0作为持续交付的核心引擎，并且帮助Jenkins自身完成云原生应用时代的转型。\n\nHelm\n\nHelm是用于管理Kubernetes资源对象的工具，类似APT，YUM和HOMEBREW，通过将Kubernetes的资源对象打包成Chart的形式，完成复杂应用的部署和版本控制，是目前业界流行的解决方案。\n\nDraft\n\nDraft是自动化应用构建并使之运行在Kubernetes上面的工具，具有语言识别能力，能够自动生成构建脚本，依赖，环境并打包成docker镜像并部署在Kubernetes集群上，加快代码开发节奏，而无需关心基础设施层面的技术实现。\n\nGitOps\n\nGitOps是weaveworks基于自己多年Kubernetes实践推出的应用部署解决方案，它将Git作为整个应用部署的单一可信数据源（SSOT），通过类似代码开发的Pull Request流程完成应用部署的Review和自动化实现，并且将部署配置信息纳入版本控制。\n","tags":["草稿"],"categories":["draft"]},{"title":"hexo插件","url":"//node/npm/hexo/","content":"\n\n\n\n\n\n## 本地搜索\n\n```\nnpm install --save hexo-generator-search\n```\n\n<!--more-->\n\n### hexo\n\n_config.yml\n\n```\nsearch:\n  path: search.json\n  field: all\n  content: true\n  limit: 1000\n```\n\n\n\n\n\n### 主题spfk\n\n#### _config.yml\n\n```\nsearch_box: true\n```\n\n#### 左侧left-col.ejs\n\n/hexo/themes/spfk/layout/_partial/left-col.ejs\n\n```ejs\n<div id=\"id_search\"   onclick = \"document.getElementById('local_search').style.display='block'\">\n <span class=\"search-icon\">\n\t<i class=\"fa fa-search\"> </i>\n   </span> 搜索\n</div>\n```\n\n#### 弹出层layout.ejs\n\n/hexo/themes/spfk/layout/layout.ejs\n\n```ejs\n<div id=\"local_search\" class=\"search-popup\" >\n  <div class=\"search-header\">\n\t    <i class=\"fa fa-search\"> </i> <input id=\"local-search-input\" class=\"search-input\" placeholder=\"搜索...\" spellcheck=\"false\" type=\"search\"/>\n  </div>\n  <div id=\"local-search-result\"></div>\n</div>\n```\n\n####  触发搜索 after-footer.ejs\n\n/hexo/themes/spfk/layout/_partial/after-footer.ejs\n\n##### 引入search.js\n\n```js\n<%- js('js/jquery-1.9.1.min') %>\n<%- js('js/search') %>\n\n<% if (theme.search_box) { %>\n   <script type=\"text/javascript\">\n\tvar inputArea       = document.querySelector(\"#local-search-input\");\n\tinputArea.onclick   = function(){ getSearchFile(); this.onclick = null }\n\tinputArea.onkeydown = function(){ if(event.keyCode == 13) return false }\n\tvar getSearchFile = function(){\n\t      searchFunc(\"<%= config.root %>\" + \"search.json\", 'local-search-input', 'local-search-result');\n\t}\n          $(document).on('click', function(e) {\n\t\t   var si= $(e.target).closest('#id_search').length;\n           var d= $(e.target).closest('#local_search').length;\n             if(si==1){ \n\t\t\tdocument.body.style.overflow='hidden';\n\t\t}\n             if( si==0 && d==0){\n              document.body.style.overflow=''\n               $('#local_search').hide();\n              }    \n\n       });\n\n  </script>\n<% } %>\n```\n\n##### search.js\n\n/hexo/themes/spfk/source/js/search.js\n\n```js\nvar searchFunc = function (path, search_id, content_id) {\n  // 0x00. environment initialization\n  'use strict';\n  var $input = document.getElementById(search_id);\n  var $resultContent = document.getElementById(content_id);\n  $resultContent.innerHTML = \"<ul><span class='local-search-empty'>首次搜索，正在载入索引文件，请稍后……<span></ul>\";\n  $.ajax({\n    // 0x01. load xml file\n    url: path,\n    dataType: \"json\",\n    success: function (datas) {\n      $resultContent.innerHTML = \"\";\n      $input.addEventListener('input', function () {\n        // 0x03. parse query to keywords list\n        var str = '<ul class=\\\"search-result-list\\\">';\n        var keywords = this.value.trim().toLowerCase().split(/[\\s\\-]+/);\n        $resultContent.innerHTML = \"\";\n        if (this.value.trim().length <= 0) {\n          return;\n        }\n        // 0x04. perform local searching\n        datas.forEach(function (data) {\n          var isMatch = true;\n          var content_index = [];\n          if (!data.title || data.title.trim() === '') {\n            data.title = \"Untitled\";\n          }\n          var orig_data_title = data.title.trim();\n          var data_title = orig_data_title.toLowerCase();\n             if (!data.content || data.content.trim() === '') {\n                         console.log(data.content)//空文章\n                      data.content = \"no content\";\n                 }\n          var orig_data_content = data.content.trim().replace(/<[^>]+>/g, \"\");\n          var data_content = orig_data_content.toLowerCase();\n          var data_url = data.url;\n     \n          var index_title = -1;\n          var index_content = -1;\n          var first_occur = -1;\n          // only match artiles with not empty contents\n          if (data_content !== '') {\n            keywords.forEach(function (keyword, i) {\n              index_title = data_title.indexOf(keyword);\n              index_content = data_content.indexOf(keyword);\n\n              if (index_title < 0 && index_content < 0) {\n                isMatch = false;\n              } else {\n                if (index_content < 0) {\n                  index_content = 0;\n                }\n                if (i == 0) {\n                  first_occur = index_content;\n                }\n                // content_index.push({index_content:index_content, keyword_len:keyword_len});\n              }\n            });\n          } else {\n            isMatch = false;\n          }\n          // 0x05. show search results\n          if (isMatch) {\n            str += \"<li><a href='\" + data_url + \"' class='search-result-title' target='_blank'>\" + orig_data_title + \"</a>\";\n            var content = orig_data_content;\n            if (first_occur >= 0) {\n              // cut out 100 characters\n              var start = first_occur - 20;\n              var end = first_occur + 10;\n\n              if (start < 0) {\n                start = 0;\n              }\n\n              if (start == 0) {\n                end = 100;\n              }\n\n              if (end > content.length) {\n                end = content.length;\n              }\n\n              var match_content = content.substr(start, end);\n\n              // highlight all keywords\n              keywords.forEach(function (keyword) {\n                var regS = new RegExp(keyword, \"gi\");\n                match_content = match_content.replace(regS, \"<em class=\\\"search-keyword\\\">\" + keyword + \"</em>\");\n              });\n\n              str += \"<p class=\\\"search-result\\\">\" + match_content + \"...</p>\"\n            }\n            str += \"</li>\";\n          }\n        });\n        str += \"</ul>\";\n        if (str.indexOf('<li>') === -1) {\n          return $resultContent.innerHTML =  \"<ul><span class='local-search-empty'>没有找到内容，请尝试更换检索词。<span></ul>\";\n        }\n        $resultContent.innerHTML =  str;\n      });\n    }\n  });\n}\n```\n\n##### css\n\n/hexo/themes/spfk/source/css/search.css\n\n```css\n\n.search-popup {\n  display: none;\n  background: #32503d;\n  border-radius: 5px;\n  height: 80%;\n  left: calc(50% - 350px);\n  position: fixed;\n  top: 10%;\n  width: 700px;\n  z-index: 1500;\n}\n\n.search-popup .search-header {\n  background: #eee;\n  border-top-left-radius: 5px;\n  border-top-right-radius: 5px;\n  display: flex;\n  padding: 5px;\n}\n.search-popup input.search-input {\n  background: transparent;\n  border: 0;\n  outline: 0;\n  width: 100%;\n}\n\n\n.search-popup ul.search-result-list {\n  margin: 0 5px;\n  padding: 0;\n  width: 100%;\n \n}\n\nul.search-result-list li::marker {\n content: '😩';\n}\n\n\n.search-popup p.search-result {\n  border-bottom: 2px dashed #7de485d4;\n  padding: 5px 0;\n  line-height: 21px;\n}\n.search-popup a.search-result-title {\n  font-weight: bold;\n}\n.search-popup .search-keyword {\n  border-bottom: 1px dashed #ff2a2a;\n  color: #ff2a2a;\n  font-weight: bold;\n}\n.search-popup #local-search-result{\n  display: flex;\n  height: calc(100% - 55px);\n  overflow: auto;\n  padding: 5px 25px;\n}\n.search-popup #no-result {\n  color: #ccc;\n  margin: auto;\n}\n```\n\n\n\n## live2d\n\n### helper\n\n```\nnpm install --save hexo-helper-live2d\n```\n\n\n\n_config.yml\n\n```\nlive2d:\nenable: true\nscriptFrom: local\nmodel: \n  use: live2d-widget-model-hibiki #模型选择\ndisplay: \n  position: right  #模型位置\n  width: 150       #模型宽度\n  height: 300      #模型高度\nmobile: \n  show: false      #是否在手机端显示\n```\n\n\n\n### js  推荐\n\n放在合适位置 footer.ejs  \n\n```\n<script src=\"https://eqcn.ajz.miesnfu.com/wp-content/plugins/wp-3d-pony/live2dw/lib/L2Dwidget.min.js\"></script>\n<script>\n    L2Dwidget.init({\n        \"model\": {\n　　　　　　　//jsonpath控制显示那个小萝莉模型\n            jsonPath: \"https://unpkg.com/live2d-widget-model-haruto@1.0.5/assets/haruto.model.json\",\n            \"scale\": 1\n        },\n        \"display\": {\n            \"position\": \"right\", //看板娘的表现位置\n            \"width\": 150,  //小萝莉的宽度\n            \"height\": 300, //小萝莉的高度\n            \"hOffset\": 0,\n            \"vOffset\": -20\n        },\n        \"mobile\": {\n            \"show\": true,\n            \"scale\": 0.5\n        },\n        \"react\": {\n            \"opacityDefault\": 0.7,\n            \"opacityOnHover\": 0.2\n        }\n    });\n</script>\n```\n\n\n\n## hexo-blog-encrypt\n\n加密doc  https://github.com/D0n9X1n/hexo-blog-encrypt/blob/master/ReadMe.zh.md#%E4%BF%AE%E6%94%B9%E5%8A%A0%E5%AF%86%E6%A8%A1%E6%9D%BF\n\n```\nnpm install --save hexo-blog-encrypt\n```\n\n单篇\n\n```\n---\ntitle: Hello World\ntags:\n- 加密\ndate: 1022-02-30 21:12:21\npassword: 123   #添加该行配置密码访问\n---\n```\n\n标签维度_config.yml\n\n```\n# 安全插件 hexo-blog-encrypt 配置\nencrypt: \n  abstract: 有东西被加密了, 请输入密码查看.\n  message: 您好, 私密文章需要密码访问.\n  tags:\n  - {name: private-cs, password: cs@qazqwe;}\n  - {name: tagName, password: 密码@B}\n  wrong_pass_message: 抱歉, 这个密码看着不太对, 请再试试.\n  wrong_hash_message: 抱歉, 私密文章不能被校验, 不过您还是能看看解密后的内容.\n```\n\n\n\n\n\n\n\n#### 文章底部版权声明\n\nthemes/spfk/layout/_partial/post/nav.ejs\n\n```\n<a href=\"<%- config.root %>\" title=\"访问 <%= theme.author %> 的个人博客\"><%= theme.author%></a>\n```\n\n\n\n","tags":["search","hexo"],"categories":["lang","npm"]},{"title":"解压/压缩","url":"//linux/shell/decompress/","content":"\n\n\n## tar\n\n### 解压\n\n```\ntar -zxvf  helm-v3.9.3-linux-amd64.tar.gz\n```\n\n>-z    tar.gz  tgz\n>\n>-j    tar.bz2   tbz\n>\n>-C  接指定目录\n\n\n\n### 压缩\n\n\n\n```\ntar zcvf /dir/file.tar.gz   /dir/file\n```\n\n> -z  gzip压缩\n>\n> -j  bzip2压缩\n>\n> -zp  gzip压缩，并且保留权限信息(-p的属性是很重要的，尤其是当您要保留原本文件的属性时)\n>\n> --strip-components 1  去掉最外层目录\n","tags":["tar","unzip","xz","decompress"],"categories":["linux","shell"]},{"title":"download工具命令","url":"//linux/k8s/download/","content":"\n\n\n## wget\n\n### 常规使用\n\n```\nwget [options] [url]\n```\n\n#### 指定文件\n\n```\nwget  -P /opt/docker  https://get.helm.sh/helm-v3.9.3-linux-amd64.tar.gz\n```\n\n>-c 断点续传\n>\n>-O 下载并以不同的文件名保存\n>\n> -b 后台下载\n>\n>–spider 测试下载链接\n>\n>--limit-rate=1m  速度限制为1m/s\n\n\n\n### 批量下载\n\n#### 有规律\n\n```\nwget http://www.xxxx.com/file_{1..4}.txt\n```\n\n> 比如：file_1.txt，file_2.txt，file_3.txt\n\n\n\n#### 没有规律\n\n```\ncat >downloads.txt<<EOF\nhttp://www.xxxx.com/xxx\nhttp://www.xxxx.com/xxx\nEOF\nwget -i downloads.txt\n```\n\n\n\n### 下载整个目录\n\n\n\n```\nwget -r -np -nH -R index.html http://url/files/download/\n```\n\n>-r : 遍历所有子目录\n>-np : 不到上一层子目录去\n>-nH : 不要将文件保存到主机名文件夹\n>-R index.html : 不下载 index.html 文件\n>\n>-k 将网页内绝对链接转为相对链接\n\n\n\n### 模拟\n\n模拟 Edge 浏览器发出来的请求\n\n```\nwget --debug --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59\" http://www.baidu.com\n```\n\n模拟手机\n\n```\nwget --debug --header=\"User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 13_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Mobile/15E148 Safari /604.1\" http://www.baidu.com\n```\n\n\n\n\n\n## curl\n\n\n\n```\ncurl   -ikv   http://www.baidu.com\n```\n\n","tags":["download","wget","curl"],"categories":["linux","shell"]},{"title":"helm工具","url":"//linux/k8s/helm/","content":"\n\n\n### 安装\n\n下载 https://helm.sh/docs/intro/install/\n\n```\nwget  -P /opt/docker  https://get.helm.sh/helm-v3.9.3-linux-amd64.tar.gz\nmkdir /opt/docker/helm-v3.9.3\ntar -zxvf  helm-v3.9.3-linux-amd64.tar.gz  -C  ./helm-v3.9.3   --strip-components 1\n```\n\n\n\n### 设置环境变量\n\n```\n$ cat >> ~/.bashrc <<EOF\n#helm\nexport PATH=$PATH:/opt/docker/helm-v3.9.3\nEOF\n$ helm version\nversion.BuildInfo{Version:\"v3.9.3\", GitCommit:\"414ff28d4029ae8c8b05d62aa06c7fe3dee2bc58\", GitTreeState:\"clean\", GoVersion:\"go1.17.13\"}\n\n```\n\n\n\n### 添加源\n\n<!--more-->\n\n```\nhelm repo add stable http://mirror.azure.cn/kubernetes/charts \nhelm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts \nhelm repo list\n```\n\n\n\n#### show\n\n```\nhelm show chart stable/mysql\n```\n\n\n\n#### install\n\n有六种不同的方式来标识需要安装的chart：\n\n1. 通过chart引用： helm install mymaria example/mariadb\n2. 通过chart包： helm install mynginx ./nginx-1.2.3.tgz\n3. 通过未打包chart目录的路径： helm install mynginx ./nginx\n4. 通过URL绝对路径： helm install mynginx https://example.com/charts/nginx-1.2.3.tgz\n5. 通过chart引用和仓库url： helm install --repo https://example.com/charts/ mynginx nginx\n6. 通过OCI注册中心： helm install mynginx --version 1.2.3 oci://example.com/charts/nginx\n\n\n\n\n\n>❯ helm list\n>WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/cs/.kube/config\n>WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /home/cs/.kube/config\n>NAME\tNAMESPACE\tREVISION\tUPDATED\tSTATUS\tCHART\tAPP VERSION\n>\n>\n>\n>#helm list -A\n\n\n\n\n\nhttps://github.com/mysql/mysql-operator\n\n\n\n[helm/mysql-operator](https://github.com/mysql/mysql-operator/tree/trunk/helm/mysql-operator)\n\nenvs.k8sClusterDomain\n\n> persists try setting MYSQL_OPERATOR_K8S_CLUSTER_DOMAIN via environment.\n\n\n\n<details>\n  <summary>helm安装打包目录</summary>\n  <pre><a>helm install -f ...</a><code>\n❯ helm install -f ./mysql-operator/values.yaml -name mysql-operator --namespace mysql-operator --create-namespace ./mysql-operator\nWARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/cs/.kube/config\nWARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /home/cs/.kube/config\nNAME: mysql-operator\nLAST DEPLOYED: Thu Aug 31 20:42:51 2023\nNAMESPACE: mysql-operator\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCreate an MySQL InnoDB Cluster by executing:\n1. When using a source distribution / git clone: `helm install [cluster-name] -n [ns-name] ~/helm/mysql-innodbcluster`\n2. When using the Helm repo from ArtifactHub\n2.1 With self signed certificates\n    export NAMESPACE=\"your-namespace\"\n    # in case the namespace doesn't exist, please pass --create-namespace\n    helm install my-mysql-innodbcluster mysql-operator/mysql-innodbcluster -n $NAMESPACE \\\n        --version 2.1.0 \\\n        --set credentials.root.password=\">-0URS4F3P4SS\" \\\n        --set tls.useSelfSigned=true\n</br>\n2.2 When you have own CA and TLS certificates\n        export NAMESPACE=\"your-namespace\"\n        export CLUSTER_NAME=\"my-mysql-innodbcluster\"\n        export CA_SECRET=\"$CLUSTER_NAME-ca-secret\"\n        export TLS_SECRET=\"$CLUSTER_NAME-tls-secret\"\n        export ROUTER_TLS_SECRET=\"$CLUSTER_NAME-router-tls-secret\"\n        # Path to ca.pem, server-cert.pem, server-key.pem, router-cert.pem and router-key.pem\n        export CERT_PATH=\"/path/to/your/ca_and_tls_certificates\"\n</br>\n        kubectl create namespace $NAMESPACE\n</br>\n        kubectl create secret generic $CA_SECRET \\\n            --namespace=$NAMESPACE --dry-run=client --save-config -o yaml \\\n            --from-file=ca.pem=$CERT_PATH/ca.pem \\\n        | kubectl apply -f -\n</br>\n        kubectl create secret tls $TLS_SECRET \\\n            --namespace=$NAMESPACE --dry-run=client --save-config -o yaml \\\n            --cert=$CERT_PATH/server-cert.pem --key=$CERT_PATH/server-key.pem \\\n        | kubectl apply -f -\n</br>\n        kubectl create secret tls $ROUTER_TLS_SECRET \\\n            --namespace=$NAMESPACE --dry-run=client --save-config -o yaml \\\n            --cert=$CERT_PATH/router-cert.pem --key=$CERT_PATH/router-key.pem \\\n        | kubectl apply -f -\n</br>\n        helm install my-mysql-innodbcluster mysql-operator/mysql-innodbcluster -n $NAMESPACE \\\n        --version 2.1.0 \\\n        --set credentials.root.password=\">-0URS4F3P4SS\" \\\n        --set tls.useSelfSigned=false \\\n        --set tls.caSecretName=$CA_SECRET \\\n        --set tls.serverCertAndPKsecretName=$TLS_SECRET \\\n        --set tls.routerCertAndPKsecretName=$ROUTER_TLS_SECRET\n  </code></pre>\n</details>\n\n\n\n```\n❯ kubectl get deployment -n mysql-operator mysql-operator\nNAME             READY   UP-TO-DATE   AVAILABLE   AGE\nmysql-operator   1/1     1            1           74s\n\n\n❯ helm install mycluster ./mysql-innodbcluster \\\n        --namespace mysql-operator \\\n        --set tls.useSelfSigned=true \\\n        --set credentials.root.user='root' \\\n        --set credentials.root.password='cs@123456' \\\n        --set credentials.root.host='%' \\\n        --set serverInstances=3 \\\n        --set routerInstances=1\nNAME: mycluster\nLAST DEPLOYED: Sun Sep  3 20:47:47 2023\nNAMESPACE: mysql-operator\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n```\n\n\n\ndependency\n\n本地 \"file://../prometheus\"\n\n>❯ helm dependency build\n>Error: the lock file (Chart.lock) is out of sync with the dependencies file (Chart.yaml). Please update the dependencies\n>❯ helm dependency update\n>Hang tight while we grab the latest from your chart repositories...\n>...Successfully got an update from the \"cluster-proportional-autoscaler\" chart repository\n>...Successfully got an update from the \"aliyun\" chart repository\n>...Successfully got an update from the \"jetstack\" chart repository\n>...Successfully got an update from the \"hashicorp\" chart repository\n>...Successfully got an update from the \"flannel\" chart repository\n>...Successfully got an update from the \"mysql-operator\" chart repository\n>...Successfully got an update from the \"stable\" chart repository\n>...Successfully got an update from the \"coredns\" chart repository\n>...Successfully got an update from the \"bitpoke\" chart repository\n>...Successfully got an update from the \"radondb\" chart repository\n>...Successfully got an update from the \"prometheus-community\" chart repository\n>...Successfully got an update from the \"istio\" chart repository\n>Update Complete. ⎈Happy Helming!⎈\n>Saving 4 charts\n>Deleting outdated charts\n>\n>❯ helm package  metrics-server   #打包本地文件\n\n\n\n\n\n\n\n\n\n#### uninstall\n\n```\nhelm uninstall  mysql-operator -n mysql-operator\n```\n\n\n\n\n\n```\nextraArgs:\n  argument1: value1\n  argument2: value2\n  booleanArg1:\n  \n      args:\n{{- range $key, $value := .Values.extraArgs }}\n    {{- if $value }}\n    - --{{ $key }}={{ $value }}\n    {{- else }}\n    - --{{ $key }}\n    {{- end }}\n{{- end }}\n```\n\n\n\n### 模板语法\n\n- helm内置对象\n\n  Release, release相关属性\n  Chart, Chart.yaml文件中定义的内容\n  Values, values.yaml文件中定义的内容\n\n- 引用方式\n\n  \\{{ .Release.Name \\}}  通过双括号注入，小数点开头表示从最顶层命名空间引用\n\n\n\n常用函数\n\n• quote：将值转换为字符串，即加双引号\n\n• default：设置默认值，如果获取的值为空则为默认值\n\n• indent和nindent：缩进字符串 ，nindent 换行缩进\n\n• toYaml：引用一块YAML内容，如健康检查，资源配额resources，或者端口\n\n• 其他函数：upper、title等\n\n\n\n#### [Helm 按需渲染 CM](https://www.zhaowenyu.com/helm-doc/)\n\n","tags":["helm"],"categories":["linux","k8s"]},{"title":"kubelet组件","url":"//linux/k8s/kubelet/","content":"\n\n\n\n\n#### 二进制\n\nversion 1.18\n\n##### kubelet.env\n\n```shell\n[vagrant@k8s kubernetes]$ cat > /opt/kubernetes/kubelet/kubelet.env <<EOF\nKUBELET_OPTIONS=\" --pod-infra-container-image=k8s.org/k8s/pause:3.2   \\\n--bootstrap-kubeconfig=/opt/kubernetes/config/bootstrap.kubeconfig   \\\n--kubeconfig=/opt/kubernetes/config/kubelet.kubeconfig   \\\n--config=/opt/kubernetes/kubelet/kubelet-config.yaml    \\\n--cni-bin-dir=/opt/kubernetes/cni/bin    \\\n--cni-conf-dir=/opt/kubernetes/cni/net.d    \\\n--network-plugin=cni    \\\n-runtime-cgroups=/systemd/system.slice    \\\n--log-dir=/var/log/kubernetes/kubelet     \\\n--logtostderr=false    \\\n--v=2\"\nEOF\n```\n\n<!--more-->\n\n##### kubelet-config.yaml\n\n```\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\naddress: \"192.168.56.102\"\nport: 10250\nhealthzBindAddress: \"192.168.56.102\"\nhealthzPort: 10248\nreadOnlyPort: 0\ncgroupDriver: \"cgroupfs\"\nclusterDomain: \"cluster.local\"\nclusterDNS: [\"121.21.0.0\"]\nfailSwapOn: false\ntlsCertFile: \"/opt/kubernetes/pem/kubelet.pem\"\ntlsPrivateKeyFile: \"/opt/kubernetes/pem/kubelet-key.pem\"\nauthentication:\n    x509:\n        clientCAFile: \"/opt/kubernetes/pem/ca.pem\"\n    webhook:\n        enabled: true\n        cacheTTL: \"2m0s\"\n    anonymous:\n        enabled: false\nauthorization:\n    mode: Webhook\n    webhook:\n        cacheAuthorizedTTL: \"5m0s\"\n        cacheUnauthorizedTTL: \"30s\"\nhairpinMode: \"promiscuous-bridge\"\nserializeImagePulls: false\nfeatureGates:\n    RotateKubeletClientCertificate: true\n    RotateKubeletServerCertificate: true\n```\n\n\n\n#### 容器\n\nversion 1.22\n\n##### kubelet.env\n\n```shell\n[vagrant@k8s kubernetes]$ cat > /opt/kubernetes/kubelet.env <<EOF\n KUBELET_OPTIONS=\" --hostname-override=k8s  \\\n --pod-infra-container-image=k8s.org/k8s/pause:3.4.1 \\\n --kubeconfig=/etc/kubernetes/kubelet.conf    \\\n --config=/var/lib/kubelet/config.yaml     \\\n --register-node=true        \\\n --runtime-cgroups=/systemd/system.slice    \\\n --logtostderr=true \"\nEOF\n```\n\n> --network-plugin=cni  **去掉**\n\n\n\n##### kubelet.conf\n\n/etc/kubernetes/kubelet.conf\n\n```\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: xxxx..xxxxxxx==\n    server: https://192.168.56.108:6443\n  name: k8s\ncontexts:\n- context:\n    cluster: k8s\n    user: system:node:k8s\n  name: system:node:k8s@k8s\ncurrent-context: system:node:k8s@k8s\nkind: Config\npreferences: {}\nusers:\n- name: system:node:k8s\n  user:\n    client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem\n    client-key: /var/lib/kubelet/pki/kubelet-client-current.pem\n```\n\n\n\n##### config.yaml\n\n/var/lib/kubelet/config.yaml\n\n```\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfailSwapOn: false\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n```\n\n\n\n#### service\n\n<p id=\"id-service\" hidden/>\n\n##### kubelet.service\n\n```\n[vagrant@k8s kubernetes]$ cat >/usr/lib/systemd/system/kubelet.service <<EOF\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=/var/lib/kubelet\nEnvironmentFile=/opt/kubernetes/kubelet.env\nExecStart=/opt/kubernetes/bin/kubelet  $KUBELET_OPTIONS\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\nkubeadm部署,不用启动,会自动拉起\n\n初始化自动生成\n\n/etc/kubernetes/kubelet.conf\n\n/var/lib/kubelet/config.yaml\n\n#### 静态pod\n\n```\n# cat /var/lib/kubelet/config.yaml  | grep staticPodPath:\nstaticPodPath: /etc/kubernetes/manifests\n\n```\n\n\n\n\n\n\n\n开机自启动\n\n```\nsystemctl enable kubelet\n```\n\n","tags":["kubelet"],"categories":["linux","k8s"]},{"title":"Mathjax公式","url":"//tool/text/markdown/formula/","content":"\n\n\nWhen $a \\ne 0$, there are two solutions to \\(ax^2 + bx + c = 0\\) and they are\n\n$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$\n\n![](/pics/mathjax01.png)\n\n\n\n<!--more-->\n\nhttp://mathjax.josephjctang.com/\n\n```shell\n$ grep theme.mathjax -rl --include=\\*.{ejs,js} /home/cs/oss/hexo/themes/spfk\n/home/cs/oss/hexo/themes/spfk/layout/_partial/head.ejs\n$ sed -i 's/theme.mathjax/page.mathjax/' /hexo/themes/spfk/layout/_partial/after-footer.ejs\n```\n\n> <% if (page.mathjax){ %>\n\n\n\n/hexo/public/js/MathJax.js 添加引入\n\n```\n  <script type=\"text/javascript\"\n     src=\"http://mathjax.josephjctang.com/MathJax.js?config=TeX-MML-AM_HTMLorMML\">\n  </script>\n```\n\n文章开头加入\n\n```\ntitle: xxxx\npermalink: xxxx/\ntags: xxxx\ndate: xxxx\nmathjax: true\n```\n\n> mathjax: true\n\n\n\n引入目录\n\n![](/pics/mathjax.png)\n","tags":["formula"],"categories":["markdown"]},{"title":"harbor镜像私库","url":"//linux/k8s/harbor/","content":"\n## 配置要求\n\n### 硬件\n\n| 资源 | 最低  | 推荐   |\n| ---- | ----- | ------ |\n| CPU  | 2 CPU | 4 CPU  |\n| Mem  | 4 GB  | 8 GB   |\n| Disk | 40 GB | 160 GB |\n\n\n\n### 软件\n\ndocker  v17.06.0-ce+  [Docker 引擎文档](https://docs.docker.com/engine/installation/)\n\ndocker-compose v1.18.0+  [Docker Compose 文档](https://docs.docker.com/compose/install/)\n\nOpenSSL\n\n\n\n### 网络端口\n\nHTTPS  443/4443\n\nHTTP  80\n\n\n\n## 安装\n\n<p id=\"harbor-install\" hidden/>\n\n仓库\n\nhttps://github.com/goharbor/harbor/releases\n\n文档\n\nhttps://goharbor.io/docs/2.5.3/install-config/download-installer/\n\n\n\n### harbor\n\n#### 证书ca.key\n\nhttps://goharbor.io/docs/2.5.3/install-config/configure-https/\n\n##### 生成CA私钥\n\n```shell\n openssl genrsa -out ca.key 4096\n```\n\n<!--more-->\n\n##### 生成CA证书\n\n```shell\n openssl req -x509 -new -nodes -sha512 -days 3650 \\\n -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=k8s.org\" \\\n  -key ca.key \\\n  -out ca.crtopenssl genrsa -out ca.key 4096\n```\n\n#### 服务器证书\n\n##### 生成私钥\n\n```shell\n openssl genrsa -out k8s.org.key 4096\n```\n\n##### 生成证书签名请求（CSR）\n\n```shell\nopenssl  req -sha512 -new \\\n -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=k8s.org\" \\\n -key k8s.org.key \\\n -out k8s.org.csr\n```\n\n##### 生成一个x509 v3扩展文件\n\n```shell\n cat > v3.ext <<-EOF\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1=k8s.org\nDNS.2=k8s\nDNS.3=k8s\nEOF\n```\n\n##### 使用该v3.ext文件为您的Harbor主机生成证书\n\n```shell\nopenssl x509 -req -sha512 -days 3650 \\\n    -extfile v3.ext \\\n    -CA ca.crt -CAkey ca.key -CAcreateserial \\\n    -in k8s.org.csr \\\n    -out k8s.org.crt\n```\n\n\n\nDocker守护程序将.crt文件解释为CA证书，并将.cert文件解释为客户端证书\n\n```shell\nopenssl x509 -inform PEM -in k8s.org.crt -out k8s.org.cert\n```\n\n\n\n#### harbor.yml\n\n代理网址 https://ghproxy.com  下载\n\nhttps://ghproxy.com/https://github.com/goharbor/harbor/releases/download/v2.5.3/harbor-offline-installer-v2.5.3.tgz\n\n```\ncs@debian:~/下载/新建文件夹$ md5sum harbor-offline-installer-v2.5.3.tgz \nd858f6969829e4ce2769a790ecaa0cf7  harbor-offline-installer-v2.5.3.tgz\n\ncs@debian:~/下载/新建文件夹$ tar xzvf harbor-offline-installer-v2.5.3.tgz\ncs@debian:~/下载/新建文件夹$ tree -L 1 ./harbor\n./harbor\n├── common.sh\n├── harbor.v2.5.3.tar.gz\n├── harbor.yml.tmpl\n├── install.sh\n├── LICENSE\n└── prepare\n\n0 directories, 6 files\n```\n\n\n\n```\nsed -n '/hostname/s/reg.mydomain.com/192.168.56.1/'p ./harbor/harbor.yml.tmpl \nhostname: 192.168.56.1\nsed -n '/port:/s/443/8443/'p ./harbor/harbor.yml.tmpl \n  port: 8443\nsed -n '/certificate:/s/\\/your.*path/\\/opt\\/nginx\\/conf\\/conf.d\\/ssl\\/k8s.org.crt/'p ./harbor/harbor.yml.tmpl \n  certificate: /opt/nginx/conf/conf.d/ssl/k8s.org.crt\n```\n\n>hostname\n>\n>https   port ,certificate,private_key\n>\n>external_url\n>\n>harbor_admin_password\n>\n>data_volume\n>\n>用外部数据库,redis时需要配置 external_database,external_redis \n\n\n\n```\nsudo ./install.sh\n```\n\n> 默认的 Harbor 安装不包括 Notary 或 Trivy 等服务\n>\n> ./install.sh --with-notary --with-trivy --with-chartmuseum\n>\n>  --with-notary  数据权限\n>\n> --with-trivy   漏洞扫描\n>\n> --with-chartmuseum helm\n\n\n\n### docker\n\n#### certs.d\n\n```shell\ntree -L 3 /etc/docker/\n/etc/docker/\n├── certs.d\n│   └── k8s.org\n│       ├── ca.crt\n│       ├── k8s.org.cert\n│       └── k8s.org.key\n├── daemon.json\n└── key.json\n\n2 directories, 5 files\n```\n\n> cp yourdomain.com.cert /etc/docker/certs.d/yourdomain.com/\n>cp yourdomain.com.key /etc/docker/certs.d/yourdomain.com/\n>cp ca.crt /etc/docker/certs.d/yourdomain.com/\n\n\n\n#### daemon.json\n\n```json\n{\n    \"data-root\": \"/opt/data/docker\",\n   \"registry-mirrors\" : [\n    \"http://hub-mirror.c.163.com\"\n  ],\n\"insecure-registries\":[\n  \"https://k8s.org\"\n  ],\n  \"debug\" : true,\n  \"experimental\" : true\n}\n\n```\n\n> insecure-registries 私库地址,非域名格式 ip:端口\n\n\n\n#### login\n\n登录密码会保存认证,下次push镜像就不需要输入密码了\n\n```shell\ncs@debian:~$ docker login k8s.org\ncs@debian:~$ cat  ~/.docker/config.json \n{\n\t\"auths\": {\n\t\t\"cs.org\": {\n\t\t\t\"auth\": \"YWRtaW46YWRtaW4=\"\n\t\t},\n\t\t\"k8s.org\": {\n\t\t\t\"auth\": \"YWRtaW46Y3MxMjM0NTY=\"\n\t\t}\n\t},\n\t\"HttpHeaders\": {\n\t\t\"User-Agent\": \"Docker-Client/18.09.3 (linux)\"\n\t}\n}\n```\n\n\n\n\n\n### nginx\n\n/opt/nginx/conf/conf.d/http/harbor.conf\n\n```\nupstream harbors{\n     server 192.168.56.1:8443;\n     #server 192.168.56.2:8443;\n}\n\n\nlog_format  harbor_log  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                     '$status $body_bytes_sent \"$http_referer\" '\n                     '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n\nserver {\n       listen       443 ssl;\n       server_name  k8s.org;\n\n        ssl_certificate      conf.d/ssl/k8s.org.crt;\n        ssl_certificate_key  conf.d/ssl/k8s.org.key;\n\n        ssl_session_cache    shared:SSL:1m;\n        ssl_session_timeout  5m;\n\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers  on;\n\n       access_log  logs/harbors.log  harbor_log;\n       location / {\n            client_max_body_size  1024m;  # 设置接收客户端 body 最大长度为 1024M\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass https://harbors;\n        }\n}\n```\n\n> error parsing HTTP 413 response body: ...... <title>413 Request Entity Too Large</title>\n>\n> **client_max_body_size**\n\n\n\n## 推送\n\n**域名/目录/镜像名:版本号**\n\n```shell\n$ docker images | grep etcd\nk8s.org/k8s/etcd                      3.4.13-0            51401ddb110e        23 months ago       145MB\n\n$ docker push  k8s.org/k8s/etcd:3.4.13-0\n```\n\n\n\n### 项目 \n\n![](/pics/harbor-01.png)\n\n### 镜像\n\n![](/pics/harbor-02.png)\n\n\n\n## 高可用\n\n通过配置数据库(mysql ,redis集群),存储来实现\n\n\n\n## ERROR\n\n### pull Retrying in\n\nhttps://github.com/vmware/harbor/issues/3062\n\n/opt/nginx/conf/nginx.conf\n\n```\nhttp {\n    ......\n      ####添加以下配置\n      proxy_buffers 4 32k;\n      proxy_busy_buffers_size 64k;\n      proxy_temp_file_write_size 64k;\n      #unlimit the proxy temp file size limitaion. Look at issue #3062 (https://github.com/vmware/harbor/issues/3062)\n      proxy_max_temp_file_size 0;\n\n  ....      \n  }\n```\n\n\n\n```\nhttp:\n  relativeurls: true\n```\n\nharbor的helm里需要加上registry.relativeurls=true\n\n参考：https://github.com/docker/distribution/issues/970#issuecomment-284227065\n\n\n\n### ImagePullBackOff\n\n#### 创建一个基于现有凭证的 Secret\n\n```\n$ kubectl create secret generic login --from-file=.dockerconfigjson=/home/cs/.docker/config.json  --type=kubernetes.io/dockerconfigjson \nsecret/login created\n```\n\n\n\n#### 在命令行上提供凭证来创建 Secret\n\n```\nkubectl create secret docker-registry regcred \\\n--docker-server=<你的镜像仓库服务器> \\\n--docker-username=<你的用户名> \\\n--docker-password=<你的密码> \\\n--docker-email=<你的邮箱地址>\n```\n\n>在这里：\n\n>-  是你的私有 Docker 仓库全限定域名（FQDN）。 DockerHub 使用 https://index.docker.io/v1/。\n>-  是你的 Docker 用户名。\n>-  是你的 Docker 密码。\n>-  是你的 Docker 邮箱。\n\n这样你就成功地将集群中的 Docker 凭证设置为名为 regcred 的 Secret\n\n#### 检查 Secret \n\n\n\n```yaml\n$ kubectl get secrets\nNAME                  TYPE                                  DATA   AGE\nlogin                 kubernetes.io/dockerconfigjson        1      85d\n$ kubectl get secret login --output=yaml  \napiVersion: v1\ndata:\n  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJjcy5vcmciOiB7CgkJCSJhdXRoIjogIllXUnRhVzQ2WVdSdGFXND0iCgkJfSwKCQkiazhzLm9yZyI6IHsKCQkJImF1dGgiOiAiWVdSdGFXNDZZM014TWpNME5UWT0iCgkJfQoJfSwKCSJIdHRwSGVhZGVycyI6IHsKCQkiVXNlci1BZ2VudCI6ICJEb2NrZXItQ2xpZW50LzE4LjA5LjMgKGxpbnV4KSIKCX0KfQ==\nkind: Secret\n....\n```\n\n\n\n```\n$ kubectl get secret login --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode\n{\n\t\"auths\": {\n\t\t\"cs.org\": {\n\t\t\t\"auth\": \"YWRtaW46YWRtaW4=\"\n\t\t},\n\t\t\"k8s.org\": {\n\t\t\t\"auth\": \"YWRtaW46Y3MxMjM0NTY=\"\n\t\t}\n\t},\n\t\"HttpHeaders\": {\n\t\t\"User-Agent\": \"Docker-Client/18.09.3 (linux)\"\n\t}\n}\n```\n\n\n\n```\necho \"YWRtaW46Y3MxMjM0NTY=\" | base64 --decode \nadmin:cs12xx\n```\n\n\n\n#### pod\n\n创建一个使用你的 Secret 的 Pod\n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: private-reg\nspec:\n  containers:\n  - name: private-reg-container\n    image: <your-private-image>\n  imagePullSecrets:\n  - name: login\n```\n\n\n\n\n\n### 版本升级\n\n2.1.0->2.8.3\n\n`❯ tar -xvf  ./harbor-offline-installer-v2.8.3.tgz`\n\n>harbor/harbor.v2.8.3.tar.gz\n>harbor/prepare\n>harbor/LICENSE\n>harbor/install.sh\n>harbor/common.sh\n>harbor/harbor.yml.tmpl\n>\n>\n\n\n\n`❯ docker image load -i harbor.v2.8.3.tar.gz`\n\n>Loaded image: goharbor/registry-photon:v2.8.3\n>\n>Loaded image: goharbor/notary-server-photon:v2.8.3\n>\n>Loaded image: goharbor/notary-signer-photon:v2.8.3\n>\n>Loaded image: goharbor/harbor-log:v2.8.3\n>\n>Loaded image: goharbor/redis-photon:v2.8.3\n>\n>Loaded image: goharbor/harbor-jobservice:v2.8.3\n>\n>Loaded image: goharbor/prepare:v2.8.3\n>\n>Loaded image: goharbor/harbor-core:v2.8.3\n>\n>Loaded image: goharbor/harbor-registryctl:v2.8.3\n>\n>Loaded image: goharbor/nginx-photon:v2.8.3\n>\n>Loaded image: goharbor/trivy-adapter-photon:v2.8.3\n>\n>Loaded image: goharbor/harbor-portal:v2.8.3\n>Loaded image: goharbor/harbor-db:v2.8.3\n>Loaded image: goharbor/harbor-exporter:v2.8.3\n>\n>\n\n\n\n`❯ docker run -it --rm -v /:/hostfs goharbor/prepare:v2.8.3 migrate -i /opt/kubernetes/harbor//harbor.yml`\n\n>❯ docker run -it --rm -v /:/hostfs goharbor/prepare:v2.8.3 migrate -i /opt/kubernetes/harbor/harbor.yml\n>migrating to version 2.1.0\n>migrating to version 2.2.0\n>migrating to version 2.3.0\n>migrating to version 2.4.0\n>migrating to version 2.5.0\n>migrating to version 2.6.0\n>migrating to version 2.7.0\n>migrating to version 2.8.0\n>Written new values to /opt/kubernetes/harbor/harbor.yml\n>\n>\n\n\n\n\n\n```\n❯ docker rmi `docker images | grep goharbor | grep 2.1 | awk '{print $3}'`\n```\n\n\n\n\n\npostgresql 数据版本升级利用 `pg_upgrade`工具   --待实验\n\nhttps://blog.csdn.net/heran36/article/details/131250813\n","tags":["harbor"],"categories":["linux","k8s"]},{"title":"kubeadm容器化安装","url":"//linux/k8s/kubeadm/","content":"\n### docker\n\n#### daemon.json\n\n```shell\n[vagrant@k8s ~]$ sudo vi /etc/docker/daemon.json\n[vagrant@k8s ~]$ docker info | grep Driver\nStorage Driver: overlay2\nLogging Driver: json-file\nCgroup Driver: cgroupfs\n[vagrant@k8s ~]$ sudo systemctl restart docker \n[vagrant@k8s ~]$ docker info | grep Driver\nStorage Driver: overlay2\nLogging Driver: json-file\nCgroup Driver: systemd\n[vagrant@k8s ~]$ sudo cat  /etc/docker/daemon.json\n{\n \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n \"insecure-registries\":[\"https://k8s.org\"]\n\n}\n```\n\n>\"exec-opts\": [\"native.cgroupdriver=systemd\"]\n\n Error response from daemon: OCI runtime create failed: systemd cgroup flag passed, but systemd support for managing cgroups is not available\n\n\n\n/etc/sysconfig/modules/ipvs.modules\n\n```\ncat > /etc/sysconfig/modules/ipvs.modules <<EOF\n#!/bin/bash\nmodprobe -- br_netfilter\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack_ipv4\nEOF\nchmod 755 /etc/sysconfig/modules/ipvs.modules\n```\n\n\n\n```\n cat  /etc/sysctl.conf\nnet.ipv4.vs.conntrack=1\nnet.ipv4.vs.conn_reuse_mode=0\nnet.ipv4.vs.expire_nodest_conn=1\n```\n\n\n\n\n\n### 准备images list\n\n```\n./kubeadm config images list\nI0809 21:56:57.334915    4785 version.go:254] remote version is much newer: v1.24.3; falling back to: stable-1.21\nk8s.gcr.io/kube-apiserver:v1.21.14\nk8s.gcr.io/kube-controller-manager:v1.21.14\nk8s.gcr.io/kube-scheduler:v1.21.14\nk8s.gcr.io/kube-proxy:v1.21.14\nk8s.gcr.io/pause:3.4.1\nk8s.gcr.io/etcd:3.4.13-0\nk8s.gcr.io/coredns/coredns:v1.8.0\n```\n\n<!--more-->\n\n\n\n### 依赖conntrack\n\n![](/pics/k8s-not-ipvs-02.png)\n\n```\nyum -y install socat conntrack-tools\n```\n\n\n\n### init配置文件\n\n#### 命令生成默认文件\n\n```\nkubeadm config print init-defaults  > config.yaml\n```\n\n\n\n```\n#生成KubeletConfiguration示例文件 \nkubeadm config print init-defaults --component-configs KubeletConfiguration\n\n#生成KubeProxyConfiguration示例文件 \nkubeadm config print init-defaults --component-configs KubeProxyConfiguration\n```\n\n\n\n```\nansible k8s-108 -m copy -a \"src=/opt/kubernetes/client/k8s-1.21-11/bin/config.yaml dest=/opt/kubernetes  mode=0644\"   -b --become-method sudo --become-user root\n```\n\n\n\n\n\n#### config.yaml\n\n```yaml\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.56.108 #ip\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: k8s # hostname “xxx” could not be reached\n  taints: null\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: k8s.org/k8s  # 镜像仓库源\nkind: ClusterConfiguration\nkubernetesVersion: 1.21.12  #版本\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\ncgroupDriver: systemd\nfailSwapOn: False\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nipvs:\n  minSyncPeriod: 0s\n  scheduler: \"rr\"\n  syncPeriod: 30s\nmode: \"ipvs\"\n```\n\n\n\n#### kubectl\n\n![](/pics/k8s-get-pend-01.png)\n\ndocker: network plugin is not ready: cni config uninitialized\n\n[kubelet.service详解](/linux/k8s/kubelet#id-service)\n\n\n\n### 初始化过程\n\n```shell\n[vagrant@k8s kubernetes]$ sudo ./bin/kubeadm   init --config config.yaml\nW0809 20:30:08.653353    3073 kubelet.go:215] detected \"cgroupfs\" as the Docker cgroup driver, the provided value \"systemd\" in \"KubeletConfiguration\" will be overrided\n[init] Using Kubernetes version: v1.21.12\n[preflight] Running pre-flight checks\n\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n\t[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.56.108]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s localhost] and IPs [192.168.56.108 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s localhost] and IPs [192.168.56.108 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 12.505234 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node k8s as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: abcdef.0123456789abcdef\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.56.108:6443 --token abcdef.0123456789abcdef \\\n\t--discovery-token-ca-cert-hash sha256:01661c34149742e27fa96db2f1c4a8d4675d2f0b5133f8cd25a45e031eb23653 \n```\n\n\n\n### 节点配置文件\n\n```\nkubeadm config print join-defaults > join-config.yaml\n```\n\n\n\n\n\n```\nkubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap\n```\n\n>error: failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User \"kubelet-bootstrap\" cannot create certificatesigningrequests.certificates.k8s.io at the cluster scope\n>\n\n\n\n\n\n### 网络插件podnetwork\n\nhttps://kubernetes.io/docs/concepts/cluster-administration/addons/\n\n\n\n#### flanneld\n\n[查看flanneld.yaml](/linux/k8s/flanneld)\n\n```shell\nansible k8s-108 -m copy -a \"src=/home/cs/oss/0s/k8s/kube/kube-flanneld.yml  dest=/opt/kubernetes  mode=0644\"   -b --become-method sudo --become-user root\n```\n\n\n\n```shell\n[vagrant@k8s kubernetes]$ kubectl apply -f kube-flanneld.yaml \nWarning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\npodsecuritypolicy.policy/psp.flannel.unprivileged created\nWarning: rbac.authorization.k8s.io/v1beta1 ClusterRole is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRole\nclusterrole.rbac.authorization.k8s.io/flannel created\nWarning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBinding\nclusterrolebinding.rbac.authorization.k8s.io/flannel created\nserviceaccount/flannel created\nconfigmap/kube-flannel-cfg created\ndaemonset.apps/kube-flannel-ds-amd64 created\n```\n\n\n\n#### calico\n\nhttps://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises\n\ncalico.yaml https://docs.projectcalico.org/manifests/calico.yaml\n\n\n\n### kubectl权限\n\n#### ~/.kube/config\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n\n\n\n\n### 组件状态cs\n\n#### Unhealthy \n\n![](/pics/k8s-get-cs-01.png)\n\n\n\n注释`port=0`行\n\n```shell\n[vagrant@k8s kubernetes]$ sudo sed -i '/port=0/s/^/#/'  /etc/kubernetes/manifests/kube-controller-manager.yaml\n[vagrant@k8s kubernetes]$ sudo sed -i '/port=0/s/^/#/'  /etc/kubernetes/manifests/kube-scheduler.yaml\n```\n\n![](/pics/k8s-get-cs-02.png)\n\n\n\n### 加入集群\n\n集群初始化时的添加命令\n\n```\nkubeadm join 192.168.56.108:6443 --token abcdef.0123456789abcdef \\\n\t--discovery-token-ca-cert-hash sha256:01661c34149742e27fa96db2f1c4a8d4675d2f0b5133f8cd25a45e031eb23653\n```\n\n命令方式获取join参数\n\n```\nkubeadm token create --print-join-command\n```\n\n\n\n\n\n重新生成certificate-key,生成用于加入控制平面的secret\n\n```\nkubeadm init phase upload-certs --upload-certs\n```\n\n> Using certificate key:xxxx\n\n\n\n#### 加入控制节点\n\n```\nkubeadm join 192.168.56.108:6443 --token abcdef.0123456789abcdef \\\n\t--discovery-token-ca-cert-hash sha256:01661c34149742e27fa96db2f1c4a8d4675d2f0b5133f8cd25a45e031eb23653    --control-plane --certificate-key xxxx\n```\n\n\n\n\n\n\n\n### Pending状态\n\n```\nkubectl logs kube-flannel-ds-amd64-7wjtn -n kube-system\n```\n\n> Error registering network: failed to acquire lease: node \"k8s\" pod cidr not assigned\n\n![](/pics/k8s-get-node-01.png)\n\nmaster节点一直NotReady  和  coredns pod一直pending\n\n [安装flanneld.yaml](/linux/k8s/flanneld#id-flanneld)\n\n![](/pics/k8s-get-node-02.png)\n\n\n\n### pod-network-cidr\n\n#### 修改 \n\n--pod-network-cidr\n\n```\n1）kubectl -n kube-system edit cm kubeadm-config\n2）vim /etc/kubernetes/manifests/kube-scheduler.yaml\n```\n\n#### 检查配置\n\n```\nkubectl cluster-info dump | grep -m 1 cluster-cidr\n```\n\n**kube-proxy的cluster-cidr与kuber-controller-manager的cluster-cidr**\n\n\n\n\n\n```objectivec\n kubectl scale deployment --replicas=0 dns-autoscaler -n kube-system\ndeployment.extensions/dns-autoscaler scaled\n# kubectl patch deployment coredns -p '{\"spec\":{\"replicas\":17}}' -n kube-system\ndeployment.extensions/coredns patched\n# kubectl get pod -n kube-system |grep coredns |wc -l\n```\n\n\n\n### 重启\n\n```\nsystemctl status kubelet\nsudo systemctl start kubelet\n```\n\n> *静态 Pod* 在指定的节点上由 kubelet 守护进程直接管理，不需要 [API 服务器](https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/) 监管,kubelet 监视每个静态 Pod（在它崩溃之后重新启动）\n>\n> –pod-manifest-path=\n\n#### 常见的 Static Pod\n\n- etcd\n- kube-apiserver\n- kube-controller-manager\n- kube-scheduler\n\n\n\n### 卸载\n\n```shell\nsudo kubeadm reset -f\nsudo rm -rf /var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni /etc/kubernetes\n```\n\n\n\n\n\n### 多集群\n\n#### 多个配置\n\n一台机器管理多个集群\n\n```shell\ncs@debian:~$ ls -l ~/.kube/\n总用量 36\ndrwxr-x--- 3 cs cs 4096 4月  20 14:37 cache\n-rw------- 1 cs cs 9852 8月  10 21:58 config\n-rw-r--r-- 1 cs cs 5597 8月  10 21:56 config1   #k8s 容器部署\n-rw------- 1 cs cs 6201 8月   6 16:57 config2   #kubernetes二进制部署\ndrwxr-x--- 3 cs cs 4096 8月  10 21:58 http-cache\n```\n\n#### 合并配置\n\n```shell\n$ KUBECONFIG=/home/cs/.kube/config1:/home/cs/.kube/config2 kubectl config view --flatten >/home/cs/.kube/config\n```\n\n![](/pics/k8s-view-cluster.png)\n\n\n\n#### 获取集群配置\n\n```shell\ncs@debian:~$ kubectl config get-contexts\nCURRENT   NAME                   CLUSTER      AUTHINFO           NAMESPACE\n          admin@kubernetes       kubernetes   admin              \n*         kubernetes-admin@k8s   k8s          kubernetes-admin  \n```\n\n##### 容器部署\n\n```\ncs@debian:~$ kubectl get cs\nNAME                 STATUS    MESSAGE             ERROR\nscheduler            Healthy   ok                  \ncontroller-manager   Healthy   ok                  \netcd-0               Healthy   {\"health\":\"true\"}   \ncs@debian:~$ kubectl get node\nNAME   STATUS   ROLES                  AGE     VERSION\nk8s    Ready    control-plane,master   4m57s   v1.21.11\n```\n\n\n\n\n\n#### 换集群\n\nuse-context\n\n```shell\n#当前集群\ncs@debian:~$ kubectl config current-context   \nkubernetes-admin@k8s\n\ncs@debian:~$ kubectl config use-context admin@kubernetes   \nSwitched to context \"admin@kubernetes\".\n```\n\n##### 二进制部署\n\n```shell\ncs@debian:~$ kubectl get cs\nNAME                 STATUS    MESSAGE              ERROR\nscheduler            Healthy   ok                   \ncontroller-manager   Healthy   ok                   \netcd-1               Healthy   {\"health\": \"true\"}   \netcd-0               Healthy   {\"health\": \"true\"}   \netcd-2               Healthy   {\"health\": \"true\"}   \ncs@debian:~$ kubectl get node\nNAME       STATUS     ROLES    AGE    VERSION\nmaster02   Ready      <none>   121d   v1.18.8\nmaster03   Ready      <none>   121d   v1.18.8\nnode04     Ready      <none>   121d   v1.18.8\nnode05     NotReady   <none>   121d   v1.18.8\nnode06     Ready      <none>   121d   v1.18.8\n```\n\n\n\n\n\n![](/pics/k8s-more-cluster.png)\n\n> current-context 显示 current_context\n> delete-cluster  删除 kubeconfig 文件中指定的集群\n> delete-context  删除 kubeconfig 文件中指定的 context\n> get-clusters    显示 kubeconfig 文件中定义的集群\n> get-contexts    描述一个或多个 contexts\n> rename-context  从 kubeconfig 文件重命名上下文。\n> set             设置 kubeconfig 文件中的一个单个值\n> set-cluster     设置 kubeconfig 文件中的一个集群条目\n> set-context     设置 kubeconfig 文件中的一个 context 条目\n> set-credentials 设置 kubeconfig 文件中的一个用户条目\n> unset           取消设置 kubeconfig 文件中的一个单个值\n> use-context     设置 kubeconfig 文件中的当前上下文\n> view            显示合并的 kubeconfig 配置或一个指定的 kubeconfig 文件\n\n\n\n","tags":["kubeadm"],"categories":["linux","k8s"]},{"title":"flanneld虚拟网络","url":"//linux/k8s/flanneld/","content":"\n\n\ngithub https://github.com/flannel-io/flannel/tree/v0.16.1/Documentation\n\n<p id=\"id-flanneld\" hidden />\n\n### flannel\n\n\n\n<details>\n  <summary>flannel详情</summary>\n  <pre><a>flannel.yaml</a><code>\n---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: psp.flannel.unprivileged\n  annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default\n    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default\n    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default\n    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default\nspec:\n  privileged: false\n  volumes:\n  - configMap\n  - secret\n  - emptyDir\n  - hostPath\n  allowedHostPaths:\n  - pathPrefix: \"/etc/cni/net.d\"\n  - pathPrefix: \"/etc/kube-flannel\"\n  - pathPrefix: \"/run/flannel\"\n  readOnlyRootFilesystem: false\n  # Users and groups\n  runAsUser:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  fsGroup:\n    rule: RunAsAny\n  # Privilege Escalation\n  allowPrivilegeEscalation: false\n  defaultAllowPrivilegeEscalation: false\n  # Capabilities\n  allowedCapabilities: ['NET_ADMIN', 'NET_RAW']\n  defaultAddCapabilities: []\n  requiredDropCapabilities: []\n  # Host namespaces\n  hostPID: false\n  hostIPC: false\n  hostNetwork: true\n  hostPorts:\n  - min: 0\n    max: 65535\n  # SELinux\n  seLinux:\n    # SELinux is unused in CaaSP\n    rule: 'RunAsAny'\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nrules:\n- apiGroups: ['extensions']\n  resources: ['podsecuritypolicies']\n  verbs: ['use']\n  resourceNames: ['psp.flannel.unprivileged']\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  verbs:\n  - get\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes\n  verbs:\n  - list\n  - watch\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes/status\n  verbs:\n  - patch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: flannel\nsubjects:\n- kind: ServiceAccount\n  name: flannel\n  namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: flannel\n  namespace: kube-system\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: kube-flannel-cfg\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\ndata:\n  cni-conf.json: |\n    {\n      \"name\": \"cbr0\",\n      \"cniVersion\": \"0.3.1\",\n      \"plugins\": [\n        {\n          \"type\": \"flannel\",\n          \"delegate\": {\n            \"hairpinMode\": true,\n            \"isDefaultGateway\": true\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"capabilities\": {\n            \"portMappings\": true\n          }\n        }\n      ]\n    }\n  net-conf.json: |\n    {\n      \"Network\": \"10.244.0.0/16\",\n      \"Backend\": {\n        \"Type\": \"vxlan\"\n      }\n    }\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-flannel-ds\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\nspec:\n  selector:\n    matchLabels:\n      app: flannel\n  template:\n    metadata:\n      labels:\n        tier: node\n        app: flannel\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      hostNetwork: true\n      priorityClassName: system-node-critical\n      tolerations:\n      - operator: Exists\n        effect: NoSchedule\n      serviceAccountName: flannel\n      initContainers:\n      - name: install-cni-plugin\n        image: k8s.org/k8s/flannel-cni-plugin:v1.0.0-amd64\n        command:\n        - cp\n        args:\n        - -f\n        - /flannel\n        - /opt/cni/bin/flannel\n        volumeMounts:\n        - name: cni-plugin\n          mountPath: /opt/cni/bin\n      - name: install-cni\n        image: k8s.org/k8s/flannel:v0.15.1-amd64\n        command:\n        - cp\n        args:\n        - -f\n        - /etc/kube-flannel/cni-conf.json\n        - /etc/cni/net.d/10-flannel.conflist\n        volumeMounts:\n        - name: cni\n          mountPath: /etc/cni/net.d\n        - name: flannel-cfg\n          mountPath: /etc/kube-flannel/\n      containers:\n      - name: kube-flannel\n        image: k8s.org/k8s/flannel:v0.15.1-amd64\n        command:\n        - /opt/bin/flanneld\n        args:\n        - --ip-masq\n        - --kube-subnet-mgr\n        - --iface=eth1\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"50Mi\"\n          limits:\n            cpu: \"100m\"\n            memory: \"50Mi\"\n        securityContext:\n          privileged: false\n          capabilities:\n            add: [\"NET_ADMIN\", \"NET_RAW\"]\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: run\n          mountPath: /run/flannel\n        - name: flannel-cfg\n          mountPath: /etc/kube-flannel/\n      volumes:\n      - name: run\n        hostPath:\n          path: /run/flannel\n      - name: cni-plugin\n        hostPath:\n          path: /opt/cni/bin\n      - name: cni\n        hostPath:\n          path: /etc/cni/net.d\n      - name: flannel-cfg\n        configMap:\n          name: kube-flannel-cfg  </code></pre>\n</details>\n\n\n\n\n\n### 异常\n\n#### CrashLoopBackOff\n\ncoredns跟fannel\n\n![xx](/pics/coredns-flannel-q.png)\n\n##### 网段问题\n\nError registering network: failed to acquire lease: node \"k8s01\" pod cidr not assigned\n\n![assigned](/pics/allocate-node-cidrs.png)\n\n\n\n[kubeadm join command](https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/)\n\n   --pod-network-cidr 的网段要跟fannel配置里Network的网段一致\n\n\n\nflannel.yaml\n\n```\n[root@k8s01 ~]# cat /opt/flannel.yaml | grep -i Network\n  - \"networking.k8s.io\"\n      \"Network\": \"10.244.0.0/16\",\n      hostNetwork: true\n```\n\n\n\n[kube-controller-manager command](https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager)\n\n\n\n```\n# cat /etc/kubernetes/manifests/kube-controller-manager.yaml  | grep -A 16 command\n  - command:\n    - kube-controller-manager\n    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf\n    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf\n    - --bind-address=127.0.0.1\n    - --client-ca-file=/etc/kubernetes/pki/ca.crt\n    - --cluster-name=kubernetes\n    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt\n    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key\n    - --controllers=*,bootstrapsigner,tokencleaner\n    - --kubeconfig=/etc/kubernetes/controller-manager.conf\n    - --leader-elect=true\n    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt\n    - --root-ca-file=/etc/kubernetes/pki/ca.crt\n    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key\n    - --use-service-account-credentials=true\n    image: k8s.org/k8s/kube-controller-manager:v1.26.1\n```\n\n>--allocate-node-cidrs=true  基于云驱动来为 Pod 分配和设置子网掩码\n>\n>--cluster-cidr=10.244.0.0/16  集群中 Pod 的 CIDR 范围\n\n\n\n### coredns\n\n![1](/pics/flannel-1.png)\n\n\n\n![2](/pics/flannel-2.png)\n\n\n\n![3](/home/cs/oss/hexo/themes/spfk/source/pics/flannel-3.png)\n","tags":["flanneld"],"categories":["linux","k8s"]},{"title":"kubernetes部署结构","url":"//linux/k8s/k8s/","content":"\n## go env\n\n编译二进制\n\nYou have a working [Go environment](https://golang.org/doc/install).\n\n```shell\nGOPATH=`go env | grep GOPATH | cut -d '\"' -f 2 `\nmkdir -p $GOPATH/src/k8s.io\ncd $GOPATH/src/k8s.io\ngit clone https://github.com/kubernetes/kubernetes\ncd kubernetes\ngit checkout v1.21.12\nmake\n```\n\n\n\n## 前置条件配置\n\n- 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令\n- 每台机器 `2 GB` 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存）\n- `2 CPU` 核或更多\n- 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)\n- 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见[这里](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#verify-mac-address)了解更多详细信息。\n- 开启机器上的某些端口。请参见[这里](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports) 了解更多详细信息。\n- 禁用交换分区。为了保证 kubelet 正常工作，你 **必须** 禁用交换分区\n\n更多见 https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n\n\n\n## 2种 HA 集群方式\n\n文档 https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/ha-topology/\n\n### 堆叠（Stacked）etcd \n\n这种拓扑将控制平面和 etcd 成员耦合在同一节点上,设置简单.存在耦合失败的风险\n\n![](/pics/etcd-stacked.png)\n\n\n\n<!--more-->\n\n### 外部 etcd 节点\n\n这种拓扑结构解耦了控制平面和 etcd 成员.需要两倍于堆叠 HA 拓扑的主机数量\n\n![](/pics/etcd-external.png)\n","tags":["kubernetes"],"categories":["linux","k8s"]},{"title":"iptable防火墙","url":"//linux/shell/iptable/","content":"\n\n\n\n\n\n\n\n\n### 数据流向\n\n![](/pics/iptable-01.png)\n\n\n\n-  当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 \n- 如果数据包就是**`进入本机`**的，它就会到达INPUT链。数据包到了**`INPUT链`**后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。 \n- 如果数据包是要**`转发出去`**的，且内核允许转发，数据包就会如图所示向右移动，经过**`FORWARD链`**，然后到达POSTROUTING链输出。\n  \n\n![](/pics/iptable-01-1.png)\n\n\n\n```shell\n#临时生效\necho 1 > /proc/sys/net/ipv4/ip_forward\n#永久生效\ncs@debian:~/oss/hexo$ cat /etc/sysctl.conf | grep net.ipv4.ip_\nnet.ipv4.ip_forward=1\n```\n\n<!--more-->\n\n![](/pics/iptable-01-2.png)\n\n\n\n\n\n### 命令规则\n\n![](/pics/iptable-02.png)\n\n- 所有表名必须小写\n\n  filter/nat/mangle\n\n- 所有链名必须大写\n   INPUT/OUTPUT/FORWARD/PREROUTING/POSTROUTING\n\n| 名称        | 功能                                                         | 作用的表                                                     |\n| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| PREROUTING  | 主机外报文进入位置                                           | mangle, nat（目标地址转换，，通常指响应报文）                |\n| INPUT       | 报文进入本机用户空间位置                                     | filter, mangle                                               |\n| OUTPUT      | 报文从本机用户空间出去的位置                                 | filter, mangle, nat                                          |\n| FOWARD      | 报文经过路由并且发觉不是本机决定转发但还不知道从哪个网卡出去 | filter, mangle（中转）                                       |\n| POSTROUTING | 报文经过路由被转发出去                                       | 许mangle，nat（源地址转换，把原始地址转换为转发主机出口网卡地址） |\n\n \n\n- 所有匹配必须小写\n   -s/-d/-m <module_name>/-p\n\n- 所有动作必须大写\n   ACCEPT/DROP/SNAT/DNAT/MASQUERADE\n\n\n\n","tags":["iptable"],"categories":["linux","shell"]},{"title":"grep常用过滤","url":"//linux/shell/grep/","content":"\n\n\n### 前后行 A B C\n\ngrep -A 显示匹配指定内容及之后的n行\n\ngrep -B 显示匹配指定内容及之前的n行\n\ngrep -C  显示匹配指定内容及其前后各n行\n\n```shell\ncs@debian:~/oss/hexo$ cat /opt/nginx/logs/k8s-access.log | grep -C 5 \"2022:15:43:27\"\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:22 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:23 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:24 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:25 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:26 +0800] 502 0\n127.0.0.1 - 192.168.56.103:6443, 192.168.56.101:6443, 192.168.56.102:6443 - [31/Jul/2022:15:43:27 +0800] 502 0, 0, 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:28 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:29 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:30 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:30 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:31 +0800] 502 0\n```\n\n\n\n### 与操作  \n\n多次匹配\n\n```shell\ncs@debian:~/oss/hexo$ cat /opt/nginx/logs/k8s-access.log | grep \"2022:15:43:2\" | grep 502\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:20 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:21 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:21 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:22 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:23 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:24 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:25 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:26 +0800] 502 0\n127.0.0.1 - 192.168.56.103:6443, 192.168.56.101:6443, 192.168.56.102:6443 - [31/Jul/2022:15:43:27 +0800] 502 0, 0, 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:28 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:29 +0800] 502 0\n```\n\n\n\n### 或操作 |\n\n<!--more-->\n\n```shell\ncs@debian:~/oss/hexo$ cat /opt/nginx/logs/k8s-access.log | grep \"502\\|15:43:3\\|kube-apiserver\"\n\n```\n\n>grep  -E  \"502|15:43:3|kube-apiserver\"\n>\n>egrep   \"502|15:43:3|kube-apiserver\"\n>\n>awk  \"502|15:43:3|kube-apiserver\"   file\n\n\n\n\n\n### 特殊字符 fgrep\n\n搜索文件包含正则表达式元字符串时,例如`$`、`^`、`/`等，`fgrep`很有用\n\n```shell\ncs@debian:~/oss/hexo$ egrep \"^Hello\"  12\ncs@debian:~/oss/hexo$ grep \"^Hello\"  12\ncs@debian:~/oss/hexo$ fgrep \"^Hello\"  12\n^Hello\\\n```\n\n它`不解析正则表达式`、想搜什么就跟什么\n\n\n\n### 压缩文件  zgrep\n\n```shell\nzgrep  pattern1  ./*   |  grep  pattern2\n```\n\n>zegrep  \n>\n>\n>zcat file1.gz file2.gz\n","tags":["grep"],"categories":["linux","shell"]},{"title":"tree工具","url":"//linux/shell/tree/","content":"\n\n\n\n\n### 目录层级 -Ld\n\n-d 目录\n\n-L  level 层级\n\n\n\n```\ncs@debian:/$ tree -Ld  1\n.\n├── bin\n├── boot\n├── dev\n├── etc\n├── home\n├── lib\n├── lib64\n├── lost+found\n├── media\n├── mnt\n├── opt\n├── proc\n├── root\n├── run\n├── sbin\n├── snap\n├── srv\n├── sys\n├── tmp\n├── usr\n└── var\n```\n\n\n\n### 路径前缀 -f\n\n-f   打印路径的前缀(根据命令指定显示)\n\n```\ncs@debian:/opt/apache$ tree -Ldf  1 ./\n.\n├── ./apache-maven-3.8.6\n├── ./kafka-2.1.1\n├── ./maven-3.6.0\n├── ./tomcat-8.5.38\n└── ./zookeeper-3.4.13\n\n5 directories\ncs@debian:/opt/apache$ tree -Ldf  1 /opt/apache/\n/opt/apache\n├── /opt/apache/apache-maven-3.8.6\n├── /opt/apache/kafka-2.1.1\n├── /opt/apache/maven-3.6.0\n├── /opt/apache/tomcat-8.5.38\n└── /opt/apache/zookeeper-3.4.13\n\n5 directories\n```\n\n\n\n<!--more-->\n\n\n\n### 过滤 -I\n\n\n\n```\ncs@debian:~/oss/0s$ tree -L 3  -I \"src|target\" ./spring-boot/cs-framework/  ./spring-boot/cs-framework/\n├── cs-msc\n│   ├── lib\n│   │   ├── json-jena-1.0.jar\n│   │   └── Msc.jar\n│   ├── msc\n│   │   ├── libmsc32.so\n│   │   ├── libmsc64.so\n│   │   ├── msc32.dll\n│   │   └── msc64.dll\n│   ├── pom.xml\n│   └── READER.md\n├── cs-ocr\n│   ├── libs\n│   │   └── ocr_sdk-1.3.6.jar\n│   └── pom.xml\n└── pom.xml\n\n5 directories, 11 files\n```\n\n\n\n```\ncs@debian:~/oss/0s$ tree -L 3  -I *.jar* ./spring-boot/cs-framework/  \n./spring-boot/cs-framework/\n├── cs-msc\n│   ├── lib\n│   ├── msc\n│   │   ├── libmsc32.so\n│   │   ├── libmsc64.so\n│   │   ├── msc32.dll\n│   │   └── msc64.dll\n│   ├── pom.xml\n│   ├── READER.md\n│   ├── src\n│   │   └── main\n│   └── target\n│       ├── classes\n│       ├── generated-sources\n│       ├── maven-archiver\n│       └── maven-status\n├── cs-ocr\n│   ├── libs\n│   ├── pom.xml\n│   ├── src\n│   │   └── main\n│   └── target\n│       ├── classes\n│       ├── generated-sources\n│       ├── maven-archiver\n│       └── maven-status\n└── pom.xml\n\n19 directories, 8 files\n```\n\n\n\n\n\n### 匹配 -P\n\n```\ncs@debian:~/oss/0s$ tree -L 3 -P *xml -I \"src|target\" ./spring-boot/cs-framework/  \n./spring-boot/cs-framework/\n├── cs-msc\n│   ├── lib\n│   ├── msc\n│   └── pom.xml\n├── cs-ocr\n│   ├── libs\n│   └── pom.xml\n└── pom.xml\n\n5 directories, 3 files\n```\n\n\n\n### 大小时间 -ts\n\n-t 时间排序(默认从旧到新,r反序)\n\n-s 大小\n\n```\ncs@debian:/opt/apache$ tree -Ldrts  1 /opt/apache/\n/opt/apache/\n├── [       4096]  apache-maven-3.8.6\n├── [       4096]  tomcat-8.5.38\n├── [       4096]  maven-3.6.0\n├── [       4096]  kafka-2.1.1\n└── [       4096]  zookeeper-3.4.13\n\n5 directories\n```\n\n\n\n### 权限角色 -pus\n\n-p 权限\n\n-u  角色\n\n-g 组\n\n```\ncs@debian:/opt/apache$ tree -Ldpu  1 /opt/apache/\n/opt/apache/\n├── [drwxr-xr-x cs      ]  apache-maven-3.8.6\n├── [drwxr-xr-x cs      ]  kafka-2.1.1\n├── [drwxr-xr-x cs      ]  maven-3.6.0\n├── [drwxr-xr-x cs      ]  tomcat-8.5.38\n└── [drwxr-xr-x cs      ]  zookeeper-3.4.13\n\n5 directories\n\n```\n\n\n\n\n\n\n\n### 着色 -C\n\n-n 关闭\n\n-C 打开\n\n```shell\ncs@debian:/opt/apache$ tree -LdC  1 /opt/apache/\n/opt/apache/\n├── [       4096]  apache-maven-3.8.6\n├── [       4096]  tomcat-8.5.38\n├── [       4096]  maven-3.6.0\n├── [       4096]  kafka-2.1.1\n└── [       4096]  zookeeper-3.4.13\n\n5 directories\n\n```\n\n\n\n\n\n### 格式  -j\n\n -i 不打印虚线\n\n-X xml格式 \n\n-J   json格式\n\n```\ncs@debian:/opt/apache$ tree -Ldrtsi  1 /opt/apache/\n/opt/apache/\n[       4096]  apache-maven-3.8.6\n[       4096]  tomcat-8.5.38\n[       4096]  maven-3.6.0\n[       4096]  kafka-2.1.1\n[       4096]  zookeeper-3.4.13\n\n5 directories\ncs@debian:/opt/apache$ tree -LdrtsX  1 /opt/apache/\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<tree>\n  <directory name=\"/opt/apache/\">\n    <directory name=\"apache-maven-3.8.6\" size=\"4096\">\n    </directory>\n    <directory name=\"tomcat-8.5.38\" size=\"4096\">\n    </directory>\n    <directory name=\"maven-3.6.0\" size=\"4096\">\n    </directory>\n    <directory name=\"kafka-2.1.1\" size=\"4096\">\n    </directory>\n    <directory name=\"zookeeper-3.4.13\" size=\"4096\">\n    </directory>\n  </directory>\n  <report>\n    <directories>5</directories>\n  </report>\n</tree>\ncs@debian:/opt/apache$ tree -LdrtsJ  1 /opt/apache/\n[\n  {\"type\":\"directory\",\"name\":\"/opt/apache/\",\"contents\":[\n    {\"type\":\"directory\",\"name\":\"apache-maven-3.8.6\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"tomcat-8.5.38\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"maven-3.6.0\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"kafka-2.1.1\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"zookeeper-3.4.13\",\"size\":4096,\"contents\":[\n    ]}\n  ]},\n  {\"type\":\"report\",\"directories\":5}\n]\n```\n\n\n\n","tags":["tree"],"categories":["linux","shell"]},{"title":"maven介绍","url":"//tool/maven/","content":"\n\n\n\n\n\n\n## 安装\n\n### 环境变量\n\n```\ncs@debian:~/oss/hexo$ wget https://dlcdn.apache.org/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz -O apache-maven-3.8.6-bin.tar.gz\ncs@debian:~/oss/hexo$ tar -zxvf apache-maven-3.8.6-bin.tar.gz -C /opt/apache\ncs@debian:~/oss/hexo$ cat >>  ~/.bashrc <<EOF\n#maven\nif [ -d \"/opt/apache/maven-3.8.6\" ] ; then\n    export MAVEN_HOME=/opt/apache/maven-3.8.6\n    export PATH=${MAVEN_HOME}/bin:\\$PATH\nfi\nEOF\n```\n\n### 版本\n\n```\ncs@debian:~/oss/hexo$ mvn -version\n```\n\n> Apache Maven 3.8.6 (84538c9988a25aec085021c365c560670ad80f63)\n> Maven home: /opt/apache/apache-maven-3.8.6\n> Java version: 11.0.12, vendor: Oracle Corporation, runtime: /opt/jdk/jdk-11.0.12\n> Default locale: zh_CN, platform encoding: UTF-8\n> OS name: \"linux\", version: \"4.9.0-8-amd64\", arch: \"amd64\", family: \"unix\"\n\n\n\n##  基本命令\n\n### 编译\n\n```\nmvn compile　\n```\n\n  --src/main/java目录java源码编译生成class （target目录下）\n\n　　　　　　　　　　\n\n### 测试\n\n```\nmvn test　\n```\n\n   --src/test/java 目录编译\n\n　　　　　　　　　　\n\n### 清理\n\n```\nmvn clean\n```\n\n  --删除target目录，也就是将class文件等删除\n\n　　　　　　　　　　\n\n### 打包\n\n```\nmvn package　\n```\n\n --生成压缩文件：java项目#jar包；web项目#war包，也是放在target目录下\n\n　　　　　　　　　　\n\n### 安装\n\n```\nmvn install　　\n```\n\n--将压缩文件(jar或者war)上传到本地仓库\n\n　　　　　　　　　　\n\n### 部署|发布\n\n```\nmvn deploy　　\n```\n\n--将压缩文件上传私服\n\n\n\n### [多模块](#idmore)\n\n\n\n\n\n场景:几百个微服务只打部分包\n\n\n\n<!--more-->\n\n\n\n### 周期\n\n| **验证（validate）**                        | 验证项目是正确的，所有必要的信息可用。                       |\n| ------------------------------------------- | ------------------------------------------------------------ |\n| **初始化（initialize）**                    | 初始化构建状态，例如设置属性或创建目录。                     |\n| **产生来源（generate-sources）**            | 生成包含在编译中的任何源代码。                               |\n| **流程源（process-sources）**               | 处理源代码，例如过滤任何值。                                 |\n| **生成资源（generate-resources）**          | 生成包含在包中的资源。                                       |\n| **流程资源（process-resources）**           | 将资源复制并处理到目标目录中，准备打包。                     |\n| **编译（compile）**                         | 编译项目的源代码。                                           |\n| **工艺类（process-classes）**               | 从编译后处理生成的文件，例如对Java类进行字节码增强。         |\n| **生成测试来源（generate-test-sources）**   | 生成包含在编译中的任何测试源代码。                           |\n| **流程测试来源（process-test-sources）**    | 处理测试源代码，例如过滤任何值。                             |\n| **生成测试资源（generate-test-resources）** | 创建测试资源。                                               |\n| **流程测试资源（process-test-resources）**  | 将资源复制并处理到测试目标目录中。                           |\n| **测试编译（test-compile）**                | 将测试源代码编译到测试目标目录中                             |\n| **流程检验类（process-test-classes）**      | 从测试编译中处理生成的文件，例如对Java类进行字节码增强。对于Maven 2.0.5及以上版本。 |\n| **测试（test）**                            | 使用合适的单元测试框架运行测试。这些测试不应该要求代码被打包或部署。 |\n| **制备包（prepare-package）**               | 在实际包装之前，执行必要的准备包装的操作。这通常会导致打包的处理版本的包。（Maven 2.1及以上） |\n| **打包（package）**                         | 采取编译的代码，并以其可分发的格式（如JAR）进行打包。        |\n| **预集成测试（pre-integration-test）**      | 在执行集成测试之前执行所需的操作。这可能涉及诸如设置所需环境等。 |\n| **集成测试（integration-test）**            | 如果需要，可以将该包过程并部署到可以运行集成测试的环境中。   |\n| **整合后的测试（post-integration-test）**   | 执行集成测试后执行所需的操作。这可能包括清理环境。           |\n| **校验（verify）**                          | 运行任何检查以验证包装是否有效并符合质量标准。               |\n| **安装（install）**                         | 将软件包安装到本地存储库中，以作为本地其他项目的依赖关系。   |\n| **部署（deploy）**                          | 在集成或发布环境中完成，将最终软件包复制到远程存储库，以与其他开发人员和项目共享。 |\n\n\n\n## 高级命令\n\n<p id=\"idmore\" hidden/>\n\n在多模块 Maven项目中，反应堆（Reactor）是一个包含了所有需要构建模块的抽象概念，对于Maven用户来说，主要关心的是两点：\n\n1. 哪些模块会被包含到反应堆中？\n2. 反应堆中所有模块的构建顺序是什么？\n\n\n\n```\n$ tree -L 3 -P *xml -I \"src|target\" ./spring-boot/\n./spring-boot/\n├── cs-framework\n│   ├── cs-msc\n│   │   ├── lib\n│   │   ├── msc\n│   │   └── pom.xml\n│   ├── cs-ocr\n│   │   ├── libs\n│   │   └── pom.xml\n│   ├── cs-shiro\n│   │   └── pom.xml\n│   └── pom.xml\n├── cs-tool\n│   ├── cs-common\n│   │   └── pom.xml\n│   ├── cs-email\n│   │   └── pom.xml\n│   ├── cs-jpa\n│   │   └── pom.xml\n│   ├── cs-rw-aop\n│   │   └── pom.xml\n│   ├── cs-rw-druid\n│   │   └── pom.xml\n│   └── pom.xml\n└── pom.xml\n```\n\n\n\n一级\n\n```xml\n<groupId>com.cs</groupId>\n  <artifactId>cs-parent</artifactId>\n   <version>${version}</version>\n\n  <modules>\n    <module>cs-framework</module>\n    <module>cs-tool</module>\n  </modules>\n  <packaging>pom</packaging>\n  \n  <name>cs-parent</name>\n```\n\n\n\n\n\n二级\n\n```xml\n <parent>\n    <groupId>com.cs</groupId>\n    <artifactId>cs-parent</artifactId>\n    <version>${version}</version>\n  </parent>\n\n <groupId>com.cs</groupId>\n  <artifactId>cs-framework</artifactId>\n   <version>${version}</version>\n  <name>cs-framework</name>\n  <packaging>pom</packaging>\n  \n   <modules>\n     <module>cs-shiro</module>\n    <module>cs-ocr</module>\n    <module>cs-msc</module>\n  </modules>\n```\n\n\n\n子\n\n```xml\n  <parent>\n    <groupId>com.cs</groupId>\n    <artifactId>cs-framework</artifactId>\n    <version>${version}</version>\n  </parent>\n  <groupId>com.cs</groupId>\n  <artifactId>cs-ocr</artifactId>\n  <version>${version}</version>\n  <name>cs-ocr</name>\n```\n\n\n\n```\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary for cs-parent 0.0.1-SNAPSHOT:\n[INFO] \n[INFO] cs-parent .......................................... SUCCESS [  0.163 s]\n[INFO] cs-tool ............................................ SUCCESS [  0.005 s]\n[INFO] cs-common .......................................... SUCCESS [  0.800 s]\n[INFO] cs-framework ....................................... SUCCESS [  0.006 s]\n[INFO] cs-ocr ............................................. SUCCESS [  3.194 s]\n[INFO] cs-msc ............................................. SUCCESS [  0.271 s]\n[INFO] cs-jpa ............................................. SUCCESS [  0.471 s]\n[INFO] cs-rw-aop .......................................... SUCCESS [  1.074 s]\n[INFO] cs-rw-druid ........................................ SUCCESS [  0.893 s]\n[INFO] cs-email ........................................... SUCCESS [  2.520 s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  9.736 s\n[INFO] Finished at: 2022-07-30T21:51:32+08:00\n[INFO] ------------------------------------------------------------------------\n```\n\n\n\n\n\n### 指定 -pl\n\n手动选择项目，多个逗号隔开\n\n```\nmvn install -pl web/style,web/login\n```\n\n>-pl,--projects <arg>                   \n>Build specified reactor projects instead of all projects. \n>A project can be specified by [groupId]:artifactId or by its relative path.\n\n\n\n### 所需依赖 -am\n\n构建某个子模块\n\n```\nmvn install -pl web/style  -am\n```\n\n>项目被指定，构建该项目所需依赖\n>\n> -am,--also-make                      \n>  If project list is specified, also  build projects required by the  list\n\n构建 parent ，framework, web, redis ,style\n\n\n\n### 依赖该模块 -amd \n\n构建父模块，公用模块\n\n```\nmvn install -pl web/redis  -amd\n```\n\n> 项目被指定，构建依赖该模块的模块 \n>\n> -amd,--also-make-dependents          \n>    If project list is specified, also  build projects that depend on projects on the list\n\n构建 redis, login, style\n\n\n\n### 裁剪 -rf\n\n在前命令裁剪基础上，从rf指定模块开始构建\n\n```\nmvn install -pl web/style  -am -rf  web/redis\n```\n\n>从原有构建过程中裁剪反应堆，去掉指定模块原有构建顺序的前面部分\n>\n>-rf,--resume-from <arg>              \n>Resume reactor from specified  project\n\n构建 redis style\n\n\n\n\n\n\n\n## 错误\n\n### find main class\n\n repackage failed: Unable to find main class\n\n```\n <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <phase>none</phase>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n   </build>\n```\n\n","tags":["maven","mvn"],"categories":["tool"]},{"title":"k8s集群","url":"//linux/k8s/k8s01/","content":"\n\n\n\n\n\n\n### 常用命令\n\n缩写\n\n```\ncertificatesigningrequests (缩写 csr)\ncomponentstatuses (缩写 cs)\nconfigmaps (缩写 cm)\ncustomresourcedefinition (缩写 crd)\ndaemonsets (缩写 ds)\ndeployments (缩写 deploy)\nendpoints (缩写 ep)\nevents (缩写 ev)\nhorizontalpodautoscalers (缩写 hpa)\ningresses (缩写 ing)\nlimitranges (缩写 limits)\nnamespaces (缩写 ns)\nnetworkpolicies (缩写 netpol)\nnodes (缩写 no)\npersistentvolumeclaims (缩写 pvc)\npersistentvolumes (缩写 pv)\npoddisruptionbudgets (缩写 pdb)\npods (缩写 po)\npodsecuritypolicies (缩写 psp)\nreplicasets (缩写 rs)\nreplicationcontrollers (缩写 rc)\nresourcequotas (缩写 quota)\nserviceaccounts (缩写 sa)\nservices (缩写 svc)\nstatefulsets (缩写 sts)\nstorageclasses (缩写 sc)\n```\n\n\n\n#### 自动补全\n\n```\nsudo apt install bash-completion\n\nsource /usr/share/bash-completion/bash_completion\nsource <(kubectl completion bash)\n\necho \"source <(kubectl completion bash)\" >> ~/.bashrc\n```\n\n> /usr/bin/zsh   /usr/bin/bash\n\n\n\n#### cs(master节点)\n\ncomponentstatuses\n\n```\ncs@debian:~$ kubectl get cs\nNAME                 STATUS    MESSAGE              ERROR\nscheduler            Healthy   ok                   \ncontroller-manager   Healthy   ok                   \netcd-2               Healthy   {\"health\": \"true\"}   \netcd-0               Healthy   {\"health\": \"true\"}   \netcd-1               Healthy   {\"health\": \"true\"}  \n```\n\n\n\n#### node节点\n\n```\ncs@debian:~$ kubectl  get node\nNAME       STATUS   ROLES    AGE    VERSION\nmaster02   Ready    <none>   101d   v1.18.8\nmaster03   Ready    <none>   101d   v1.18.8\nnode04     Ready    <none>   101d   v1.18.8\nnode05     Ready    <none>   101d   v1.18.8\nnode06     Ready    <none>   101d   v1.18.8\n\nkubectl get node -o wide\n```\n\n<!--more-->\n\n空间\n\n```\ncs@debian:~$ kubectl get namespaces \nNAME                   STATUS   AGE\ndefault                Active   101d\ndevops                 Active   100d\nkube-node-lease        Active   101d\nkube-public            Active   101d\nkube-system            Active   101d\nkubernetes-dashboard   Active   92d\n```\n\n\n\n#### pod\n\n```\ncs@debian:~$ kubectl get pod\nNo resources found in default namespace.\n\ncs@debian:~$ kubectl get pod -n kube-system \nNAME                                         READY   STATUS    RESTARTS   AGE\ncoredns-56ff7bc666-prc6l                     1/1     Running   4          11d\ncoredns-56ff7bc666-qwdsh                     1/1     Running   8          92d\ntraefik-ingress-controller-7769cb875-x76rs   1/1     Running   1          46h\n```\n\n>-n  接namespaces的NAME值,省略为default\n\n\n\n```\nkubectl get pods -o wide\nkubectl get pods -A -o wide\n```\n\n\n\n\n\n#### describe\n\n ingress **Tab提示**\n\n```\ncs@debian:~$ kubectl get ingress -n devops \ningressclasses.networking.k8s.io      ingresses.networking.k8s.io           ingressroutetcps.traefik.containo.us  \ningresses.extensions                  ingressroutes.traefik.containo.us     ingressrouteudps.traefik.containo.us  \n\ncs@debian:~$ kubectl get ingressroutetcps.traefik.containo.us -n devops \nNAME    AGE\nredis   47h\n\ncs@debian:~$ kubectl describe ingressroutetcps.traefik.containo.us redis -n devops \nName:         redis\nNamespace:    devops\nLabels:       <none>\nAnnotations:  API Version:  traefik.containo.us/v1alpha1\nKind:         IngressRouteTCP\nMetadata:\n  Creation Timestamp:  2022-07-19T13:01:37Z\n  Generation:          1\n  Managed Fields:\n    API Version:  traefik.containo.us/v1alpha1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:annotations:\n          .:\n          f:kubectl.kubernetes.io/last-applied-configuration:\n      f:spec:\n        .:\n        f:entryPoints:\n        f:routes:\n    Manager:         kubectl\n    Operation:       Update\n    Time:            2022-07-19T13:01:37Z\n  Resource Version:  261095\n  Self Link:         /apis/traefik.containo.us/v1alpha1/namespaces/devops/ingressroutetcps/redis\n  UID:               c79681ee-1bf1-4843-9666-457970d78f27\nSpec:\n  Entry Points:\n    redis\n  Routes:\n    Match:  HostSNI(`*`)\n    Services:\n      Name:  redis-service\n      Port:  6379\nEvents:      <none>\n```\n\n\n\n\n\n#### log\n\n\n\n```\ncs@debian:~$ kubectl logs  --tail=5 redis-app-1 -n devops\n63:M 21 Jul 2022 12:15:34.720 * Synchronization with replica 121.21.25.3:6379 succeeded\n63:M 21 Jul 2022 12:15:36.469 # Cluster state changed: ok\n63:M 21 Jul 2022 12:15:40.604 * FAIL message received from 67f931358b8004268db0b57932293602ab3de629 about b49a123e2764b665ee898c21f983b9cda70cda00\n63:M 21 Jul 2022 12:15:42.635 * Marking node a0e2f50ba382870da1ce4d23b66a1375826d6dc8 as failing (quorum reached).\n63:M 21 Jul 2022 12:15:42.635 # Cluster state changed: fail\n\ncs@debian:~$ kubectl logs  -f  --tail=5 redis-app-1 -n devops\n63:M 21 Jul 2022 12:15:34.720 * Synchronization with replica 121.21.25.3:6379 succeeded\n63:M 21 Jul 2022 12:15:36.469 # Cluster state changed: ok\n63:M 21 Jul 2022 12:15:40.604 * FAIL message received from 67f931358b8004268db0b57932293602ab3de629 about b49a123e2764b665ee898c21f983b9cda70cda00\n63:M 21 Jul 2022 12:15:42.635 * Marking node a0e2f50ba382870da1ce4d23b66a1375826d6dc8 as failing (quorum reached).\n63:M 21 Jul 2022 12:15:42.635 # Cluster state changed: fail\n^C\n```\n\n>-f   类似 **tail -f** \n>\n>-p,  --previous[=false]: 如果为true，输出pod中曾经运行过，但目前已终止的容器的日志\n>       --since=0: 仅返回相对时间范围，如5s、2m或3h，之内的日志。默认返回所有日志。只能同时使用since 和since-time中的一种\n>      --since-time=\"\": 仅返回指定时间（RFC3339格式）之后的日志。默认返回所有日志。只能同时使用since和since-time中的一种\n>      --tail=-1: 要显示的最新的日志条数。默认为-1，显示所有的日志\n\n\n\n#### patch\n\n更新容器的镜像\n\n```\nkubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n或\nkubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n```\n\n设置服务对外的IP\n\n```\nkubectl patch svc <svc-name> -n <namespace> -p '{\"spec\": {\"type\": \"LoadBalancer\", \"externalIPs\":[\"192.168.31.241\"]}}'\n```\n\n\n\n#### scale\n\n对副本数进行扩展或缩小\n\n\n\n前提条件校验 ；当前副本数量或 `--resource-version`\n\n\n\n缩减副本数到2\n\n```\nkubectl scale rc rc-nginx-3 —replicas=2\n```\n\n\n\n当前副本数为2，则将其扩展至3\n\n```\nkubectl scale --current-replicas=2 --replicas=3 deployment/mysql\n```\n\n\n\n\n\n#### 重启\n\n```\nkubectl rollout restart deployment <deployment_name> -n <namespace>\n```\n\n\n\n#### 选择器\n\n--field-selector\n\n`status.podIP`\n\n```\ncs@debian:~/oss/hexo$  kubectl  get pod --field-selector status.podIP=121.21.35.3 -o wide -n devops\nNAME          READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES\nredis-app-1   1/1     Running   1          9d    121.21.35.3   node04   <none>           <none>\n```\n\n>1. metadata.name=my-service\n>2. metadata.namespace!=default\n>3. status.phase=Pending\n>\n>\n\n选择了所有**`status.phase`**不为**`Running`**且`spec.restartPolicy`为**`Always`**的Pod.\n\n```\nkubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always\n```\n\n\n\n#### events\n\n显示集群内的详细事件，如果最近出现故障，你可以查看集群事件以了解故障前后发生的情况。如果你知道只有特定名称空间中存在问题，你可以将事件过滤到该名称空间。\n\n```\n$ kubectl get events \nLAST SEEN   TYPE     REASON                    OBJECT     MESSAGE\n2d18h       Normal   Starting                  node/k8s   Starting kubelet.\n2d18h       Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory\n2d18h       Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure\n2d18h       Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID\n2d18h       Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods\n2d18h       Normal   Starting                  node/k8s   Starting kubelet.\n2d18h       Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory\n2d18h       Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure\n2d18h       Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID\n2d18h       Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods\n2d18h       Normal   NodeReady                 node/k8s   Node k8s status is now: NodeReady\n2d18h       Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller\n2d18h       Normal   Starting                  node/k8s   Starting kube-proxy.\n2d18h       Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller\n23m         Normal   Starting                  node/k8s   Starting kubelet.\n23m         Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory\n23m         Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure\n23m         Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID\n23m         Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods\n23m         Normal   Starting                  node/k8s   Starting kube-proxy.\n22m         Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller\n```\n\n\n\n#### api-resources\n\n```\nkubectl api-resources -o wide --sort-by name\n```\n\n\n\n#### 调试 [故障排除](https://kubernetes.io/zh-cn/docs/tasks/debug/debug-application/)\n\n启动参数`--feature-gates=EphemeralContainers=true`配置到kube-api和kubelet服务上重启\n\n```\n# 查看pod所在宿主及pod name\n$ kubectl get po -o wide\n# 根据pod name查看对应的docker 容器\n$ docker ps | grep centos-687ff6c787-47gvh\n# 根据输出的容器id，挂载容器网络并运行一个debug容器，使用 nicolaka/netshoot 这个镜像。这个镜像里集成了很多网络调试工具。\n$ docker run -it --rm --name=debug --network=container:bb009aab414f nicolaka/netshoot bash\n接下来就进入了与这个pod的相同的网络namespace，可以进行网络相关的调试了\n```\n\n\n\n```\nfor pod in $(kubectl get -o name pod  -n kube-system); \ndo\n    kubectl debug --image security/pod_scanner -p $pod /sanner.sh\ndone\n```\n\n> 批量跑某个命名空间下的安全扫描的脚本而不用干扰原容器\n\n\n\n\n\n##### 没有开启Ephemeral Containers\n\n```\nkubectl debug mypod -it \\\n--container=debug \\\n--image=busybox \\\n--copy-to=my-debugger \\\n--same-node=true \\\n--share-processes=true\n```\n\n>--copy-to   指定新pod的名称\n>--replace=true   是否删除原容器\n>--same-node=true  是否调度到和原容器一样的node上\n>--share-processes=true  是否共享容器pid空间\n\n\n\n##### 利用Ephemeral Containers\n\n```\nkubectl run ephemeral-demo --image=k8s.gcr.io/pause:3.1 --restart=Never\n```\n\n\n\n[kubectl debug](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#debug)\n\n```\n#kubectl v1.12.0 或更高的版本, 可以直接使用:\nkubectl debug -h\n```\n\n调试 Pod\n\n```\n❯ kubectl debug -it vault-1 -n vault --image=k8s.org/cs/netshoot  -- bash\nDefaulting debug container name to debugger-z9zr4.\nIf you don't see a command prompt, try pressing enter.\nvault-1:/root$\n\n```\n\nservice ping不通\n\n```\n$  cat /var/lib/kubelet/config.yaml  | grep -A 1 DNS\nclusterDNS:\n- 10.96.1.10\n\n$ zgrep \"cluster-cidr\\|cluster-ip\" /etc/kubernetes/manifests/*\n/etc/kubernetes/manifests/kube-apiserver.yaml:    - --service-cluster-ip-range=10.96.0.0/12\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --cluster-cidr=121.21.0.0/16\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --service-cluster-ip-range=10.96.0.0/16\n```\n\n> dial tcp: lookup vault-2.vault-internal on 121.21.0.0:53: read udp 121.21.64.55:53568->121.21.0.0:53 i/o timeout\n>\n> cat /etc/resolv.conf   dns（service clusterIP跟serviceSubnet）\n>\n> 发现vault-1 跟 vault-0.vault-internal ，vault-2.vault-internal都ping不通\n\n\n\npod ping不通\n\n```\nkube-flannel-cfg\n\n```\n\n\n\n>[ERROR] storage.raft: failed to make requestVote RPC: target=\"{Voter vault-0 vault-0.vault-internal:8201}\" error=\"dial tcp 121.21.80.174:8201: connect: connection refused\" term=679\n>\n> [ERROR] storage.raft: failed to make requestVote RPC: target=\"{Voter vault-2 vault-2.vault-internal:8201}\" error=\"dial tcp 121.21.48.151:8201: connect: connection refused\" term=679\n\n\n\n\n\n\n\n清理调试 Pod\n\n```\nCreating debugging pod node-debugger-mynode-pdx84 with container debugger on node ....\n\n❯kubectl delete pod node-debugger-mynode-pdx84\n```\n\n\n\n\n\n##### nsenter\n\n```\n sudo yum install -y util-linux\n```\n\n\n\n```\n$ docker inspect -f {{.State.Pid}} nginx\n#nsenter命令进入该容器的网络命令空间\n$ nsenter -n -t6700\n```\n\n","tags":["kubernetes","kubectl"],"categories":["linux","k8s"]},{"title":"traefik","url":"//linux/k8s/traefik/","content":"\n\n\n### **Installing Resource Definition and RBAC**\n\n\n\n```\n# Install Traefik Resource Definitions:\nkubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.10/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml\n\n# Install RBAC for Traefik:\nkubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.10/docs/content/reference/dynamic-configuration/kubernetes-crd-rbac.yml\n```\n\n>The `apiextensions.k8s.io/v1beta1` CustomResourceDefinition is deprecated in Kubernetes `v1.16+` and will be removed in `v1.22+`.\n>\n>For Kubernetes `v1.16+`, please use the Traefik `apiextensions.k8s.io/v1` CRDs instead.\n\n\n\n### Traefik & CRD & Let's Encrypt\n\ntraefik.sh\n\n<details>\n  <summary>traefik:v2.2.10</summary>\n  <pre><a>bash traefik.sh</a><code>\n#!/bin/bash\nDIR=\"$(cd \"$(dirname \"$0\")\" && pwd)\"\n</br>\nbase_file=$DIR/test\ncrd=1-crd.yaml\nrbac=2-rbac.yaml\nrole=3-role.yaml\nstatic=4-static_config.yaml\ndynamic=5-dynamic_toml.toml\ndeploy=6-deploy.yaml\nsvc=7-service.yaml\ningress=8-ingress.yaml\n</br>\n</br>\ny_crd(){\n\tcat >$1 <<EOF\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ingressroutes.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: IngressRoute\n    plural: ingressroutes\n    singular: ingressroute\n  scope: Namespaced\n</br>\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: middlewares.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: Middleware\n    plural: middlewares\n    singular: middleware\n  scope: Namespaced\n</br>\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ingressroutetcps.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: IngressRouteTCP\n    plural: ingressroutetcps\n    singular: ingressroutetcp\n  scope: Namespaced\n</br>\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ingressrouteudps.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: IngressRouteUDP\n    plural: ingressrouteudps\n    singular: ingressrouteudp\n  scope: Namespaced\n</br>\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: tlsoptions.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: TLSOption\n    plural: tlsoptions\n    singular: tlsoption\n  scope: Namespaced\n</br>\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: tlsstores.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: TLSStore\n    plural: tlsstores\n    singular: tlsstore\n  scope: Namespaced\n</br>\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: traefikservices.traefik.containo.us\n</br>\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: TraefikService\n    plural: traefikservices\n    singular: traefikservice\n  scope: Namespaced\nEOF\n}\n</br>\ny_rbac(){\n\tcat>$1 <<EOF\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n</br>\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - persistentvolumes\n    verbs:\n      - get\n      - list\n      - watch\n      - create  # persistentvolumes\n      - delete\n  - apiGroups:\n      - \"\"\n    resources:\n      - persistentvolumeclaims\n    verbs:\n      - get\n      - list\n      - watch\n      - update  # persistentvolumeclaims         \n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses/status\n    verbs:\n      - update\n  - apiGroups:\n      - traefik.containo.us\n    resources:\n      - middlewares\n      - ingressroutes\n      - traefikservices\n      - ingressroutetcps\n      - ingressrouteudps\n      - tlsoptions\n      - tlsstores\n    verbs:\n      - get\n      - list\n      - watch\nEOF\n}\n</br>\ny_role(){\n   cat >$1 <<EOF\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n  - kind: ServiceAccount\n    name: traefik-ingress-controller\n    namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  namespace: kube-system\n  name: traefik-ingress-controller\nEOF\n</br>\n}\n</br>\n#静态配置动态文件======================?\ny_static_config(){\n   cat >$1 <<EOF\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: traefik-config-yaml\n  namespace: kube-system\ndata:\n  traefik.yaml: |-\n    ping: \"\"\n    serversTransport:\n      insecureSkipVerify: true\n    api:\n      insecure: true\n      dashboard: true\n      debug: false\n    metrics:\n      prometheus: \"\"\n    entryPoints:\n      web:\n        address: \":80\"\n      websecure:\n        address: \":443\"\n      mysql:\n        address: \":3306\"\n      redis:    \n        address: \":6379\"\n      jenkins:\n        address: \":8081\"\n      gogo:\n        address: \":8082\"\n      prometheus:\n        address: \":8181\"\n    providers:\n      kubernetesCRD: \"\"\n      kubernetesIngress: \"\"\n      file:\n        directory: /etc/conf.d/\n        watch: true\n    log:\n      filePath: \"\"\n      level: error \n      format: json\n    accessLog:\n      filePath: \"\"\n      format: json\n      bufferingSize: 0\n      filters:\n        #statusCodes: [\"200\"]\n        retryAttempts: true\n        minDuration: 20\n      fields:\n        defaultMode: keep\n        names:\n          ClientUsername: drop  \n        headers:\n          defaultMode: keep\n          names:\n            User-Agent: redact\n            Authorization: drop\n            Content-Type: keep\nEOF\n}\n</br>\ngenkey(){\nopenssl req \\\n        -newkey rsa:2048 -nodes -keyout tls.key \\\n        -x509 -days 3650 -out tls.crt \\\n        -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=k8s.org\" \n#kubectl create secret generic traefik-cert --from-file=tls.crt --from-file=tls.key -n kube-system        \n}\n</br>\ny_dynamic_toml(){\n   cat >$1 <<EOF\ndefaultEntryPoints = [\"http\",\"https\"]\n[entryPoints]\n  [entryPoints.http]\n  address = \":80\"\n  [entryPoints.https]\n  address = \":443\"\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \"/ssl/tls.crt\"\n      KeyFile = \"/ssl/tls.key\"\ntls:\n  certificates:\n    - certFile: /path/to/domain.cert\n      keyFile: /path/to/domain.key\n      stores: #stores 列表将被忽略，并自动设置为 [\"default\"]\n        - default\n</br>\nEOF\n}\n</br>\ny_deploy(){\n   cat >$1 <<EOF\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    app: traefik\nspec:\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      name: traefik\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 1\n      #设置node筛选器，在特定label的节点上启动  kubectl label node 192.168.56.109 tklabel=ok\n      nodeSelector: \n         tklabel: \"ok\"\n      containers:\n        - image: k8s.org/k8s/traefik:v2.2.10\n          name: traefik\n          ports:\n            - name: web\n              containerPort: 80\n              hostPort: 80         ## 将容器端口绑定所在服务器的 80 端口\n            - name: websecure\n              containerPort: 443\n              hostPort: 443        ## 将容器端口绑定所在服务器的 443 端口\n            # - name: redis\n            #   containerPort: 6379\n            #  hostPort: 6379\n            - name: admin\n              containerPort: 8080  ## Traefik Dashboard 端口\n          resources:\n            limits:\n              cpu: 200m\n              memory: 256Mi\n            requests:\n              cpu: 100m\n              memory: 256Mi\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n              add:\n                - NET_BIND_SERVICE\n          args:\n            - --configfile=/config/traefik.yaml\n          volumeMounts:\n            - mountPath: \"/config\"\n              name: \"config\"\n            - mountPath: \"/ssl\"\n              name: \"ssl\"\n      volumes:\n        - name: config\n          configMap:\n            name: traefik-config-yaml\n        - name: ssl\n          secret:\n            secretName: traefik-cert\nEOF\n}\n</br>\ny_service(){\n   cat >$1 <<EOF\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik\n  namespace: kube-system\nspec:\n  ports:\n    - name: web\n      port: 80\n    - name: websecure\n      port: 443\n    - name: admin   #没有会显示 404 page not found\n      port: 8080\n  selector:\n    app: traefik\n</br>\nEOF\n}\n</br>\ny_ingress(){\n   cat >$1 <<\"EOF\"\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-dashboard-route\n  namespace: kube-system\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`master02`) #pod节点 192.168.56.109\n      kind: Rule\n      services:\n        - name: traefik\n          port: 8080\nEOF\n}\n</br>\n[ -d \"$base_file\" ] || { echo \"没有目录,则创建目录\" && mkdir $base_file; }\n[ -n \"$(which openssl)\" ] || { echo \"需要用到openssl,没有找到,退出\" && exit 1; }\ncd $base_file\n</br>\n# genkey  \n# [ -f \"tls.key\" ] || { echo \"没有生成密钥,退出\" && exit 1; }\n#kubectl create secret generic traefik-cert --from-file=tls.crt --from-file=tls.key -n kube-system\n# #kubectl create configmap traefik-conf --from-file=$dynamic -n kube-system\n</br>\narr=($crd $rbac $role $static $dynamic $deploy  $svc $ingress)\n</br>\nfor i in ${arr[@]}; do\necho \"开始生成:\"$i \ny_${i:2:0-5}  $i\n[ -f \"$i\" ] || { echo \"没有生成$i,退出\" && exit 1; }\n#kubectl apply -f  $i\ndone  </code></pre>\n</details>\n\n\n<details>\n  <summary>traefik-v2.10.4</summary>\n  <pre><a>bash traefik.sh</a><code>\n#!/bin/bash\nDIR=\"$(cd \"$(dirname \"$0\")\" && pwd)\"\n</br>\nversion=\"k8s.org/k8s/traefik:v2.10.4\"\nbase_file=$DIR/test\ncrd=1-crd.yaml\nrbac=2-rbac.yaml\nstatic=3-static_config.yaml\ndynamic=4-dynamic_toml.toml\ndeploy=5-deploy.yaml\nsvc=6-service.yaml\ningress=7-ingress.yaml\n</br>\ny_crd(){\n\t[ -f \"$DIR/crd.yml\" ] && {  echo \"cp crd\" && cp $DIR/crd.yml  $DIR/test/$1 && return 0; }\n  url=https://raw.githubusercontent.com/traefik/traefik/v2.10/docs/content/reference/dynamic-configuration/kubernetes-crd-definition-v1.yml\n  echo \"请执行wget -O crd.yml  $url\"\n}\n</br>\ny_rbac(){\n[ -f \"$DIR/rabc.yml\" ] && {  echo \"cp rabc\" && cp $DIR/rabc.yml  $DIR/test/$2 && return 0; }\n    url=https://raw.githubusercontent.com/traefik/traefik/v2.10/docs/content/reference/dynamic-configuration/kubernetes-crd-rbac.yml\n  echo \"请执行wget -O rabc.yml  $url\"\n}\n</br>\n</br>\n#静态配置动态文件======================?\ny_static_config(){\n   cat >$1 <<EOF\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: traefik-config-yaml\ndata:\n  traefik.yaml: |-\n    ping: \"\"\n    serversTransport:\n      insecureSkipVerify: true\n    api:\n      insecure: true\n      dashboard: true\n      debug: false\n    metrics:\n      prometheus: \"\"\n    entryPoints:\n      web:\n        address: \":80\"\n      websecure:\n        address: \":443\"\n      mysql:\n        address: \":3306\"\n      redis:    \n        address: \":6379\"\n      jenkins:\n        address: \":8081\"\n      gogo:\n        address: \":8082\"\n      prometheus:\n        address: \":8181\"\n    providers:\n      kubernetesCRD: \"\"\n      kubernetesIngress: \"\"\n      file:\n        directory: /etc/conf.d/\n        watch: true\n    log:\n      filePath: \"\"\n      level: error \n      format: json\n    accessLog:\n      filePath: \"\"\n      format: json\n      bufferingSize: 0\n      filters:\n        #statusCodes: [\"200\"]\n        retryAttempts: true\n        minDuration: 20\n      fields:\n        defaultMode: keep\n        names:\n          ClientUsername: drop  \n        headers:\n          defaultMode: keep\n          names:\n            User-Agent: redact\n            Authorization: drop\n            Content-Type: keep\nEOF\n}\n</br>\n</br>\ngenkey(){\nopenssl req \\\n        -newkey rsa:2048 -nodes -keyout tls.key \\\n        -x509 -days 3650 -out tls.crt \\\n        -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=ui.k8s.cn\" \n        #ui.k8s.cn 对应rule host\n#kubectl create secret generic traefik-cert --from-file=tls.crt --from-file=tls.key -n kube-system        \n}\n</br>\ny_dynamic_toml(){\n   cat >$1 <<EOF\ndefaultEntryPoints = [\"http\",\"https\"]\n[entryPoints]\n  [entryPoints.http]\n  address = \":80\"\n  [entryPoints.https]\n  address = \":443\"\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \"/ssl/tls.crt\"\n      KeyFile = \"/ssl/tls.key\"\n</br>\nEOF\n}\n</br>\ny_deploy(){\n   cat >$1 <<EOF\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n</br>\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik-ingress-controller\n  labels:\n    app: traefik\nspec:\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      name: traefik\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 1\n      containers:\n        - image: $version\n          name: traefik\n          ports:\n            - name: web\n              containerPort: 80\n              hostPort: 80         ## 将容器端口绑定所在服务器的 80 端口\n            - name: websecure\n              containerPort: 443\n              hostPort: 443        ## 将容器端口绑定所在服务器的 443 端口\n            - name: redis\n              containerPort: 6379\n              hostPort: 6379\n            - name: admin\n              containerPort: 8080  ## Traefik Dashboard 端口\n          resources:\n            limits:\n              cpu: 200m\n              memory: 256Mi\n            requests:\n              cpu: 100m\n              memory: 256Mi\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n              add:\n                - NET_BIND_SERVICE\n          args:\n            - --configfile=/config/traefik.yaml\n          volumeMounts:\n            - mountPath: \"/config\"\n              name: \"config\"\n            - mountPath: \"/ssl\"\n              name: \"ssl\"\n      volumes:\n        - name: config\n          configMap:\n            name: traefik-config-yaml\n        - name: ssl\n          secret:\n            secretName: traefik-cert\nEOF\n}\n</br>\ny_service(){\n   cat >$1 <<EOF\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik\n#  namespace: kube-system\nspec:\n  ports:\n    - name: web\n      port: 80\n    - name: websecure\n      port: 443\n    - name: admin   #没有会显示 404 page not found\n      port: 8080\n  selector:\n    app: traefik\n</br>\nEOF\n}\n</br>\n#kubectl apply -f https://raw.githubusercontent.com/traefik/traefik/v2.10/docs/content/user-guides/crd-acme/04-ingressroutes.yml\ny_ingress(){\n   cat >$1 <<\"EOF\"\napiVersion: traefik.io/v1alpha1  #v3 版本废弃v1alpha1，使用v1\nkind: IngressRoute\nmetadata:\n  name: dashboard\nspec:\n  entryPoints:\n  - websecure\n  routes:\n  - match: Host(`ui.k8s.cn`)\n    kind: Rule\n    services:\n    - name: api@internal\n      kind: TraefikService\n  tls:\n     secretName: traefik-cert\nEOF\n}\n</br>\n[ -d \"$base_file\" ] || { echo \"没有目录,则创建目录\" && mkdir $base_file; }\n[ -n \"$(which openssl)\" ] || { echo \"需要用到openssl,没有找到,退出\" && exit 1; }\ncd $base_file\n</br>\n# genkey  \n# [ -f \"tls.key\" ] || { echo \"没有生成密钥,退出\" && exit 1; }\n#kubectl create secret generic traefik-cert --from-file=tls.crt --from-file=tls.key -n kube-system\n# #kubectl create configmap traefik-conf --from-file=$dynamic -n kube-system\n# \narr=($crd $rbac $static $dynamic $deploy  $svc $ingress)\n</br>\nfor i in ${arr[@]}; do\necho \"开始生成:\"$i \ny_${i:2:0-5}  $i\n[ -f \"$i\" ] || { echo \"没有生成$i,退出\" && exit 1; }\n# kubectl apply -f  $i\ndone\n</br>\n</br>\n</br>\n  </code></pre>\n</details>\n\n\n\n\n```\n$bash traefik.sh\n$ tree  ./test\n./test\n├── 1-crd.yaml\n├── 2-rbac.yaml\n├── 3-role.yaml\n├── 4-static_config.yaml\n├── 5-dynamic_toml.toml\n├── 6-deploy.yaml\n├── 7-service.yaml\n└── 8-ingress.yaml\n```\n\n\n\nhttps://www.lvbibir.cn/posts/tech/kubernetes-traefik-2-router/\n\n\n\n\n\nhelm\n\n\n\n```\n❯ helm install -f ./traefik/values.yaml  -name traefik   --namespace kube-system  ./traefik\nNAME: traefik\nLAST DEPLOYED: Wed Sep  6 20:00:43 2023\nNAMESPACE: kube-system\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nTraefik Proxy v2.10.4 has been deployed successfully on kube-system namespace !\n❯ helm upgrade  -name traefik --namespace kube-system  ./traefik\nRelease \"traefik\" has been upgraded. Happy Helming!\nNAME: traefik\nLAST DEPLOYED: Wed Sep  6 20:08:33 2023\nNAMESPACE: kube-system\nSTATUS: deployed\nREVISION: 2\nTEST SUITE: None\nNOTES:\nTraefik Proxy v2.10.4 has been deployed successfully on kube-system namespace !\n❯helm uninstall  -name traefik --namespace kube-system\nrelease \"traefik\" uninstalled\n```\n\n\n\n\n\n### nginx\n\n\n\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: todo\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    nginx.ingress.kubernetes.io/app-root: /app/\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      rewrite ^(/app)$ $1/ redirect;\n      rewrite ^/stylesheets/(.*)$ /app/stylesheets/$1 redirect;\n      rewrite ^/images/(.*)$ /app/images/$1 redirect;\nspec:\n  rules:\n  - host: todo.qikqiak.com\n    http:\n      paths:\n      - backend:\n          serviceName: todo\n          servicePort: 3000\n        path: /app(/|$)(.*)\n```\n\n","tags":["traefik","ingress"],"categories":["linux","k8s"]},{"title":"etcd集群","url":"//linux/k8s/etcd/","content":"etcd 下载\n\n\n\n\n\n\n\nhttps://github.com/bitnami/bitnami-docker-etcd\n\n\n\n\n\n```\n$ etcdctl set /atomic.io/network/config '{\"Network\":\"121.21.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}'\n```\n\n>{\"Network\":\"121.21.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}\n\n\n\nCouldn't fetch network config: client: response is invalid json. The endpoint is probably not valid etcd cluster endpoint. timed out\n\n查阅 flanneld 官网文档，上面标准了 flannel 这个版本不能给 etcd 3 进行通信\n\n```\n$ etcdctl put /atomic.io/network/config '{\"Network\":\"121.21.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}'\n$ etcdctl del /atomic.io/network/config\n```\n\n>API VERSION:3.2\n>\n>Did you mean this?\n>\tget\n>\tput\n>\tdel\n>\tuser\n\n\n\netcd environment文档\n\nhttps://doczhcn.gitbook.io/etcd/index/index-1/configuration\n\n\n\n\n\n\n\n```shell\ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs.ko \ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_rr\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_rr.ko \ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_wrr\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_wrr.ko \ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_sh\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_sh.ko\ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_nq\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_nq.ko\n```\n\n\n\n```shell\ncs@debian:~/oss/0s/k8s$ sudo ipvsadm -ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn\n\n```\n\n\n\n```shell\n#两种临时方法\n# echo 1 > /proc/sys/net/ipv4/vs/conntrack\n# sysctl -w net.ipv4.vs.conntrack=1\n```\n\n> 想永久保留配置，可以修改/etc/sysctl.conf文件\n\n\n\n\n\n```\nkubectl create clusterrolebinding test:anonymous --clusterrole=cluster-admin --user=system:anonymous\n```\n\n> configmaps is forbidden: User “system:anonymous” cannot list resource “configmaps” in [API](https://so.csdn.net/so/search?q=API&spm=1001.2101.3001.7020) group “” in the namespace “default”\n\n\n\n```\n[vagrant@k8s master]$ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap\nclusterrolebinding.rbac.authorization.k8s.io/kubelet-bootstrap created\n```\n\n>error: failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User \"kubelet-bootstrap\" cannot create certificatesigningrequests.certificates.k8s.io at the cluster\n\n\n\nproxy\n\nunable to create proxier: can't set sysctl net/ipv4/conf/all/route_localnet to 1: open /proc/sys/net/ipv4/conf/all/route_localnet: read-only file system\n\n\n\n```\n sduo  cat > /etc/sysconfig/modules/ipvs.modules <<EOF\n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- ip_vs_nq\nmodprobe -- nf_conntrack_ipv4\nEOF\n```\n\n\n\n```yaml\n      containers:\n      - name: kube-flannel\n        image: k8s.org/k8s/flannel:v0.11.0-amd64\n        command:\n        - /opt/bin/flanneld\n        args:\n        - --ip-masq\n        - --kube-subnet-mgr\n        - --iface=eth1\n```\n\n> --iface=eth1\n\n\n\n\n\n```shell\ncs@debian:~$ ansible k8s-108 -m copy -a \"src=/home/cs/oss/0s/k8s/kube-apiserver/docker-compose.yml dest=/opt/kubernetes/master/docker-compose.yml\"   -b --become-method sudo --become-user root\n```\n\nansible k8s-108 -m copy -a \"src=/opt/kubernetes/client/k8s-1.21-11/bin/config.yaml dest=/opt/kubernetes  mode=0644\"   -b --become-method sudo --become-user root\n\n\n\n\n\n```\n[root@k8s kubernetes]# cat > /etc/sysctl.d/k8s.conf << EOF\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n```\n\n\n\n\n\n```\n cat>/opt/kubernetes/kubelet.env<<EOF\n KUBELET_OPTIONS=\" --hostname-override=192.168.56.108 \\\n  --pod-infra-container-image=k8s.org/k8s/pause:3.4.1 \\\n  --bootstrap-kubeconfig=/opt/kubernetes/config/bootstrap.kubeconfig \\\n  --kubeconfig=/opt/kubernetes/config/kubelet.kubeconfig \\\n   --config=/opt/kubernetes/config/kubelet-conf.yaml   \\\n  --register-node=true \\\n  --cni-bin-dir=/opt/kubernetes/cni/bin --cni-conf-dir=/opt/kubernetes/cni/net.d --network-plugin=cni  \\\n   --runtime-cgroups=/systemd/system.slice  \\\n  --logtostderr=true \"\nEOF\n```\n\n\n\n\n\n\n\n```\n\tcat>/usr/lib/systemd/system/kubelet.service<<EOF\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=/var/lib/kubelet\nEnvironmentFile=/opt/kubernetes/kubelet.env\nExecStart=/opt/kubernetes/bin/kubelet  \\$KUBELET_OPTIONS\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n\n\n\n\n\n\n","tags":["etcd"],"categories":["linux","k8s"]},{"title":"redis集群","url":"//linux/k8s/redis/","content":"\n\n\n### pod\n\n```\nkubectl -n devops get pods\nNAME          READY   STATUS    RESTARTS   AGE\nredis-app-0   1/1     Running   0          50m\nredis-app-1   1/1     Running   0          50m\nredis-app-2   1/1     Running   0          44m\nredis-app-3   1/1     Running   0          38m\nredis-app-4   1/1     Running   0          38m\nredis-app-5   1/1     Running   0          38m\n\nkubectl -n devops exec -it redis-app-2 /bin/bash\nkubectl -n devops exec -it redis-app-4 /bin/bash\n```\n\nredis-cli -c -p 6379\n\n![](/pics/k8s-redis-c-set01.png)\n\n\n\n### svc ClusterIP\n\n两次认证?\n\n```\ncs@debian:~/oss/hexo$ kubectl get svc -n devops\nNAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)              AGE\njenkins                  ClusterIP   121.21.92.146    <none>        8081/TCP,50000/TCP   105d\nredis-headless-service   ClusterIP   None             <none>        6379/TCP             13d\nredis-service            ClusterIP   121.21.24.33     <none>        6379/TCP             13d\ntomcat                   ClusterIP   121.21.191.100   <none>        8082/TCP             105d\n\ncs@debian:~/oss/hexo$ kubectl exec -it redis-app-1 -n devops  /bin/bash\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.\n.............\nroot@redis-app-1:/data# redis-cli  -c -h 121.21.24.33 -p 6379\n121.21.24.33:6379> auth 123456\nOK\n121.21.24.33:6379> ping\nPONG\n121.21.24.33:6379> get test21\n-> Redirected to slot [8530] located at 121.21.35.3:6379\n(error) NOAUTH Authentication required.  \n121.21.35.3:6379> auth 123456\nOK\n121.21.35.3:6379> get test21\n\"20220721cs\"\n```\n\n\n\n\n\n\n\ntraefik  deploay  配置 redis\n\n```\ncs@debian:/opt/kubernetes/yaml/k8s/tcp/redis$ redis-cli  -c  -p  6379\n127.0.0.1:6379> auth 123456\nOK\n127.0.0.1:6379> ping\nPONG\n```\n\n>127.0.0.1 - 192.168.56.103:6379, 192.168.56.101:6379, 192.168.56.102:6379 - [19/Jul/2022:22:10:12 +0800] 200 0, 0, 82\n\n\n\n### 不通超时\n\n![](/pics/k8s-redis-timeout.png)\n\n\n\n![](/pics/k8s-redis-c-set02.png)\n\n根据podip定位集群pod\n\n```\ncs@debian:~/oss/hexo$  kubectl  get pod --field-selector status.podIP=121.21.35.3 -o wide -n devops\nNAME          READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES\nredis-app-1   1/1     Running   1          9d    121.21.35.3   node04   <none>           <none>\n```\n\n","tags":["redis","redis-cluster"],"categories":["linux","k8s"]},{"title":"redis集群","url":"//services/database/redis/redis-cluster/","tags":["redis-cluster"],"categories":["services","database","redis"]},{"title":"mysql配置文件","url":"//services/database/mysql/my/","content":"\n\n\n## linux\n\n### my.cnf\n\n```\n[mysqld]\n#server-id                      = 224\nuser = mysql\nport                           = 3305\nmysqlx_port                    = 33060\nmysqlx_socket                  = /tmp/mysqlx.sock\ndatadir                        = /opt/mysql/data\nsocket                         = /tmp/mysql.sock\npid-file                       = /tmp/mysqld.pid\nauto_increment_offset          = 2\nauto_increment_increment       = 2 \nlog-error                      = /opt/mysql/log/error.log\nslow-query-log                 = 1\nslow-query-log-file            = /opt/mysql/log/slow.log\nlong_query_time                = 0.2\nlog-bin                        = bin.log\nrelay-log                      = relay.log\nbinlog_format                 =ROW\nrelay_log_recovery            = 1\ncharacter-set-client-handshake = FALSE\ncharacter-set-server           = utf8mb4\ncollation-server               = utf8mb4_unicode_ci\ninit_connect                   ='SET NAMES utf8mb4'\ninnodb_buffer_pool_size        = 1G\njoin_buffer_size               = 128M\nsort_buffer_size               = 2M\nread_rnd_buffer_size           = 2M\nlog_timestamps                 = SYSTEM\nlower_case_table_names         = 1\ndefault-authentication-plugin  =mysql_native_password\n```\n\n\n\n\n\n## win\n\n### my.ini\n\n```\n[client]\nport=3306\n\n[mysql]\ndefault-character-set=utf8mb4\n\n\n[mysqld]\nport=3306\n#password=123456\n#character-set-client-handshake=FALSE  \ncharacter-set-server=utf8mb4 \n#collation-server = utf8mb4_general_ci  \ninit_connect='SET NAMES utf8mb4'\n\n\nbasedir=\"D:/360Downloads/mysql-5.7.20-winx64\"\n#Path to the database root\ndatadir=\"D:/360Downloads/mysql-5.7.20-winx64/data\"\n\nlog-error=\"D:/360Downloads/mysql-5.7.20-winx64/log/mysqld_err.log\"\n#log-bin=\"D:/360Downloads/mysql-5.7.20-winx64/log/mysqld_bin.bin\"\n\ndefault-storage-engine=INNODB\n#从 5.6开始，timestamp 的默认行为已经是 deprecated 了\nexplicit_defaults_for_timestamp=true\n\nsql_mode=\"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\" \n\n```\n\n\n\n## 主从\n\ndoc https://dev.mysql.com/doc/refman/8.0/en/replication-howto-masterstatus.html\n\n新帐号\n\n>CREATE USER 'repl'@'192.168.16.232' IDENTIFIED BY '123456';\n\n\n\n 只复制\n\n> GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.16.232';\n\n\n\n\n\n### 主 \n\n配置mysql.cnf \n\n```\n[mysqld]\nserver-id=1\n```\n\n```\n\nshow master status;\n```\n\n>  File: mysql-bin.000001\n>  Position: 765\n\n\n\n### 从\n\n配置mysql.cnf\n\n```\n[mysqld]\nserver-id=2\n```\n\n备份\n\n```\nmysql -uroot -h 主 -p  database >back.sql;\n\n#登陆从库\nsource back.sql;\n\n```\n\n\n\n```\n\nstop slave;\n\nreset slave;\n\nreset master;\n\n```\n\n关键 \n\n把 show master status\\G `File`和`Position`对号入座\n\n```\n\n     CHANGE MASTER TO  \n\n     MASTER_HOST='master_host_name',\n\n     MASTER_USER='主用户名',\n\n     MASTER_PASSWORD='主密码',\n\n     MASTER_LOG_FILE='主status File',\n\n     MASTER_LOG_POS=主status Position;\n\n```\n\n开启从库\n\n```\nstart slave;\n```\n\n检查状态\n\n```\n\nshow slave status\\G\n\n```\n\n>Slave_IO_Running: Yes\n>\n>Slave_SQL_Running: Yes\n","tags":["mysql"],"categories":["services","database"]},{"title":"mysql安装","url":"//services/database/mysql/install/","content":"\n\n\n\n\n## linux\n\n<p id=\"install-mysql\" hidden />\n\n下载  https://downloads.mysql.com/archives/community/\n\n**Compressed TAR Archive, Minimal Install** **不包含调试和测试工具**\n\n```\nxz -d mysql-8.0.28-linux-glibc2.17-x86_64-minimal.tar.xz\ntar -xvf mysql-8.0.28-linux-glibc2.17-x86_64-minimal.tar\n```\n\n\n\n### 用户组\n\n```\n#添加组\nsudo groupadd mysql\nsudo useradd  -r -M -s /sbin/nologin  -g mysql mysql -d /opt/mysql\n\n# cs 或 ${USER}\nsudo chown mysql:${USER} -R  /opt/mysql/*\n\ncs@debian:~/data/software$ cat /etc/group | grep mysql\nmysql:x:512:cs\ncs@debian:~/data/software$ cat /etc/passwd | grep mysql\nmysql:x:512:512::/home/mysql:/sbin/nologin\n```\n\n\n\n### 初始化数据库\n\n```\n$ sudo /opt/mysql/bin/mysqld  --initialize --user=mysql --console\n```\n\n>......\n>\n>----2022-01-30T00:14:24.872326+08:00 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: `bDB,fVSmt2/U`\n\n\n\n### 修改配置\n\n默认`/etc/my.cnf`\n\n```\n url=/opt/mysql\n sed -n \"/^basedir=/s#=#==$url#\"p ./mysql.server\n sed -n \"/^datadir=/s#=#=$url/data#\"p ./mysql.server\n sed -n \"s#conf=.*#conf=$url/my.cnf#\"p ./mysql.server\n```\n\n\n\n### 开机启动\n\n```\nsudo cp /opt/mysql/support-files/mysql.server  /etc/init.d/mysql\n设置为开机自动运行\nsudo update-rc.d mysql defaults\n设置为取消开机自动运行\nsudo update-rc.d -f mysql remove\n```\n\n\n\n### 密码\n\n```\n##### 临时密码登录,执行语句提示 You must reset your password using ALTER USER statement before executing this statement.\n--- alter user user() identified by \"123456\";  ##密码字符串双引号\n\n---低于版本8---SET PASSWORD FOR root@localhost = '123456';\n---版本8以上---ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456'; \n\n##用户密码过期时间250天\nALTER USER ‘cs’@‘localhost' PASSWORD EXPIRE INTERVAL 250 DAY;\n###禁用过期     --恢复默认策略 PASSWORD EXPIRE DEFAULT----\nALTER USER 'cs'@'localhost' PASSWORD EXPIRE NEVER;\n\n###密码过期的策略\nshow variables like 'default_password_lifetime';\n---设置密码永不过期，需要把default_password_lifetime修改为 0\n---set global default_password_lifetime = 0;\n\n CREATE USER 'cs'@'localhost' IDENTIFIED BY '123456';\n\n\n###修改执行生效语句\nflush privileges;\n```\n\n\n\n## win\n\n[下载地址：http://dev.mysql.com/downloads/mysql/](http://dev.mysql.com/downloads/mysql/) \n\n管理员权限运行cmd\n\n```\nE:\\MySQL\\MySQL Server 5.7\\bin>mysqld install MySQL --defaults-file=\"E:\\MySQL\\MySQL Server 5.7\\my.ini\"\n```\n\ninstall/Remove of the Service Denied!  \n\n\n\n```\nbin>mysqld --initialize --user=mysql --console\n```\n\n启动服务\n\n```\nnet start MySQL\n```\n\n删除  \n\n```\nsc delete MySQL\n```\n\n\n\n\n\n## other\n\n\n\n### Permission denied\n\n检查目录所属用户mysql \n\n\n\n`rm /tmp/mysql*`\n\n```\n❯ ls -l /tmp/mysql*\n-rw-r----- 1 mysql mysql 6  6月  4 21:08 /tmp/mysqld.pid\nsrwxrwxrwx 1 mysql mysql 0  6月  4 21:08 /tmp/mysql.sock\n-rw------- 1 mysql mysql 6  6月  4 21:08 /tmp/mysql.sock.lock\nsrwxrwxrwx 1 mysql mysql 0  6月  4 21:08 /tmp/mysqlx.sock\n-rw------- 1 mysql mysql 6  6月  4 21:08 /tmp/mysqlx.sock.lock\n```\n\n\n\n\n\n### 端口\n\n```\n/opt/mysql/bin/mysqld  --initialize-insecure --user=mysql  --lower-case-table-names=1\n/opt/mysql/bin/mysqld --user=mysql  &\n```\n\n>╰─❯ 2023-06-04T11:50:10.086155Z 0 [System] [MY-010116] [Server] /opt/mysql/bin/mysqld (mysqld 8.0.32) starting as process 5008\n>2023-06-04T11:50:10.089112Z 0 [Warning] [MY-010122] [Server] One can only use the --user switch if running as root\n>2023-06-04T11:50:10.094189Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n>2023-06-04T11:50:10.195060Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n>2023-06-04T11:50:10.385679Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.\n>2023-06-04T11:50:10.385746Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.\n>2023-06-04T11:50:10.386292Z 0 [ERROR] [MY-010262] [Server] Can't start server: Bind on TCP/IP port: Address already in use\n>2023-06-04T11:50:10.386343Z 0 [ERROR] [MY-010257] [Server] Do you already have another mysqld server running on port: 3306 ?\n>2023-06-04T11:50:10.386383Z 0 [ERROR] [MY-010119] [Server] Aborting\n>2023-06-04T11:50:11.974477Z 0 [System] [MY-010910] [Server] /opt/mysql/bin/mysqld: Shutdown complete (mysqld 8.0.32)  MySQL Community Server - GPL.\n\n\n\n```\nsudo netstat -apn | grep 3306\n```\n\n","tags":["install","mysql"],"categories":["services","database"]},{"title":"pip包管理","url":"//lang/python/pip/","content":"\n\n\n## 安装\n\n```\ncs@debian:~/oss/typoraCracker$ sudo apt-get install python3-pip\ncs@debian:~/oss/typoraCracker$ pip3 -V\npip 20.3.4 from /usr/local/lib/python3.5/dist-packages/pip (python 3.5)\n```\n\n\n\n## 升级\n\n```\ncs@debian:~/oss/typoraCracker$ sudo pip3 install --upgrade pip\nCollecting pip\n  Downloading http://mirrors.aliyun.com/pypi/packages/27/79/8a850fe3496446ff0d584327ae44e7500daf6764ca1a382d2d02789accf7/pip-20.3.4-py2.py3-none-any.whl (1.5MB)\n    100% |████████████████████████████████| 1.5MB 5.8MB/s \nInstalling collected packages: pip\n  Found existing installation: pip 9.0.1\n    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\nSuccessfully installed pip-20.3.4\n```\n\n\n\n## 国内源   \n\n<p id=\"pip-source\"  hidden/>\n\n```\nhttps://pypi.doubanio.com/simple/豆瓣 \nhttps://mirrors.aliyun.com/pypi/simple/ 阿里 \nhttps://mirrors.bfsu.edu.cn/pypi/web/simple/ 中国科学技术大学\nhttps://pypi.tuna.tsinghua.edu.cn/simple/ 清华大学\n\n```\n\n\n\n设置\n\n```\n$ pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/\nWriting to ~/.config/pip/pip.conf\n\n```\npip.ini\n\n```\n[global]\ntimeout = 6000\nindex-url = https://mirrors.aliyun.com/pypi/simple\nextra-index-url = https://pypi.mirrors.ustc.edu.cn/simple/https://mirrors.aliyun.com/pypi/simple/https://pypi.tuna.tsinghua.edu.cn/simple/http://pypi.mirrors.ustc.edu.cn/simple/https://pypi.org/simple/\n[install]\ntrusted-host = pypi.mirrors.ustc.edu.cnpypi.mirrors.ustc.edu.cnmirrors.aliyun.compypi.tuna.tsinghua.edu.cnpypi.mirrors.ustc.edu.cnpypi.org\n```\n\n>extra-index-url  备用\n>\n>trusted-host此参数是为了避免麻烦，否则使用的时候可能会提示不受信任\n\n\n\n## 卸载\n\n```\nsudo apt-get remove python3-pip\n```\n\n","tags":["pip"],"categories":["lang","python"]},{"title":"tomcat优化","url":"//services/container/tomcat/","content":"\n\n\n\n\n## jvm参数\n\n\n\n```\nJAVA_OPTS=\"-server -XX:NewSize=256m -XX:MaxNewSize=256m -XX:PermSize=512M -XX:MaxPermSize=1024m -Xms2048m -Xmx2048m \"\n```\n\n\n\n>-Xms：Java虚拟机初始化时堆的最小内存，一般与 Xmx配置为相同值，这样的好处是GC不必再为扩展内存空间而消耗性能；\n>\n>-Xmx：Java虚拟机可使用堆的最大内存；\n>\n>-XX:PermSize：Java虚拟机永久代大小；\n>\n>-XX:MaxPermSize：Java虚拟机永久代大小最大值；\n>\n>-XX:NewSize=：新生代空间初始化大小 \n>\n>-XX:MaxNewSize=：新生代空间最大值\n\n## 配置优化\n\n### 连接属性\n\n/tomcat-8.5.38/conf/server.xml\n\n\n\nhttps://tomcat.apache.org/tomcat-8.5-doc/config/executor.html\n\n```\n<Executor   name=\"tomcatThreadPool\"\n  namePrefix=\"req-thead-exc\"\n  maxHttpHeaderSize=\"8192\" \n  maxThreads=\"1000\"\n  minSpareThreads=\"75\"\n  maxQueueSize=\"Integer.MAX_VALUE\"\n  maxIdleTime=\"60000\"\n  threadPriority=\"5\"\n  className=\"org.apache.catalina.core.StandardThreadExecutor\"\n />\n```\n\n> maxThreads:  服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量,压测计算,要排除单纯处理业务耗时方法,如果未指定，默认值为200\n>\n> minSpareThreads：线程的最小运行数目，这些始终保持运行。如果未指定，默认值为10。\n>\n> maxHttpHeaderSize：请求和响应的HTTP头的最大大小，以字节为单位指定。如果没有指定，这个属性被设置为8192（8 KB）。\n\n\n\n\n\n```\nsed -i '/connectionTimeout=/i\\  executor=\"tomcatThreadPool\"' /opt/apache/tomcat-8.5.38/conf/server.xml \n\n<Connector port=\"8080\" protocol=\"HTTP/1.1\" \n  executor=\"tomcatThreadPool\"\n  connectionTimeout=\"20000\"   \n  redirectPort=\"8443\" />  \n```\n\n> connectionTimeout代表连接超时时间，单位为毫秒,默认值为60000。通常情况下设置为30000。\n\nhttps://tomcat.apache.org/tomcat-8.5-doc/config/http.html\n\n\n\n###  cache\n\n/tomcat-8.5.38/conf/context.xml\n\ntomcat8以上对resource采取了cache，而默认的大小是10M\n\n\n\nconsider increasing the maximum size of the cache\n\n\n\n```\nsed -i '/^<\\/Context>/i\\<Resources cachingAllowed=\"true\"  cacheMaxSize=\"102400\" \\/>'  /opt/apache/tomcat-8.5.38/conf/context.xml\n```\n\n><Resources cachingAllowed=\"true\"  cacheMaxSize=\"102400\" />\n>\n>context.xml文件内添加到<Context>节点内</Context>\n>\n>cacheMaxSize值按需设置,单位K , ","tags":["tomcat"],"categories":["services","container"]},{"title":"apt","url":"//linux/debian/apt/","content":"\n\n\n## apt-get\n\n源 \n\n```\nsed -i \"s@http://\\(deb\\|security\\).debian.org@https://mirrors.aliyun.com@g\" /etc/apt/sources.list\n\n\ndeb https://mirrors.aliyun.com/debian/ bullseye main non-free contrib\ndeb-src https://mirrors.aliyun.com/debian/ bullseye main non-free contrib\ndeb https://mirrors.aliyun.com/debian-security/ bullseye-security main\ndeb-src https://mirrors.aliyun.com/debian-security/ bullseye-security main\ndeb https://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib\ndeb-src https://mirrors.aliyun.com/debian/ bullseye-updates main non-free contrib\ndeb https://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib\ndeb-src https://mirrors.aliyun.com/debian/ bullseye-backports main non-free contrib\n\n\nsudo apt update && sudo apt upgrade  -y\n```\n\n\n\n升级\n\n```\napt-get update\t\t\t   // 更新源文件，并不会做任何安装升级操作 \napt-get upgrade\t\t       // 升级所有已安装的包 \n```\n\n安装\n\n```\napt-get install packagename\t\t// 安装指定的包\n```\n\n查询包\n\n```\napt-cache depends packagename   //该包依赖哪些包\n```\n\n列出所有已经安装\n\n```\napt list --installed\n```\n\n\n\n删除\n\n```\napt-get autoremove packagename --purge  //删除包及其依赖的软件包+配置文件等\n```\n\n\n\n清理\n\n```\napt-get clean \t\t\t\t\t\t// 清理无用的包  \napt-get autoclean \t\t\t\t\t// 清理无用的包  \napt-get check \t\t\t\t\t\t// 检查是否有损坏的依赖\n```\n\n\n\n## apt-mark 标记\n\n系统中禁用 Chrome 更新\n\n```\ncs@debian:~$ sudo apt-mark  hold google-chrome-stable\ngoogle-chrome-stable 设置为保留。\n```\n\n> auto\t标记指定软件包为自动安装\n> manual\t标记指定软件包为手动安装\n> minimize-manual\t将 meta 包的所有依赖项标记为自动安装\n> hold\t标记指定软件包为保留（held back），阻止软件自动更新\n> unhold\t取消指定软件包的保留（held back）标记，解除阻止自动更新\n> showauto\t列出所有自动安装的软件包\n> showmanual\t列出所有手动安装的软件包\n> showhold\t列出设为保留的软件包\n\n\n\ncentos\n\n```\necho 'exclude=google-chrome-stable' >> /etc/yum.conf\n```\n\n\n\n### sudo\n\n\n\n/etc/sudoers 只读\n\n```\n❯ ls -l /etc/sudoers\n-r--r----- 1 root root 689  2月 20 21:59 /etc/sudoers\n\nchmod +w /etc/sudoers\n```\n\n-输入命令 vi /etc/sudoers 进入sudoers文件；\n\n-在vi命令模式中，\n\n输入 /%sudo 搜索定位到 %sudo ALL = (ALL:ALL) ALL，或者手动定位\n\n-在vi插入模式中（按一下 i 键），\n\n 在  %sudo ALL = (ALL:ALL) ALL 下面键入 cs  ALL = (ALL:ALL) ALL  \n\n（同样，这里 cs代表我的普通用户名，大家根据实际修改）\n\n-在vi命令模式中，输入 :x ,即可退出vi并保存文件\n\n别忘了再吧sudoer改回只读模式 chmod -w /etc/sudoers\n\n\n\n## yum\n\n<p id=\"yum-local\"  hibben />\n\n下载安装包在指定目录\n\n```\nyum install --downloadonly --downloaddir=/mnt  zabbix-agent\n```\n\n\n\nyumdownloader  `yum install -y yum-utils`\n\n```\n# 下载包时,同时下载相关依赖\nyumdownloader --resolve --destdir=/apps/yumtmp/downloader php \n```\n\n\n\n\n\n```\n> rpm -qa |grep httpd #找到安装的https包\nxxxx\n\n##卸载上面命令找到的包\n> rpm -e --nodeps  xxx\n```\n\n\n\n### 本地安装\n\n#### 一: yum -C install\n\n把下载的包,拷贝进缓存包的默认目录`/var/cache/yum/base/packages`\n使用命令`yum -C install [packageName]`从缓存中安装包\n\n#### 二: yum localinstall\n\n直接指定本地包的文件\n\n```sh\n# 安装当前目录下所有的包\nyum localinstall *.rpm\n```\n\n#### 三: rpm -ivh --force\n\n暴力安装当前目录下所有的包, 忽略依赖顺序, 简单又省事\n\n```sh\nrpm -ivh --force *.rpm\n```\n\n> --*force*就是强制安装\n>\n> --nodeps就是安装时不检查依赖关系\n\n","tags":["apt","sudo"],"categories":["linux","debian"]},{"title":"强弱类型语言","url":"//lang/sawtl/","content":"\n\n\n## 弱类型语言\n\n是一种弱类型定义的语言,某一个变量被定义类型,该变量可以根据环境变化自动进行转换,不需要经过显性强制转换 代表js,php,lua\n\n\n\njs\n\n![](/pics/was-1.png)\n\n+操作是将A的类型转化为了字符串，然后进行拼接\n\n-操作是将B的类型转化为了数字，然后进行减法\n\n\n\nlua\n\n```\n> a=5 \n> b=\"5\"\n> print(b+a)\n10.0\n> print(b-a)\n0.0\n> print(a==b)\nfalse\n\n```\n\n<!--more-->\n\n![](/pics/saw-2.png)\n\n\n\n## 强类型语言\n\njava\n\n```\npublic class Main{\n    public static void main(String []args) {\n    int a=5;\n    String b=\"5\";\n       System.out.println(a+b);//55\n       // System.out.println(a-b);//编译不通过,错误：二元运算符“-”的操作数类型错误\n    }\n} \n```\n\n\n\ngo\n\n```\npackage main\nvar a = 5\nvar b string = \"5\"\n\n\nfunc main(){\n    println(a+b) //无效操作：a + b（不匹配的类型 int 和 string）\n    println(a-b) //无效操作：a - b（不匹配的类型 int 和 string）\n}\n```\n\n","tags":["强弱类型"],"categories":["lang"]},{"title":"mongodb","url":"//database/mongo/","content":"\n\n\n# linux 环境\n\n## 下载 \n\nwget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-debian81-3.4.4.tgz\n\n```\ntar zxvf mongodb*.tar\nmv /opt/mongo*  /opt\ncd /opt/mongodb*  && touch  mongodb.conf\n```\n\n## 配置文件\n\n```\ndbpath=/home/cs/Download/mongodb/data #数据库路径\nlogpath=/home/cs/Download/mongodb/data/logs/mongodb.log #日志输出文件路径\nlogappend=true #错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\njournal=true #启用日志文件，默认启用\nquiet=true #这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nport=27017 #端口号 默认为27017\n```\n\n启动\n\n```\ncs@debian:/opt/mongodb-3.4.4/bin$ ./mongod  --config  /opt/mongodb-3.4.4/mongodb.conf\n```\n\n\n后台运行\n\n```\nmongo  -f   mongo.conf   & \n```\n\n\n使用 fork 必须加上logpath\n\n```\nmongo   --fork  --logpath=log/mongodb.log   \n\n```\n\n多条命令执行时 &&  可以把 fork配置到conf\n\n\n```\necho   { \\\n                echo 'dbpath=/data/db'; \\\n                echo 'port=27017'; \\\n                echo 'logpath=/data/mongo.log'; \\\n                echo 'logappend=true'; \\\n                echo 'fork=true'; \\\n             } > mongod.conf  \n```\n\n\n\n## 启动\n\nmongo-start.sh\n\n```\n#!/bin/bash\ncd /opt/mongodb-3.4.4/bin \n./mongod  --config  /opt/mongodb-3.4.4/mongodb.conf  &\nexit\n!\n```\n\n\n\n# win 环境\n\n下载  http://dl.mongodb.org/dl/win32/x86_64\nzip 免安装包\n\n\n\n启动\n\n```\nE:\\MongoDB\\Server\\bin>mongod.exe --config  E:\\MongoDB\\mongo.conf\n```\n\nmongo.conf\n\n```\ndbpath=E:\\MongoDB\\data #数据库路径\nlogpath=E:\\MongoDB\\logs\\mongodb.log #日志输出文件路径\nlogappend=true #错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\njournal=true #启用日志文件，默认启用\nquiet=true #这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nport=27017 #端口号 默认为27017\n```\n\n打开 http://127.0.0.1:27017/ \nIt looks like you are trying to access MongoDB over HTTP on the native driver port.\n\n## 安装服务\n\n管理员cmd\nE:\\MongoDB\\Server\\bin>`mongod --install --serviceName \"MongoDB\" --config` \"E:\\MongoDB\\mongo.conf\"\nE:\\MongoDB\\Server\\bin>  `net  start MongoDB`  \n\n## 删除服务\n\n`sc delete MongoDB`\n\n\n\n\n\nhttps://www.runoob.com/mongodb/mongodb-connections.html","tags":["mongodb"],"categories":["database"]},{"title":"singleton单例模式","url":"//other/design-pattern/singleton/","content":"\n\n\n## 懒汉  \n\n **第一次调用时实例化**\n\n```\npublic class LHanDanli {\n//定义一个私有类变量来存放单例，私有的目的是指外部无法直接获取这个变量，而要使用提供的公共方法来获取\nprivate static LHanDanli dl = null;\n//定义私有构造器，表示只在类内部使用，亦指单例的实例只能在单例类内部创建\nprivate LHanDanli(){}\n//定义一个公共的公开的方法来返回该类的实例，由于是懒汉式，需要在第一次使用时生成实例，所以为了线程安全，使用synchronized关键字来确保只会生成单例\npublic static synchronized LHanDanli getInstance(){\nif(dl == null){\ndl = new LHanDanli();\n}\nreturn dl;\n}\n}\n```\n## 双重判断  \n\n不用每次获取对象都加锁\nvolatile  屏蔽虚拟机代码优化(代码执行顺序)，运行效率会成问题\n\n```\npublic class SLHanDanli {\nprivate static volatile SLHanDanli dl = null;\nprivate SLHanDanli(){}\npublic static SLHanDanli getInstance(){\nif(dl == null){\n          synchronized (SLHanDanli.class) {\n       if(dl == null){\n    dl = new SLHanDanli();\n}\n}\n }\nreturn dl;\n}\n}\n`\n\n```\n\n## 饿汉   \n\n加载类内就实例化\n\n<!--more-->\n\n```\npublic class EHanDanli {\n//此处定义类变量实例并直接实例化，在类加载的时候就完成了实例化并保存在类中\nprivate static EHanDanli dl = new EHanDanli();\n//定义无参构造器，用于单例实例\nprivate EHanDanli(){}\n//定义公开方法，返回已创建的单例\npublic static EHanDanli getInstance(){\n    return dl;\n}\n}\n\n```\n会有占用空间的问题存在\n\n\n\n\n\n\n\n## 静态内部类 \n\n类加载机制   只有在调用时，才会加载实例，\n静态实例化``jvm线程安全``\n\n```\npublic class ClassInnerClassDanli {\n    public static class DanliHolder{\n        private static ClassInnerClassDanli dl = new ClassInnerClassDanli();\n    }\n    private ClassInnerClassDanli(){}\n        public static ClassInnerClassDanli getInstance(){\n                return DanliHolder.dl;\n        }\n    }\n}\n```\n","tags":["singleton"],"categories":["design-pattern"]},{"title":"常用语法","url":"//linux/k8s/docker1/","content":"\n\n\n\n\n```\n sudo  service docker status\n\n sudo service docker stop\n\n sudo service docker start\n```\n\n\n\n#### 搜索\n\n```\ndocker search Python\n\n```\n\n#### 拉取\n\n```\ndocker pull python:2.7\n\n```\n\n\n\n#### 查询\n\n镜像  `image`\n\n```\ndocker images\n\n```\n\n\n\n 容器 `container`\n\n```\ndocker ps  #run container\n\ndocker ps -a  #all container\n\n```\n\n##### 日志\n\n```\ndocker logs -f  <container or id>\n\n```\n\n##### 容器信息\n\n```\ndocker inspect  <id>\n\n#查看指定信息\ndocker inspect  <id>  --format '{{.Args}}'\n\ndocker inspect --format='{{.NetworkSettings.IPAddress}}' $CONTAINER_ID\n\n```\n\n<!--more-->\n\n#### 运行\n\n创建镜像  当前路径 **.** 英文点表示\n\n```\ndocker build -t  <镜像名> <Dockerfile路径>\n\n```\n\n修改名字,版本\n\n```\ndocker tag <IMAGE ID>  <名称:版本号>\n\n```\n\n容器安装程序\n\n```\ndocker run python:3.5.3 pip -V\n\n#指定源更新\ndocker run python:3.5.3 pip -i https://mirrors.aliyun.com/pypi/simple/ numpy\n\ndocker run <镜像名> apt-get install -y <程序>  \n\n```\n\n`-y` 交互\n\n\n\n```\n# tomcat 后台运行  p local port:container port     4452镜像id前4位\n\n docker run -d -p 8080:8080 4452\n\n```\n\n 保存容器\n\n```\ndocker commit  <id> <镜像名:版本号>\n\n```\n\n\n\n##### 进入容器\n\n```\n# /bin/bash\ndocker run -i -t  python:3.5.3  /bin/bash\n\n```\n\n##### 共享目录\n\n```\ndocker run -it -v <宿主机绝对路径目录>:<容器目录>  <镜像id>    /bin/bash\n\n```\n\n`-e` 环境变量\n\n```\ndocker run  -e \"MYSQL_ROOT_PASSWORD=19930221\" -it 797e57bb4fea\n\n```\n\n#### 停止\n\n```\ndocker stop <CONTAINER ID>\n\n```\n\n#### 删除\n\n要先停止运行容器stop id\n\n```\ndocker rmi <tag>:<no>\n\n#删除版本是 v1.21.12的所有镜像\ndocker rmi  `docker images | grep v1.21.12 | awk '{print $1\":\"$2}'`\n```\n\n\n\n所有镜像\n\n```\n#docker rmi $(docker images  -q)\n```\n\n\n\n所有容器\n\n```\ndocker rm $(docker ps -a -q)\n\n##删除 Exited 容器\ndocker rm $(docker ps -a | grep \"Exited\" | awk '{print $1 }')\n```\n\n#### 迁移\n\n备份\n\n```\ndocker save <镜像名>  -o  ~/save.tar  \n\n```\n\n还原\n\n```\ndocker load  -i  ~/docker/save.tar\n\n```\n\n\n\n**Ctrl + P + Q** 退出容器\n\n\n\n\n\n#### 性能限制\n\n\n\n容器使用状态\n\n```\ndocker stats  containerId  \n```\n\nk,b,m,g内存\n\ndoc https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources\n\n\n\nnginx代理\n\n\n\n```\ntinkle-style-dev:\n  restart: always\n  ports:\n    - '18082:8080/tcp'\n  environment:\n    - TZ=Asia/Shanghai\n    - TERM=xterm\n  memswap_limit: 0\n  labels:\n    aliyun.scale: '1'\n  shm_size: 0\n  image: >-\n    registry-internal.cn-shenzhen.aliyuncs.com/tinkle/docker-registry:centos7-lite-1.0\n  memswap_reservation: 0\n  volumes:\n    - >-\n      /mnt/acs_mnt/nas/21ac64b65d/baopinghui/style-service:/app/0.0.1-SNAPSHOT/style-service/:rw\n    - '/home/data/tmpfile/style-service:/tmp:rw'\n    - /mnt/acs_mnt/nas/21ac64b65d/baopinghui/style-service/tinkle-style.conf:/etc/supervisor.conf.d/tinkle-style.conf:rw\n  kernel_memory: 0\n  mem_limit: 0\n```\n\n\n\n/tinkle-style-dev/docker-compose.yml  不指明`container_name`容器名\n\n`docker-compose up -d` 默认 tinkle-style-dev_tinkle-style-dev_1\n\n```\nupstream backend {\n    server tinkle-core-dev_tinkle-core-dev_1:8080;\n}\nupstream style{\n    server tinkle-style-dev_tinkle-style-dev_1:8080;\n}\nupstream ocr{\n    server tinkle-ocr-dev_tinkle-ocr-dev_1:8080;\n}\n log_format  main1  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"'\n                       '$upstream_addr $upstream_response_time $request_time ';\nserver {\n\tlisten       80;\n\tserver_name  api.baopinghui.com;\n\tcharset utf-8;\n\taccess_log  logs/host.access.log  main1;\n      \n      \n\tlocation / {\n\t\t#root   html;\n\t\t#index  index.html index.htm;\n\t\tif ( $request_uri ~* /fastNeuralStyleController ) {\n  \t\t\tproxy_pass http://style;\n\t\t }\n\t\tif ( $request_uri ~* /(style)/(.*) ){\n\t\t\tproxy_pass http://style/$2;\n\t\t}\n\t\tproxy_pass http://backend/;\n\t\tproxy_set_header   Host    $host;\n\t\tproxy_set_header   Cookie $http_cookie; \n\t\tproxy_set_header   X-Real-IP        $remote_addr;\n\t\tproxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n\t\tadd_header From localhost;\n\t\tproxy_cookie_path / /; \n\t}\n}\n```\n\n\n\n#### GPU\n\n[nvidia驱动安装](/tool/gpu#gpu)\n\n\n\n\n#### 错误\n\nNo `command` specified\n\n```\ndocker run -it   xidx  /bin/bash  -c \"ls\"\n```\n\n\n\nOCI runtime create failed: container_linux.go:344: starting container process caused \"exec: \\\"/bin/bash\\\": stat `/bin/bash: no such file or directory`\": unknown.  \n\n```\ndocker run -it   xidx  sh\n```\n\n\n\n","tags":["docker"],"categories":["linux","k8s"]},{"title":"sed替换查找","url":"//linux/shell/sed/","content":"\n### 参数\n\n```\nsed [options] 'command' file(s) \n\nsed [options] -f scriptfile file(s)\n```\n\n>g 表示行内全面替换。     global 全局   \n>p 表示打印行。 P 打印模板第一行\n>r 读文件\n>-n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 \n>-e ：直接在命令列模式上进行 sed 的动作编辑； \n>-f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；\n>-r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) -i ：直接修改读取的文件内容，而不是输出到终端   \n> w 表示把行写入一个文件。\n> x 表示互换模板块中的文本和缓冲区中的文本。\n> y 表示把一个字符翻译为另外的字符（但是不用于正则表达式）\n> \\1 子串匹配标记 \n>& 已匹配字符串标记元字符集\n>^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 \n>$ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。\n> . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。\n> * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。\n> [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。\n>  [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。\n>  \\(..\\) 匹配子串，保存匹配的字符，如s/\\(love\\)able/\\1rs，loveable被替换成lovers。\n>  & 保存搜索字符用来替换其他字符，如s/love/**&**/，love这成**love**。\n>  \\< 匹配单词的开始，如:/\\ 匹配单词的结束，如/love\\>/匹配包含以love结尾的单词的行。\n>  x\\{m\\} 重复字符x，m次，如：/0\\{5\\}/匹配包含5个0的行。\n>  x\\{m,\\} 重复字符x，至少m次，如：/0\\{5,\\}/匹配至少有5个0的行。\n>  x\\{m,n\\} 重复字符x，至少m次，不多于n次，如：/0\\{5,10\\}/匹配5~10个0的行。\n\n \n\n### 批量替换\n\n把目录下所有格式文件内容进行批量替换\n\n```shell\nsed -n \"s#$src#$dest#g\"p `grep $src -rl --include=\\*.{yaml,md} $path`\n```\n\n>扫描path路径对应格式的文件,把src替换成dest,\n\n>**sed** \n>\n>-n p  结合打印改变内容,不执行变更\n>\n>**grep**\n>\n>-r 表示查找当前目录以及所有子目录\n>\n>-l 表示仅列出符合条件的文件名\n>\n>--include=\"*.[ch]\" 表示仅查找.c、.h文件\n>\n>上面不适用大多数情况,推荐下面\n>\n>--include=*.{yaml,md}\n\n<!--more-->\n\n​           \n\n样本1 test.txt   (cat -n 显示行号)\n\n```\n111111111 \n222222222   \n```\n\n \n\n#### **a\\ ** 追加\n\n在当前行下面插入文本。  append  追加\n\nN;2a  指定第二行后追加append\n\n```shell\ncs@debian:~/～$ sed -i 'N;2a这是a' test.txt \ncs@debian:~/～$ cat -n test.txt    \n1\t11111111    \n2\t22222222    \n3\t这是a      \n```\n\n​        \n\n/匹配/  不确定行数 a\\ **反斜杠可以不要** a\n\n```shell\n cs@debian:~/～$ sed -i \"/这是a/a\\匹配追加\" test.txt \n cs@debian:~/～$ cat -n test.txt    \n 1\t这是i    \n 2\t11111111    \n 3\t22222222    \n 4\t这是a    \n 5  匹配追加      \n```\n\n​        \n\n####  **i\\ **  插入\n\n在当前行上面插入文本。 insert 插入\n\n N;2i 指定第二行前插入insert  'N;2i\\这是i' （\\省略）\n\n```\ncs@debian:~/～$ sed -i 'N;2i这是i' test.txt\ncs@debian:~/～$ cat -n test.txt    \n1\t这是i    \n2\t11111111    \n3\t22222222    \n```\n\n​          \n\n/匹配/  不确定行数\n\n```\ncs@debian:~/～$ sed -i \"/这是i/i\\匹配插入\" test.txt \ncs@debian:~/～$ cat -n test.txt    \n1\t匹配插入    \n2\t这是i    \n3\t11111111    \n4\t22222222    \n5\t这是a      \n```\n\n​        \n\n匹配多个---》 批量插入\n\n```\n cs@debian:~/～$ sed -i \"/这是/i\\匹配多个\" test.txt \n cs@debian:~/～$ cat -n test.txt    \n 1\t匹配多个    \n 2\t这是i    \n 3\t11111111    \n 4\t22222222    \n 5\t匹配多个    \n 6\t这是a   \n```\n\n​           \n\n c\\ 把选定的行改为新的文本。 \n\n\n\n#### d 删除\n\n删除选择的行。\n\n确定行数\n\n```\ncs@debian:~/～$  sed '2,5d' test.txt\n```\n\n> #2-5行删除  \n>\n>  '2d' 第2行\n>\n>   '10,$d' 10到最后一行\n\n​             \n\n匹配删除 删除匹配下一行  d删除 p打印  #加 -i 直接修改 \n\n```\nsed '/这是i/d' test.txt\n```\n\n\n\n\n\n样本2\n\n```\ncs@debian:~/～$ cat -n test.txt     \n1\t11111111     \n2\t这是i     \n3\t22222222     \n4\t这是a     \n5\t33333333             \n```\n\n\n\n#### n N p\n\n```shell\ncs@debian:~/～$ sed '/这是i/{n;d;p}' test.txt\n11111111     \n这是i     \n这是a     \n33333333\ncs@debian:~/～$ sed '/这是i/{N;d;p}' test.txt \n11111111     \n这是a     \n33333333\n```\n\n>n匹配下一行  \n>\n>N匹配当前行和下一行\n\n\n\nn命令-->移动到匹配行的下一行  {n;操作;}\n\n```\n$ sed -i '/^ZOOKEEPER_PREFIX/{n;s#$#JAVA_HOME=/opt/jdk/jdk-11.0.12#;}' ./zkEnv.sh\n```\n\n>ZOOKEEPER_PREFIX=\"${ZOOBINDIR}/..\"\n>\n>JAVA_HOME=/opt/jdk/jdk-11.0.12\n>\n>#check to see if the conf dir is given as an optional argument\n\n\n\n上一行 (提供多的特征匹配)\n\n```\nsed -n '/^if.*JAVA_HOME/i\\JAVA_HOME=/opt/jdk/jdk-11.0.12' ./zkEnv.sh \n```\n\n>JAVA_HOME=/opt/jdk/jdk-11.0.12\n>\n>if [[ -n \"$JAVA_HOME\" ]] && [[ -x \"$JAVA_HOME/bin/java\" ]];  then\n>\n>​    JAVA=\"$JAVA_HOME/bin/java\"\n>\n>elif type -p java; then\n\n\n\n\n\n N 将下一行读入并附加到当前行后面放到当前空间模式\n\n 最后一行结束\n\n```shell\ncs@debian:~/～$ echo -e \"11111\\n2222222\\n3333\" | sed 'N;p'\n11111\n2222222\n11111\n2222222\n333\n```\n\n\n\n P模式空间第一行 N再次执行就到了3 ，隔行  \n\n```shell\ncs@debian:~/～$ echo -e \"11111\\n2222222\\n3333\\n44\\n55\\n6\" | sed 'N;P'\n1111111111\n2222222\n33333333\n44\n5555\n6\n```\n\n\n\n```\ncs@debian:~$ cat /etc/hosts\n127.0.0.1\tlocalhost\n192.168.56.1  master01 ui.k8s.cn k8s.org jenkins.k8s.cn  gogs.k8s.cn\n192.168.56.101  node01\n192.168.56.108  node02 \ncs@debian:/ip$ ip=192.168.56.108\ncs@debian:/ip$ cat hosts | sed -e  \"s/^\\(${ip}\\)\\([[:space:]]*\\)\\(.*\\)/\\3/g\" p\nnode01\n```\n\n\n\n```\ncs@debian:/ip$ ip=node02\ncs@debian:/ip$ cat hosts | sed -n \"s/\\(.*\\)\\([[:space:]]*\\)\\(${ip}\\)/\\1/g\"p\n192.168.56.108  \n```\n\n\n\n```shell\nzookeeper.connect=localhost:2181\n cat ./config/server.properties | sed -n 's/^zookeeper\\.connect=\\(.*\\)/\\1/'p\nlocalhost:2181\ncat ./config/server.properties | sed -n \"s#^listeners=PLAINTEXT://\\(.*\\)#\\1#\"p\n127.0.0.1:9092\n```\n\n\n\n​         \n\n\n\n####  D\n\n 删除模板块的第一行。\n\n\n\n####  s 替换\n\ns/指定字符/替换字符/\n\nrelative/directory/  改为/etc/supervisor.conf.d/\n\n```shell\ncs@debian:~/～$ sed -n   's/relative\\/directory\\//\\/etc\\/supervisor.conf.d\\//'p /etc/supervisord.conf\n```\n\n> -n选项和p命令一起使用表示只打印发生替换的行\n\n  \n\n 防火墙关闭\n\n```\ncat /etc/selinux/config | grep ^SELINUX= | sed  's/^SELINUX=.*/SELINUX=disabled/'\nsed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config\n```\n\n\n\n替换整行\n\n  ```shell\ncs@debian:~/～$  sed  -i  '2s/^.*$/xxxxx/'  file  \n  ```\n\n\n\n\n\n#### 截取 \n\n```shell\ncs@debian:~/～$ echo \"tinkle-app-style-0.0.1-SNAPSHOT.jar\" | sed 's/\\([a-z]-*\\)-[0-9].*/\\1/'\n```\n\n\n\n```shell\ncs@debian:~/～$  echo \"abcdef-shea-df\" | sed 's/\\(.*\\)-\\(.*\\)-\\(.*\\)/\\2/g'\n命令解释\n\\(.*\\)- : 表示第一个引号前的内容\n-\\(.*\\)-：表示两引号之间的内容\n-\\(.*\\)：表示引号后的内容\n\\2: 表示第二对括号里面的内容\n括号里的表达式匹配的内容，可以用\\1，\\2等进行引用，第n个括号对内的内容，就用\\n引用。\n这个命令的意思是：\n用\\2代表的第二个括号的内容（shea）去替换整个字符串，这样就得到了我们所需要的子字符串了。\n```\n\n\n\n```shell\ncs@debian:~$ echo \"etch-master.sh\" | sed 's/\\(.*\\)-\\(.*\\)\\.\\(.*\\)/\\2/g'\nmaster\ncs@debian:~$ echo \"gen-flanneld.sh\" | sed 's/^gen-\\(.*\\)\\..*/\\1/g'\nflanneld\n```\n\n\n\n```shell\ncs@debian:~$ systemctl status flanneld.service\n● flanneld.service - Flanneld overlay address etcd agent\n   Loaded: loaded (/opt/kubernetes/flanneld/flanneld.service; disabled; vendor p\n   Active: inactive (dead)\ncs@debian:~$ systemctl status flanneld.service | grep Active: | sed 's/.*(\\([a-z]*\\)).*/\\1/g'\ndead\ncs@debian:~$ systemctl status nginx | grep Active | sed 's/.*(\\(.*\\)).*/\\1/g'\nrunning\ncs@debian:~$ systemctl status kube-scheduler  |  sed -n 's/.*ctive:.*(\\(.*\\)).*/\\1/g'p\ndead\n```\n\n\n\n### 标记跳转\n\n删除前一行  (:a  ;ta) a标记，ta执行成功在跳转，类似循环\n\n   ```shell\ncs@debian:~/～$ sed -e :a -e '$!N;s/.*\\n\\(.*是.*\\)/\\1/;ta' -e 'P;D'  test.txt\n这是i\n这是a\n33333333 \n   ```\n\n\n\n前置 s/正则/\\1/    $最后一行 ！不进行 \n\n```shell\ncs@debian:~/～$ sed -e   '$!N;s/.*\\n\\(.*是i\\)/\\1/' -e 'p;d'  test.txt\n这是i\n22222222\n这是a\n33333333\ncs@debian:~/～$ sed -e   '$!N;s/.*\\n\\(.*是i\\)/\\1/' -e 'P;D'  test.txt\n这是i\n22222222\n这是a\n33333333\ncs@debian:~/～$ sed -e :a -e '$!N;s/.*\\n\\(.*是.*\\)/\\1/;ta' -e 'P;D'  test.txt\n这是i\n这是a\n33333333\n```\n\n\n\n\n\ntest\n\n```\n3d5f\n<Proxy>\n这是i\n<P>\n22222222\n</Proxy>\nabcde\n```\n\n替换Proxy 标签中间部分\n\n```shell\nsed '/<P/{:a;N;/<\\//!ba;s/>[^<].*</>\\n替换你们\\n</}'  test\n\n<p  :a;N;/<\\//!ba\n匹配<Proxy  :a标记  </ 结束匹配标记  !b （匹配不了，执行下句命令）\ns/>[^<]*</>\\n1234567\\n</\n>把中间内容<  替换指定内容\n```\n\n\n\n\n\n\n\n\n\n### 注释       \n\njoin.yaml\n\n```\n#kind: JoinConfiguration\n\nnodeRegistration:\n  name: debian  #节点名,master要能解析\n```\n\n#### 添加\n\n```\nsed -n '/debian/s/^/#/'p ./join.yaml\n```\n\n> \\#  name: debian  #节点名,master要能解析\n\n```\nsed -n 's/debian/#&/'p ./join.yaml\n```\n\n>  name: #debian  #节点名,master要能解析\n\n\n\n```\ncs@debian:~$ cat /etc/fstab | grep swap | sed '/swap/s/^/#/' \n## swap was on /dev/sda5 during installation\n##UUID=0fd6cee8-fdfa-459b-a7c6-1898ea2ade8e none            swap    sw              0       0\n[vagrant@master03 ~]$ cat /etc/fstab | grep swap | sed '/swap/s/^/#/' \n##/swapfile none swap defaults 0 0\n```\n\n\n\n```\nsed -i '/匹配字符串/,+4 s/^/#/' 文件名   #匹配行和下面4行\n```\n\n> +4表示匹配行和下面4行，一共5行注释\n\n\n\n\n\n#### 删除\n\n```\n#去掉所有行注释\nsed -n '/^#.*$/s/^#//'p ./join.yaml\n#去匹配行注释\nsed -n '/^#.*debian.*$/s/^#//'p ./join.yaml\n```\n\n>  name: debian  #节点名,master要能解析\n\n\n\n```shell\nsed 's/^#.*\\(en_US.UTF-8\\)/\\1/' test\n```\n\n\n\n\n\n```\n#去注释行\nsed -i '/^#/d' ./join.yaml\n#去空行和注释行\nsed -i '/^$/d;/^#/' ./join.yaml\n#空格字符\nsed -n  '/^[:space:]/##/' ./join.yaml\n```\n\n\n\n```\nsed -i '/匹配字符串/,+4 s/^#*//' 文件名\n\n[vagrant@node06 ~]$ grep 'HOME'  /etc/profile\nexport JAVA_HOME=/opt/mq/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n# echo $(sed -n  '/export\\ JAVA_HOME/,+2 s/export/#/'p /etc/profile)\n# sed -i '/export\\ JAVA_HOME/,+2 s/export/#/' /etc/profile\n```\n\n\n\n#### 乱码\n\n unknown directive\n\n```\nroot@racknerd-070082:~# cat -n -v /usr/local/openresty/nginx/conf/nginx.conf | grep 88\n    88\t M-BM-  M-BM-  M-BM-  M-BM- proxy_set_header Host 127.94.137.185;\n    \nroot@racknerd-070082:~# sed 's/\\xc2\\xa0/ /g' -i /usr/local/openresty/nginx/conf/nginx.conf\nroot@racknerd-070082:~# cat -n -v /usr/local/openresty/nginx/conf/nginx.conf | grep 88\n    88\t        proxy_set_header Host 127.94.137.185;\n\n```\n\n> cat -v #显示输出不打印M-等一些特殊字符\n>\n>  sed 's/\\xc2\\xa0/ /g' -i 文件路径  #把\"M-BM-\" 替换成空格\n\n![](/pics/cat-unknown.png)\n\n\n\n","tags":["sed"],"categories":["linux","shell"]},{"title":"磁盘或Inode使用率高","url":"//linux/shell/usage_high/","content":"\n\n\n## Inode\n\n**一个文件占用一个inode ，且inode是固定的，小文件过多就可能造成磁盘空间剩余挺多，但是inode耗尽的情况。**\n\n### df -i\n\n查看当前系统inode使用情况\n\n\n\n![](/pics/inode-1-2848.png)\n\n一级一级往下，统计inode文件数量。数字大就表示占用inode多\n\n<!--more-->\n\n如果命令在那个目录卡住,表示该目录,文件特多,ctrl+c停止,从该目录开始排查\n\n![](/pics/inode-3-4837.png)\n\n\n\n### wc  -l \n\n```\nfor i in /home/* ; do echo $i; find $i | wc -l; done\n```\n\n![](/pics/inode-2-4723.png)\n\n删除\n\n```\n find  /home/go/test/  -maxdepth 1  -type f   -mtime +0   -exec  rm  -rf  {} \\;\n```\n\n>+1 内表示 1 * 24 +24小时以外..\n>+0 才表示 0 * 24 +24小时以外\n>1 表示 1*24 + 24 到 24 之间..\n>0 表示 0*24 + 24 到 0 之间..\n\n\n\n修改大小\n\n```\n#卸载\numount /home/cs/go \n#建立文件系统，指定inode节点数 \nmkfs.ext3 /dev/sda6 -N 18276352 \n#修改fstab文件 \nvim /etc/fstab \n/dev/sda6 /home/cs/go ext3 defaults 1 2 \n#重新加载并检查挂载文件 \nmount -a \n#查看修改后的inode参数 \ndumpe2fs -h /dev/sda6 | grep node\n\n```\n\n\n\n\n\n多核cpu生成百万文件\n\n```\ncd ~/go/test\nseq 1000000 | xargs -i  -P 0 dd if=/dev/urandom of={}.txt bs=1024 count=1\n```\n\n\n\n## disk\n\n### df  -h\n\n排查目录\n\ndu -sh * | sort  -nr | head -5\n\n\n\n查找大于1G的文件\n\n```console-bash\nfind /  -type f -size +1G\n```\n\n\n\n 没有大文件,查看已经删除的文件\n\n```\nlsof -n |grep deleted\n```\n\n删除的文件有程序在使用,一直没有释放掉,kill掉pid\n\n\n\n## cpu\n\nps -aux | sort -k3nr | head -5\n\n\n\n### top  \n\n shift+p    切到cpu排序高到低\n\n### tid\n\nps -Lfp pid或者ps -mp pid -o THREAD，tid，time或者top -Hp pid\n\n```\nps -mp $pid -o THREAD，tid，time | sort -nr\n```\n\n\n\n#线程ID转成16进制用于查询\n\n```\n$ printf \"%x\\n\"  $tid\na221\n```\n\n### jstack\n\n```\njstack $pid | grep \"a221\"  -A  30\n```\n\n> -A  -B -C(大写)  后面都跟阿拉伯数字 \n>-A是显示匹配后和它后面的n行。after \n>-B是显示匹配行和它前面的n行。 before\n>-C是匹配行和它前后各n行。 context\n\n\n\n```\nps -ef | grep $name\njstack $pid >> ./dump.log\n```\n\n\n\n### Thread Dump\n\n***\\*kill -3 PID命令只能打印那一瞬间java进程的堆栈信息\\****，适合在服务器响应慢，cpu、内存快速飙升等异常情况下使用，可以方便地定位到导致异常发生的java类，解决如死锁、连接超时等原因导致的系统异常问题。**该命令不会杀死进程。**\n\n- tomcat  堆栈信息会打印在catalina.out\n- nohup启动 堆栈信息会在nohup.out\n\n\n\n## mem\n\n\n\n### free -m\n\n\n\nps -aux | sort -k4nr | head -5\n\n\n\n\n\n## 工具\n\narthas  \n\n下载 https://github.com/alibaba/arthas/releases\n\n文档 https://arthas.aliyun.com/doc/advanced-use.html\n\n\n\njvisualvm\n\n${JDK_HOME}\\bin\\jvisualvm\n\nhttps://www.cnblogs.com/mzq123/p/11166640.html","tags":["usage_high"],"categories":["linux","shell"]},{"title":"网络概念介绍","url":"//network/network/","content":"\n\n\n## http 应用层\n\n在两台计算机相互传递信息时，HTTP规定了每段数据以什么形式表达才是能够被另外一台计算机理解\n\n\n\n第一步：在浏览器输入内容（网址）\n\n第二步：浏览器把 域名 发送到DNS上 ，进行解析 得到IP之后链接到指定\n\n​    服务器 （服务器地址110,102.13.32:80 从浏览器到服务器使用底层TCP/IP）\n\n第三步：实现TCP/IP协议用Socket 用Socket套接字\n\n第四步：服务器端口80监听客户端链接（客户端到服务器端链接）\n\n\n\nHTTP 1.0 一个链接发送一个请求\n\nHTTP 1.1 一个链接发送多个请求\n\n\n\nget  向服务器 【索取】 数据的一种 请求\n\n  一般用于 获取/查询  资源信息\n\n  get用于信息获取，而且应该是安全（指非修改信息）和幂等\n\n  如：新闻头版不断更新，该操作被认为安全和幂等，从自身角度来看没有改变资源\n\n\n\npost  向服务器 【提交】 数据的一种 请求\n\n  一般用于 更新 资源信息\n\n​\tpost表示可能修改服务器上的资源请求\n\n​\t如：评论新闻，提交后站点资源不同，资源被修改\n\n\n\n表面现象\n\n​\tget请求数据附在URL上； post提交数据放在http包体中\n\n​\tget字节限制（1024） 实质是浏览器（和服务器）的限制 ； post理论没有限制\n\n​\tpost 安全（security）性比 get安全（security）性高\n\n\n\n\n\n## tpc/udp 传输层\n\n规定的是数据应该怎么传输才能稳定且高效的传递与计算机之间。\n\n\n\n| \\          | TCP                                    | UDP                                  |\n| ---------- | -------------------------------------- | ------------------------------------ |\n| 是否连接   | 面向连接                               | 面向非连接                           |\n| 传输可靠性 | 可靠                                   | 不可靠                               |\n| 应用场合   | 传输大量的数据，对可靠性要求较高的场合 | 传送少量数据、对可靠性要求不高的场景 |\n| 速度       | 慢                                     | 快                                   |\n\n\n\n## https\n\nHTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议","tags":["tcp","http"],"categories":["network"]},{"title":"npm初始","url":"//lang/npm/npm初始/","content":"\n\n\nhttps://www.npmjs.com/package/npm\n\n## 源加速\n\n设置\n\n```\necho \"registry = https://registry.npm.taobao.org\">>~/.npmrc\n```\n\n查看当前源\n\n```\nnpm config get registry\n```\n\n<!--more-->\n\n## 使用\n\n### 全局安装(-g)\n\n typescript\n\n```\nnpm install -g typescript\n```\n\n>/opt/node/bin/tsc -> /opt/node/lib/node_modules/typescript/bin/tsc\n>/opt/node/bin/tsserver -> /opt/node/lib/node_modules/typescript/bin/tsserver\n>+ typescript@4.7.3\n>added 1 package from 1 contributor in 2.252s\n>\n\n\n\n### 卸载\n\n```\nnpm uninstall -g  typescript\n```\n\n\n\n- **`i`** 是 **`install`** 的简写\n- **`-g`** 是全局安装，不带 **`-g`** 会安装在个人文件夹\n- **`-S`** 与 **`--save`** 的简写，安装包信息会写入 **`dependencies`** 中;生产阶段,项目运行时的依赖\n- **`-D`** 与 **`--save-dev`** 的简写，安装包写入 **`devDependencies`** 中;开发阶段,只在开发阶段起作用,例如代码提示工具\n\n\n\n## 后台运行\n\n### pm2\n\n```shel\nnpm install pm2  -g \n```\n\n>pm2 start run.js --name my-api # 命名进程\n>pm2 list               # 显示所有进程状态\n>pm2 monit              # 监视所有进程\n>pm2 logs               #  显示所有进程日志\n>pm2 stop all           # 停止所有进程\n>pm2 restart all        # 重启所有进程\n>pm2 reload all         # 0秒停机重载进程 (用于 NETWORKED 进程)\n>pm2 stop 0             # 停止指定的进程\n>pm2 restart 0          # 重启指定的进程\n>pm2 startup            # 产生 init 脚本 保持进程活着\n>pm2 web                # 运行健壮的 computer API endpoint (http://localhost:9615)\n>pm2 delete 0           # 杀死指定的进程\n>pm2 delete all         # 杀死全部进程\n\n\n\n```shell\ncat >run.js<<EOF\nconst { exec } = require('child_process')\nexec('hexo server',(error, stdout, stderr) => {\n    if(error){\n            console.log('exec error: ${error}')\n            return\n    }\nconsole.log('stdout: ${stdout}')\nconsole.log('stderr: ${stderr}')\n})\nEOF\n\npm2 start run.js\n\n```\n\n","tags":["源"],"categories":["lang","npm"]},{"title":"vi/vim基本命令","url":"//linux/shell/vim/","content":"\n\n\n![](/pics/vim-4855.png)\n\necs 退出 **编辑状态**  到  **命令状态** \n\n### 插入\n\n在光标前 `i`\n\n移到在行首 `I`\n\n光标后 `a`\n\n当前行尾 `A`\n\n当前行之下另起一行 `o` 进入编辑状态\n\n当前行之上另起一行 `O`\n\n##### 替换\n\n当前字符 `r`\n<!--more-->\n\n当前及其后,直到按Esc `R`\n\n#####  粘贴\n\n 剪切  `dd`当前行  ,移动到目标行 `p`粘贴\n\n复制  `yy`当前行  ,`p`粘贴  \n\n复制2个单词 `y2w`  向下2行 `y2j`  向上2行 `y2k`\n\n寄存器 `:reg [args]`  **+**剪切板\n\n复制当前行 `\"+yy`   `\"+nyy`\n\n剪切板内容粘贴到光标后 `\"+p`\n\n\n\n##### 搜索\n\n跳到指定行(21行) `:21`  或 `21G`   \n\n返回原光标处 ` ``  `\n\n##### 移动\n\n左`j` 下`j` 上`k` 右`l`\n\n单词末尾 `e`\n\n2个单词   前移  `2b`  后移 `2w`\n\n行首  `0` 或 `^`           行尾 `$`  2行行尾 `2$`\n\n上行(减号)  `-`   下行  `+`\n\n\n\n跳到对应括号(代码块)  `%`\n\n### 恢复\n\n撤销(本次编辑模式没有改动) `u`\n\n恢复上一步撤销  `ctrl+r`\n\n### 删除\n\n删除字符 `x`\n\n删除当前行及后面n-1行  `ndd` \n\n\n\n### 退出\n\n保存 `:wq` 或 `:x`\n\n强制退出 `:q!`\n\n\n\n\n\n### 编辑压缩包内文件\n\n 打开压缩包 进入文件可以编辑  （/name ）  **待验证**\n\n\n\n\n\nLANG=”Zn_CN.UTF-8”  #临时设置语言\n\necho $LANG #当前系统设置编码 \n","tags":["vim"],"categories":["linux","shell"]},{"title":"find查找搜索","url":"//linux/shell/find/","content":"\n\n\n查找\n\n> find [OPTIONS] [查找起始路径] [查找条件] [处理动作]\n\n[OPTIONS]  忽略\n\n\n\n### 路径\n\n  相对    `./`\n\n  绝对   `/`\n\n### 条件\n\n#### 名称\n\n**name**    `find  /  -name   mysql`\n\n**iname**   `find  /  -iname  cmake`   *忽略大小写*\n\n**regex**  `find / -regex  /docker*`  正则模糊查询\n\n#### size 大小\n\n<!--more-->\n\n**size**   `find  / -size  +20M` \n\n *+* 大于    *-*小于    *K*  *M*  *G*\n\n`   20M`       (20-1,20]\n\n`-  20M`    [0,20-1]\n\n`+ 20M`    (20,+∞]\n\n#### 时间\n\n**atime**  文件最后访问  \n\n*  [#, #-1) ：最后访问时间在#天前（大于等于#天前，小于#-1天前）\n\n  等价于最后访问时间与当前的时间差 大于 (#-1)*24小时，小于等于 #*24小时\n\n\n*  (#, 0] ：最后访问时间在#天以内，不包括24小时前的那一刻。\n\n等价于最后访问时间与当前的时间差小于 #*24小时\n\n*  (oo, #-1] ：最后访问时间在#-1天以前的。包括#-1天前\n\n等价于最后访问时间与当前的时间差大于等于 #*24小时\n\n```\n#查找最近10天内被访问过的所有文件\n[root@centos7 ~]# find . -type f -atime -10\n \n#查找超过10天内被访问过的所有文件\n[root@centos7 ~]# find . -type f -atime +10\n \n#查找访问时间超过20分钟的所有文件\n[root@centos7 ~]# find . -type f -amin +20\n \n#找出比mingongge修改时间更长的所有文件\n[root@centos7 ~]# find . -type f -newer mingongge\n```\n\n**mtime**  文件最后修改\n\n**ctime**  文件最后改变\n\n\n\n```\n\nsudo find /boot/burg/themes/  -name '[^Metro]*' | xargs rm -rf\n\n```\n\n#### -path  排除路径\n\n\n\n#### -type  类型\n\n   d 目录  f文件 \n\n\n\n\n\n#### -prune 忽略\n\n配备到path路径，则跳过该目录\n\n```\n\nsudo find  /  -path \"/home/cs/lua-5.3.4\"  -prune -o -type f    -name  lua*\n\n```\n\n\n\n​    \n\n#### -o  or \n\n```shell\ncs@debian:~/oss/test$ find ./ -path ./cs -prune -o -type f -name *.js -print\n./cs1/c.js\n./cs2/s.js\ncs@debian:~/oss/test$ find ./ \\( -path ./cs -o -path ./cs1 \\) -prune -o -type f -name *.js -print\n./cs2/s.js\n```\n\n> 多个目录, 括号前后空格,\\转义\n\n\n\n#### -a and\n\n```\nfind   ./cs2  ./cs1   -type f  -name *js -a  -name c.*  -print\n./cs2/c.ejs\n./cs1/c.ejs\n./cs1/c.js\n```\n\n","tags":["find"],"categories":["linux","shell"]},{"title":"top排查服务器","url":"//linux/shell/top/","content":"\n\n\ntop -M  \n\ntop -c \n\ntop -p $pid\n\n![](/pics/top-4834.png)\n\n>排序默认从大到小,R反向排序\n>\n>M：根据内存排序\n>\n>P：根据CPU使用排序\n>\n>T：根据使用时间排序\n>\n>\\>：向右移动一列排序\n>\n><:向左移动一列排序\n\n界面shift+m (根据内存排序)\n\n![](/pics/top-M-5210.png)\n\n\n\n### 第一行top\n\n等同命令uptime\n\n```\ncs@debian:~/go$ uptime\n 22:00:22 up  8:59,  1 user,  load average: 0.13, 0.32, 0.36\n```\n\n<!--more-->\n\n>系统当前时间 up 系统到目前为止运行的时间，\n>\n> 当前系统的登陆用户数量，\n>\n>load average后面的三个数字分别表示距离现在一分钟，五分钟，十五分钟的负载情况\n\nload average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了\n\n\n\n\n\n\n\n### 第二行 Tasks\n\n```\nTasks: 241 total,   1 running, 240 sleeping,   0 stopped,   0 zombie\n```\n\n>tasks表示任务（进程），214则表示现在有241个进程，\n>\n>running  其中处于运行中的有1个，\n>\n>sleeping  240个在休眠(挂起)，\n>\n>stopped  停止的进程数为0，\n>\n>zombie   僵尸的进程数为0个\n\n\n\n### 第三行%Cpu\n\n```\n%Cpu(s):  3.6 us,  0.6 sy,  0.0 ni, 95.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n```\n\n>us——用户空间(user)占用cpu的百分比\n>sy——内核空间(system)占用cpu的百分比\n>ni——改变过优先级(niced)的进程占用cpu的百分比\n>id——空闲（idolt）CPU百分比\n>wa——IO等待(wait)占用cpu的百分比\n>hi——IRQ 硬中断(Hardware)占用cpu的百分比\n>si——软中断（software）占用cpu的百分比\n>st——被hypervisor偷去的时间\n\n\n\n### 第四五行 kib内存\n\n```\nKiB Mem : 16257204 total, 12933272 free,  1288736 used,  2035196 buff/cache\nKiB Swap:  7812092 total,  7812092 free,        0 used. 14425716 avail Mem \n```\n\n>Mem：物理内存总量（16G）\n>free: 空闲内存总量(1G)\n>used: 使用中的内存总量\n>buff/cache: 用作内核缓存的内存量\n\n>Swap： 交换区总量\n>free：空闲交换区总量\n>used： 使用的交换区总量\n>avail Mem：表示可用于进程下一次分配的物理内存数量，这个大小一般比free大一点，因为除了free的空间外，系统还能立即释放出一些空间来\n\n\n\n\n\n### 第七行 进程信息区\n\n```\n PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND  \n```\n\n>PID — 进程id\n>USER — 进程所有者\n>PR — 进程优先级\n>NI — nice值。负值表示高优先级，正值表示低优先级\n>VIRT — 进程使用的`虚拟内存`总量，单位kb。VIRT=SWAP+RES\n>RES — `常驻内存`,进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\n>SHR — `共享内存`大小，单位kb\n>S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程\n>%CPU — 上次更新到现在的CPU时间占用百分比\n>%MEM — 进程使用的物理内存百分比\n>TIME+ — 进程使用的CPU时间总计，单位1/100秒\n>COMMAND — 进程名称（命令名/命令行）\n\n\n\n### 其他\n\n```\ncs@debian:~/go$ sudo netstat -anp|grep 12347\ntcp        0      0 0.0.0.0:4000            0.0.0.0:*               LISTEN      12347/hexo \n```\n\n\n\n```\ncs@debian:~/go$ lsof -i:4000\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nhexo    12347   cs   21u  IPv4 324187      0t0  TCP *:4000 (LISTEN)\ncs@debian:~/go$ ps -ef|grep 12347\ncs       12347  1640  0 21:56 pts/2    00:00:03 hexo\ncs       13306  1622  0 22:23 pts/0    00:00:00 grep 12347\n```\n\n\n\n列出所有正在运行的java进程\n\n```\ncs@debian:~/go$ jps\n13600 Jps\n```\n\n>| 参数 | 说明                            |\n>| ---- | ------------------------------- |\n>| `-l` | 输出主类全名或jar路径           |\n>| `-q` | 只输出LVMID                     |\n>| `-m` | 输出JVM启动时传递给main()的参数 |\n>| `-v` | 输出JVM启动时显示指定的JVM参数  |\n\n\n\n\n\n\n","tags":["shell"],"categories":["linux","shell"]},{"title":"初识jvm","url":"//lang/gc/","content":"\n## 调优参数\n\n选项 Xms,Xmx,newSize,MaxSize ,PermSize, MaxPermSize\n\nXms(young和old区使用大小)\n\nXmx(young和old区最大承受大小)\n\nnewSize(young区使用大小)\n\nMaxSize(young区最大承受大小)\n\nPermSize(持久区使用大小)\n\nMaxPermSize(持久区最大使用大小)\n\n<!--more-->\n\nsuivivorRatio(设置Eden和survivor比例  默认是8:1)\n\n-Xms：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。\n-Xmx：表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。\n\n-XX:newSize：表示新生代初始内存的大小，应该小于-Xms的值；\n-XX:MaxnewSize：表示新生代可被分配的内存的最大上限；当然这个值应该小于-Xmx的值；\n\n-XX:PermSize：表示非堆区初始内存分配大小（方法区）\n-XX:MaxPermSize：表示对非堆区分配的内存的最大上限（方法区）。\n\n\n\n## 工作流程\n\n![](/pics/jvm-work-4037.png)\n\n1、编译阶段：首先.java经过javac编译成.class文件\n\n2、加载阶段：然后.class文件经过类的加载器加载到JVM内存。(装载、连接、初始化)\n\n-  先把class的信息读到内存来\n-  会对class的信息进行验证、为类变量分配内存空间并对其赋默认值\n-  执行初始化静态块内容，并且为静态变量进行真正的赋值操作\n\n3、解释阶段：class字节码经过字节码解释器解释成系统可识别的指令码。\n\n4、执行阶段：系统再向硬件设备发送指令码执行操作。\n\n\n\n\n\n## 数据区域\n\n![](/pics/jvm-area-4346.png)\n\n Matespace(元空间)在本地内存区域\n\n> -XX:MetaspaceSize，初始空间大小\n>\n> -XX:MaxMetaspaceSize，最大空间，默认是没有限制的\n\n\n\n## 垃圾回收区域\n\n![](/pics/gc-area-4008.png)\n\n### Yong Generation\n\n负责新接收的对象\n\n默认区域划分8:1\n\n#### Eden   80%\n\nEden区域触发第一次GC\n\n#### Survivor \n\n##### From 10%\n\n上一次MinorGC存活者,等待下次扫描\n\n##### To 10%\n\n一次MinorGC过程后的存活者\n\nMinorGC过程\n\n1. eden,survivorFrom复制到survivorTo,年龄加1\n2. 清空(eden,survivorFrom) \n3. survivorTo 与survivorFrom互换\n\nGC过程中to区满后(或者达到年龄标准,无法储存的某个对象)就移到old区\n\n### Old Generation\n\n存放yong多次GC后仍存活的对象\n\nold空间不足时会触发MajorGC(Full GC)\n\nMajorGC过程\n\n- 先扫描全部,标记存活对象,清除没有标记的对象\n\n### Permanent Generation\n\n静态文件(java类,方法,元数据)\n\n\n\n## 垃圾回收算法\n\n![](/pics/gc-yg-3223.png)\n\n\n\nhttps://zhuanlan.zhihu.com/p/343746128\n\n\n\n\n\n\n\n![](/pics/new-area-3239.png)\n\n","tags":["jvm"],"categories":["lang","gc"]},{"title":"markdown画图","url":"//tool/text/markdown/flow/","content":"\ndoc https://mermaid.js.org/intro/\n\n[**Live Editor!**](https://mermaid.live/)\n\n## 流程图\n\n```mermaid\ngraph LR;\nSTART(开始)-->准备材料-->编写博客-->推送文章-->END(结束)\n```\n\n\n\n\n\n```mermaid\ngraph TB;\nsubgraph 前置\nA(准备写博客)-->B{想了很久}\nend\nB--N-->C[放弃]\nB--Y-->F{思考流程}\nsubgraph 工作中\nF-.圆形流程图.->J((圆形流程))\nF-.右向旗帜流程图.->H>右向旗帜流程]\nend\nH---I(测结束)\nC---I(结束)\nJ---I(结束)\n```\n\n<!--more-->\n\n\n\n```flow\nstart=>start: 接收到消息\ninfo=>operation: 读取信息\ncd=>condition: 是否存在\nsetC=>subroutine: 设置缓存\ngetC=>operation: 读取缓存\nxx=>inputoutput: 返回信息\nend=>end: 处理结束\n\nstart->info->cd\ncd(yes)->getC->xx\ncd(no)->setC->xx\nxx->end\n```\n\n\n\n![md_flow](/pics/md_flow.png)\n\n\n>基本语法：定义模块 id=>关键字: 描述 （“描述”的前面必须有空格，“=>” 两端不能有空格）\n>\n>关键字：\n>\n>start 流程开始，以圆角矩形绘制\n>\n>operation 操作，以直角矩形绘制\n>\n>condition 判断，以菱形绘制\n>\n>subroutine 子流程，以左右带空白框的矩形绘制\n>\n>inputoutput 输入输出，以平行四边形绘制\n>\n>end 流程结束，以圆角矩形绘制\n>\n>定义模块间的流向：\n>\n>模块1 id->模块2 id ：\n>\n>一般的箭头指向条件模块id (描述)->模块id(direction) ：条件模块跳转到对应的执行模块，并指定对应分支的布局方向\n\n\n\n\n\n## 泳道图\n\n\n\n```mermaid\nsequenceDiagram\nTitle: 建造者模式\ndirector->>builder: 指导\nbuilder ->> building: 建造\n```\n\n\n\n```mermaid\nsequenceDiagram\nTitle: 写markdown设计文档\nparticipant auther as 你\nparticipant brower as 浏览器\nparticipant soft as typora软件\nauther->>brower: 打开浏览器\nauther -x +brower: 输入编辑器的官网地址\nbrower --x -auther: 加载官网地址内容\nauther ->> +brower: 点击下载\nbrower ->> -brower: 下载\nauther ->> soft: 打开\nloop 循环写，直到字数比较满意\nauther ->> soft: 编写\nend\nalt 发现网上有更好的文章\nauther ->> soft: 关闭\nelse 没有我的想法好\nauther ->> soft: 写更好的文章\nend\npar 并行执行\nauther ->> soft : 编写多篇文档\nend\nopt time > 24：00\nauther ->> soft : 关闭，去睡觉\nend\nNote left of auther : 一个技术大佬\nNote over brower,soft : 助力你进步的工具\n```\n\n\n\n| 类型 | 描述                             |\n| ---- | -------------------------------- |\n| ->   | 无箭头的实线                     |\n| –>   | 无箭头的虚线                     |\n| ->>  | 有箭头的实线(主动发出消息)       |\n| –>>  | 有箭头的虚线(响应)               |\n| -x   | 末端为X的实线(主动发出异步消息)  |\n| –x   | 有箭头的实线(以异步形式响应消息) |\n\n>alt 可以理解为可替代的方案，可能的情况\n>\n>opt可以理解为一个if语句，满足条件下执行的操作\n\n\n\n## UML类图\n\n\n\n```mermaid\nclassDiagram\nclass classA{\nint\tid\n-List<String> msg\ngetId(int id) List~int~\n}\nclassA : setMessages(List~string~ messages)\n```\n\n\n\n\n```mermaid\nclassDiagram\nclass Shape{\n    <<interface>>\n    noOfVertices\n    draw()\n}\nclass Color{\n    <<enumeration>>\n    RED\n    BLUE\n    GREEN\n    WHITE\n    BLACK\n}\n```\n\n\n\n\n```mermaid\nclassDiagram\n    classA --|> classB : 继承\n    classC --* classD : 组合\n    classE --o classF : 聚合\n    classG --> classH : 单向关联\n    classI -- classJ : 双向关联\n    classK ..> classL : 依赖\n    classM ..|> classN : 接口实现\n    classO .. classP : Link(Dashed)\n```\n\n\n\n\n\n```mermaid\n   classDiagram\n    Customer \"1\" --> \"*\" Ticket\n    Student \"1\" --> \"1..*\" Course\n    Galaxy --> \"many\" Star : Contains\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["flow","mermaid"],"categories":["markdown"]},{"title":"zk选举","url":"//services/zookeeper/选举机制/","content":"\n#### 核心机制\n\n- 逻辑时间 epoch ,判断是否是同一轮投票(网络原因导致投票广播信息滞后)\n- 事物ID(Zxid),事物ID最大的数据最新  \n- 服务器ID(myid),数值大的权重大  \n\n<!--more-->\n\n```flow\nstart=>start: 选self\ninfo=>operation: 广播信息\nj1=>condition: 投票结果状态\n\nj2=>condition:  是否过时\nyj2=>operation: 清空投票信息\nnj2=>operation: 更新投票信息\n\nj3=>condition: 是否同一轮\nyj3=>operation: 比较投票信息\nnj3=>operation: 已完成投票信息\n\nj=>condition:  是否形成共识\nend=>end: 退出\n\nstart->info->j1\nj1(yes)->j3\nj1(no)->j2\n\nj2(yes)->yj2(right)->nj2\nj2(no)->nj2\n\nj3(yes)->yj3->j\nj3(no)->nj3->j\n\nnj2->yj3->j\nj(no)->info\nj(yes)->end\n\n```\n\n\n\n\n\n####  比较逻辑\n\n![](/pics/zk_flow_2232.png)\n\n\n\n同一轮,对投票信息(epoch,zxid,myid)进行比较(zxid,myid)\n\n是否过时:\n\n*过时*(小于),更新使用self信息(epoch,zxid,myid)\n\n非过时(大于),清空信息,更新(epoch)进行比较(zxid,myid)\n\n  \n\n根据以下规则,超过半数收到相同投票选出leader\n\n> 逻辑时钟小的选举结果被忽略，重新投票\n>\n> 统一逻辑时钟后，事物ID大的胜出\n>\n> 事物ID相同的情况下，服务器ID大的胜出\n\n","tags":["服务发现","选举"],"categories":["services","zookeeper"]},{"title":"stream写法","url":"//lang/java/stream/","content":"\n\n\n\n\n\n\n\n\n\n\n```\n  public static void main(String[] args) {\n    ArrayList<String> list = new ArrayList<>(Arrays.asList(\"I\", \"love\", \"you\", \"too\"));\n    for(String str : list){\n        if(str.length()>3)\n            System.out.println(str);\n    }\n    list.forEach(str->System.out.println(str));\n    list.stream().filter(str->str.length()>3).forEach(System.out::println);\n  }\n```\n\n>用stream的filter来替代if/else业务逻辑\n\n\n\n```\nfor(int i=0;i<10;i++){\n    if(....){\n      //...........\n    }else{\n        //.......\n    }\n}\n\nlist.stream().filter().limit(10).foreach();\n```\n\n\n\n## Stream\n\n![](/pics/stream-1.png)\n\n<!--more-->\n\n### 流创建\n\n```\n\nList<String> list = Arrays.asList(\"hello\",\"world\",\"stream\");\n//创建顺序流\nStream<String> stream = list.stream();\n//创建并行流\nStream<String> parallelStream = list.parallelStream();\n```\n\n\n\n#### 静态方法\n\n**`of()、iterate()、generate()`**\n\n```\nStream<String> stream1 = Stream.of(\"I\", \"love\", \"you\", \"too\");\nstream1.forEach(System.out::println);\n\nStream<Integer> stream2 = Stream.iterate(0, i -> i + 2).limit(3);\nstream2.forEach(System.out::println);\n\nStream<Boolean> stream3 = Stream.generate(new Random()::nextBoolean).limit(3);\nstream3.forEach(System.out::println);\n```\n\n\n\n并行流  多线程  把一个内容分成多个数据块 不同线程分别处理每个数据块的流,最后合并(*无序数据处理*)\n\n```\nOptional<Integer> findFirst = list.stream().parallel().filter( x -> x>4 ).findFirst();\n```\n\n> 可以通过`parallel()`把顺序流转换成并行流\n\n![](/pics/stream-type2.png)\n\n\n\n### 中间操作\n\n#### 无状态（Stateless）\n\n指元素的处理不受之前元素的影响\n\n##### filter\n\n**筛选，是按照一定的规则校验流中的元素，将符合条件的元素提取到新的流中的操作**\n\n```\nlist.stream().filter(str->str.length()>3).forEach(System.out::println);\n```\n\n相当于if\n\n##### 映射(map、flatMap、peek)\n\n###### map\n\n```\n List<String> out =  list.stream().\n        map(String::toUpperCase).\n        collect(Collectors.toList());\n System.out.println(out);//[I, LOVE, YOU, TOO]\n```\n\n\n\n```\n    List<Product> list = new ArrayList<>();\n    Test t = new Test();\n\n    list.add(t.new Product(1, \"domestic phone\", new BigDecimal(6899.99)));\n    list.add(t.new Product(2, \"overseas notebook\", new BigDecimal(14989.98)));\n\n    String out =  list.stream().\n     //map(a->a.name.split(\" \")[1]).//phone&&notebook\n    map(a->a.name.replaceAll(\" \", \"-\")).//domestic-phone&&overseas-notebook\n    collect(Collectors.joining(\"&&\"));\n    System.out.println(out);\n```\n\n###### flatMap\n\n```\n    List<String> list = Arrays.asList(\"a:b:c\", \"1:3:5\");\n    List<String> listNew = list.stream().\n            flatMap(s -> Arrays.stream(s.split(\":\")) ).\n            collect(Collectors.toList());\n \n    System.out.println(\"处理前的集合：\" + list);\n    System.out.println(\"处理后的集合：\" + listNew);\n```\n\n>处理前的集合：[a:b:c, 1:3:5]\n>处理后的集合：[a, b, c, 1, 3, 5]\n\n\n\n###### peek\n\n```\n    Stream<String> stream = Stream.of(\"hello\", \"world\");\n    stream.peek(System.out::println).collect(Collectors.toList());\n```\n\n\n\n终端操作。通常分为 **最终的消费** （`foreach` 之类的）和 **归纳** （`collect`）两类。\n\n\n\n#### 有状态（Stateful）\n\n指该操作只有拿到所有元素之后才能继续下去\n\n###### distinct\n\n使用hashCode（）和equals（）方法来获取不同的元素\n\n```\nStream<String> stream = Stream.of(\"1\", \"3\",\"4\",\"10\",\"4\",\"6\",\"23\",\"3\");\nstream.distinct().forEach(System.out::println);\n\n```\n\n\n\n###### sorted\n\n```\n    HashMap<Integer, String> map = new HashMap<>();\n    map.put(1,\"phone\");\n    map.put(2,\"notebook\");\n    map.entrySet().stream().sorted(\n                    Collections.reverseOrder(Map.Entry.comparingByKey())//倒序\n                    //Comparator.comparing(e -> e.getKey())//正序\n            ).forEach(System.out::println);\n```\n\n\n\n###### skip\n\n```\n    Stream<Integer> stream = Stream.of(3,1,10,16,8,4,9);\n    stream.limit(3).skip(2).forEach(System.out::print);\n```\n\n>limit(3)  Iloveyou\n>\n>skip(2)  you\n\n\n\n### 终结操作\n\n#### 短路（Short-circuiting）\n\n指遇到某些符合条件的元素就可以得到最终结果\n\n\n\n###### anyMatch\n\nStream 中只要有一个元素符合传入的 predicate，返回 true\n\n```\nstream.anyMatch(s->s==2)\n```\n\n###### allMatch\n\nStream 中全部元素符合传入的 predicate，返回 true\n\n\n\n###### noneMatch\n\nStream 中没有一个元素符合传入的 predicate，返回 true\n\n\n\n###### findFirst\n\n用于返回满足条件的第一个元素\n\n```\nArrayList<String> list = new ArrayList<>(Arrays.asList(\"I\", \"love\", \"you\", \"too\"));\nSystem.out.println(\n\tlist.stream().filter(s-> s.length()>2).findFirst().get()\n);\n\n```\n\n###### findAny\n\n返回流中的任意元素\n\n```\n    System.out.println(\n            list.parallelStream().filter(s-> s.length()>2).findAny().get()\n    );\n```\n\n>love 或 you\n\n并行数据多返回满足第一个\n\n\n\n#### 非短路（Unshort-circuiting）\n\n指必须处理完所有元素才能得到最终结果\n\n\n\n###### reduce\n\nreduce操作效率不高，因为它创建了大量的中间`String`和`StringBuilder`\n\n```\n list.stream().\n \t \tmap(a->a.name.replaceAll(\" \", \"-\")).\n\t\treduce((str1, str2) -> str1 + \"&&\" + str2).get();\n```\n\n>等价 collect(Collectors.joining(\"&&\"))\n\n\n\n###### toArray\n\n```\n    Product[] array = list.stream().toArray(Product[]::new);\n   //Arrays.stream(array).sorted(Comparator.comparing(s>s.getId())).forEach(System.out::println);\n    Arrays.stream(array).filter(s->s.id>1).forEach(System.out::println);\n```\n\n","tags":["stream"],"categories":["lang","java"]},{"title":"go语法规则","url":"//lang/go/","content":"\n\n\n###  声明赋值\n\n**:=**  临时,局部变量\n\n###  方法首字母\n\n类似java,不等同(private 只能当前类访问)\n\n**public** 大写 跨包调用\n\n**private**小写 包内调用\n\n<!--more-->\n\n```go\n##f2.go\npackage t1\n\nimport (\n\t\"fmt\"\n)\n\nvar gloal string = \" 全局\"\n//...可变参函数\nfunc Tfun2(a ...string) (string, string) {\n\ttemp := \" 局部\"\n\tnf(a)\n\treturn a[0] + gloal, a[1] + temp\n}\n\nfunc nf(a []string) {\n    //for i := range a \n    //for _, v := range a \n\tfor i, v := range a {\n\t\tif a[i] == \"dd\" {\n\t\t\tfmt.Println(a, v)\n\t\t}\n\t}\n}\n##f1.go\npackage t1\n\nimport (\n\t\"fmt\"\n)\n\nfunc Tfun1() {\n\ta, b := Tfun2(\"a is\", \"b is\", \"dd\")\n\tfmt.Println(a, b)\n}\n\n##main.go\npackage main\n\nimport (\n\t\"fmt\"\n\tt1 \"go_learn/test\"\n)\n\nfunc main() {\n\tmf()\n}\n\nfunc mf() {\n\tfmt.Println(\"main调用包test fun1\")\n\tt1.Tfun1() //两个返回值\n}\n```\n\n\n\n","tags":["规则","语法"],"categories":["lang","go"]},{"title":"ps","url":"/linux/shell/ps/","content":"\nps (process status) 命令用于显示当前进程的状态，类似于 windows 的任务管理器\n\n\n\n### 查找指定进程\n\n```\n$ ps -ef | grep  key\ncs        4565  4533  0 21:14 pts/2    00:00:00 /opt/ELK/elasticsearch-7.17.1/modules/x-pack-ml/platform/linux-x86_64/bin/controller\n```\n\n> key 运行进程的关键字 (如:ps -ef | grep  tomcat)\n>\n> UID 启动进程的用户名\n>\n> PID  进程pid\n>\n> PPID \n>\n> C \n>\n> STIME 开始启动时间 \n>\n> TTY  终端号\n>\n> TIME  运行时间\n>\n> CMD   启动进程的命令\n\n<!--more-->\n\n### 查找进程使用情况\n\n```\nps -aux | grep Typora\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\ncs  7458  1.2  0.8 4913400 139224 ?      Sl   15:11   0:08 /usr/share/typora/Typora /home/cs/go/ps.md\n\n```\n\n- USER: 行程拥有者\n- PID: pid\n- %CPU: 占用的 CPU 使用率\n- %MEM: 占用的记忆体使用率\n- VSZ: 占用的虚拟记忆体大小\n- RSS: 占用的记忆体大小\n- TTY: 终端的次要装置号码 (minor device number of tty)\n- STAT: 该行程的状态:\n  - D: 无法中断的休眠状态 (通常 IO 的进程)\n  - R: 正在执行中\n  - S: 静止状态\n  - T: 暂停执行\n  - Z: 不存在但暂时无法消除\n  - W: 没有足够的记忆体分页可分配\n  - <: 高优先序的行程\n  - N: 低优先序的行程\n  - L: 有记忆体分页分配并锁在记忆体内 (实时系统或捱A I/O)\n- START: 行程开始时间\n- TIME: 执行的时间\n- COMMAND:所执行的指令\n\n\n\n#### 内存\n\n```\n$ ps -aux | sort -k4nr | head -3\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\ncs   2119  4.8  1.6 1183553740 265420 ?   Sl   14:02   4:06 /opt/google/chrome/chrome -- ...\ncs   1660  5.1  1.5 34393500 254380 ?     SLl  13:59   4:30 /opt/google/chrome/chrome --...\ncs   1753  1.0  1.4 1179343396 242272 ?   Sl   13:59   0:57 /opt/google/chrome/chrome --...\n```\n\n>a all所有\n>\n>u userid,该进程用户id\n>\n>x 所有程序,不已终端区分\n>\n>sort 排序\n>\n>k 代表从第几列开始\n>\n>4n 4列(%MEM)开始\n>\n>r 反向(reverse) ,默认从小到大\n>\n>head  头几列(-3 ,显示前3列)\n\n\n\n#### cpu\n\n```\n$ ps -aux | sort -k3nr | head -3\n```\n\n\n\n#### lsof\n\n**查看端口占用**\n\n```\n❯ sudo lsof -i:80\nCOMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnginx   779   root   15u  IPv4  23975      0t0  TCP *:http (LISTEN)\nnginx   780 nobody   15u  IPv4  23975      0t0  TCP *:http (LISTEN)\n❯ sudo lsof -i:3305\nCOMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nmysqld  2160 mysql   52u  IPv6  29109      0t0  TCP *:3305 (LISTEN)\n```\n\n\n\n#### netstat\n\n**查看所有端口和PID号**\n\n```\n❯ sudo netstat -tanlp | grep -I  2160\ntcp6       0      0 :::3305                 :::*                    LISTEN      2160/mysqld         \n```\n\n> -a或--all：显示所有连线中的Socket；\n>\n> -t或--tcp：显示TCP传输协议的连线状况；\n> -u或--udp：显示UDP传输协议的连线状况；\n>\n> -n : 拒绝显示别名，能显示数字的全部转化为数字\n>\n> -l或--listening：显示监控中的服务器的Socket；\n>\n> -p或--programs：显示正在使用Socket的程序识别码和程序名称；\n","tags":["shell"],"categories":["linux","shell"]},{"title":"md语法","url":"//tool/text/markdown/mdgrammar/","content":"\n<p id=\"id-sample\" hidden/>\n\n/hexo/_config.yml \n\n```\npermalink: :title//\n```\n\n### 站内文章链接\n\n#### 绝对路径\n\n/_posts\n\n```\n$ tree -L 2 ./_posts/\n./_posts/\n├── linux\n│   ├── debian\n│   ├── k8s\n│   └── shell\n├── markdown\n│   ├── flow.md\n│   ├── formula.md\n│   └── mdgrammar.md\n\n```\n\n\n\n```\n[点击查看md写flow文章](/markdown/flow)\n```\n\n>[点击查看md写flow文章](/markdown/flow)\n>\n>[] 自定义链接标题\n>\n>()绝对地址,permalink的值\n\n#### post_link\n\n```\n{% post_link tool/text/markdown/flow/ '点击查看md写flow文章' %}\n```\n\n> {% post_link tool/text/markdown/flow '点击查看md写flow文章' %}\n>\n> post_link 相对路径 '标题' \n\n\n\n### 跳转\n\n#### 页内跳转指定位置\n\n锚点链接\n\n```\n[跳到本页的开头](#id-sample)\n```\n\n[跳到开头](#id-sample)\n\n#### 其他页面跳转到指定位置\n\n锚点链接\n\n```\n[跳到其他页指定位置](permalink的值#id-sample)\n```\n\n\n\n#### 设置锚点\n\n```\n锚点<p id=\"id-sample\" hidden/>\n```\n\n","tags":["grammar"],"categories":["markdown"]},{"title":"初识K8S","url":"/linux/k8s/初识K8S/","content":"\n### Master服务\n\n#### 安装kubernetes\n\n[官网下载kubernetes](https://kubernetes.io/docs/setup/release/notes/)\n\n```\ntar -xvf kubernetes.tar.gz  -C /opt/\n```\n\n下载 Client Binaries，Server Binaries\n\n```\nuname -s -m  #获取版本官网下载或执行下面命令下载\nbash /opt/kubernetes/cluster/get-kube-binaries.sh\n```\n\n <!--more--> \n\n> Kubernetes release: v1.11.0\n>\n> Server: linux/amd64 (to override, set KUBERNETES_SERVER_ARCH)\n>\n> Client: linux/amd64 (autodetected)\n>\n> Will download **kubernetes-server-linux-amd64.tar.gz** from https://dl.k8s.io/v1.11.0\n>\n> Will download and extract **kubernetes-client-linux-amd64.tar.gz** from https://dl.k8s.io/v1.11.0\n>\n> Is this ok? [Y]/n\n\nkubernetes-server\n\n```\ntar -tf   kubernetes-server-linux-amd64.tar.gz  #查看文件\ntar -xvf   kubernetes-server-linux-amd64.tar.gz  -C /opt/kubernetes/   --strip-components 1\n```\n\n\n\nkubernetes-client\n\n```\ntar -tf   kubernetes-client-linux-amd64.tar.gz\ntar -xvf   kubernetes-client-linux-amd64.tar.gz  -C /opt/kubernetes/   --strip-components 1\n```\n\n\n\n执行文件(配置文件可以直接路径)\n\n```\nsudo ln -s /opt/kubernetes/server/bin/kube-apiserver  /usr/bin/\nsudo ln -s /opt/kubernetes/server/bin/kube-controller-manager  /usr/bin/\nsudo ln -s /opt/kubernetes/server/bin/kube-scheduler  /usr/bin/\n```\n\n\n\n#### 准备依赖服务 etcd\n\n[etcd releases下载](https://github.com/etcd-io/etcd/releases) 如果s3.amazonaws.com下不动。。。\n\n被墙了 被墙了 被墙了\n\ngo 编译\n\n```\n#mkdir -p $GOPATH/src/go.etcd.io/ \n#cd $GOPATH/src/go.etcd.io/\n#git https://github.com/etcd-io/etcd.git\ncs@debian:~/gopath/etcd$ ./bulid\n```\n\n\n\n> can’t load package: package go.etcd.io/etcd: cannot find package “go.etcd.io/etcd” in any of:\n>\n> /opt/go/src/go.etcd.io/etcd (from $GOROOT)\n>\n> /home/cs/gopath/src/go.etcd.io/etcd (from $GOPATH)\n\n```\n$GOPATH/bin/etcd   #运行\n$ ETCDCTL_API=3 ./bin/etcdctl put foo bar\nOK\n```\n\n##### 创建用户\n\n```\nsudo groupadd  -g 995 etcd\nsudo useradd -s /sbin/nologin -M -c \"etcd user\" -u 995 etcd -g  etcd\nsduo mkdir -p /etc/etcd \nsudo mkdir -p /var/lib/etcd \nsudo chown -R etcd.etcd /var/lib/etcd\n```\n\n##### etcd.service\n\n```\n[Unit] \nDescription=Etcd Server \nAfter=network.target \nAfter=network-online.target \nWants=network-online.target \n \n[Service] \nType=notify \nWorkingDirectory=/var/lib/etcd/ \nEnvironmentFile=-/etc/etcd/etcd.conf \nUser=etcd \n# set GOMAXPROCS to number of processors \nExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\" --listen-client-urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\"\" \nRestart=on-failure \nLimitNOFILE=65536 \n \n[Install] \nWantedBy=multi-user.target\n```\n\n> sudo systemctl start etcd.service\n>\n> 该命令启动不了 /bin/bash -c “GOMAXPROCS=$(nproc) /usr/bin/etcd –name=\\”${ETCD_NAME}\\” –data-dir=\\”${ETCD_DATA_DIR}\\” –listen-client-urls=\\”${ETCD_LISTEN_CLIENT_URLS}\\””\n>\n> sudo systemctl status etcd.service\n>\n> **bash[9841]: run the stateless etcd v3 gRPC L7 reverse proxy\n>\n> debian systemd[1]: etcd.service: main process exited, code=exited, status=2/INVALIDARGUMENT\n>\n> debian systemd[1]: Failed to start Etcd Server.\n> **\n\n设置etcd\nExecStart=/opt/etcd-v3.3.9/etcd\n\n##### 启动etcd服务\n\n```\ntemp=\"etcd.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● etcd.service - Etcd Server\n>\n> Loaded: loaded (/lib/systemd/system/etcd.service; enabled)\n>\n> Active: active (running) since 六 2018-09-08 14:53:26 CST; 5min ago\n> Main PID: 804 (etcd)\n>\n> CGroup: /system.slice/etcd.service\n>\n> └─804 /opt/etcd-v3.3.9/etcd\n\n```\n./etcdctl cluster-health\n```\n\n> member 8e9e05c52164694d is healthy: got healthy result from [http://localhost:2379](http://localhost:2379/)\n>\n> cluster is healthy\n\n#### kube-apiserver\n\n##### 创建用户\n\n```\nsudo groupadd -g 996 kube\nsudo useradd -s /sbin/nologin -M -c \"kube user\" -u 996 kube -g kube\nsudo mkdir -p /etc/kubernetes\nsudo mkdir -p /usr/libexec/kubernetes\nsudo chown -R kube.kube /usr/libexec/kubernetes\nsudo chown -R kube.kube /var/run/kubernetes\n```\n\n##### kube-apiserver.service\n\n```\n[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes\n#Dependent service\nAfter=etcd.service\n\n[Service]\nEnvironmentFile=-/etc/kubernetes/apiserver\nExecStart=/opt/kubernetes/server/bin/kube-apiserver $KUBE_API_ARGS\nRestart=on-failure\nType=notify\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n> 1.error creating self-signed certificates: mkdir /var/run/kubernetes: permission denied\n>\n> 2.error: –[etcd](https://chengshea.github.io/linux/debian/docker/install-kubernetes/#etcd)-servers must be specified\n\n配置\n\n```\nsudo cat>/etc/kubernetes/apiserver<<EOF\nKUBE_API_ARGS=\"--etcd-servers=http://localhost:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=169.169.0.0/16 --service-node-port-range=1-65535 --admission-control=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ResourceQuota --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n> –etcd-servers：就是etcd的地址。\n>\n> –insecure-bind-address：apiserver绑定主机的非安全IP地址，设置0.0.0.0表示绑定所有IP地址。\n>\n> –insecure-port：apiserver绑定主机的非安全端口，默认为8080。\n>\n> –service-cluster-ip-range：Kubernetes集群中Service的虚拟IP地址段范围，以CIDR格式表示，该IP范围不能与物理机真实IP段有重合。\n>\n> -service-node-port-range：Kubernetes集群中Service可映射的物理机端口范围，默认为30000~32767.\n>\n> –admission-control： Kubernetes集群的准入控制设置，各控制模块以插件形式依次生效。\n>\n> –logtostderr：设置为false表示将日志写入文件，不写入stderr。\n>\n> –log-dir： 日志目录。\n>\n> –v：日志级别。\n>\n> [更多参数查看官方文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/)\n\n##### 启动\n\n```\ntemp=\"kube-apiserver.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kube-apiserver.service - Kubernetes API Server\n>\n> Loaded: loaded (/lib/systemd/system/kube-apiserver.service; disabled)\n>\n> Active: active (running) since 六 2018-09-08 15:42:02 CST; 2s ago\n> Docs: https://github.com/GoogleCloudPlatform/kubernetes\n>\n> Main PID: 3560 (kube-apiserver)\n>\n> CGroup: /system.slice/kube-apiserver.service\n>\n> └─3560 /opt/kubernetes/server/bin/kube-apiserver –etcd-servers=[http://localhost:2379](http://localhost:2379/) …….\n\n#### kube-controller-manager\n\n##### kube-controller-manager.service\n\n```\n[Unit]\nDescription=Kubernetes Scheduler Plugin\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=kube-apiserver.service\nRequires=kube-apiserver.service\n\n[Service]\nEnvironmentFile=-/etc/kubernetes/controller-manager\nUser=kube\nExecStart=/opt/kubernetes/server/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_ARGS\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n配置\n\n```\nsudo touch /etc/kubernetes/controller-manager && sudo  chmod 757 /etc/kubernetes/controller-manager\ncat>/etc/kubernetes/controller-manager<<EOF\nKUBE_CONTROLLER_MANAGER_ARGS=\"--master=http://192.168.56.101:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2\" \nEOF\n```\n\n\n\n##### 启动\n\n```\ntemp=\"kube-controller-manager.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kube-controller-manager.service - Kubernetes Scheduler Plugin\n>\n> Loaded: loaded (/lib/systemd/system/kube-controller-manager.service; disabled)\n>\n> Active: active (running) since 六 2018-09-08 16:54:32 CST; 2s ago\n>\n> Docs: https://github.com/GoogleCloudPlatform/kubernetes\n>\n> Main PID: 5980 (kube-controller)\n>\n> CGroup: /system.slice/kube-controller-manager.service\n>\n> └─5980 /opt/kubernetes/server/bin/kube-controller-manager –master=[http://localhost:8080](http://localhost:8080/) ……\n\n#### kube-scheduler\n\n##### kube-scheduler.service\n\n```\n[Unit]\nDescription=Kubernetes Scheduler Manager\nDocumentation=https://github.com/kubernetes\nAfter=kube-apiserver.service\nRequires=kube-apiserver.service\n\n[Service]\nEnvironmentFile=/etc/kubernetes/scheduler\nExecStart=/opt/kubernetes/server/bin/kube-scheduler $KUBE_SCHEDULER_ARGS\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n配置\n\n```\nsudo touch /etc/kubernetes/scheduler && sudo  chmod 757 /etc/kubernetes/scheduler\ncat>/etc/kubernetes/scheduler<<EOF\nKUBE_SCHEDULER_ARGS=\"--master=http://localhost:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n##### 启动\n\n```\ntemp=\"kube-scheduler.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kube-scheduler.service - Kubernetes Scheduler Manager\n>\n> Loaded: loaded (/lib/systemd/system/kube-scheduler.service; disabled)\n>\n> Active: active (running) since 六 2018-09-08 17:02:09 CST; 7s ago\n>\n> Docs: https://github.com/kubernetes\n> Main PID: 6340 (kube-scheduler)\n>\n> CGroup: /system.slice/kube-scheduler.service\n>\n> └─6340 /opt/kubernetes/server/bin/kube-scheduler –master=[http://localhost:8080](http://localhost:8080/) ……\n\n### Node节点服务\n\n#### kubelet\n\n##### kubelet.service\n\n```\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=-/var/lib/kubelet\nEnvironmentFile=-/etc/kubernetes/kubelet\nExecStart=/opt/kubernetes/server/bin/kubelet $KUBELET_ARGS  \nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n```\n\n> kubelet.service holdoff time over, scheduling restart\n\n配置\n\n```\nsudo mkdir -p /var/lib/kubelet\nsudo touch /etc/kubernetes/kubelet && sudo  chmod 757 /etc/kubernetes/kubelet\ncat>/etc/kubernetes/kubelet<<EOF\nKUBELET_ARGS=\"--kubeconfig=/etc/kubernetes/kubeconfig --hostname-override=127.0.0.1 --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n> [–kubeconfig代替了–api-servers](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/)\n>\n> \n> –[require-kubeconfig 1.7版开始默认true ](https://github.com/kubernetes/kubernetes/issues/36745)\n>\n> Kubernetes 1.8开始要求关闭系统的Swap\n\n##### 启动\n\n```\ntemp=\"kubelet.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kubelet.service - Kubernetes Kubelet Server\n>\n> Loaded: loaded (/lib/systemd/system/kubelet.service; disabled)\n>\n> Active: active (running) since 二 2018-09-11 18:34:48 CST; 29ms ago\n>\n> Docs: https://github.com/kubernetes\n> Main PID: 9018 (kubelet)\n>\n> CGroup: /system.slice/kubelet.service\n>\n> └─9018 /opt/kubernetes/server/bin/kubelet –kubeconfig=/etc/kubernetes/kubeconfig –hostname-override=127.0.0.1 –logtostderr=false –log-dir=/var/log/kubernetes –v=2 –cgroup-driver=systemd\n\n#### kube-proxy\n\n##### kube-proxy.service\n\n```\n[Unit]\nDescription=Kubernetes Kube-Proxt Server\nDocumentation=https://github.com/kubernetes\nAfter=network.target\nRequires=network.target\n\n[Service]\nEnvironmentFile=-/etc/kubernetes/proxy\nExecStart=/opt/kubernetes/server/bin/kube-proxy $KUBE_PROXY_ARGS\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n配置\n\n```\nsudo touch /etc/kubernetes/proxy && sudo  chmod 757 /etc/kubernetes/proxy\ncat>/etc/kubernetes/proxy<<EOF\nKUBE_PROXY_ARGS=\"--master=http://localhost:8080  --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n##### 启动\n\n```\ntemp=\"kube-proxy.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n./kubectl get cs\n./kubectl get node\n```","tags":["docker","k8s"],"categories":["linux","docker"]},{"title":"内网穿透","url":"/network/内网穿透/","content":"\n### ngrok\n\n提供内网穿透服务，可以在自己主机部署服务供外网访问\n\n同类产品： [花生壳](https://hsk.oray.com/download/) ，[nat123](http://www.nat123.com/Pages_2_32.jsp)\n\n官网 https://ngrok.com/\n\ngithub https://github.com/inconshreveable/ngrok\n\n### 安装\n\n官网注册[获取authtoken](https://dashboard.ngrok.com/get-started)\n\n生成配置\n\n```\n./ngrok authtoken   ********\n`\n```\n\n <!--more--> \n\n> Authtoken saved to configuration file:***.ngrok2/ngrok.yml\n>\n> 默认路径 https://ngrok.com/docs#default-config-location\n>\n> 运行\n>\n> ```\n> ./ngrok http 8010\n> ```\n>\n> \n>\n> 访问 http://localhost:4040/\n\n### 自定义\n\n隧道定义参数详解 https://ngrok.com/docs#tunnel-definitions\n\n每个隧道都必须定义\n\n- proto 需要 所有 隧道协议名称，中的一个http，tcp，tls\n- addr 需要 所有 转发流量到这个本地端口号或网络地址\n\n示例配置 https://ngrok.com/docs#config-examples\n\n**ngrok.cfg**\n\n```\nauthtoken: **************\ntunnels:\n  httpbin:\n    proto: http\n    addr: 8090\n    #subdomain: dev.com #子域名请求 收费\n```\n\n\n\n启动\n\n```\n#默认配置\n./ngrok start httpbin\n#指定额外配置文件\n./ngrok start  -config ./ngrok.cfg   httpbin\n```","tags":["ngrok","内网穿透"],"categories":["other","network"]},{"title":"评论","url":"/lang/node/hexo/评论/","content":"\n### 由来\n\n[gitment](https://github.com/imsun/gitment)使用 **github issue** 保存评论\n\n### 准备\n\n右键新标签页打开 https://github.com/settings/applications/new\n\n创建\n![app-id](http://ojtd6k176.bkt.clouddn.com/github-new-app.png)\n\n获取 id secret\n![参数](http://ojtd6k176.bkt.clouddn.com/github-app-id.png)\n\n### hexo Theme\n\n根据 *个人主题* 添加\n\n#### 样式\n\nsource/css/gitment.css\n\n- css [详情右键新标签页](https://github.com/chengshea/record/blob/master/issue/gitment.css)\n\nsource/js/gitment.js\n\n- js [详情右键新标签页](https://github.com/chengshea/record/blob/master/issue/gitment.js)\n\n#### 布局调用\n <!--more--> \n调用认证\n/layout/_partial/comments/gitment.ejs\n\n```\n<div id=\"gitment\"></div>\n<!-- 主页不要加载gitment -->\n<%if (!index){ %>\n<script>\nvar gitment = new Gitment({\nowner: 'chengshea',\nrepo: 'chengshea.github.io',\noauth: {\nclient_id: '3478952f5e3ade06xxxxx',\nclient_secret: '3ca8b3ada58c7993cbb385839f83ba8xxxxxx',\n },\n})\ngitment.render('gitment')\n</script>\n<% } %>\n```\n\n\n\n添加评论\n/layout/_partial/article.ejs\n\n```\n<% if (!index && post.comments){ %>\n    <%  if (theme.gitment.on) { %>\n        <%- partial('comments/gitment') %>\n    <% } else if (theme.disqus.on) { %>\n        <%- partial('comments/disqus', {\n            shortname: theme.disqus.shortname\n          }) %>\n    <% } else if (config.disqus_shortname) { %>\n        <%- partial('comments/disqus', {\n            shortname: config.disqus_shortname\n          }) %>\n    <% } %>\n<% } %>\n```\n\n\n\n**_config.yml** 配置添加gitment开启\n\n```\ngitment:\n       on: true\n       enable: true\n       owner: chengshea\n       repo: chengshea.github.io\n       client_id: 3478952f5e3adexxxxx\n       client_secret: 3ca8b3ada58c7993cbb385839f83bxxxxx\n```\n\n\n\n管理OAuth Apps\n\nhttps://github.com/settings/developers","tags":["issues"],"categories":["hexo"]},{"title":"科学上网","url":"/network/on-line/","content":"\n### 准备\n  有时候因工作需要，查询资料，下载，就需要科学上网\n\n  **linux 环境下**\n  * pip \n  * shadowsocks\n\n\n### 安装\npip\n```\nwget https://bootstrap.pypa.io/get-pip.py\npython get-pip.py\n```\nshadowsocks\n```\n$sudo pip install shadowsocks \n```\n <!--more--> \n### 配置\n####  服务端\nss.json\n```json\n{\n    \"server\":\"server_ip\",\n    \"server_port\":8888,\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\":1080,\n    \"password\":\"mypassword\",\n    \"timeout\":300,\n    \"method\":\"aes-256-cfb\",\n    \"fast_open\": false\n}\n```\n多号\n```json\n{\n    \"server\": \"server_ip\",\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\": 1080,\n    \"port_password\": {\n        \"8881\": \"aaaa81\",  \n        \"8882\": \"aaaa82\",\n        \"8883\": \"aaaa83\",\n        \"8884\": \"aaa84\"\n    },\n    \"timeout\": 300,\n    \"method\": \"aes-256-cfb\",\n    \"fast_open\": false\n}\n```\n\n\n\n| Name          | Explanation                                                  |\n| ------------- | ------------------------------------------------------------ |\n| server        | the address your server listens                              |\n| server_port   | server port                                                  |\n| local_address | the address your local listens                               |\n| local_port    | local port                                                   |\n| password      | password used for encryption                                 |\n| timeout       | in seconds                                                   |\n| method        | default: \"aes-256-cfb\", see [Encryption](https://github.com/shadowsocks/shadowsocks/wiki/Encryption) |\n| fast_open     | use [TCP_FASTOPEN](https://github.com/shadowsocks/shadowsocks/wiki/TCP-Fast-Open), true / false |\n| workers       | number of workers, available on Unix/Linux                   |\n\nfast_open\n\n```\necho 3 > /proc/sys/net/ipv4/tcp_fastopen\n```\n\n>0 关闭\n>\n>1  客户端使用fastopen  ，默认\n>\n>2  服务端使用fastopen\n>\n>3  无论客户端，服务端都使用 TFO功能\n\n**ssserver --help**\n\n` -d start/stop/restart`\n```\nssserver  -c  /xx/ss.json  -d start\n```\n\n#### 客户端\nss.json\n```\n$cat  /xx/ss.json\n{\n    \"server\": \"server_ip\",\n    \"server_port\": 443,\n    \"password\": \"mypassword\",\n    \"method\": \"aes-256-cfb\",\n    \"remarks\": \"\"\n}\n```\n\n**sslocal --help**\n```\nsslocal -c  /xx/ss.json\n```\n\n\n\n#### aes-256-gcm\n\nshadowsocks2.8.2版本，不支持aes-256-gcm\n\n```\npip install https://github.com/shadowsocks/shadowsocks/archive/master.zip -U\n```\n\n\n\n\n\n### 运行原理\n\n![proxy](http://ojtd6k176.bkt.clouddn.com/proxy-12.56.png)\n* 首先通过SS Local和VPS进行通信，通过Socks5协议进行通信 <br/>\n* SS Local连接到VPS， 并对Socks5中传输的数据进行对称加密传输，传输的数据格式是SS的协议\n* SS Server收到请求后，对数据解密，按照SS协议来解析数据。\n* SS Server根据协议内容转发请求。\n* SS Server获取请求结果后回传给SS Local\n* SS Local获取结果回传给应用程序\n下面2者必须同时满足\n\n1.代理服务器本地可以访问到;\n\n2.代理服务器可以访问目标网站。\n\n### 启动\n小脚本，再次吐槽qt客户端，太重了\n```\n#!/bin/bash\n\nvar=''\ncd /opt/Shadowsocks\nname=`whoami`\n\nif [ ! -d '/home/$name/ss' ];then\n   mkdir ~/ss\nfi\n \nfunction state(){\n  var=$(ps -ef | grep sslocal | grep -v grep | awk '{print $2}')\n}\n\nstate\n\nif test -z $var ;then\n  sslocal -c  $PWD/ss.json >>~/ss/log 2>&1 &\nelse\n  echo \"kill ---$var\"\n  kill -9 $var\n  state\n  if test -z $var ;then rm -r ~/ss ;fi\nfi  \n```\n\n","tags":["online","private-cs"],"categories":["other"]},{"title":"shield","url":"/services/elk/es-shield/","content":"\n### 简介\n  **Shield**拦截所有对ElasticSearch的请求，并加上认证与加密，保障ElasticSearch及相关系统的安全性\n\n  [<span id='top'>安装 doc</span>]( https://www.elastic.co/guide/en/shield/2.4/installing-shield.html)\n\n### 准备\n\n版本2.4.2{% post_link services/elk/安装ElasticSearch 安装ElasticSearch %}\n <!--more--> \n**以下操作需要你安装了elasticsearch为前提**\n\n\n\n* [license-2.4.2](https://download.elastic.co/elasticsearch/release/org/elasticsearch/plugin/license/2.4.2/license-2.4.2.zip)\n* [shield-2.4.2](https://download.elastic.co/elasticsearch/release/org/elasticsearch/plugin/shield/2.4.2/shield-2.4.2.zip)\n\n### 安装\n**以es，插件为<span id='custom'>自定义</span>目录为背景**\n\nes自定义目录**/opt/elasticsearch**\n\n安装脚本**plugin**注意下面变量值\n\n* CONF_DIR (elasticsearch.yml目录)\n `CONF_DIR=\"/opt/elasticsearch/config\"`\n* ES_ENV_FILE (elasticsearch目录)\n `ES_ENV_FILE=\"/opt/elasticsearch/config/default/elasticsearch\"`\n\nlicense\n```\ncs@debian:/opt/elasticsearch$ bin/plugin install file:///home/cs/Download/license-2.4.2.zip\n```\n>Installed license into /home/cs/Download/es/plugins/license\n\n\nshield\n```\ncs@debian:/opt/elasticsearch$ bin/plugin install file:///home/cs/Download/shield-2.4.2.zip\n```\n >Installed license into /home/cs/Download/es/plugins/shield\n\n安装成功目录（部分）\n```\ncs@debian:/opt/elasticsearch$ tree -L 3 /opt/elasticsearch\n/opt/elasticsearch\n├── bin\n│   ├── elasticsearch\n│   ├── elasticsearch.in.sh\n│   ├── elasticsearch-systemd-pre-exec\n│   ├── plugin\n│   ├── shield\n│   │   ├── esusers  添加角色密码脚本\n│   │   ├── esusers.bat\n│   │   ├── migrate\n│   │   ├── migrate.bat\n│   │   ├── syskeygen\n│   │   └── syskeygen.bat\n│   └── watcher\n│       ├── croneval\n│       └── croneval.bat\n├── config\n│   ├── default\n│   │   └── elasticsearch\n│   ├── elasticsearch.yml\n│   ├── logging.yml\n│   ├── scripts\n│   └── shield\n│       ├── logging.yml\n│       ├── role_mapping.yml\n│       ├── roles.yml\n│       ├── users\n│       └── users_roles\n├── lib\n```\n\n### 添加新用户\n\n执行脚本**esusers**需要注意参数\n* CONF_DIR ( 判断 $CONF_DIR/shield 目录)\n   后面密码会写入到配置文件（usersusers_roles）内\n* ES_CLASSPATH (shield 生成密码的执行类)\n  ```\n  java -cp org.elasticsearch.shield.authc.esusers.tool.ESUsersTool\n  ```\n  \n\nESUsersTool类在shield插件目录**shield-2.4.2.jar**\n\n  **注意** [自定义目录](#custom)即 *plugins* 不再 *ES_HOME* 目录下，执行脚本需要确认**ES_CLASSPATH**位置正确\n\n  1.添加变量 ES_PLUGIN\n  ```shell\n  ES_PLUGIN=`dirname $(sed -n 's/path.plugins://p'  $ES_HOME/config/elasticsearch.yml)`\n  ```\n   2.修改\n  ```shell\n#ES_CLASSPATH=\"$ES_CLASSPATH:$ES_HOME/plugins/shield/*\"\nES_CLASSPATH=\"$ES_CLASSPATH:$ES_PLUGIN/plugins/shield/*\"  \n  ```\n\n<br/>\n\n执行添加命令[文档](#top)\n```\ncs@debian:/opt/elasticsearch$ ./bin/shield/esusers useradd cs -p cs@121 -r admin\n```\n>useradd 添加的新用户名 cs <br/>\n-p  密码   cs@121    <br/>\n-r  角色（role） admin  <br/>\n\n启动\n```\ncs@debian:/opt/elasticsearch$ ./bin/elasticsearch -d\n```\n>cs@debian:`$ curl -u cs  \"http://localhost:9200/?pretty\"  <br/>\nEnter host password for user 'cs': <br/>\n{ <br/>\n  \"name\" : \"Sepulchre\",<br/>\n  \"cluster_name\" : \"elasticsearch\",<br/>\n  \"cluster_uuid\" : \"Ey7sWEIPRZGstn2LSKCCTQ\",<br/>\n  \"version\" : {<br/>\n    \"number\" : \"2.4.2\",<br/>\n    \"build_hash\" : \"161c65a337d4b422ac0c805f284565cf2014bb84\",<br/>\n    \"build_timestamp\" : \"2016-11-17T11:51:03Z\",<br/>\n    \"build_snapshot\" : false,<br/>\n    \"lucene_version\" : \"5.5.2\"<br/>\n  },<br/>\n  \"tagline\" : \"You Know, for Search\"<br/>\n}\n\n\n### 总结\n注意脚本运行，主要参数（变量）值\n","tags":["auth","safe"],"categories":["ELK","elasticsearch"]},{"title":"git server 搭建","url":"/tool/git-server/","content":"## 准备\n*    ssh\n*    git \n\n\n## gitosis\n### 添加用户\n仓库服务器执行\n```\nuseradd git\nmkdir -p /home/git\nchown -R git:git /home/git\n```\n\n密钥\n```\ncp  ~/.ssh/id_rsa.pub   /tmp/git.pub\n```\n <!--more--> \n### 安装\n\n```\ngit clone git://github.com/res0nat0r/gitosis.git\ncd gitosis\npython setup.py install\n```\n\n初始化\n```\nsu  git\ngitosis-init < ~/.ssh/id_rsa.pub\n```\n\n### 管理\n拉取\n```\n$git clone git@192.168.16.232:repositories/gitosis-admin.git\n$ tree -L 2 gitosis-admin\ngitosis-admin\n├── gitosis.conf\n└── keydir\n    └── git@ubuntu.pub\n```\n配置密钥\n```\ncp ~/.ssh/id_rsa.pub  gitosis-admin/keydir/cs.pub\n```\n添加权限 **gitosis.conf**\n```\n[group dev]  \nmembers = cs #这里的cs对上面公匙cs.pub文件名cs  \nwritable = test #项目名test\n```\n\n### <span id=\"pull\">测试拉取</span>\n\n```\nmkdir  test && cd test\necho \"测试test仓库\">rep\ngit init\ngit add .\ngit  commit -am \"add test\"\ngit remote add origin git@192.168.16.232:test.git\ngit  push origin master\n```\n> 提示要密码 <br />\n设置密码（root用户操作）\n```\npasswd gits\n2次 123456\n```\n或\n```\nsu gits\necho \"你的密钥\">>~/.ssh/authorized_keys\n```\n\n\n## gitolite\n### 添加用户\n仓库服务器执行\n```\nuseradd gits\nmkdir -p /home/gits\nchown -R gits:gits  /home/gits\n```\n\n初始化\n```\n$ cp  ~/.ssh/id_rsa.pub   /tmp/git.pub\n$ su gits\n$ git clone https://github.com/sitaramc/gitolite\n$ gitolite/install -to $HOME/bin\n$ ~/bin/gitolite setup -pk /tmp/git.pub\n```\n\n**密码**\n\n见gitosis测试[拉取](#pull)的操作\n\n\n### 管理\n本地拉取\n```shell\ngit clone gits@192.168.16.232:repositories/gitolite-admin\n```\n> 正克隆到 'gitolite-admin'...  <br />\ngits@192.168.16.232's password:  <br />\nremote: Counting objects: 6, done. <br />\nremote: Compressing objects: 100% (4/4), done. <br />\nremote: Total 6 (delta 0), reused 0 (delta 0)\n接收对象中: 100% (6/6), 完成. <br />\n检查连接... 完成。 <br />\n\n查看目录\n```\n$ tree -L 2  gitolite-admin\ngitolite-admin\n├── conf\n│   └── gitolite.conf\n└── keydir\n    └── git.pub\n```\ncp密钥，配置权限\n```\n$ cat  gitolite-admin/conf/gitolite.conf \nrepo gitolite-admin\n    RW+     =   git\n\nrepo testing\n    RW+     =   @all\n```\n> RW+  所有权限  <br />\ndoc: https://github.com/sitaramc/gitolite#access-rule-examples <br />\n\n\n最后\n```\ngit add .\ngit commit -am \"add new user xx\"\ngit push origin master\n```\n>更多高级配置在/home/gits/.gitolite.rc\n\n\n## gogs\n官网 https://try.gogs.io/\n\n带**UI**的服务，部署方便，轻量级\n\ngitlab太占内存了，云服务器跑成本高呀\n```\n# Pull image from Docker Hub.\n$ docker pull gogs/gogs\n\n# Create local directory for volume.\n$ mkdir -p /var/gogs\n\n# Use `docker run` for the first time.\n$ docker run --name=gogs -p 10022:22 -p 10080:3000 -v /var/gogs:/data gogs/gogs\n\n# Use `docker start` if you have stopped it.\n$ docker start gogs\n```\n>doc https://github.com/gogits/gogs/tree/master/docker#usage\n","tags":["git"],"categories":["tool"]},{"title":"git pull","url":"/tool/git-pull/","content":"### pull\n稀疏检出*sparse checkout*\n <!--more--> \n```\n#!/bin/bash\n\nprint_help() {\n  cat <<EOF\n  use params \n   -h , --help   说明   不支持分支\n   -u , --url   *必须，下载文件的链接（如https:://github.io/xx/tree/master/a/b ,下载b）\n  \n\nEOF\n}\n\nfunction src(){\n   if [[ \"$1\" =~ \"github.com\" ]] || [[ \"$1\" =~ \"gitee.com\" ]];then\n     echo \"downloadUrl--> $1\"\n   else \n     echo \"不支持\"\n     exit 1\n   fi\n}\n\nwhile [ $# -ge 0 ]; do\n    case $1 in\n        -h|--help)\n           print_help  \n           exit 1\n            ;;\n        -u|--url)\n              src $2\n              break \n            ;;\n         *  )\n           echo \"use param -h or --help !\"  \n           exit 1\n            ;;\n    esac\ndone\nfunction type(){\n   uri=$(echo $1 | grep \"/tree/master/\" | grep -v grep)\n   echo \"---$uri\"\n   if [[ $uri != \"\" ]];then\n     echo \"-------/tree/master\"\n     uri=${url%/tree/master*}\".git\"\n     down=${url#*/tree/master/}\n   else\n     echo \"-------/blob/master\"\n     uri=$(echo $1 |grep -v grep | grep \"/blob/master/\")\n     if [[ $uri != \"\" ]];then\n       uri=${url%/blob/master*}\".git\"\n       down=${url#*/blob/master/}\n     else\n       echo \"只支持拉取master文件下载\"\n       exit 1\n     fi\n   fi \n}\n\nurl=$2\n\nfile=${url##*/}\n\nuri=\ndown=\ntype $2\n \n\nif [ ! -f \"$file\" ];then\n\tmkdir $file\nfi\ncd $file\n\ngit init\necho \"==================添加 源===================\"\ngit remote add -f origin $uri \n#稀疏检出\ngit config core.sparsecheckout true\n#拉取文件\necho \"$down\">>.git/info/sparse-checkout\necho \"==================开始拉取===================\"\ngit pull origin master\n \nrm -rf .git\nmv $file/*  . && rm -r $file\n\n\necho \"==================$PWD===================\"\t\n```\n>利用git稀疏检出拉取部分文件\n\n### js实现下载\n[kinolien gitzip ](http://kinolien.github.io/gitzip/)","tags":["git"],"categories":["tool"]},{"title":"git命令","url":"//tool/git-cmd/","content":"\n\n#### checkout\n\n单个文件回滚\n\n```\n#获取版本commit SHA-1 标识符前8位\ngit log\n\n#回滚到指定版本\ngit checkout 0ebdd2639e8 _config.yml\n\n#撤消此更改并还原文件的最新版\ngit checkout HEAD index.html\n```\n\n\n\n如果有其他分支，不会clone到本地\n\n```\ngit branch -a\n\ngit checkout -b src origin/src\n\ngit pull origin src\n```\n\n\n\n\n\n\n\n#### cached\n\n文件从 Git 跟踪中删除，但将其保留在文件系统\n\n```\ngit rm --cached <file>\n```\n\n> git rm <file>  #将文件从 Git 仓库和文件系统中完全删除\n\n\n\n#### show\n\n\n\n```\n#查看已添加到 Git 索引的文件内容\ngit show :_config.yml\n\n# <commit> 是要查看的提交的 SHA-1 标识符\ngit show <commit>:<path>\n```\n\n\n\n\n\n### pull\n\n稀疏检出*sparse checkout*\n <!--more--> \n\n\n\n```\n#!/bin/bash\n\nprint_help() {\n  cat <<EOF\n  use params \n   -h , --help   说明   不支持分支\n   -u , --url   *必须，下载文件的链接（如https:://github.io/xx/tree/master/a/b ,下载b）  \nEOF\n}\n\nfunction src(){\n   if [[ \"$1\" =~ \"github.com\" ]] || [[ \"$1\" =~ \"gitee.com\" ]];then\n     echo \"downloadUrl--> $1\"\n   else \n     echo \"不支持\"\n     exit 1\n   fi\n}\n\nwhile [ $# -ge 0 ]; do\n    case $1 in\n        -h|--help)\n           print_help  \n           exit 1\n            ;;\n        -u|--url)\n              src $2\n              break \n            ;;\n         *  )\n           echo \"use param -h or --help !\"  \n           exit 1\n            ;;\n    esac\ndone\nfunction type(){\n   uri=$(echo $1 | grep \"/tree/master/\" | grep -v grep)\n   echo \"---$uri\"\n   if [[ $uri != \"\" ]];then\n     echo \"-------/tree/master\"\n     uri=${url%/tree/master*}\".git\"\n     down=${url#*/tree/master/}\n   else\n     echo \"-------/blob/master\"\n     uri=$(echo $1 |grep -v grep | grep \"/blob/master/\")\n     if [[ $uri != \"\" ]];then\n       uri=${url%/blob/master*}\".git\"\n       down=${url#*/blob/master/}\n     else\n       echo \"只支持拉取master文件下载\"\n       exit 1\n     fi\n   fi \n}\n\nurl=$2\n\nfile=${url##*/}\n\nuri=\ndown=\ntype $2\n \n\nif [ ! -f \"$file\" ];then\n\tmkdir $file\nfi\ncd $file\n\ngit init\necho \"==================添加 源===================\"\ngit remote add -f origin $uri \n#稀疏检出\ngit config core.sparsecheckout true\n#拉取文件\necho \"$down\">>.git/info/sparse-checkout\necho \"==================开始拉取===================\"\ngit pull origin master\n \nrm -rf .git\nmv $file/*  . && rm -r $file\n\necho \"==================$PWD===================\"\t\n```\n>利用git稀疏检出拉取部分文件\n\n### js实现下载\n[kinolien gitzip ](http://kinolien.github.io/gitzip/)","tags":["git","pull","cmd"],"categories":["tool"]},{"title":"avd","url":"/other/avd/","content":"\n### 创建AVD失败\n \n see log 查看日志\n ```\n WARN - vdmanager.AvdManagerConnection - Failed to create the SD card. \n WARN - vdmanager.AvdManagerConnection - Failed to create sdcard in the     AVD folder.\n ```\n \n#### 目录权限\n```\ncs@debian:~/repository/Android/sdk$ chmod +x tools/*\ncs@debian:~/repository/Android/sdk$ chmod +x platform-tools/*\n```\n\n#### 安装\n```\nsudo apt-get install  lib32z1 lib32ncurses5 #代替ia32-libs  \n```\n创建提示\n>/sdk/emulator/mksdcard: error while loading shared libraries: libgcc_s.so.1: cannot open shared object file: No such file or directory \n\n```\ncs@debian:~$ locate libgcc_s.so.1\n/lib/x86_64-linux-gnu/libgcc_s.so.1\n```\n 可以看到系统x86_64 不支持32\n> WARN - vdmanager.AvdManagerConnection - /home/cs/repository/Android/sdk/emulator/mksdcard: error while loading shared libraries: libgcc_s.so.1: cannot open shared object file: No such file or directory \nerror while loading shared libraries: libgcc_s.so.1: wrong ELF class: ELFCLASS64 \n\n <!--more--> \n\n搜索[libgcc_s.so.1](https://pkgs.org/download/libgcc_s.so.1)\n\n没有找到deb,下载的rpm\n```\nrpm2cpio  libgcc-4.1.2-55.el5.i386.rpm  | cpio -div\n```\n解压后\n```\nsudo ln -s /home/cs/repository/Android/sdk/lib32/libgcc_s.so.1  /lib/\n```\n创建AVD成功**等待近2分钟后出现**\n>Error while waiting for device: Timed out after 300seconds waiting for emulator to come online.\n\n#### 最终解决方法\n**SDK tools > SDK Tools** 勾选 **Android Emulator** \n\n**虚拟化应用** *VirtualBox* *docker* 等，与avd不能同时开启\n\n **Tools - Android** 勾选取消 *Enable ADB Integration* （对我无用）\n \nGraphics选项，**Software**而不是Automatic或Hardware","tags":["android","Simulator"],"categories":["linux","install"]},{"title":"docker-compose","url":"/linux/k8s/compose/","content":"#### 安装 \ngit下载地址:https://github.com/docker/compose/releases\n\n推荐pip安装\n```\nsudo pip install -U docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose -version\n```\n  <!--more--> \n#### 使用\n>build\n\n指定Dockerfile 文件,compose会利用它自动构建\n```\nbuild: /path\n```\n> command\n\n覆盖容器启动后默认命令\n```\ncommand:\n       - \"python\" \n       - \"neural_style.py\" \n       - \"--content\" \n       - \"/neural/input.jpg\" \n```\n> links\n\n链接其它服务的容器\n```\nlinks:\n    - redis\n```\n> ports\n\n暴露端口信息给宿主机,使用(host:container) 必须字符串格式,yaml解析涉及进制\n```\nports:\n      - \"8888:8888\"\n      - \"127.0.0.1:8001:8001\"\n```\n\n> volumes\n\n挂载路径,宿主机(host:container);上访模式(host:container:ro)\n``` \nvolumes:\n    - ~/tmp:/tmp/dir\n    - \n```\n> volumes_from\n\n挂载容器或服务\n```\nvolumes_from:\n    - jupyter\n    - service_name\n```\n> devices\n\n设配映射列表\n```\ndevices:\n    - \"/dev/nivida0:/dev/nivida0\"\n    - \"/dev/nivida1:/dev/nivida1\"\n```\n> depends_on\n\nexpress之间依赖关系,\n * `docker-compose up` 按照依赖顺序启动\n\n```\n depends_on:\n     - elasticsearch\n```\n\n> labels\n\n向docker容器添加元数据\n```\nlabels:\n   - aliyun.gpu=2\n\n```\n>其它\n\ndocker run 支持\n```\ncpu_shares: 73\n#指定工作目录\nworking_dir: /code  \n\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nhostname: foo\ndomainname: foo.com\nmem_limit: 1000000000\nprivileged: true\nrestart: always\nstdin_open: true\ntty: true\n```\n\n#### 示例\n\n\n\n```\nversion: '2'\nservices:\n  jupyter:\n    image: registry.cn-hangzhou.aliyuncs.com/denverdino/tensorflow:1.0.0\n    container_name: jupyter\n    ports:\n      - \"8888:8888\"\n    environment:\n      - PASSWORD=tensorflow\n    volumes:\n      - \"/tmp/tensorflow_logs\"\n      - \"./notebooks:/root/notebooks\"\n    command:\n      - \"/run_jupyter.sh\"\n      - \"/root/notebooks\"\n  tensorboard:\n    image: registry.cn-hangzhou.aliyuncs.com/denverdino/tensorflow:1.0.0\n    container_name: tensorboard\n    ports:\n      - \"6006:6006\"\n    volumes_from:\n      - jupyter\n    command:\n      - \"tensorboard\"\n      - \"--logdir\"\n      - \"/tmp/tensorflow_logs\"\n      - \"--host\"\n      - \"0.0.0.0\"\n```\n\n\n\nlogstash\n\n```\nlogstash:\n  image: logstash:2.4.1\n  command: /opt/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf\n  privileged: false\n  restart: always\n  ports:\n  - 21020:21020\n  volumes:\n  - /mnt/tinkle_data/logstash/logstash.conf:/etc/logstash/conf.d/logstash.conf\n```\n\nkibana\n\n```\nkibana:\n  image: daocloud.io/library/kibana:4.6.1\n  privileged: false\n  restart: always\n  ports:\n  - 5601:5601\n  volumes:\n  - /mnt/tinkle_data/kibana/kibana.yml:/opt/kibana/config/kibana.yml\n```\n\nelasticsearch\n\n```\nes:\n  restart: always\n  ports:\n    - '9200:9200/tcp'\n    - '9300:9300/tcp'\n  environment:\n    - LANG=C.UTF-8\n    - JAVA_HOME=/docker-java-home/jre\n    - TZ=Asia/ShangHai\n  memswap_limit: 0\n  labels:\n    aliyun.scale: '1'\n  shm_size: 0\n  image: 'elasticsearch:2.4.1'\n  memswap_reservation: 0\n  volumes:\n    - '/home/data/es:/usr/share/elasticsearch/data:rw'\n    - '/mnt/elasticsearch/plugins:/usr/share/elasticsearch/plugins:rw'\n  kernel_memory: 0\n  mem_limit: 0\n```\n\nredis\n\n```\nredis:\n  image: redis:3.2.5\n  command: \n     -  /etc/redis/6379.conf\n  privileged: false\n  restart: always\n  ports:\n  - 6379:6379\n  volumes:\n  - /mnt/tinkle_data/redis/data:/data/\n  - /mnt/tinkle_data/redis/conf/6379.conf:/etc/redis/6379.conf\n```\n\n\n\n```\nmysql:\n  image: 'mysql:5.7.17'\n  ports:\n    - '3306:3306'\n  restart: always\n  environment:\n    - MYSQL_ROOT_PASSWORD=19930221\n  labels:\n    aliyun.scale: '1'\n  volumes:\n    - '/home/data/mysql/mysql:/var/lib/mysql'\n    - '/home/data/mysql/conf/mysql.cnf:/etc/mysql/conf.d/mysql.cnf'\n```\n\n\n\n```\n#docker-compose services  mysql的服务名\njdbc_url=jdbc:mysql://服务名:3306/databasename\n```\n\n","tags":["install","docker-engine","docker compose"],"categories":["linux","k8s","docker"]},{"title":"docker","url":"/linux/k8s/docker/","content":"#### 安装 engine\n卸载旧版\n`sudo apt-get purge docker.io*`\n\n编辑 ` /etc/apt/sources.list.d/docker.list`\n```\necho 'deb https://apt.dockerproject.org/repo debian-jessie main'> /etc/apt/sources.list.d/docker.list\n```\n安装依赖：` apt-transport-https`\n\n```\nsudo apt-get install docker-engine\ndocker version\n...permission问题\n```\n创建组\n```\n cat /etc/group | grep ^docker  #不存在\n sudo groupadd docker  #存在忽略，创建组\nsudo gpasswd -a ${USER} docker   #添加当前用户到组\nsudo restart  #重启生效\n```\n <!--more--> \n#### 安装 compose\n官方文档 https://docs.docker.com/compose/install/#alternative-install-options\n\n##### 方法一\ncurl 安装\n```\nsudo apt-get install curl\n```\n/usr/local/bin 需要权限\n```\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.11.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n..... \ncurl: (56) SSL read: error:00000000:lib(0):func(0):reason(0), errno 104\n网络中断n次，推荐离线\n```\n[离线下载](https://dl.bintray.com/docker-compose/master/)\n```\nsudo mv docker-compose-Linux-x86_64 /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose --version\n```\n\n##### 方法二\npip安装`pip install docker-compose`\n**强烈建议您使用 virtualenv，因为许多操作系统有python系统包与docker-compose依赖关系冲突**\n\n\n####  国内源\n`docker search  xxxx` \n**error response from daemon: Get https://index.docker.io**\n被 GFW强了\nDocker配置文件`/etc/default/docker`\n```\nsudo mousepad /etc/default/docker\n\n#添加 阿里源\nDOCKER_OPTS=\"--registry-mirror=http://mirrors.aliyun.com\"\n```\n加速地址\n```\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://自己专属.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n#### docker-compose.yml\n常用配置 {% post_link  linux/k8s/docker  '安装 compose' %}\n\n#### 卸载\n```\n#docker-engine\nsudo apt-get remove docker-engine\n\n# docker-compose \n#curl\n$ rm /usr/local/bin/docker-compose\n# pip\n$ pip uninstall docker-compose\n```\n\n\n\ndocker.service\n\n```\ncat >/usr/lib/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=http://docs.docker.com\nAfter=network.target docker.socket\n[Service]\nType=notify\nEnvironmentFile=$BASE/flanneld/subnet.env\nWorkingDirectory=/usr/local/bin\nExecStart=/usr/bin/dockerd \\\n                \\$DOCKER_NETWORK_OPTIONS \\\n                -H unix:///var/run/docker.sock \nExecReload=/bin/kill -s HUP $MAINPID\n# Having non-zero Limit*s causes performance problems due to accounting overhead\n# in the kernel. We recommend using cgroups to do container-local accounting.\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTimeoutStartSec=0\n# set delegate yes so that systemd does not reset the cgroups of docker containers\nDelegate=yes\n# kill only the docker process, not all processes in the cgroup\nKillMode=process\nRestart=on-failure\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n","tags":["install","docker-engine","docker compose"],"categories":["linux","debian","docker"]},{"title":"dpkg","url":"/linux/debian/dpkg/","content":"## dpkg\n\n\n\n```\napt-get install xxx\n....\nCould not exec dpkg!\nE: Sub-process /usr/bin/dpkg returned an error code (100)\n```\n\n\n```\n ls -l /usr/bin/dpkg #什么没有呀！！！\n find /usr -type f -name dpkg\n .....\n```\n  <!--more--> \n 那执行\n```\n apt-get install dpkg  \n ....\n 显示已安装 **使用方法一**\n```\n\n 搜索 **dpkg debian download **\n [download](https://packages.debian.org/jessie/dpkg)\n\n\n#### 方法一\n```\n ar x  ~/文档/dpkg_1.17.27_amd64.deb data.tar.gz\n \n mkdir /tmp/dpkg\n cp data.tar.gz /tmp/dpkg\n cd /tmp/dpkg\n \n tar xfvz data.tar.gz ./usr/bin/dpkg\n \nsudo cp ./usr/bin/dpkg /usr/bin/\nsudo apt-get update\n```\n####  方法二\n\n`./configure`\nconfigure: error: libbz2 library or header not found\nSee `config.log' for more details\n安装 **libbz2**\nhttps://packages.debian.org/jessie/libbz2-1.0\n\nconfigure: error: liblzma library or header not found\nSee `config.log' for more details\n安装 **liblzma**\nhttps://packages.debian.org/jessie/liblzma5\n\nconfigure: error: no curses library found\n安装 ** curses  **\nhttps://packages.debian.org/jessie/libncurses5-dev\n\n\n\n### 参数\n\n#### -i | --install\n\n```\nsudo dpkg -i xxxxx_amd64.deb\n```\n\n> 修复包+依赖关系\n>\n> sudo apt-get install -f\n\n\n\n\n\n#### -l | --list \n\n [<表达式> ...]        简明地列出软件包的状态。\n\n```shell\ncs@debian:~$ dpkg -l | grep microsoft\nhi  microsoft-edge-stable                103.0.1264.62-1                   amd64        The web browser from Microsoft\n\n```\n\n\n\n####  -L | --listfiles  \n\n <软件包名> ...  列出属于指定软件包的文件。\n\n```\ncs@debian:~$ dpkg -L  microsoft-edge-stable \n/.\n/etc\n/etc/cron.daily\n/opt\n/opt/microsoft\n/opt/microsoft/msedge\n/opt/microsoft/msedge/MEIPreload\n....\n```\n\n\n\n####  -r|--remove \n\n```\ncs@debian:~$ sudo dpkg -r  microsoft-edge-stable \n[sudo] cs 的密码：\n(正在读取数据库 ... 系统当前共安装有 149708 个文件和目录。)\n正在卸载 microsoft-edge-stable (103.0.1264.62-1) ...\n正在处理用于 man-db (2.7.6.1-2) 的触发器 ...\n正在处理用于 desktop-file-utils (0.23-1) 的触发器 ...\n正在处理用于 mime-support (3.60) 的触发器 ...\n```\n\n> 连同配置文件一起删除(-P|--purge)\n>\n> dpkg -r --purge microsoft-edge-stable\n\n\n\n指定安装位置\n\n```\ndpkg -i --instdir=/opt/chrome   xxx.deb\n```\n\n\n\n\n\n查看处于rc状态的软件包 (清除所有已删除包的残余配置文件)\n\n```\ndpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg --purge\n```\n\n\n\n指定软件类型\n\n```\ndpkg -l nvidia* | grep ^rc | cut -d' ' -f3 |  sudo xargs dpkg --purge\n```\n\n\n\n\n\n## apt-get\n\napt不向下兼容apt-get\n\n\n\n### install\n\napt-get install  xxx\n\n\n\n### search\n\n搜索包含有xxx的软件包的名字 apt-cache search xxx\n\n\n\n### remove\n\n只删除软件包  apt-get remove xxx\n\n删除相应的配置文件  apt-get remove  --purge xxx\n\n依赖的软件包卸载掉 apt-get autoremove xxx \n\n\n\n\n\n\n\n## 解压\n\n###  deb\n\n```\ndpkg -x typora_1.5.5-1_amd64.deb ./\n```\n\n\n\n[ar](https://commandnotfound.cn/linux/1/106/ar-%E5%91%BD%E4%BB%A4)\n\n```\nar -vx   fileName.deb\n```\n\n>1. t            - 显示归档文件的内容\n>2. x[o]         - 从归档文件中分解文件\n>\n>通用修饰符：\n>\n>1. [c]          - 不在必须创建库的时候给出警告\n>2. [S]          - 不要创建符号表\n>3. [T]          - 做一个压缩档案\n>4. [v]          - 输出较多信息\n>5. [V]          - 显示版本号\n\n\n\n### tar\n\n```\nxz -d  data.tar.xz\n```\n\n\n\n```\ntar -zxvf   data.tar.gz\ntar -xvf   data.tar\n```\n\n","tags":["install","dpkg"],"categories":["linux","debian","tools"]},{"title":"live","url":"/tool/redis-live/","content":"Redis live\n Redis Live是一个用来监控redis实例,分析查询语句并且有web界面的监控工具,使用python编写\n#### Install Dependencies\n* **tornado** pip install tornado\n* **redis.py** pip install redis\n* **python-dateutil** pip install python-dateutil\n if you're running Python < 2.7:\n*  ** argparse** pip install argparse\n官方说明： http://www.nkrode.com/article/real-time-dashboard-for-redis\n <!--more--> \n#### pip\n下载地址:  https://pypi.python.org/pypi/pip#downloads\npip 依赖 setuptools\nFinished processing dependencies for setuptools==32.3.1\n\n```bash\n$tar -zxvf  pip-9.0.1.tar.gz\n$python setup.py build \n$sudo python setup.py install\nFinished processing dependencies for pip==9.0.1\n```\n\n\n\nFinished processing dependencies for python-dateutil==2.6.0\n\n\nFinished processing dependencies for redis==2.10.5\n\n```\n$sudo apt-get install build-essential python-dev\n```\nDpkg: Warning: ** ldconfig ** could not be found in the PATH environment variable or no executable privileges\nTip: The root PATH environment variable should normally contain ** / usr / local / sbin, / usr / sbin, and / sbin **\n```bash\n$locate ldconfig   #sbin目录存在 ldconfig\n$sudo mousepad ~/.bashrc\nexport PATH=/usr/loca/sbin:/usr/sbin:/sbin:$PATH\n$source ~/.bashrc\n```\n\nFinished processing dependencies for tornado==4.5.dev1\n\n列出安装的packages\n```\n$ sudo pip freeze\n```\n\n####  redislive\n```\ngit clone https://github.com/kumarnitin/RedisLive.git\n```\n配置文件**redis-live.conf**【redis-live.conf.example】\n```\n{\n\t\"RedisServers\":\n\t[ \n\t\t{\n  \t\t\t\"server\": \"154.17.59.99\",\n  \t\t\t\"port\" : 6379\n\t\t},\n\t\t\n\t\t{\n  \t\t\t\"server\": \"localhost\",\n  \t\t\t\"port\" : 6380,\n  \t\t\t\"password\" : \"some-password\"\n\t\t}\t\t\n\t],\n\n\t\"DataStoreType\" : \"redis\",\n\n\t\"RedisStatsServer\":\n\t{\n\t\t\"server\" : \"ec2-184-72-166-144.compute-1.amazonaws.com\",\n\t\t\"port\" : 6385\n\t},\n\t\n\t\"SqliteStatsStore\" :\n\t{\n\t\t\"path\":  \"to your sql lite file\"\n\t}\n}\n```\n启动服务\n```\n./redis-monitor.py --duration=30     //启动监控，duration是心跳时间\n./redis-live.py                    //启动web服务，默认监听8888端口\n```\n**env: ...py 权限不够**\n给予执行权\n```\nchmod +x  redis-monitor.py\nchmod +x  redis-live.py \n```\n打开 http://localhost:8888/index.html","tags":["redis","监控工具","install"],"categories":["nosql","redis"]},{"title":"kibana","url":"/services/elk/kibana/","content":"\n#### debian\n```\n$>sudo dpkg -i kibana-4.6.1-amd64.deb\n$>dpkg -L  kibana \n```\n \n#### win\n[nssm](#)\n\n#### 创建索引\n** logstash.conf **  \n <!--more--> \n```\noutput {\n    elasticsearch {\n        hosts => [\"127.0.0.1:9200\"]\n        index => \"logstash-nginx-json-%{+YYYY.MM}\"\n    }\n   stdout {codec => rubydebug}\n}\n```\n* 只有日志输入到es，才会触发创建索引","tags":["install","win"],"categories":["ELK","kibana"]},{"title":"logstash","url":"/services/elk/logstash/","content":"\n#### debian安装\n```\n $>sudo dpkg -i logstash-2.4.1_all.deb\n$> dpkg -L  logstash\n```\n#### win安装\nservice工具 [nssm](#)\n <!--more--> \n#### 配置\nlogstash.conf\n```\ninput {\n    file {\n        path => [ \"F:/ELK/nginx-1.10.2/logs/access.log\" ]\n\t\ttype => \"nginx_access\"\n        start_position => \"beginning\"\n        ignore_older => 0\n    }\n\tfile {\n        path => [ \"F:/ELK/nginx-1.10.2/logs/access_json.log\" ]\n\t\t#codec => \"json\"\n\t\ttype => \"nginx_json\"\n        start_position => \"beginning\"\n        ignore_older => 0\n    }\n}\n\nfilter {\n if [type] == \"nginx_access\" {\n    grok {\n\t    patterns_dir => \"F:/ELK/logstash-2.4.1/patterns\"        #设置自定义正则路径\n        match => { \"message\" => \"%{NGINXACCESS}\" }\n    }\n\n\n    date {\n      match => [ \"log_timestamp\",\"dd/MMM/yyyy:HH:mm:ss Z\"]\n\n    }\n   \n  }\n  \n  if [type] == \"nginx_json\" {\n        json {\n            source => \"message\"\n            #target => \"doc\"\n            remove_field => [\"message\"]\n        }\n\t\tif [@fields][ip] != \"-\" {\n\t\t\tgeoip {\n\t\t\t\t\tsource => \"[@fields][ip]\"\n \t\t\t\t\ttarget => \"geoip\"\n\t\t\t\t\tfields => [\"city_name\", \"continent_code\", \"country_code3\", \"country_name\", \"ip\", \"postal_code\", \"region_name\"]\n\t\t\t\t\tdatabase => \"F:/ELK/logstash-2.4.1/ip/GeoLiteCity.dat\"\n\t\t\t\t\tadd_field => [ \"[geoip][coordinates]\", \"%{[geoip][longitude]}\" ]\n\t\t\t\t\tadd_field => [ \"[geoip][coordinates]\", \"%{[geoip][latitude]}\"  ]\n\t\t\t}\n\t\t\n\t\t\tmutate {\n\t\t\t\t\tconvert => [ \"[geoip][coordinates]\", \"float\"]\n\t\t\t\t\t\n\t\t\t}\n   \n\t\t}\n \t}\n \n}\noutput {\n if [type] == \"nginx_access\" {\n    elasticsearch {\n        hosts => [\"127.0.0.1:9200\"]\n        index => \"logstash-nginx-access-%{+YYYY.MM}\"\n    }\n   stdout {codec => rubydebug}\n  }\n  if [type] == \"nginx_json\" {\n    elasticsearch {\n        hosts => [\"127.0.0.1:9200\"]\n        index => \"logstash-nginx-json-%{+YYYY.MM}\"\n    }\n   stdout {codec => rubydebug}\n  }\n \n}\n```","tags":["install","win","log"],"categories":["ELK","logstash"]},{"title":"安装elasticsearch","url":"/services/elk/安装ElasticSearch/","content":"## elasticsearch 目录结构\n\n|type | description | location |\n|-------|---------------------|-------|\n|home | Home of elasticsearch installation |\t/usr/share/elasticsearch \n| bin\t| Binary scripts including elasticsearch to start a node |\t/usr/share/elasticsearch/bin\n|conf\t| Configuration files elasticsearch.yml and logging.yml\t|/etc/elasticsearch\n|conf |Environment variables including heap size,file descriptors\t|/etc/default/elasticsearch\n|data\t| The location of the data files\t|/var/lib/elasticsearch/\n|logs\t| Log files location\t|/var/log/elasticsearch\n|plugins\t| Plugin files location\t|/usr/share/elasticsearch/plugins\n\n下载地址\n\n####  window7\nbin目录执行安装\n```\nF:\\ELK\\elasticsearch-2.4.1\\bin>service install\nInstalling service      :  \"elasticsearch-service-x64\"\nUsing JAVA_HOME (64-bit):  \"F:\\java\\jdk8\"\nThe service 'elasticsearch-service-x64' has been installed.\n```\n安装成功，如果启动失败（进logs目录，查看错误信息）\n <!--more--> \n```\n[error] [ 6376] Failed creating java %JAVA_HOME%\\jre\\bin\\server\\jvm.dll\n [error] [ 6376] 系统找不到指定的路径。\n ```\n 直接利用管理服务\n ```\n #运行 service manager 会弹出服务管理界面 修改jvm指定路径\nF:\\ELK\\elasticsearch-2.4.1\\bin>service manager\n```\n\n#### debian8\n```\nsudo dpkg -i  elasticsearch-2.4.2.deb\nbin$> ./elasticsearch   #启动提示没有权限\n```\n需要授权执行命令** chmod +x bin/elasticsearch  ** \n再次执行** ./elasticsearch -d **即可后台启动 \n使用** ps aux|grep elasticsearch **可以查看是否启动\n\n**设置开机启动**\n创建脚本 start.sh\n```\n#!bin/bash\nexport JAVA_HOME=/usr/bin/java\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n #切换到cs用户（带环境变量）\nsu -cs<<!\ncd /opt/elasticsearch/bin\n./elasticsearch &\nexit\n!\n```\n修改启动文件 mousepad /etc/init.d/elasticsearch\n```\n#!bin/bash\n### BEGIN INIT INFO\n# Provides:          elasticsearch\n# Required-Start:    $all\n# Required-Stop:     $all\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-De.ion: starts the elasticsearch  server\n# De.ion:       starts elasticsearch using start-stop-daemon\n### END INIT INFO\nsh /opt/elasticsearch/start.sh\n```\n","tags":["install","win","search"],"categories":["ELK","elasticsearch"]},{"title":"搭建hexo","url":"/lang/node/hexo/搭建hexo/","content":"\n\n\n\n\n### 准备工具\n\nnode https://nodejs.org/zh-cn/download/\ngit\nhexo\n\n### node 安装\n\n#### linux\n\n``` bash\n$tar  -zxvf  node.tar.gz\n$cd node\n$./config  --prefix=/opt/node\n$sudo make\n$sudo make install\n```\n添加环境变量\n```bash\n#set nodejs\nexport NODE_HOME=/opt/node\nexport PATH=$NODE_HOME/bin:$PATH\n$node -v #显示版本号\n$sudo node -v #当用root执行，commond not found\n#mousepad  ~/.bashrc\nalias sudo='sudo env PATH=$PATH'\n```\n <!--more--> \n\n#### win10\n\n‪C:/Users/Shea/.npmrc\n\n```\nprefix=K:\\node\\last\\node_global\ncache=K:\\node\\last\\node_cache\nregistry=https://registry.npm.taobao.org/\n```\n\n##### 环境变量\n\n###### 用户变量path\n\nK:\\node\\last\n\nK:\\node\\last\\node_global\n\n###### 系统变量\n\nNODE_PATH=K:\\node\\last\\node_global\\node_modules\n\n#### 检查版本\n\n```powershell\nPS K:\\chengshea.github.io> node -v\nv16.17.0\nPS K:\\chengshea.github.io> npm -v\n8.15.0\n```\n\nError: EPERM: operation not permitted\n> node目录 右键----属性----安全--选择当前用户（编辑）--权限 -- 完全控制\n\n\n\n\nhexo : 无法加载文件 K:\\node\\last\\node_global\\hexo.ps1，因为在此系统上禁止运行脚本\n\n> 设置->隐私和安全性->开发者选项->**PowerShell** 勾选 应用\n\n\n\n### git\n\n\n``` bash\n$cd ~/.ssh #查看没有密钥\n$ ssh-keygen -t rsa -C \"你git的user.email\"\n```\n路径默认 最好输入密码\n最后得到两个文件：id_rsa和id_rsa.pub\n\n``` bash\n$ cat ~/.ssh/id_rsa.pub #复制到github ssh key \n$ssh git@github.com  \n```\n\n### hexo\n在指定目录下执行终端\n```bash\n$sudo npm install hexo-cli -g #安装在当前目录\n#忽略warn\n$sudo npm install hexo --save\n$hexo -v\n```\n给予文件夹权限\n初始化 ，安装组件\n```\n$hexo init\n$npm install\n```\n### 部署\n本地部署\n```\n$hexo g  #generate 简写\n$hexo s #server  默认端口4000\n$hexo server -p 5000\n```\npush \n\n```\n$hexo d #deploy\n```\n\n后台运行\n\n```\nnpm install -g pm2\n\ncat <<EOF | tee run.js\n//run\nconst { exec } = require('child\\_process')\nexec('hexo server',(error, stdout, stderr) => {\n        if(error){\n                console.log('exec error: \\${error}')\n                return\n        }\n        console.log('stdout: \\${stdout}');\n        console.log('stderr: \\${stderr}');\n})\nEOF\n\npm2  start run.js\n```\n\n> start|stop|restart\n\n\n\n\n\n\n\n### themes\n\n部分主题是18,19年,node版本太高,**版本不一致**\n\n会导致hexo server 正常,但hexo generate 生成的public目录文件**全为为0kb**\n\n版本降级,或升级到一定版本,如\n\n```json\n{\n  \"name\": \"hexo-site\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"build\": \"hexo generate\",\n    \"clean\": \"hexo clean\",\n    \"deploy\": \"hexo deploy\",\n    \"server\": \"hexo server\"\n  },\n  \"hexo\": {\n    \"version\": \"6.2.0\"\n  },\n  \"dependencies\": {\n    \"hexo\": \"^6.2.0\",\n    \"hexo-deployer-git\": \"^3.0.0\",\n    \"hexo-generator-archive\": \"^1.0.0\",\n    \"hexo-generator-baidu-sitemap\": \"^0.1.9\",\n    \"hexo-generator-category\": \"^1.0.0\",\n    \"hexo-generator-index\": \"^2.0.0\",\n    \"hexo-generator-search\": \"^2.4.3\",\n    \"hexo-generator-tag\": \"^1.0.0\",\n    \"hexo-renderer-ejs\": \"^1.0.0\",\n    \"hexo-renderer-marked\": \"^5.0.0\",\n    \"hexo-renderer-stylus\": \"^2.1.0\",\n    \"hexo-server\": \"^3.0.0\",\n    \"highlight.js\": \"^11.6.0\"\n  }\n}\n```\n\n\n\n### 版本问题\n\n会导致 跳转链接变成下载文件\n\n```\n#添加\nsed -i \"/^permalink/s/$/\\//\"  `grep 'permalink:'  -rl --include=\\*.md  ./source/_posts/`\n#删除\nsed -n \"/^permalink/s/\\/$//\"p  `grep 'permalink:'  -rl --include=\\*.md  ./source/_posts/`\n```\n\n> permalink: xx/xxx/xxx/\n\n等一系列问题,**注意版本**\n\n\n\nnode版本问题https://nodejs.org/zh-cn/download/releases/\n\nhttps://www.npmjs.com/package/hexo-cli\n\n```\nnpm ls --depth 0\n\nhexo g --debug\n```\n\n\n\npost_link\n\nhexo@6.3.0\n\n- feat(tag/post_link): throw on post_link error by [@xbc5](https://github.com/xbc5) in [#4938](https://github.com/hexojs/hexo/pull/4938)\n\n```\n{% post_link a-existent-post-name 'Title' %}\n```\n\n>a-existent-post-name  可以是相对路径 permalink\n\n\n\n\n\n### nginx\n\n```\n#/usr/local/openresty/nginx/conf/conf.d/hexo.conf\n# /etc/nginx/conf.d/http/hexo.conf\ncat <<EOF | tee /usr/local/openresty/nginx/conf/conf.d/hexo.conf\nserver {\n        listen      1314;\n        server_name  localhost;\n\n        location / {\n            proxy_pass_header Server;\n            proxy_set_header Host \\$http_host;\n            proxy_set_header X-Real-IP \\$remote_addr;\n            proxy_set_header X-Scheme \\$scheme;\n            proxy_pass http://localhost:4000/;\n        }\n}\nEOF\n\n\n```\n\n\n\n```\n/usr/bin/openresty -t\n\nsystemctl restart openresty\n\nsystemctl restart nginx\n```\n\n","tags":["hexo"],"categories":["npm","hexo"]},{"title":"https签名","url":"/network/https自己签名/","content":"#### 为服务器端和客户端准备公钥、私钥\n```\n#私钥\n>openssl genrsa -out server.key 1024 -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n```\n#公钥\n>openssl rsa -in server.key -pubout -out server.pem\n```\n#### 生成 CA 证书\n```\n <!--more--> \n#ca私钥\n>openssl genrsa -out ca.key 1024 -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n **第一次填写信息**\n```\n>openssl req -new -key ca.key -out ca.csr -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n\nCountry Name (2 letter code) [AU]:\nState or Province Name (full name) [Some-State]:\nLocality Name (eg, city) []:\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:\nOrganizational Unit Name (eg, section) []:\n**Common Name** (e.g. server FQDN or YOUR name) []:localhost\nEmail Address []:\n\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:12345678\nAn optional company name []:cs\n\n```\n>openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt -days 365\n```\n\n#### 生成服务器端证书\n服务器端需要向 CA 机构申请签名证书，在申请签名证书之前依然是创建自己的 CSR 文件  **与第一次信息填写一样**\n```\n>openssl req -new -key server.key -out server.csr -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n向自己的 CA 机构申请证书，签名过程需要 CA 的证书和私钥参与，最终颁发一个带有 CA 签名的证书\n```\n>openssl x509 -req -CA ca.crt -CAkey ca.key -CAcreateserial -in server.csr -out server.crt\n```\nSignature ok\nsubject=/C=AU/ST=Some-State/O=Internet Widgits Pty Ltd/CN=localhost\nGetting CA Private Key\n\n\n#### 生成cer文件\n使用openssl 进行转换\n```\n>openssl x509 -in server.crt -out server.cer -outform der\n```\n\n 生成p12\n```\nF:\\logs\\http>openssl pkcs12 -export -clcerts -in server.crt -inkey server.key -out client.p12\nWARNING: can't open config file: /usr/local/ssl/openssl.cnf\nLoading 'screen' into random state - done\nEnter Export Password:12345678\nVerifying - Enter Export Password:12345678\n```\n\n","tags":["https","签名"],"categories":["http协议","https"]}]
[{"title":"hexo插件","url":"/lang/node/npm/hexo/","content":"\n\n\n\n\n\n## 本地搜索\n\n```\nnpm install --save hexo-generator-search\n```\n\n\n\n### hexo\n\n_config.yml\n\n```\nsearch:\n  path: search.json\n  field: all\n  content: true\n  limit: 1000\n```\n\n\n\n\n\n### 主题spfk\n\n#### _config.yml\n\n```\nsearch_box: true\n```\n\n#### 左侧left-col.ejs\n\n/hexo/themes/spfk/layout/_partial/left-col.ejs\n\n```ejs\n<div id=\"id_search\"   onclick = \"document.getElementById('local_search').style.display='block'\">\n <span class=\"search-icon\">\n\t<i class=\"fa fa-search\"> </i>\n   </span> 搜索\n</div>\n```\n\n#### 弹出层layout.ejs\n\n/hexo/themes/spfk/layout/layout.ejs\n\n```ejs\n<div id=\"local_search\" class=\"search-popup\" >\n  <div class=\"search-header\">\n\t    <i class=\"fa fa-search\"> </i> <input id=\"local-search-input\" class=\"search-input\" placeholder=\"搜索...\" spellcheck=\"false\" type=\"search\"/>\n  </div>\n  <div id=\"local-search-result\"></div>\n</div>\n```\n\n####  触发搜索 after-footer.ejs\n\n/hexo/themes/spfk/layout/_partial/after-footer.ejs\n\n##### 引入search.js\n\n```\n<%- js('js/jquery-1.9.1.min') %>\n<%- js('js/search') %>\n\n<% if (theme.search_box) { %>\n   <script type=\"text/javascript\">\n\tvar inputArea       = document.querySelector(\"#local-search-input\");\n\tinputArea.onclick   = function(){ getSearchFile(); this.onclick = null }\n\tinputArea.onkeydown = function(){ if(event.keyCode == 13) return false }\n\tvar getSearchFile = function(){\n\t      searchFunc(\"<%= config.root %>\" + \"search.json\", 'local-search-input', 'local-search-result');\n\t}\n          $(document).on('click', function(e) {\n\t\t   var si= $(e.target).closest('#id_search').length;\n           var d= $(e.target).closest('#local_search').length;\n             if( si==0 && d==0){\n               $('#local_search').hide();\n              }    \n\n       });\n\n  </script>\n<% } %>\n```\n\n##### search.js\n\n/hexo/themes/spfk/source/js/search.js\n\n```js\nvar searchFunc = function (path, search_id, content_id) {\n  // 0x00. environment initialization\n  'use strict';\n  var $input = document.getElementById(search_id);\n  var $resultContent = document.getElementById(content_id);\n  $resultContent.innerHTML = \"<ul><span class='local-search-empty'>首次搜索，正在载入索引文件，请稍后……<span></ul>\";\n  $.ajax({\n    // 0x01. load xml file\n    url: path,\n    dataType: \"json\",\n    success: function (datas) {\n      $resultContent.innerHTML = \"\";\n      $input.addEventListener('input', function () {\n        // 0x03. parse query to keywords list\n        var str = '<ul class=\\\"search-result-list\\\">';\n        var keywords = this.value.trim().toLowerCase().split(/[\\s\\-]+/);\n        $resultContent.innerHTML = \"\";\n        if (this.value.trim().length <= 0) {\n          return;\n        }\n        // 0x04. perform local searching\n        datas.forEach(function (data) {\n          var isMatch = true;\n          var content_index = [];\n          if (!data.title || data.title.trim() === '') {\n            data.title = \"Untitled\";\n          }\n          var orig_data_title = data.title.trim();\n          var data_title = orig_data_title.toLowerCase();\n             if (!data.content || data.content.trim() === '') {\n                         console.log(data.content)//空文章\n                      data.content = \"no content\";\n                 }\n          var orig_data_content = data.content.trim().replace(/<[^>]+>/g, \"\");\n          var data_content = orig_data_content.toLowerCase();\n          var data_url = data.url;\n     \n          var index_title = -1;\n          var index_content = -1;\n          var first_occur = -1;\n          // only match artiles with not empty contents\n          if (data_content !== '') {\n            keywords.forEach(function (keyword, i) {\n              index_title = data_title.indexOf(keyword);\n              index_content = data_content.indexOf(keyword);\n\n              if (index_title < 0 && index_content < 0) {\n                isMatch = false;\n              } else {\n                if (index_content < 0) {\n                  index_content = 0;\n                }\n                if (i == 0) {\n                  first_occur = index_content;\n                }\n                // content_index.push({index_content:index_content, keyword_len:keyword_len});\n              }\n            });\n          } else {\n            isMatch = false;\n          }\n          // 0x05. show search results\n          if (isMatch) {\n            str += \"<li><a href='\" + data_url + \"' class='search-result-title' target='_blank'>\" + orig_data_title + \"</a>\";\n            var content = orig_data_content;\n            if (first_occur >= 0) {\n              // cut out 100 characters\n              var start = first_occur - 20;\n              var end = first_occur + 10;\n\n              if (start < 0) {\n                start = 0;\n              }\n\n              if (start == 0) {\n                end = 100;\n              }\n\n              if (end > content.length) {\n                end = content.length;\n              }\n\n              var match_content = content.substr(start, end);\n\n              // highlight all keywords\n              keywords.forEach(function (keyword) {\n                var regS = new RegExp(keyword, \"gi\");\n                match_content = match_content.replace(regS, \"<em class=\\\"search-keyword\\\">\" + keyword + \"</em>\");\n              });\n\n              str += \"<p class=\\\"search-result\\\">\" + match_content + \"...</p>\"\n            }\n            str += \"</li>\";\n          }\n        });\n        str += \"</ul>\";\n        if (str.indexOf('<li>') === -1) {\n          return $resultContent.innerHTML =  \"<ul><span class='local-search-empty'>没有找到内容，请尝试更换检索词。<span></ul>\";\n        }\n        $resultContent.innerHTML =  str;\n      });\n    }\n  });\n}\n```\n\n##### css\n\n/hexo/themes/spfk/source/css/search.css\n\n```css\n\n.search-popup {\n  display: none;\n  background: #32503d;\n  border-radius: 5px;\n  height: 80%;\n  left: calc(50% - 350px);\n  position: fixed;\n  top: 10%;\n  width: 700px;\n  z-index: 1500;\n}\n\n.search-popup .search-header {\n  background: #eee;\n  border-top-left-radius: 5px;\n  border-top-right-radius: 5px;\n  display: flex;\n  padding: 5px;\n}\n.search-popup input.search-input {\n  background: transparent;\n  border: 0;\n  outline: 0;\n  width: 100%;\n}\n\n\n.search-popup ul.search-result-list {\n  margin: 0 5px;\n  padding: 0;\n  width: 100%;\n \n}\n\nul.search-result-list li::marker {\n content: '😩';\n}\n\n\n.search-popup p.search-result {\n  border-bottom: 2px dashed #7de485d4;\n  padding: 5px 0;\n  line-height: 21px;\n}\n.search-popup a.search-result-title {\n  font-weight: bold;\n}\n.search-popup .search-keyword {\n  border-bottom: 1px dashed #ff2a2a;\n  color: #ff2a2a;\n  font-weight: bold;\n}\n.search-popup #local-search-result{\n  display: flex;\n  height: calc(100% - 55px);\n  overflow: auto;\n  padding: 5px 25px;\n}\n.search-popup #no-result {\n  color: #ccc;\n  margin: auto;\n}\n```\n\n\n\n\n\n\n\n","tags":["search","hexo"],"categories":["lang","node","npm"]},{"title":"decompress解压/压缩","url":"/linux/shell/decompress/","content":"\n\n\n## tar\n\n### 解压\n\n```\ntar -zxvf  helm-v3.9.3-linux-amd64.tar.gz\n```\n\n>-z    tar.gz  tgz\n>\n>-j    tar.bz2   tbz\n>\n>-C  接指定目录\n\n\n\n### 压缩\n\n\n\n```\ntar zcvf /dir/file.tar.gz   /dir/file\n```\n\n> -z  gzip压缩\n>\n> -j  bzip2压缩\n>\n> -zp  gzip压缩，并且保留权限信息(-p的属性是很重要的，尤其是当您要保留原本文件的属性时)\n>\n> --strip-components 1  去掉最外层目录\n","tags":["tar","unzip","xz"],"categories":["linux","shell"]},{"title":"download工具命令","url":"/linux/k8s/download/","content":"\n\n\n## wget\n\n### 常规使用\n\n```\nwget [options] [url]\n```\n\n#### 指定文件\n\n```\nwget  -P /opt/docker  https://get.helm.sh/helm-v3.9.3-linux-amd64.tar.gz\n```\n\n>-c 断点续传\n>\n>-O 下载并以不同的文件名保存\n>\n> -b 后台下载\n>\n>–spider 测试下载链接\n>\n>--limit-rate=1m  速度限制为1m/s\n\n\n\n### 批量下载\n\n#### 有规律\n\n```\nwget http://www.xxxx.com/file_{1..4}.txt\n```\n\n> 比如：file_1.txt，file_2.txt，file_3.txt\n\n\n\n#### 没有规律\n\n```\ncat >downloads.txt<<EOF\nhttp://www.xxxx.com/xxx\nhttp://www.xxxx.com/xxx\nEOF\nwget -i downloads.txt\n```\n\n\n\n### 下载整个目录\n\n\n\n```\nwget -r -np -nH -R index.html http://url/files/download/\n```\n\n>-r : 遍历所有子目录\n>-np : 不到上一层子目录去\n>-nH : 不要将文件保存到主机名文件夹\n>-R index.html : 不下载 index.html 文件\n>\n>-k 将网页内绝对链接转为相对链接\n\n\n\n### 模拟\n\n模拟 Edge 浏览器发出来的请求\n\n```\nwget --debug --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59\" http://www.baidu.com\n```\n\n模拟手机\n\n```\nwget --debug --header=\"User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 13_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Mobile/15E148 Safari /604.1\" http://www.baidu.com\n```\n\n\n\n\n\n## curl\n\n\n\n```\ncurl   -ikv   http://www.baidu.com\n```\n\n","tags":["download","wget","curl"],"categories":["linux","shell"]},{"title":"helm工具","url":"/linux/k8s/helm/","content":"\n\n\n### 安装\n\n下载 https://helm.sh/docs/intro/install/\n\n```\nwget  -P /opt/docker  https://get.helm.sh/helm-v3.9.3-linux-amd64.tar.gz\nmkdir /opt/docker/helm-v3.9.3\ntar -zxvf  helm-v3.9.3-linux-amd64.tar.gz  -C  ./helm-v3.9.3   --strip-components 1\n```\n\n\n\n### 设置环境变量\n\n```\n$ cat >> ~/.bashrc <<EOF\n#helm\nexport PATH=$PATH:/opt/docker/helm-v3.9.3\nEOF\n$ helm version\nversion.BuildInfo{Version:\"v3.9.3\", GitCommit:\"414ff28d4029ae8c8b05d62aa06c7fe3dee2bc58\", GitTreeState:\"clean\", GoVersion:\"go1.17.13\"}\n\n```\n\n\n\n### 添加源\n\n\n\n```\nhelm repo add stable http://mirror.azure.cn/kubernetes/charts \nhelm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts \nhelm repo list\n```\n\n\n\nshow\n\n```\nhelm show chart stable/mysql\n```\n\n\n\ninstall\n\n```\n helm install db stable/mysql\nWARNING: This chart is deprecated\nNAME: db\nLAST DEPLOYED: Thu Aug 18 21:33:05 2022\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nNOTES:\nMySQL can be accessed via port 3306 on the following DNS name from within your cluster:\ndb-mysql.default.svc.cluster.local\n\nTo get your root password run:\n\n    MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default db-mysql -o jsonpath=\"{.data.mysql-root-password}\" | base64 --decode; echo)\n\nTo connect to your database:\n\n1. Run an Ubuntu pod that you can use as a client:\n\n    kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il\n\n2. Install the mysql client:\n\n    $ apt-get update && apt-get install mysql-client -y\n\n3. Connect using the mysql cli, then provide your password:\n    $ mysql -h db-mysql -p\n\nTo connect to your database directly from outside the K8s cluster:\n    MYSQL_HOST=127.0.0.1\n    MYSQL_PORT=3306\n\n    # Execute the following command to route the connection:\n    kubectl port-forward svc/db-mysql 3306\n\n    mysql -h ${MYSQL_HOST} -P${MYSQL_PORT} -u root -p${MYSQL_ROOT_PASSWORD}\n```\n\n\n\n```\ns@debian:~$ kubectl  get pod -A\nNAMESPACE     NAME                          READY   STATUS    RESTARTS   AGE\ndefault       db-mysql-7f4fdddfd5-2dqql     0/1     Pending   0          67s\n```\n\n","tags":["helm"],"categories":["linux","k8s"]},{"title":"kubelet组件","url":"/linux/k8s/kubelet/","content":"\n\n\n\n\n#### 二进制\n\nversion 1.18\n\n##### kubelet.env\n\n```shell\n[vagrant@k8s kubernetes]$ cat > /opt/kubernetes/kubelet/kubelet.env <<EOF\nKUBELET_OPTIONS=\" --pod-infra-container-image=k8s.org/k8s/pause:3.2   \\\n--bootstrap-kubeconfig=/opt/kubernetes/config/bootstrap.kubeconfig   \\\n--kubeconfig=/opt/kubernetes/config/kubelet.kubeconfig   \\\n--config=/opt/kubernetes/kubelet/kubelet-config.yaml    \\\n--cni-bin-dir=/opt/kubernetes/cni/bin    \\\n--cni-conf-dir=/opt/kubernetes/cni/net.d    \\\n--network-plugin=cni    \\\n-runtime-cgroups=/systemd/system.slice    \\\n--log-dir=/var/log/kubernetes/kubelet     \\\n--logtostderr=false    \\\n--v=2\"\nEOF\n```\n\n<!--more-->\n\n##### kubelet-config.yaml\n\n```\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\naddress: \"192.168.56.102\"\nport: 10250\nhealthzBindAddress: \"192.168.56.102\"\nhealthzPort: 10248\nreadOnlyPort: 0\ncgroupDriver: \"cgroupfs\"\nclusterDomain: \"cluster.local\"\nclusterDNS: [\"121.21.0.0\"]\nfailSwapOn: false\ntlsCertFile: \"/opt/kubernetes/pem/kubelet.pem\"\ntlsPrivateKeyFile: \"/opt/kubernetes/pem/kubelet-key.pem\"\nauthentication:\n    x509:\n        clientCAFile: \"/opt/kubernetes/pem/ca.pem\"\n    webhook:\n        enabled: true\n        cacheTTL: \"2m0s\"\n    anonymous:\n        enabled: false\nauthorization:\n    mode: Webhook\n    webhook:\n        cacheAuthorizedTTL: \"5m0s\"\n        cacheUnauthorizedTTL: \"30s\"\nhairpinMode: \"promiscuous-bridge\"\nserializeImagePulls: false\nfeatureGates:\n    RotateKubeletClientCertificate: true\n    RotateKubeletServerCertificate: true\n```\n\n\n\n#### 容器\n\nversion 1.22\n\n##### kubelet.env\n\n```shell\n[vagrant@k8s kubernetes]$ cat > /opt/kubernetes/kubelet.env <<EOF\n KUBELET_OPTIONS=\" --hostname-override=k8s  \\\n --pod-infra-container-image=k8s.org/k8s/pause:3.4.1 \\\n --kubeconfig=/etc/kubernetes/kubelet.conf    \\\n --config=/var/lib/kubelet/config.yaml     \\\n --register-node=true        \\\n --runtime-cgroups=/systemd/system.slice    \\\n --logtostderr=true \"\nEOF\n```\n\n> --network-plugin=cni  **去掉**\n\n\n\n##### kubelet.conf\n\n/etc/kubernetes/kubelet.conf\n\n```\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: xxxx..xxxxxxx==\n    server: https://192.168.56.108:6443\n  name: k8s\ncontexts:\n- context:\n    cluster: k8s\n    user: system:node:k8s\n  name: system:node:k8s@k8s\ncurrent-context: system:node:k8s@k8s\nkind: Config\npreferences: {}\nusers:\n- name: system:node:k8s\n  user:\n    client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem\n    client-key: /var/lib/kubelet/pki/kubelet-client-current.pem\n```\n\n\n\n##### config.yaml\n\n/var/lib/kubelet/config.yaml\n\n```\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfailSwapOn: false\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n```\n\n\n\n#### service<a id=\"id-service\"/>\n\n##### kubelet.service\n\n```\n[vagrant@k8s kubernetes]$ cat >/usr/lib/systemd/system/kubelet.service <<EOF\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=/var/lib/kubelet\nEnvironmentFile=/opt/kubernetes/kubelet.env\nExecStart=/opt/kubernetes/bin/kubelet  $KUBELET_OPTIONS\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\nkubeadm部署,不用启动,会自动拉起\n\n初始化自动生成\n\n/etc/kubernetes/kubelet.conf\n\n/var/lib/kubelet/config.yaml\n\n\n\n开机自启动\n\n```\nsystemctl enable kubelet\n```\n\n","tags":["kubelet"],"categories":["linux","k8s"]},{"title":"Mathjax公式","url":"/markdown/formula/","content":"\n\n\nWhen $a \\ne 0$, there are two solutions to \\(ax^2 + bx + c = 0\\) and they are\n\n$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$\n\n![](/pics/mathjax01.png)\n\n\n\n<!--more-->\n\nhttp://mathjax.josephjctang.com/\n\n```shell\n$ grep theme.mathjax -rl --include=\\*.{ejs,js} /home/cs/oss/hexo/themes/spfk\n/home/cs/oss/hexo/themes/spfk/layout/_partial/head.ejs\n$ sed -i 's/theme.mathjax/page.mathjax/' /hexo/themes/spfk/layout/_partial/after-footer.ejs\n```\n\n> <% if (page.mathjax){ %>\n\n\n\n/hexo/public/js/MathJax.js 添加引入\n\n```\n  <script type=\"text/javascript\"\n     src=\"http://mathjax.josephjctang.com/MathJax.js?config=TeX-MML-AM_HTMLorMML\">\n  </script>\n```\n\n文章开头加入\n\n```\ntitle: xxxx\npermalink: xxxx\ntags: xxxx\ndate: xxxx\nmathjax: true\n```\n\n> mathjax: true\n\n\n\n引入目录\n\n![](/pics/mathjax.png)\n","tags":["formula"],"categories":["markdown"]},{"title":"harbor镜像私库","url":"/linux/k8s/harbor/","content":"\n## 配置要求\n\n### 硬件\n\n| 资源 | 最低  | 推荐   |\n| ---- | ----- | ------ |\n| CPU  | 2 CPU | 4 CPU  |\n| Mem  | 4 GB  | 8 GB   |\n| Disk | 40 GB | 160 GB |\n\n\n\n### 软件\n\ndocker  v17.06.0-ce+  [Docker 引擎文档](https://docs.docker.com/engine/installation/)\n\ndocker-compose v1.18.0+  [Docker Compose 文档](https://docs.docker.com/compose/install/)\n\nOpenSSL\n\n\n\n### 网络端口\n\nHTTPS  443/4443\n\nHTTP  80\n\n\n\n## 安装\n\n仓库\n\nhttps://github.com/goharbor/harbor/releases\n\n文档\n\nhttps://goharbor.io/docs/2.5.3/install-config/download-installer/\n\n\n\n### harbor\n\n#### 证书ca.key\n\nhttps://goharbor.io/docs/2.5.3/install-config/configure-https/\n\n##### 生成CA私钥\n\n```shell\n openssl genrsa -out ca.key 4096\n```\n\n<!--more-->\n\n##### 生成CA证书\n\n```shell\n openssl req -x509 -new -nodes -sha512 -days 3650 \\\n -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=k8s.org\" \\\n  -key ca.key \\\n  -out ca.crtopenssl genrsa -out ca.key 4096\n```\n\n#### 服务器证书\n\n##### 生成私钥\n\n```shell\n openssl genrsa -out k8s.org.key 4096\n```\n\n##### 生成证书签名请求（CSR）\n\n```shell\nopenssl  req -sha512 -new \\\n -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=k8s.org\" \\\n -key k8s.org.key \\\n -out k8s.org.csr\n```\n\n##### 生成一个x509 v3扩展文件\n\n```shell\n cat > v3.ext <<-EOF\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1=k8s.org\nDNS.2=k8s\nDNS.3=k8s\nEOF\n```\n\n##### 使用该v3.ext文件为您的Harbor主机生成证书\n\n```shell\nopenssl x509 -req -sha512 -days 3650 \\\n    -extfile v3.ext \\\n    -CA ca.crt -CAkey ca.key -CAcreateserial \\\n    -in k8s.org.csr \\\n    -out k8s.org.crt\n```\n\n\n\nDocker守护程序将.crt文件解释为CA证书，并将.cert文件解释为客户端证书\n\n```shell\nopenssl x509 -inform PEM -in k8s.org.crt -out k8s.org.cert\n```\n\n\n\n#### harbor.yml\n\n代理网址 https://ghproxy.com  下载\n\nhttps://ghproxy.com/https://github.com/goharbor/harbor/releases/download/v2.5.3/harbor-offline-installer-v2.5.3.tgz\n\n```\ncs@debian:~/下载/新建文件夹$ md5sum harbor-offline-installer-v2.5.3.tgz \nd858f6969829e4ce2769a790ecaa0cf7  harbor-offline-installer-v2.5.3.tgz\n\ncs@debian:~/下载/新建文件夹$ tar xzvf harbor-offline-installer-v2.5.3.tgz\ncs@debian:~/下载/新建文件夹$ tree -L 1 ./harbor\n./harbor\n├── common.sh\n├── harbor.v2.5.3.tar.gz\n├── harbor.yml.tmpl\n├── install.sh\n├── LICENSE\n└── prepare\n\n0 directories, 6 files\n```\n\n\n\n```\nsed -n '/hostname/s/reg.mydomain.com/192.168.56.1/'p ./harbor/harbor.yml.tmpl \nhostname: 192.168.56.1\nsed -n '/port:/s/443/8443/'p ./harbor/harbor.yml.tmpl \n  port: 8443\nsed -n '/certificate:/s/\\/your.*path/\\/opt\\/nginx\\/conf\\/conf.d\\/ssl\\/k8s.org.crt/'p ./harbor/harbor.yml.tmpl \n  certificate: /opt/nginx/conf/conf.d/ssl/k8s.org.crt\n```\n\n>hostname\n>\n>https   port ,certificate,private_key\n>\n>external_url\n>\n>harbor_admin_password\n>\n>data_volume\n>\n>用外部数据库,redis时需要配置 external_database,external_redis \n\n\n\n```\nsudo ./install.sh\n```\n\n> 默认的 Harbor 安装不包括 Notary 或 Trivy 等服务\n>\n> ./install.sh --with-notary --with-trivy --with-chartmuseum\n>\n>  --with-notary  数据权限\n>\n> --with-trivy   漏洞扫描\n>\n> --with-chartmuseum helm\n\n\n\n### docker\n\n#### certs.d\n\n```shell\ntree -L 3 /etc/docker/\n/etc/docker/\n├── certs.d\n│   └── k8s.org\n│       ├── ca.crt\n│       ├── k8s.org.cert\n│       └── k8s.org.key\n├── daemon.json\n└── key.json\n\n2 directories, 5 files\n```\n\n> cp yourdomain.com.cert /etc/docker/certs.d/yourdomain.com/\n>cp yourdomain.com.key /etc/docker/certs.d/yourdomain.com/\n>cp ca.crt /etc/docker/certs.d/yourdomain.com/\n\n\n\n#### daemon.json\n\n```json\n{\n    \"data-root\": \"/opt/data/docker\",\n   \"registry-mirrors\" : [\n    \"http://hub-mirror.c.163.com\"\n  ],\n\"insecure-registries\":[\n  \"https://k8s.org\"\n  ],\n  \"debug\" : true,\n  \"experimental\" : true\n}\n\n```\n\n> insecure-registries 私库地址,非域名格式 ip:端口\n\n\n\n#### login\n\n登录密码会保存认证,下次push镜像就不需要输入密码了\n\n```shell\ncs@debian:~$ docker login k8s.org\ncs@debian:~$ cat  ~/.docker/config.json \n{\n\t\"auths\": {\n\t\t\"cs.org\": {\n\t\t\t\"auth\": \"YWRtaW46YWRtaW4=\"\n\t\t},\n\t\t\"k8s.org\": {\n\t\t\t\"auth\": \"YWRtaW46Y3MxMjM0NTY=\"\n\t\t}\n\t},\n\t\"HttpHeaders\": {\n\t\t\"User-Agent\": \"Docker-Client/18.09.3 (linux)\"\n\t}\n}\n```\n\n\n\n\n\n### nginx\n\n/opt/nginx/conf/conf.d/http/harbor.conf\n\n```\nupstream harbors{\n     server 192.168.56.1:8443;\n     #server 192.168.56.2:8443;\n}\n\n\nlog_format  harbor_log  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                     '$status $body_bytes_sent \"$http_referer\" '\n                     '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n\nserver {\n       listen       443 ssl;\n       server_name  k8s.org;\n\n        ssl_certificate      conf.d/ssl/k8s.org.crt;\n        ssl_certificate_key  conf.d/ssl/k8s.org.key;\n\n        ssl_session_cache    shared:SSL:1m;\n        ssl_session_timeout  5m;\n\n        ssl_ciphers  HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers  on;\n\n       access_log  logs/harbors.log  harbor_log;\n       location / {\n            client_max_body_size  1024m;  # 设置接收客户端 body 最大长度为 1024M\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass https://harbors;\n        }\n}\n```\n\n> error parsing HTTP 413 response body: ...... <title>413 Request Entity Too Large</title>\n>\n> **client_max_body_size**\n\n\n\n## 推送\n\n域名/目录/镜像名:版本号\n\n```shell\n$ docker images | grep etcd\nk8s.org/k8s/etcd                      3.4.13-0            51401ddb110e        23 months ago       145MB\n\n$ docker push  k8s.org/k8s/etcd:3.4.13-0\n```\n\n\n\n### 项目 \n\n![](/pics/harbor-01.png)\n\n### 镜像\n\n![](/pics/harbor-02.png)\n\n\n\n## 高可用\n\n通过配置数据库(mysql ,redis集群),存储来实现\n\n\n\n## ERROR\n\n### pull Retrying in\n\nhttps://github.com/vmware/harbor/issues/3062\n\n/opt/nginx/conf/nginx.conf\n\n```\nhttp {\n    ......\n      ####添加以下配置\n      proxy_buffers 4 32k;\n      proxy_busy_buffers_size 64k;\n      proxy_temp_file_write_size 64k;\n      #unlimit the proxy temp file size limitaion. Look at issue #3062 (https://github.com/vmware/harbor/issues/3062)\n      proxy_max_temp_file_size 0;\n\n  ....      \n  }\n```\n\n\n\n```\nhttp:\n  relativeurls: true\n```\n\nharbor的helm里需要加上registry.relativeurls=true\n\n参考：https://github.com/docker/distribution/issues/970#issuecomment-284227065\n\n\n\n### ImagePullBackOff\n\n#### 创建一个基于现有凭证的 Secret\n\n```\n$ kubectl create secret generic login --from-file=.dockerconfigjson=/home/cs/.docker/config.json  --type=kubernetes.io/dockerconfigjson \nsecret/login created\n```\n\n\n\n#### 在命令行上提供凭证来创建 Secret\n\n```\nkubectl create secret docker-registry regcred \\\n--docker-server=<你的镜像仓库服务器> \\\n--docker-username=<你的用户名> \\\n--docker-password=<你的密码> \\\n--docker-email=<你的邮箱地址>\n```\n\n>在这里：\n\n>-  是你的私有 Docker 仓库全限定域名（FQDN）。 DockerHub 使用 https://index.docker.io/v1/。\n>-  是你的 Docker 用户名。\n>-  是你的 Docker 密码。\n>-  是你的 Docker 邮箱。\n\n这样你就成功地将集群中的 Docker 凭证设置为名为 regcred 的 Secret\n\n#### 检查 Secret \n\n\n\n```yaml\n$ kubectl get secrets\nNAME                  TYPE                                  DATA   AGE\nlogin                 kubernetes.io/dockerconfigjson        1      85d\n$ kubectl get secret login --output=yaml  \napiVersion: v1\ndata:\n  .dockerconfigjson: ewoJImF1dGhzIjogewoJCSJjcy5vcmciOiB7CgkJCSJhdXRoIjogIllXUnRhVzQ2WVdSdGFXND0iCgkJfSwKCQkiazhzLm9yZyI6IHsKCQkJImF1dGgiOiAiWVdSdGFXNDZZM014TWpNME5UWT0iCgkJfQoJfSwKCSJIdHRwSGVhZGVycyI6IHsKCQkiVXNlci1BZ2VudCI6ICJEb2NrZXItQ2xpZW50LzE4LjA5LjMgKGxpbnV4KSIKCX0KfQ==\nkind: Secret\n....\n```\n\n\n\n```\n$ kubectl get secret login --output=\"jsonpath={.data.\\.dockerconfigjson}\" | base64 --decode\n{\n\t\"auths\": {\n\t\t\"cs.org\": {\n\t\t\t\"auth\": \"YWRtaW46YWRtaW4=\"\n\t\t},\n\t\t\"k8s.org\": {\n\t\t\t\"auth\": \"YWRtaW46Y3MxMjM0NTY=\"\n\t\t}\n\t},\n\t\"HttpHeaders\": {\n\t\t\"User-Agent\": \"Docker-Client/18.09.3 (linux)\"\n\t}\n}\n```\n\n\n\n```\necho \"YWRtaW46Y3MxMjM0NTY=\" | base64 --decode \nadmin:cs12xx\n```\n\n\n\n#### pod\n\n创建一个使用你的 Secret 的 Pod\n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: private-reg\nspec:\n  containers:\n  - name: private-reg-container\n    image: <your-private-image>\n  imagePullSecrets:\n  - name: login\n```\n\n","tags":["harbor"],"categories":["linux","k8s"]},{"title":"kubeadm容器化安装","url":"/linux/k8s/kubeadm/","content":"\n### docker\n\n#### daemon.json\n\n```shell\n[vagrant@k8s ~]$ sudo vi /etc/docker/daemon.json\n[vagrant@k8s ~]$ docker info | grep Driver\nStorage Driver: overlay2\nLogging Driver: json-file\nCgroup Driver: cgroupfs\n[vagrant@k8s ~]$ sudo systemctl restart docker \n[vagrant@k8s ~]$ docker info | grep Driver\nStorage Driver: overlay2\nLogging Driver: json-file\nCgroup Driver: systemd\n[vagrant@k8s ~]$ sudo cat  /etc/docker/daemon.json\n{\n \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n \"insecure-registries\":[\"https://k8s.org\"]\n\n}\n```\n\n>\"exec-opts\": [\"native.cgroupdriver=systemd\"]\n\n Error response from daemon: OCI runtime create failed: systemd cgroup flag passed, but systemd support for managing cgroups is not available\n\n\n\n/etc/sysconfig/modules/ipvs.modules\n\n```\ncat > /etc/sysconfig/modules/ipvs.modules <<EOF\n#!/bin/bash\nmodprobe -- br_netfilter\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack_ipv4\nEOF\nchmod 755 /etc/sysconfig/modules/ipvs.modules\n```\n\n\n\n```\n cat  /etc/sysctl.conf\nnet.ipv4.vs.conntrack=1\nnet.ipv4.vs.conn_reuse_mode=0\nnet.ipv4.vs.expire_nodest_conn=1\n```\n\n\n\n\n\n### 准备images list\n\n```\n./kubeadm config images list\nI0809 21:56:57.334915    4785 version.go:254] remote version is much newer: v1.24.3; falling back to: stable-1.21\nk8s.gcr.io/kube-apiserver:v1.21.14\nk8s.gcr.io/kube-controller-manager:v1.21.14\nk8s.gcr.io/kube-scheduler:v1.21.14\nk8s.gcr.io/kube-proxy:v1.21.14\nk8s.gcr.io/pause:3.4.1\nk8s.gcr.io/etcd:3.4.13-0\nk8s.gcr.io/coredns/coredns:v1.8.0\n```\n\n<!--more-->\n\n\n\n### 依赖conntrack\n\n![](/pics/k8s-not-ipvs-02.png)\n\n```\nyum -y install socat conntrack-tools\n```\n\n\n\n### init配置文件\n\n#### 命令生成默认文件\n\n```\nkubeadm config print init-defaults  > config.yaml\n```\n\n\n\n```\n#生成KubeletConfiguration示例文件 \nkubeadm config print init-defaults --component-configs KubeletConfiguration\n\n#生成KubeProxyConfiguration示例文件 \nkubeadm config print init-defaults --component-configs KubeProxyConfiguration\n```\n\n\n\n```\nansible k8s-108 -m copy -a \"src=/opt/kubernetes/client/k8s-1.21-11/bin/config.yaml dest=/opt/kubernetes  mode=0644\"   -b --become-method sudo --become-user root\n```\n\n\n\n\n\n#### config.yaml\n\n```yaml\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.56.108 #ip\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: k8s # hostname “xxx” could not be reached\n  taints: null\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: k8s.org/k8s  # 镜像仓库源\nkind: ClusterConfiguration\nkubernetesVersion: 1.21.12  #版本\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\ncgroupDriver: systemd\nfailSwapOn: False\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nipvs:\n  minSyncPeriod: 0s\n  scheduler: \"rr\"\n  syncPeriod: 30s\nmode: \"ipvs\"\n```\n\n\n\n#### kubectl\n\n![](/pics/k8s-get-pend-01.png)\n\ndocker: network plugin is not ready: cni config uninitialized\n\n[kubelet.service详解](/linux/k8s/kubelet#id-service)\n\n\n\n### 初始化过程\n\n```shell\n[vagrant@k8s kubernetes]$ sudo ./bin/kubeadm   init --config config.yaml\nW0809 20:30:08.653353    3073 kubelet.go:215] detected \"cgroupfs\" as the Docker cgroup driver, the provided value \"systemd\" in \"KubeletConfiguration\" will be overrided\n[init] Using Kubernetes version: v1.21.12\n[preflight] Running pre-flight checks\n\t[WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/\n\t[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.56.108]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s localhost] and IPs [192.168.56.108 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s localhost] and IPs [192.168.56.108 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s\n[apiclient] All control plane components are healthy after 12.505234 seconds\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Skipping phase. Please see --upload-certs\n[mark-control-plane] Marking the node k8s as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[bootstrap-token] Using token: abcdef.0123456789abcdef\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.56.108:6443 --token abcdef.0123456789abcdef \\\n\t--discovery-token-ca-cert-hash sha256:01661c34149742e27fa96db2f1c4a8d4675d2f0b5133f8cd25a45e031eb23653 \n```\n\n\n\n### 节点配置文件\n\n```\nkubeadm config print join-defaults > join-config.yaml\n```\n\n\n\n\n\n```\nkubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap\n```\n\n>error: failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User \"kubelet-bootstrap\" cannot create certificatesigningrequests.certificates.k8s.io at the cluster scope\n>\n\n\n\n\n\n### 网络插件podnetwork\n\nhttps://kubernetes.io/docs/concepts/cluster-administration/addons/\n\n\n\n#### flanneld\n\n[查看flanneld.yaml](/linux/k8s/flanneld)\n\n```shell\nansible k8s-108 -m copy -a \"src=/home/cs/oss/0s/k8s/kube/kube-flanneld.yml  dest=/opt/kubernetes  mode=0644\"   -b --become-method sudo --become-user root\n```\n\n\n\n```shell\n[vagrant@k8s kubernetes]$ kubectl apply -f kube-flanneld.yaml \nWarning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\npodsecuritypolicy.policy/psp.flannel.unprivileged created\nWarning: rbac.authorization.k8s.io/v1beta1 ClusterRole is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRole\nclusterrole.rbac.authorization.k8s.io/flannel created\nWarning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBinding\nclusterrolebinding.rbac.authorization.k8s.io/flannel created\nserviceaccount/flannel created\nconfigmap/kube-flannel-cfg created\ndaemonset.apps/kube-flannel-ds-amd64 created\n```\n\n\n\n#### calico\n\nhttps://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises\n\ncalico.yaml https://docs.projectcalico.org/manifests/calico.yaml\n\n\n\n### kubectl权限\n\n#### ~/.kube/config\n\n```\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n\n\n\n\n### 组件状态cs\n\n#### Unhealthy \n\n![](/pics/k8s-get-cs-01.png)\n\n\n\n注释`port=0`行\n\n```shell\n[vagrant@k8s kubernetes]$ sudo sed -i '/port=0/s/^/#/'  /etc/kubernetes/manifests/kube-controller-manager.yaml\n[vagrant@k8s kubernetes]$ sudo sed -i '/port=0/s/^/#/'  /etc/kubernetes/manifests/kube-scheduler.yaml\n```\n\n![](/pics/k8s-get-cs-02.png)\n\n\n\n### 加入集群\n\n集群初始化时的添加命令\n\n```\nkubeadm join 192.168.56.108:6443 --token abcdef.0123456789abcdef \\\n\t--discovery-token-ca-cert-hash sha256:01661c34149742e27fa96db2f1c4a8d4675d2f0b5133f8cd25a45e031eb23653\n```\n\n命令方式获取join参数\n\n```\nkubeadm token create --print-join-command\n```\n\n\n\n\n\n重新生成certificate-key,生成用于加入控制平面的secret\n\n```\nkubeadm init phase upload-certs --upload-certs\n```\n\n> Using certificate key:xxxx\n\n\n\n#### 加入控制节点\n\n```\nkubeadm join 192.168.56.108:6443 --token abcdef.0123456789abcdef \\\n\t--discovery-token-ca-cert-hash sha256:01661c34149742e27fa96db2f1c4a8d4675d2f0b5133f8cd25a45e031eb23653    --control-plane --certificate-key xxxx\n```\n\n\n\n\n\n\n\n### Pending状态\n\n```\nkubectl logs kube-flannel-ds-amd64-7wjtn -n kube-system\n```\n\n> Error registering network: failed to acquire lease: node \"k8s\" pod cidr not assigned\n\n![](/pics/k8s-get-node-01.png)\n\nmaster节点一直notready  和  coredns pod一直pending\n\n安装flannel\n\n![](/pics/k8s-get-node-02.png)\n\n\n\n### pod-network-cidr\n\n#### 修改 \n\n--pod-network-cidr\n\n```\n1）kubectl -n kube-system edit cm kubeadm-config\n2）vim /etc/kubernetes/manifests/kube-scheduler.yaml\n```\n\n#### 检查配置\n\n```\nkubectl cluster-info dump | grep -m 1 cluster-cidr\n```\n\n**kube-proxy的cluster-cidr与kuber-controller-manager的cluster-cidr**\n\n\n\n\n\n```objectivec\n kubectl scale deployment --replicas=0 dns-autoscaler -n kube-system\ndeployment.extensions/dns-autoscaler scaled\n# kubectl patch deployment coredns -p '{\"spec\":{\"replicas\":17}}' -n kube-system\ndeployment.extensions/coredns patched\n# kubectl get pod -n kube-system |grep coredns |wc -l\n```\n\n\n\n### 重启\n\n```\nsystemctl status kubelet\nsudo systemctl start kubelet\n```\n\n> *静态 Pod* 在指定的节点上由 kubelet 守护进程直接管理，不需要 [API 服务器](https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/) 监管,kubelet 监视每个静态 Pod（在它崩溃之后重新启动）\n>\n> –pod-manifest-path=\n\n#### 常见的 Static Pod\n\n- etcd\n- kube-apiserver\n- kube-controller-manager\n- kube-scheduler\n\n\n\n### 卸载\n\n```shell\nsudo kubeadm reset -f\nsudo rm -rf /var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni /etc/kubernetes\n```\n\n\n\n\n\n### 多集群\n\n#### 多个配置\n\n一台机器管理多个集群\n\n```shell\ncs@debian:~$ ls -l ~/.kube/\n总用量 36\ndrwxr-x--- 3 cs cs 4096 4月  20 14:37 cache\n-rw------- 1 cs cs 9852 8月  10 21:58 config\n-rw-r--r-- 1 cs cs 5597 8月  10 21:56 config1   #k8s 容器部署\n-rw------- 1 cs cs 6201 8月   6 16:57 config2   #kubernetes二进制部署\ndrwxr-x--- 3 cs cs 4096 8月  10 21:58 http-cache\n```\n\n#### 合并配置\n\n```shell\n$ KUBECONFIG=/home/cs/.kube/config1:/home/cs/.kube/config2 kubectl config view --flatten >/home/cs/.kube/config\n```\n\n![](/pics/k8s-view-cluster.png)\n\n\n\n#### 获取集群配置\n\n```shell\ncs@debian:~$ kubectl config get-contexts\nCURRENT   NAME                   CLUSTER      AUTHINFO           NAMESPACE\n          admin@kubernetes       kubernetes   admin              \n*         kubernetes-admin@k8s   k8s          kubernetes-admin  \n```\n\n##### 容器部署\n\n```\ncs@debian:~$ kubectl get cs\nNAME                 STATUS    MESSAGE             ERROR\nscheduler            Healthy   ok                  \ncontroller-manager   Healthy   ok                  \netcd-0               Healthy   {\"health\":\"true\"}   \ncs@debian:~$ kubectl get node\nNAME   STATUS   ROLES                  AGE     VERSION\nk8s    Ready    control-plane,master   4m57s   v1.21.11\n```\n\n\n\n\n\n#### 换集群\n\nuse-context\n\n```shell\n#当前集群\ncs@debian:~$ kubectl config current-context   \nkubernetes-admin@k8s\n\ncs@debian:~$ kubectl config use-context admin@kubernetes   \nSwitched to context \"admin@kubernetes\".\n```\n\n##### 二进制部署\n\n```shell\ncs@debian:~$ kubectl get cs\nNAME                 STATUS    MESSAGE              ERROR\nscheduler            Healthy   ok                   \ncontroller-manager   Healthy   ok                   \netcd-1               Healthy   {\"health\": \"true\"}   \netcd-0               Healthy   {\"health\": \"true\"}   \netcd-2               Healthy   {\"health\": \"true\"}   \ncs@debian:~$ kubectl get node\nNAME       STATUS     ROLES    AGE    VERSION\nmaster02   Ready      <none>   121d   v1.18.8\nmaster03   Ready      <none>   121d   v1.18.8\nnode04     Ready      <none>   121d   v1.18.8\nnode05     NotReady   <none>   121d   v1.18.8\nnode06     Ready      <none>   121d   v1.18.8\n```\n\n\n\n\n\n![](/pics/k8s-more-cluster.png)\n\n> current-context 显示 current_context\n> delete-cluster  删除 kubeconfig 文件中指定的集群\n> delete-context  删除 kubeconfig 文件中指定的 context\n> get-clusters    显示 kubeconfig 文件中定义的集群\n> get-contexts    描述一个或多个 contexts\n> rename-context  从 kubeconfig 文件重命名上下文。\n> set             设置 kubeconfig 文件中的一个单个值\n> set-cluster     设置 kubeconfig 文件中的一个集群条目\n> set-context     设置 kubeconfig 文件中的一个 context 条目\n> set-credentials 设置 kubeconfig 文件中的一个用户条目\n> unset           取消设置 kubeconfig 文件中的一个单个值\n> use-context     设置 kubeconfig 文件中的当前上下文\n> view            显示合并的 kubeconfig 配置或一个指定的 kubeconfig 文件\n\n\n\n","tags":["kubeadm"],"categories":["linux","k8s"]},{"title":"flanneld虚拟网络","url":"/linux/k8s/flanneld/","content":"\n\n\ngithub https://github.com/flannel-io/flannel/tree/v0.16.1/Documentation\n\n\n\nflanneld.yaml \n\n```yaml\n---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: psp.flannel.unprivileged\n  annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default\n    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default\n    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default\n    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default\nspec:\n  privileged: false\n  volumes:\n  - configMap\n  - secret\n  - emptyDir\n  - hostPath\n  allowedHostPaths:\n  - pathPrefix: \"/etc/cni/net.d\"\n  - pathPrefix: \"/etc/kube-flannel\"\n  - pathPrefix: \"/run/flannel\"\n  readOnlyRootFilesystem: false\n  # Users and groups\n  runAsUser:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  fsGroup:\n    rule: RunAsAny\n  # Privilege Escalation\n  allowPrivilegeEscalation: false\n  defaultAllowPrivilegeEscalation: false\n  # Capabilities\n  allowedCapabilities: ['NET_ADMIN', 'NET_RAW']\n  defaultAddCapabilities: []\n  requiredDropCapabilities: []\n  # Host namespaces\n  hostPID: false\n  hostIPC: false\n  hostNetwork: true\n  hostPorts:\n  - min: 0\n    max: 65535\n  # SELinux\n  seLinux:\n    # SELinux is unused in CaaSP\n    rule: 'RunAsAny'\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nrules:\n- apiGroups: ['extensions']\n  resources: ['podsecuritypolicies']\n  verbs: ['use']\n  resourceNames: ['psp.flannel.unprivileged']\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  verbs:\n  - get\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes\n  verbs:\n  - list\n  - watch\n- apiGroups:\n  - \"\"\n  resources:\n  - nodes/status\n  verbs:\n  - patch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: flannel\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: flannel\nsubjects:\n- kind: ServiceAccount\n  name: flannel\n  namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: flannel\n  namespace: kube-system\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: kube-flannel-cfg\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\ndata:\n  cni-conf.json: |\n    {\n      \"name\": \"cbr0\",\n      \"cniVersion\": \"0.3.1\",\n      \"plugins\": [\n        {\n          \"type\": \"flannel\",\n          \"delegate\": {\n            \"hairpinMode\": true,\n            \"isDefaultGateway\": true\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"capabilities\": {\n            \"portMappings\": true\n          }\n        }\n      ]\n    }\n  net-conf.json: |\n    {\n      \"Network\": \"10.244.0.0/16\",\n      \"Backend\": {\n        \"Type\": \"vxlan\"\n      }\n    }\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-flannel-ds\n  namespace: kube-system\n  labels:\n    tier: node\n    app: flannel\nspec:\n  selector:\n    matchLabels:\n      app: flannel\n  template:\n    metadata:\n      labels:\n        tier: node\n        app: flannel\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/os\n                operator: In\n                values:\n                - linux\n      hostNetwork: true\n      priorityClassName: system-node-critical\n      tolerations:\n      - operator: Exists\n        effect: NoSchedule\n      serviceAccountName: flannel\n      initContainers:\n      - name: install-cni-plugin\n        image: k8s.org/k8s/flannel-cni-plugin:v1.0.0-amd64\n        command:\n        - cp\n        args:\n        - -f\n        - /flannel\n        - /opt/cni/bin/flannel\n        volumeMounts:\n        - name: cni-plugin\n          mountPath: /opt/cni/bin\n      - name: install-cni\n        image: k8s.org/k8s/flannel:v0.15.1-amd64\n        command:\n        - cp\n        args:\n        - -f\n        - /etc/kube-flannel/cni-conf.json\n        - /etc/cni/net.d/10-flannel.conflist\n        volumeMounts:\n        - name: cni\n          mountPath: /etc/cni/net.d\n        - name: flannel-cfg\n          mountPath: /etc/kube-flannel/\n      containers:\n      - name: kube-flannel\n        image: k8s.org/k8s/flannel:v0.15.1-amd64\n        command:\n        - /opt/bin/flanneld\n        args:\n        - --ip-masq\n        - --kube-subnet-mgr\n        - --iface=eth1\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"50Mi\"\n          limits:\n            cpu: \"100m\"\n            memory: \"50Mi\"\n        securityContext:\n          privileged: false\n          capabilities:\n            add: [\"NET_ADMIN\", \"NET_RAW\"]\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: run\n          mountPath: /run/flannel\n        - name: flannel-cfg\n          mountPath: /etc/kube-flannel/\n      volumes:\n      - name: run\n        hostPath:\n          path: /run/flannel\n      - name: cni-plugin\n        hostPath:\n          path: /opt/cni/bin\n      - name: cni\n        hostPath:\n          path: /etc/cni/net.d\n      - name: flannel-cfg\n        configMap:\n          name: kube-flannel-cfg\n```\n\n\n\n","tags":["flanneld"],"categories":["linux","k8s"]},{"title":"kubernetes部署结构","url":"/linux/k8s/k8s/","content":"\n## go env\n\n编译二进制\n\nYou have a working [Go environment](https://golang.org/doc/install).\n\n```shell\nGOPATH=`go env | grep GOPATH | cut -d '\"' -f 2 `\nmkdir -p $GOPATH/src/k8s.io\ncd $GOPATH/src/k8s.io\ngit clone https://github.com/kubernetes/kubernetes\ncd kubernetes\ngit checkout v1.21.12\nmake\n```\n\n\n\n## 前置条件配置\n\n- 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令\n- 每台机器 `2 GB` 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存）\n- `2 CPU` 核或更多\n- 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)\n- 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见[这里](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#verify-mac-address)了解更多详细信息。\n- 开启机器上的某些端口。请参见[这里](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports) 了解更多详细信息。\n- 禁用交换分区。为了保证 kubelet 正常工作，你 **必须** 禁用交换分区\n\n更多见 https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n\n\n\n## 2种 HA 集群方式\n\n文档 https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/ha-topology/\n\n### 堆叠（Stacked）etcd \n\n这种拓扑将控制平面和 etcd 成员耦合在同一节点上,设置简单.存在耦合失败的风险\n\n![](/pics/etcd-stacked.png)\n\n\n\n<!--more-->\n\n### 外部 etcd 节点\n\n这种拓扑结构解耦了控制平面和 etcd 成员.需要两倍于堆叠 HA 拓扑的主机数量\n\n![](/pics/etcd-external.png)\n","tags":["kubernetes"],"categories":["linux","k8s"]},{"title":"iptable防火墙","url":"/linux/shell/iptable/","content":"\n\n\n\n\n\n\n\n\n### 数据流向\n\n![](/pics/iptable-01.png)\n\n\n\n-  当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 \n- 如果数据包就是**`进入本机`**的，它就会到达INPUT链。数据包到了**`INPUT链`**后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。 \n- 如果数据包是要**`转发出去`**的，且内核允许转发，数据包就会如图所示向右移动，经过**`FORWARD链`**，然后到达POSTROUTING链输出。\n  \n\n![](/pics/iptable-01-1.png)\n\n\n\n```shell\n#临时生效\necho 1 > /proc/sys/net/ipv4/ip_forward\n#永久生效\ncs@debian:~/oss/hexo$ cat /etc/sysctl.conf | grep net.ipv4.ip_\nnet.ipv4.ip_forward=1\n```\n\n<!--more-->\n\n![](/pics/iptable-01-2.png)\n\n\n\n\n\n### 命令规则\n\n![](/pics/iptable-02.png)\n\n- 所有表名必须小写\n\n  filter/nat/mangle\n\n- 所有链名必须大写\n   INPUT/OUTPUT/FORWARD/PREROUTING/POSTROUTING\n\n| 名称        | 功能                                                         | 作用的表                                                     |\n| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| PREROUTING  | 主机外报文进入位置                                           | mangle, nat（目标地址转换，，通常指响应报文）                |\n| INPUT       | 报文进入本机用户空间位置                                     | filter, mangle                                               |\n| OUTPUT      | 报文从本机用户空间出去的位置                                 | filter, mangle, nat                                          |\n| FOWARD      | 报文经过路由并且发觉不是本机决定转发但还不知道从哪个网卡出去 | filter, mangle（中转）                                       |\n| POSTROUTING | 报文经过路由被转发出去                                       | 许mangle，nat（源地址转换，把原始地址转换为转发主机出口网卡地址） |\n\n \n\n- 所有匹配必须小写\n   -s/-d/-m <module_name>/-p\n\n- 所有动作必须大写\n   ACCEPT/DROP/SNAT/DNAT/MASQUERADE\n\n\n\n","tags":["iptable"],"categories":["linux","shell"]},{"title":"grep常用过滤","url":"/linux/shell/grep/","content":"\n\n\n### 前后行 A B C\n\ngrep -A 显示匹配指定内容及之后的n行\n\ngrep -B 显示匹配指定内容及之前的n行\n\ngrep -C  显示匹配指定内容及其前后各n行\n\n```shell\ncs@debian:~/oss/hexo$ cat /opt/nginx/logs/k8s-access.log | grep -C 5 \"2022:15:43:27\"\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:22 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:23 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:24 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:25 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:26 +0800] 502 0\n127.0.0.1 - 192.168.56.103:6443, 192.168.56.101:6443, 192.168.56.102:6443 - [31/Jul/2022:15:43:27 +0800] 502 0, 0, 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:28 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:29 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:30 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:30 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:31 +0800] 502 0\n```\n\n\n\n### 与操作  \n\n多次匹配\n\n```shell\ncs@debian:~/oss/hexo$ cat /opt/nginx/logs/k8s-access.log | grep \"2022:15:43:2\" | grep 502\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:20 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:21 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:21 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:22 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:23 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:24 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:25 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:26 +0800] 502 0\n127.0.0.1 - 192.168.56.103:6443, 192.168.56.101:6443, 192.168.56.102:6443 - [31/Jul/2022:15:43:27 +0800] 502 0, 0, 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:28 +0800] 502 0\n127.0.0.1 - k8s-apiserver - [31/Jul/2022:15:43:29 +0800] 502 0\n```\n\n\n\n### 或操作 |\n\n<!--more-->\n\n```shell\ncs@debian:~/oss/hexo$ cat /opt/nginx/logs/k8s-access.log | grep \"502\\|15:43:3\\|kube-apiserver\"\n\n```\n\n>grep  -E  \"502|15:43:3|kube-apiserver\"\n>\n>egrep   \"502|15:43:3|kube-apiserver\"\n>\n>awk  \"502|15:43:3|kube-apiserver\"   file\n\n\n\n\n\n### 特殊字符 fgrep\n\n搜索文件包含正则表达式元字符串时,例如`$`、`^`、`/`等，`fgrep`很有用\n\n```shell\ncs@debian:~/oss/hexo$ egrep \"^Hello\"  12\ncs@debian:~/oss/hexo$ grep \"^Hello\"  12\ncs@debian:~/oss/hexo$ fgrep \"^Hello\"  12\n^Hello\\\n```\n\n它`不解析正则表达式`、想搜什么就跟什么\n\n\n\n### 压缩文件  zgrep\n\n```shell\nzgrep  pattern1  ./*   |  grep  pattern2\n```\n\n>zegrep  \n>\n>\n>zcat file1.gz file2.gz\n","tags":["grep"],"categories":["linux","shell"]},{"title":"tree工具","url":"/linux/shell/tree/","content":"\n\n\n\n\n### 目录层级 -Ld\n\n-d 目录\n\n-L  level 层级\n\n\n\n```\ncs@debian:/$ tree -Ld  1\n.\n├── bin\n├── boot\n├── dev\n├── etc\n├── home\n├── lib\n├── lib64\n├── lost+found\n├── media\n├── mnt\n├── opt\n├── proc\n├── root\n├── run\n├── sbin\n├── snap\n├── srv\n├── sys\n├── tmp\n├── usr\n└── var\n```\n\n\n\n### 路径前缀 -f\n\n-f   打印路径的前缀(根据命令指定显示)\n\n```\ncs@debian:/opt/apache$ tree -Ldf  1 ./\n.\n├── ./apache-maven-3.8.6\n├── ./kafka-2.1.1\n├── ./maven-3.6.0\n├── ./tomcat-8.5.38\n└── ./zookeeper-3.4.13\n\n5 directories\ncs@debian:/opt/apache$ tree -Ldf  1 /opt/apache/\n/opt/apache\n├── /opt/apache/apache-maven-3.8.6\n├── /opt/apache/kafka-2.1.1\n├── /opt/apache/maven-3.6.0\n├── /opt/apache/tomcat-8.5.38\n└── /opt/apache/zookeeper-3.4.13\n\n5 directories\n```\n\n\n\n<!--more-->\n\n\n\n### 过滤 -I\n\n\n\n```\ncs@debian:~/oss/0s$ tree -L 3  -I \"src|target\" ./spring-boot/cs-framework/  ./spring-boot/cs-framework/\n├── cs-msc\n│   ├── lib\n│   │   ├── json-jena-1.0.jar\n│   │   └── Msc.jar\n│   ├── msc\n│   │   ├── libmsc32.so\n│   │   ├── libmsc64.so\n│   │   ├── msc32.dll\n│   │   └── msc64.dll\n│   ├── pom.xml\n│   └── READER.md\n├── cs-ocr\n│   ├── libs\n│   │   └── ocr_sdk-1.3.6.jar\n│   └── pom.xml\n└── pom.xml\n\n5 directories, 11 files\n```\n\n\n\n```\ncs@debian:~/oss/0s$ tree -L 3  -I *.jar* ./spring-boot/cs-framework/  \n./spring-boot/cs-framework/\n├── cs-msc\n│   ├── lib\n│   ├── msc\n│   │   ├── libmsc32.so\n│   │   ├── libmsc64.so\n│   │   ├── msc32.dll\n│   │   └── msc64.dll\n│   ├── pom.xml\n│   ├── READER.md\n│   ├── src\n│   │   └── main\n│   └── target\n│       ├── classes\n│       ├── generated-sources\n│       ├── maven-archiver\n│       └── maven-status\n├── cs-ocr\n│   ├── libs\n│   ├── pom.xml\n│   ├── src\n│   │   └── main\n│   └── target\n│       ├── classes\n│       ├── generated-sources\n│       ├── maven-archiver\n│       └── maven-status\n└── pom.xml\n\n19 directories, 8 files\n```\n\n\n\n\n\n### 匹配 -P\n\n```\ncs@debian:~/oss/0s$ tree -L 3 -P *xml -I \"src|target\" ./spring-boot/cs-framework/  \n./spring-boot/cs-framework/\n├── cs-msc\n│   ├── lib\n│   ├── msc\n│   └── pom.xml\n├── cs-ocr\n│   ├── libs\n│   └── pom.xml\n└── pom.xml\n\n5 directories, 3 files\n```\n\n\n\n### 大小时间 -ts\n\n-t 时间排序(默认从旧到新,r反序)\n\n-s 大小\n\n```\ncs@debian:/opt/apache$ tree -Ldrts  1 /opt/apache/\n/opt/apache/\n├── [       4096]  apache-maven-3.8.6\n├── [       4096]  tomcat-8.5.38\n├── [       4096]  maven-3.6.0\n├── [       4096]  kafka-2.1.1\n└── [       4096]  zookeeper-3.4.13\n\n5 directories\n```\n\n\n\n### 权限角色 -pus\n\n-p 权限\n\n-u  角色\n\n-g 组\n\n```\ncs@debian:/opt/apache$ tree -Ldpu  1 /opt/apache/\n/opt/apache/\n├── [drwxr-xr-x cs      ]  apache-maven-3.8.6\n├── [drwxr-xr-x cs      ]  kafka-2.1.1\n├── [drwxr-xr-x cs      ]  maven-3.6.0\n├── [drwxr-xr-x cs      ]  tomcat-8.5.38\n└── [drwxr-xr-x cs      ]  zookeeper-3.4.13\n\n5 directories\n\n```\n\n\n\n\n\n\n\n### 着色 -C\n\n-n 关闭\n\n-C 打开\n\n```shell\ncs@debian:/opt/apache$ tree -LdC  1 /opt/apache/\n/opt/apache/\n├── [       4096]  apache-maven-3.8.6\n├── [       4096]  tomcat-8.5.38\n├── [       4096]  maven-3.6.0\n├── [       4096]  kafka-2.1.1\n└── [       4096]  zookeeper-3.4.13\n\n5 directories\n\n```\n\n\n\n\n\n### 格式  -j\n\n -i 不打印虚线\n\n-X xml格式 \n\n-J   json格式\n\n```\ncs@debian:/opt/apache$ tree -Ldrtsi  1 /opt/apache/\n/opt/apache/\n[       4096]  apache-maven-3.8.6\n[       4096]  tomcat-8.5.38\n[       4096]  maven-3.6.0\n[       4096]  kafka-2.1.1\n[       4096]  zookeeper-3.4.13\n\n5 directories\ncs@debian:/opt/apache$ tree -LdrtsX  1 /opt/apache/\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<tree>\n  <directory name=\"/opt/apache/\">\n    <directory name=\"apache-maven-3.8.6\" size=\"4096\">\n    </directory>\n    <directory name=\"tomcat-8.5.38\" size=\"4096\">\n    </directory>\n    <directory name=\"maven-3.6.0\" size=\"4096\">\n    </directory>\n    <directory name=\"kafka-2.1.1\" size=\"4096\">\n    </directory>\n    <directory name=\"zookeeper-3.4.13\" size=\"4096\">\n    </directory>\n  </directory>\n  <report>\n    <directories>5</directories>\n  </report>\n</tree>\ncs@debian:/opt/apache$ tree -LdrtsJ  1 /opt/apache/\n[\n  {\"type\":\"directory\",\"name\":\"/opt/apache/\",\"contents\":[\n    {\"type\":\"directory\",\"name\":\"apache-maven-3.8.6\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"tomcat-8.5.38\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"maven-3.6.0\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"kafka-2.1.1\",\"size\":4096,\"contents\":[\n    ]},\n    {\"type\":\"directory\",\"name\":\"zookeeper-3.4.13\",\"size\":4096,\"contents\":[\n    ]}\n  ]},\n  {\"type\":\"report\",\"directories\":5}\n]\n```\n\n\n\n","tags":["tree"],"categories":["linux","shell"]},{"title":"maven介绍","url":"/tool/maven/","content":"\n\n\n\n\n\n\n## 安装\n\n### 环境变量\n\n```\ncs@debian:~/oss/hexo$ wget https://dlcdn.apache.org/maven/maven-3/3.8.6/binaries/apache-maven-3.8.6-bin.tar.gz -O apache-maven-3.8.6-bin.tar.gz\ncs@debian:~/oss/hexo$ tar -zxvf apache-maven-3.8.6-bin.tar.gz -C /opt/apache\ncs@debian:~/oss/hexo$ cat >>  ~/.bashrc <<EOF\n#maven\nif [ -d \"/opt/apache/maven-3.8.6\" ] ; then\n    export MAVEN_HOME=/opt/apache/maven-3.8.6\n    export PATH=${MAVEN_HOME}/bin:\\$PATH\nfi\nEOF\n```\n\n### 版本\n\n```\ncs@debian:~/oss/hexo$ mvn -version\n```\n\n> Apache Maven 3.8.6 (84538c9988a25aec085021c365c560670ad80f63)\n> Maven home: /opt/apache/apache-maven-3.8.6\n> Java version: 11.0.12, vendor: Oracle Corporation, runtime: /opt/jdk/jdk-11.0.12\n> Default locale: zh_CN, platform encoding: UTF-8\n> OS name: \"linux\", version: \"4.9.0-8-amd64\", arch: \"amd64\", family: \"unix\"\n\n\n\n##  基本命令\n\n### 编译\n\n```\nmvn compile　\n```\n\n  --src/main/java目录java源码编译生成class （target目录下）\n\n　　　　　　　　　　\n\n### 测试\n\n```\nmvn test　\n```\n\n   --src/test/java 目录编译\n\n　　　　　　　　　　\n\n### 清理\n\n```\nmvn clean\n```\n\n  --删除target目录，也就是将class文件等删除\n\n　　　　　　　　　　\n\n### 打包\n\n```\nmvn package　\n```\n\n --生成压缩文件：java项目#jar包；web项目#war包，也是放在target目录下\n\n　　　　　　　　　　\n\n### 安装\n\n```\nmvn install　　\n```\n\n--将压缩文件(jar或者war)上传到本地仓库\n\n　　　　　　　　　　\n\n### 部署|发布\n\n```\nmvn deploy　　\n```\n\n--将压缩文件上传私服\n\n\n\n### [多模块](#idmore)\n\n\n\n\n\n场景:几百个微服务只打部分包\n\n\n\n<!--more-->\n\n\n\n### 周期\n\n| **验证（validate）**                        | 验证项目是正确的，所有必要的信息可用。                       |\n| ------------------------------------------- | ------------------------------------------------------------ |\n| **初始化（initialize）**                    | 初始化构建状态，例如设置属性或创建目录。                     |\n| **产生来源（generate-sources）**            | 生成包含在编译中的任何源代码。                               |\n| **流程源（process-sources）**               | 处理源代码，例如过滤任何值。                                 |\n| **生成资源（generate-resources）**          | 生成包含在包中的资源。                                       |\n| **流程资源（process-resources）**           | 将资源复制并处理到目标目录中，准备打包。                     |\n| **编译（compile）**                         | 编译项目的源代码。                                           |\n| **工艺类（process-classes）**               | 从编译后处理生成的文件，例如对Java类进行字节码增强。         |\n| **生成测试来源（generate-test-sources）**   | 生成包含在编译中的任何测试源代码。                           |\n| **流程测试来源（process-test-sources）**    | 处理测试源代码，例如过滤任何值。                             |\n| **生成测试资源（generate-test-resources）** | 创建测试资源。                                               |\n| **流程测试资源（process-test-resources）**  | 将资源复制并处理到测试目标目录中。                           |\n| **测试编译（test-compile）**                | 将测试源代码编译到测试目标目录中                             |\n| **流程检验类（process-test-classes）**      | 从测试编译中处理生成的文件，例如对Java类进行字节码增强。对于Maven 2.0.5及以上版本。 |\n| **测试（test）**                            | 使用合适的单元测试框架运行测试。这些测试不应该要求代码被打包或部署。 |\n| **制备包（prepare-package）**               | 在实际包装之前，执行必要的准备包装的操作。这通常会导致打包的处理版本的包。（Maven 2.1及以上） |\n| **打包（package）**                         | 采取编译的代码，并以其可分发的格式（如JAR）进行打包。        |\n| **预集成测试（pre-integration-test）**      | 在执行集成测试之前执行所需的操作。这可能涉及诸如设置所需环境等。 |\n| **集成测试（integration-test）**            | 如果需要，可以将该包过程并部署到可以运行集成测试的环境中。   |\n| **整合后的测试（post-integration-test）**   | 执行集成测试后执行所需的操作。这可能包括清理环境。           |\n| **校验（verify）**                          | 运行任何检查以验证包装是否有效并符合质量标准。               |\n| **安装（install）**                         | 将软件包安装到本地存储库中，以作为本地其他项目的依赖关系。   |\n| **部署（deploy）**                          | 在集成或发布环境中完成，将最终软件包复制到远程存储库，以与其他开发人员和项目共享。 |\n\n\n\n## 高级命令\n\n在<a id=\"idmore\">多模块</a>Maven项目中，反应堆（Reactor）是一个包含了所有需要构建模块的抽象概念，对于Maven用户来说，主要关心的是两点：\n\n1. 哪些模块会被包含到反应堆中？\n2. 反应堆中所有模块的构建顺序是什么？\n\n\n\n```\n$ tree -L 3 -P *xml -I \"src|target\" ./spring-boot/\n./spring-boot/\n├── cs-framework\n│   ├── cs-msc\n│   │   ├── lib\n│   │   ├── msc\n│   │   └── pom.xml\n│   ├── cs-ocr\n│   │   ├── libs\n│   │   └── pom.xml\n│   ├── cs-shiro\n│   │   └── pom.xml\n│   └── pom.xml\n├── cs-tool\n│   ├── cs-common\n│   │   └── pom.xml\n│   ├── cs-email\n│   │   └── pom.xml\n│   ├── cs-jpa\n│   │   └── pom.xml\n│   ├── cs-rw-aop\n│   │   └── pom.xml\n│   ├── cs-rw-druid\n│   │   └── pom.xml\n│   └── pom.xml\n└── pom.xml\n```\n\n\n\n一级\n\n```xml\n<groupId>com.cs</groupId>\n  <artifactId>cs-parent</artifactId>\n   <version>${version}</version>\n\n  <modules>\n    <module>cs-framework</module>\n    <module>cs-tool</module>\n  </modules>\n  <packaging>pom</packaging>\n  \n  <name>cs-parent</name>\n```\n\n\n\n\n\n二级\n\n```xml\n <parent>\n    <groupId>com.cs</groupId>\n    <artifactId>cs-parent</artifactId>\n    <version>${version}</version>\n  </parent>\n\n <groupId>com.cs</groupId>\n  <artifactId>cs-framework</artifactId>\n   <version>${version}</version>\n  <name>cs-framework</name>\n  <packaging>pom</packaging>\n  \n   <modules>\n     <module>cs-shiro</module>\n    <module>cs-ocr</module>\n    <module>cs-msc</module>\n  </modules>\n```\n\n\n\n子\n\n```xml\n  <parent>\n    <groupId>com.cs</groupId>\n    <artifactId>cs-framework</artifactId>\n    <version>${version}</version>\n  </parent>\n  <groupId>com.cs</groupId>\n  <artifactId>cs-ocr</artifactId>\n  <version>${version}</version>\n  <name>cs-ocr</name>\n```\n\n\n\n```\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary for cs-parent 0.0.1-SNAPSHOT:\n[INFO] \n[INFO] cs-parent .......................................... SUCCESS [  0.163 s]\n[INFO] cs-tool ............................................ SUCCESS [  0.005 s]\n[INFO] cs-common .......................................... SUCCESS [  0.800 s]\n[INFO] cs-framework ....................................... SUCCESS [  0.006 s]\n[INFO] cs-ocr ............................................. SUCCESS [  3.194 s]\n[INFO] cs-msc ............................................. SUCCESS [  0.271 s]\n[INFO] cs-jpa ............................................. SUCCESS [  0.471 s]\n[INFO] cs-rw-aop .......................................... SUCCESS [  1.074 s]\n[INFO] cs-rw-druid ........................................ SUCCESS [  0.893 s]\n[INFO] cs-email ........................................... SUCCESS [  2.520 s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  9.736 s\n[INFO] Finished at: 2022-07-30T21:51:32+08:00\n[INFO] ------------------------------------------------------------------------\n```\n\n\n\n\n\n### 指定 -pl\n\n手动选择项目，多个逗号隔开\n\n```\nmvn install -pl web/style,web/login\n```\n\n>-pl,--projects <arg>                   \n>Build specified reactor projects instead of all projects. \n>A project can be specified by [groupId]:artifactId or by its relative path.\n\n\n\n### 所需依赖 -am\n\n构建某个子模块\n\n```\nmvn install -pl web/style  -am\n```\n\n>项目被指定，构建该项目所需依赖\n>\n> -am,--also-make                      \n>  If project list is specified, also  build projects required by the  list\n\n构建 parent ，framework, web, redis ,style\n\n\n\n### 依赖该模块 -amd \n\n构建父模块，公用模块\n\n```\nmvn install -pl web/redis  -amd\n```\n\n> 项目被指定，构建依赖该模块的模块 \n>\n> -amd,--also-make-dependents          \n>    If project list is specified, also  build projects that depend on projects on the list\n\n构建 redis, login, style\n\n\n\n### 裁剪 -rf\n\n在前命令裁剪基础上，从rf指定模块开始构建\n\n```\nmvn install -pl web/style  -am -rf  web/redis\n```\n\n>从原有构建过程中裁剪反应堆，去掉指定模块原有构建顺序的前面部分\n>\n>-rf,--resume-from <arg>              \n>Resume reactor from specified  project\n\n构建 redis style\n\n\n\n\n\n\n\n## 错误\n\n### find main class\n\n repackage failed: Unable to find main class\n\n```\n <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <phase>none</phase>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n   </build>\n```\n\n","tags":["maven","mvn"],"categories":["tool"]},{"title":"k8s集群","url":"/linux/k8s/k8s01/","content":"\n\n\n\n\n\n\n### 常用命令\n\n缩写\n\n```\ncertificatesigningrequests (缩写 csr)\ncomponentstatuses (缩写 cs)\nconfigmaps (缩写 cm)\ncustomresourcedefinition (缩写 crd)\ndaemonsets (缩写 ds)\ndeployments (缩写 deploy)\nendpoints (缩写 ep)\nevents (缩写 ev)\nhorizontalpodautoscalers (缩写 hpa)\ningresses (缩写 ing)\nlimitranges (缩写 limits)\nnamespaces (缩写 ns)\nnetworkpolicies (缩写 netpol)\nnodes (缩写 no)\npersistentvolumeclaims (缩写 pvc)\npersistentvolumes (缩写 pv)\npoddisruptionbudgets (缩写 pdb)\npods (缩写 po)\npodsecuritypolicies (缩写 psp)\nreplicasets (缩写 rs)\nreplicationcontrollers (缩写 rc)\nresourcequotas (缩写 quota)\nserviceaccounts (缩写 sa)\nservices (缩写 svc)\nstatefulsets (缩写 sts)\nstorageclasses (缩写 sc)\n```\n\n\n\n#### 自动补全\n\n```\nsudo apt install bash-completion\n\nsource /usr/share/bash-completion/bash_completion\nsource <(kubectl completion bash)\n\necho \"source <(kubectl completion bash)\" >> ~/.bashrc\n```\n\n\n\n#### cs(master节点)\n\ncomponentstatuses\n\n```\ncs@debian:~$ kubectl get cs\nNAME                 STATUS    MESSAGE              ERROR\nscheduler            Healthy   ok                   \ncontroller-manager   Healthy   ok                   \netcd-2               Healthy   {\"health\": \"true\"}   \netcd-0               Healthy   {\"health\": \"true\"}   \netcd-1               Healthy   {\"health\": \"true\"}  \n```\n\n\n\n#### node节点\n\n```\ncs@debian:~$ kubectl  get node\nNAME       STATUS   ROLES    AGE    VERSION\nmaster02   Ready    <none>   101d   v1.18.8\nmaster03   Ready    <none>   101d   v1.18.8\nnode04     Ready    <none>   101d   v1.18.8\nnode05     Ready    <none>   101d   v1.18.8\nnode06     Ready    <none>   101d   v1.18.8\n\nkubectl get node -o wide\n```\n\n<!--more-->\n\n空间\n\n```\ncs@debian:~$ kubectl get namespaces \nNAME                   STATUS   AGE\ndefault                Active   101d\ndevops                 Active   100d\nkube-node-lease        Active   101d\nkube-public            Active   101d\nkube-system            Active   101d\nkubernetes-dashboard   Active   92d\n```\n\n\n\n#### pod\n\n```\ncs@debian:~$ kubectl get pod\nNo resources found in default namespace.\n\ncs@debian:~$ kubectl get pod -n kube-system \nNAME                                         READY   STATUS    RESTARTS   AGE\ncoredns-56ff7bc666-prc6l                     1/1     Running   4          11d\ncoredns-56ff7bc666-qwdsh                     1/1     Running   8          92d\ntraefik-ingress-controller-7769cb875-x76rs   1/1     Running   1          46h\n```\n\n>-n  接namespaces的NAME值,省略为default\n\n\n\n```\nkubectl get pods -o wide\nkubectl get pods -A -o wide\n```\n\n\n\n\n\n#### describe\n\n ingress **Tab提示**\n\n```\ncs@debian:~$ kubectl get ingress -n devops \ningressclasses.networking.k8s.io      ingresses.networking.k8s.io           ingressroutetcps.traefik.containo.us  \ningresses.extensions                  ingressroutes.traefik.containo.us     ingressrouteudps.traefik.containo.us  \n\ncs@debian:~$ kubectl get ingressroutetcps.traefik.containo.us -n devops \nNAME    AGE\nredis   47h\n\ncs@debian:~$ kubectl describe ingressroutetcps.traefik.containo.us redis -n devops \nName:         redis\nNamespace:    devops\nLabels:       <none>\nAnnotations:  API Version:  traefik.containo.us/v1alpha1\nKind:         IngressRouteTCP\nMetadata:\n  Creation Timestamp:  2022-07-19T13:01:37Z\n  Generation:          1\n  Managed Fields:\n    API Version:  traefik.containo.us/v1alpha1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:annotations:\n          .:\n          f:kubectl.kubernetes.io/last-applied-configuration:\n      f:spec:\n        .:\n        f:entryPoints:\n        f:routes:\n    Manager:         kubectl\n    Operation:       Update\n    Time:            2022-07-19T13:01:37Z\n  Resource Version:  261095\n  Self Link:         /apis/traefik.containo.us/v1alpha1/namespaces/devops/ingressroutetcps/redis\n  UID:               c79681ee-1bf1-4843-9666-457970d78f27\nSpec:\n  Entry Points:\n    redis\n  Routes:\n    Match:  HostSNI(`*`)\n    Services:\n      Name:  redis-service\n      Port:  6379\nEvents:      <none>\n```\n\n\n\n\n\n#### log\n\n\n\n```\ncs@debian:~$ kubectl logs  --tail=5 redis-app-1 -n devops\n63:M 21 Jul 2022 12:15:34.720 * Synchronization with replica 121.21.25.3:6379 succeeded\n63:M 21 Jul 2022 12:15:36.469 # Cluster state changed: ok\n63:M 21 Jul 2022 12:15:40.604 * FAIL message received from 67f931358b8004268db0b57932293602ab3de629 about b49a123e2764b665ee898c21f983b9cda70cda00\n63:M 21 Jul 2022 12:15:42.635 * Marking node a0e2f50ba382870da1ce4d23b66a1375826d6dc8 as failing (quorum reached).\n63:M 21 Jul 2022 12:15:42.635 # Cluster state changed: fail\n\ncs@debian:~$ kubectl logs  -f  --tail=5 redis-app-1 -n devops\n63:M 21 Jul 2022 12:15:34.720 * Synchronization with replica 121.21.25.3:6379 succeeded\n63:M 21 Jul 2022 12:15:36.469 # Cluster state changed: ok\n63:M 21 Jul 2022 12:15:40.604 * FAIL message received from 67f931358b8004268db0b57932293602ab3de629 about b49a123e2764b665ee898c21f983b9cda70cda00\n63:M 21 Jul 2022 12:15:42.635 * Marking node a0e2f50ba382870da1ce4d23b66a1375826d6dc8 as failing (quorum reached).\n63:M 21 Jul 2022 12:15:42.635 # Cluster state changed: fail\n^C\n```\n\n>-f   类似 **tail -f** \n>\n>-p,  --previous[=false]: 如果为true，输出pod中曾经运行过，但目前已终止的容器的日志\n>       --since=0: 仅返回相对时间范围，如5s、2m或3h，之内的日志。默认返回所有日志。只能同时使用since 和since-time中的一种\n>      --since-time=\"\": 仅返回指定时间（RFC3339格式）之后的日志。默认返回所有日志。只能同时使用since和since-time中的一种\n>      --tail=-1: 要显示的最新的日志条数。默认为-1，显示所有的日志\n\n\n\n#### patch\n\n更新容器的镜像\n\n```\nkubectl patch pod valid-pod -p '{\"spec\":{\"containers\":[{\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"}]}}'\n或\nkubectl patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"}]'\n```\n\n设置服务对外的IP\n\n```\nkubectl patch svc <svc-name> -n <namespace> -p '{\"spec\": {\"type\": \"LoadBalancer\", \"externalIPs\":[\"192.168.31.241\"]}}'\n```\n\n\n\n#### scale\n\n对副本数进行扩展或缩小\n\n\n\n前提条件校验 ；当前副本数量或 `--resource-version`\n\n\n\n缩减副本数到2\n\n```\nkubectl scale rc rc-nginx-3 —replicas=2\n```\n\n\n\n当前副本数为2，则将其扩展至3\n\n```\nkubectl scale --current-replicas=2 --replicas=3 deployment/mysql\n```\n\n\n\n\n\n#### 重启\n\n```\nkubectl rollout restart deployment <deployment_name> -n <namespace>\n```\n\n\n\n#### 选择器\n\n--field-selector\n\n`status.podIP`\n\n```\ncs@debian:~/oss/hexo$  kubectl  get pod --field-selector status.podIP=121.21.35.3 -o wide -n devops\nNAME          READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES\nredis-app-1   1/1     Running   1          9d    121.21.35.3   node04   <none>           <none>\n```\n\n>1. metadata.name=my-service\n>2. metadata.namespace!=default\n>3. status.phase=Pending\n>\n>\n\n选择了所有**`status.phase`**不为**`Running`**且`spec.restartPolicy`为**`Always`**的Pod.\n\n```\nkubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always\n```\n\n\n\n#### events\n\n显示集群内的详细事件，如果最近出现故障，你可以查看集群事件以了解故障前后发生的情况。如果你知道只有特定名称空间中存在问题，你可以将事件过滤到该名称空间。\n\n```\n$ kubectl get events \nLAST SEEN   TYPE     REASON                    OBJECT     MESSAGE\n2d18h       Normal   Starting                  node/k8s   Starting kubelet.\n2d18h       Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory\n2d18h       Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure\n2d18h       Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID\n2d18h       Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods\n2d18h       Normal   Starting                  node/k8s   Starting kubelet.\n2d18h       Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory\n2d18h       Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure\n2d18h       Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID\n2d18h       Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods\n2d18h       Normal   NodeReady                 node/k8s   Node k8s status is now: NodeReady\n2d18h       Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller\n2d18h       Normal   Starting                  node/k8s   Starting kube-proxy.\n2d18h       Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller\n23m         Normal   Starting                  node/k8s   Starting kubelet.\n23m         Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory\n23m         Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure\n23m         Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID\n23m         Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods\n23m         Normal   Starting                  node/k8s   Starting kube-proxy.\n22m         Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller\n```\n\n\n\n#### api-resources\n\n```\nkubectl api-resources -o wide --sort-by name\n```\n\n\n\n#### 调试\n\n启动参数`--feature-gates=EphemeralContainers=true`配置到kube-api和kubelet服务上重启\n\n```\n# 查看pod所在宿主及pod name\n$ kubectl get po -o wide\n# 根据pod name查看对应的docker 容器\n$ docker ps | grep centos-687ff6c787-47gvh\n# 根据输出的容器id，挂载容器网络并运行一个debug容器，使用 nicolaka/netshoot 这个镜像。这个镜像里集成了很多网络调试工具。\n$ docker run -it --rm --name=debug --network=container:bb009aab414f nicolaka/netshoot bash\n接下来就进入了与这个pod的相同的网络namespace，可以进行网络相关的调试了\n```\n\n\n\n```\nfor pod in $(kubectl get -o name pod  -n kube-system); \ndo\n    kubectl debug --image security/pod_scanner -p $pod /sanner.sh\ndone\n```\n\n> 批量跑某个命名空间下的安全扫描的脚本而不用干扰原容器\n\n\n\n\n\n##### 没有开启Ephemeral Containers\n\n```\nkubectl debug mypod -it \\\n--container=debug \\\n--image=busybox \\\n--copy-to=my-debugger \\\n--same-node=true \\\n--share-processes=true\n```\n\n>--copy-to   指定新pod的名称\n>--replace=true   是否删除原容器\n>--same-node=true  是否调度到和原容器一样的node上\n>--share-processes=true  是否共享容器pid空间\n\n\n\n##### 利用Ephemeral Containers\n\n```\nkubectl run ephemeral-demo --image=k8s.gcr.io/pause:3.1 --restart=Never\n```\n\n\n\n```\nkubectl debug ephemeral-demo -it --image=busybox  --target=ephemeral-demo\n```\n\n> 容器运行时必须支持--target参数。 如果不支持，则临时容器可能不会启动，或者可能使用隔离的进程命名空间启动。\n\n\n\n```\nkubectl delete pod ephemeral-demo\n```\n\n##### nsenter\n\n```\n sudo yum install -y util-linux\n```\n\n\n\n```\n$ docker inspect -f {{.State.Pid}} nginx\n#nsenter命令进入该容器的网络命令空间\n$ nsenter -n -t6700\n```\n\n","tags":["kubernetes","kubectl"],"categories":["linux","k8s"]},{"title":"traefik","url":"/linux/k8s/traefik/","content":"\n\n\n\n\nTræfɪk 是一个云原生的新型的 HTTP 反向代理、负载均衡软件\n\n\n\n```\n$bash traefik.sh\n$ tree  ./test\n./test\n├── 1-crd.yaml\n├── 2-rbac.yaml\n├── 3-role.yaml\n├── 4-static_config.yaml\n├── 5-dynamic_toml.toml\n├── 6-deploy.yaml\n├── 7-service.yaml\n└── 8-ingress.yaml\n\n```\n\n\n\ntraefik.sh\n\n```shell\n#!/bin/bash\nDIR=\"$(cd \"$(dirname \"$0\")\" && pwd)\"\n\nbase_file=$DIR/test\ncrd=1-crd.yaml\nrbac=2-rbac.yaml\nrole=3-role.yaml\nstatic=4-static_config.yaml\ndynamic=5-dynamic_toml.toml\ndeploy=6-deploy.yaml\nsvc=7-service.yaml\ningress=8-ingress.yaml\n\n\ny_crd(){\n\tcat >$1 <<EOF\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ingressroutes.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: IngressRoute\n    plural: ingressroutes\n    singular: ingressroute\n  scope: Namespaced\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: middlewares.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: Middleware\n    plural: middlewares\n    singular: middleware\n  scope: Namespaced\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ingressroutetcps.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: IngressRouteTCP\n    plural: ingressroutetcps\n    singular: ingressroutetcp\n  scope: Namespaced\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ingressrouteudps.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: IngressRouteUDP\n    plural: ingressrouteudps\n    singular: ingressrouteudp\n  scope: Namespaced\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: tlsoptions.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: TLSOption\n    plural: tlsoptions\n    singular: tlsoption\n  scope: Namespaced\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: tlsstores.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: TLSStore\n    plural: tlsstores\n    singular: tlsstore\n  scope: Namespaced\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: traefikservices.traefik.containo.us\n\nspec:\n  group: traefik.containo.us\n  version: v1alpha1\n  names:\n    kind: TraefikService\n    plural: traefikservices\n    singular: traefikservice\n  scope: Namespaced\n\nEOF\n\n}\n\n\n\ny_rbac(){\n\tcat>$1 <<EOF\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - \"\"\n    resources:\n      - persistentvolumes\n    verbs:\n      - get\n      - list\n      - watch\n      - create  # persistentvolumes\n      - delete\n  - apiGroups:\n      - \"\"\n    resources:\n      - persistentvolumeclaims\n    verbs:\n      - get\n      - list\n      - watch\n      - update  # persistentvolumeclaims         \n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses/status\n    verbs:\n      - update\n  - apiGroups:\n      - traefik.containo.us\n    resources:\n      - middlewares\n      - ingressroutes\n      - traefikservices\n      - ingressroutetcps\n      - ingressrouteudps\n      - tlsoptions\n      - tlsstores\n    verbs:\n      - get\n      - list\n      - watch\nEOF\n\n}\n\n\n\ny_role(){\n   cat >$1 <<EOF\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n  - kind: ServiceAccount\n    name: traefik-ingress-controller\n    namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  namespace: kube-system\n  name: traefik-ingress-controller\nEOF\n\n}\n\n#静态配置动态文件======================?\ny_static_config(){\n   cat >$1 <<EOF\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: traefik-config-yaml\n  namespace: kube-system\ndata:\n  traefik.yaml: |-\n    ping: \"\"\n    serversTransport:\n      insecureSkipVerify: true\n    api:\n      insecure: true\n      dashboard: true\n      debug: false\n    metrics:\n      prometheus: \"\"\n    entryPoints:\n      web:\n        address: \":80\"\n      websecure:\n        address: \":443\"\n      mysql:\n        address: \":3306\"\n      redis:    \n        address: \":6379\"\n      jenkins:\n        address: \":8081\"\n      gogo:\n        address: \":8082\"\n      prometheus:\n        address: \":8181\"\n    providers:\n      kubernetesCRD: \"\"\n      kubernetesIngress: \"\"\n      file:\n        directory: /etc/conf.d/\n        watch: true\n    log:\n      filePath: \"\"\n      level: error \n      format: json\n    accessLog:\n      filePath: \"\"\n      format: json\n      bufferingSize: 0\n      filters:\n        #statusCodes: [\"200\"]\n        retryAttempts: true\n        minDuration: 20\n      fields:\n        defaultMode: keep\n        names:\n          ClientUsername: drop  \n        headers:\n          defaultMode: keep\n          names:\n            User-Agent: redact\n            Authorization: drop\n            Content-Type: keep\nEOF\n\n}\n\n\ngenkey(){\nopenssl req \\\n        -newkey rsa:2048 -nodes -keyout tls.key \\\n        -x509 -days 3650 -out tls.crt \\\n        -subj \"/C=CN/ST=GD/L=SZ/O=cs/OU=shea/CN=k8s.org\" \n#kubectl create secret generic traefik-cert --from-file=tls.crt --from-file=tls.key -n kube-system        \n}\n\ny_dynamic_toml(){\n   cat >$1 <<EOF\ndefaultEntryPoints = [\"http\",\"https\"]\n[entryPoints]\n  [entryPoints.http]\n  address = \":80\"\n  [entryPoints.https]\n  address = \":443\"\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \"/ssl/tls.crt\"\n      KeyFile = \"/ssl/tls.key\"\n\n\ntls:\n  certificates:\n    - certFile: /path/to/domain.cert\n      keyFile: /path/to/domain.key\n      stores: #stores 列表将被忽略，并自动设置为 [\"default\"]\n        - default\n\nEOF\n}\n\n\n\n\ny_deploy(){\n   cat >$1 <<EOF\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    app: traefik\nspec:\n  selector:\n    matchLabels:\n      app: traefik\n  template:\n    metadata:\n      name: traefik\n      labels:\n        app: traefik\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 1\n      #设置node筛选器，在特定label的节点上启动  kubectl label node 192.168.56.109 tklabel=ok\n      nodeSelector: \n         tklabel: \"ok\"\n      containers:\n        - image: k8s.org/k8s/traefik:v2.2.10\n          name: traefik\n          ports:\n            - name: web\n              containerPort: 80\n              hostPort: 80         ## 将容器端口绑定所在服务器的 80 端口\n            - name: websecure\n              containerPort: 443\n              hostPort: 443        ## 将容器端口绑定所在服务器的 443 端口\n            # - name: redis\n            #   containerPort: 6379\n            #  hostPort: 6379\n            - name: admin\n              containerPort: 8080  ## Traefik Dashboard 端口\n          resources:\n            limits:\n              cpu: 200m\n              memory: 256Mi\n            requests:\n              cpu: 100m\n              memory: 256Mi\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n              add:\n                - NET_BIND_SERVICE\n          args:\n            - --configfile=/config/traefik.yaml\n          volumeMounts:\n            - mountPath: \"/config\"\n              name: \"config\"\n            - mountPath: \"/ssl\"\n              name: \"ssl\"\n      volumes:\n        - name: config\n          configMap:\n            name: traefik-config-yaml\n        - name: ssl\n          secret:\n            secretName: traefik-cert\nEOF\n\n}\n\n\n\n\ny_service(){\n   cat >$1 <<EOF\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik\n  namespace: kube-system\nspec:\n  ports:\n    - name: web\n      port: 80\n    - name: websecure\n      port: 443\n    - name: admin   #没有会显示 404 page not found\n      port: 8080\n  selector:\n    app: traefik\n\nEOF\n}\n\n\n\n\ny_ingress(){\n   cat >$1 <<\"EOF\"\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-dashboard-route\n  namespace: kube-system\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`master02`) #pod节点\n      kind: Rule\n      services:\n        - name: traefik\n          port: 8080\n\nEOF\n\n}\n\n[ -d \"$base_file\" ] || { echo \"没有目录,则创建目录\" && mkdir $base_file; }\n[ -n \"$(which openssl)\" ] || { echo \"需要用到openssl,没有找到,退出\" && exit 1; }\ncd $base_file\n\n# genkey  \n# [ -f \"tls.key\" ] || { echo \"没有生成密钥,退出\" && exit 1; }\n#kubectl create secret generic traefik-cert --from-file=tls.crt --from-file=tls.key -n kube-system\n# #kubectl create configmap traefik-conf --from-file=$dynamic -n kube-system\n\narr=($crd $rbac $role $static $dynamic $deploy  $svc $ingress)\n\nfor i in ${arr[@]}; do\necho \"开始生成:\"$i \ny_${i:2:0-5}  $i\n[ -f \"$i\" ] || { echo \"没有生成$i,退出\" && exit 1; }\n#kubectl apply -f  $i\ndone\n\n```\n\n\n\n","tags":["traefik","ingress"],"categories":["linux","k8s"]},{"title":"etcd集群","url":"/linux/k8s/etcd/","content":"etcd 下载\n\n\n\n\n\n\n\nhttps://github.com/bitnami/bitnami-docker-etcd\n\n\n\n\n\n```\n$ etcdctl set /atomic.io/network/config '{\"Network\":\"121.21.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}'\n```\n\n>{\"Network\":\"121.21.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}\n\n\n\nCouldn't fetch network config: client: response is invalid json. The endpoint is probably not valid etcd cluster endpoint. timed out\n\n查阅 flanneld 官网文档，上面标准了 flannel 这个版本不能给 etcd 3 进行通信\n\n```\n$ etcdctl put /atomic.io/network/config '{\"Network\":\"121.21.0.0/16\",\"Backend\":{\"Type\":\"vxlan\"}}'\n$ etcdctl del /atomic.io/network/config\n```\n\n>API VERSION:3.2\n>\n>Did you mean this?\n>\tget\n>\tput\n>\tdel\n>\tuser\n\n\n\netcd environment文档\n\nhttps://doczhcn.gitbook.io/etcd/index/index-1/configuration\n\n\n\n\n\n\n\n```shell\ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs.ko \ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_rr\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_rr.ko \ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_wrr\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_wrr.ko \ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_sh\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_sh.ko\ncs@debian:~/oss/0s/k8s$ sudo modprobe -v ip_vs_nq\ninsmod /lib/modules/4.9.0-8-amd64/kernel/net/netfilter/ipvs/ip_vs_nq.ko\n```\n\n\n\n```shell\ncs@debian:~/oss/0s/k8s$ sudo ipvsadm -ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn\n\n```\n\n\n\n```shell\n#两种临时方法\n# echo 1 > /proc/sys/net/ipv4/vs/conntrack\n# sysctl -w net.ipv4.vs.conntrack=1\n```\n\n> 想永久保留配置，可以修改/etc/sysctl.conf文件\n\n\n\n\n\n```\nkubectl create clusterrolebinding test:anonymous --clusterrole=cluster-admin --user=system:anonymous\n```\n\n> configmaps is forbidden: User “system:anonymous” cannot list resource “configmaps” in [API](https://so.csdn.net/so/search?q=API&spm=1001.2101.3001.7020) group “” in the namespace “default”\n\n\n\n```\n[vagrant@k8s master]$ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap\nclusterrolebinding.rbac.authorization.k8s.io/kubelet-bootstrap created\n```\n\n>error: failed to run Kubelet: cannot create certificate signing request: certificatesigningrequests.certificates.k8s.io is forbidden: User \"kubelet-bootstrap\" cannot create certificatesigningrequests.certificates.k8s.io at the cluster\n\n\n\nproxy\n\nunable to create proxier: can't set sysctl net/ipv4/conf/all/route_localnet to 1: open /proc/sys/net/ipv4/conf/all/route_localnet: read-only file system\n\n\n\n```\n sduo  cat > /etc/sysconfig/modules/ipvs.modules <<EOF\n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- ip_vs_nq\nmodprobe -- nf_conntrack_ipv4\nEOF\n```\n\n\n\n```yaml\n      containers:\n      - name: kube-flannel\n        image: k8s.org/k8s/flannel:v0.11.0-amd64\n        command:\n        - /opt/bin/flanneld\n        args:\n        - --ip-masq\n        - --kube-subnet-mgr\n        - --iface=eth1\n```\n\n> --iface=eth1\n\n\n\n\n\n```shell\ncs@debian:~$ ansible k8s-108 -m copy -a \"src=/home/cs/oss/0s/k8s/kube-apiserver/docker-compose.yml dest=/opt/kubernetes/master/docker-compose.yml\"   -b --become-method sudo --become-user root\n```\n\nansible k8s-108 -m copy -a \"src=/opt/kubernetes/client/k8s-1.21-11/bin/config.yaml dest=/opt/kubernetes  mode=0644\"   -b --become-method sudo --become-user root\n\n\n\n\n\n```\n[root@k8s kubernetes]# cat > /etc/sysctl.d/k8s.conf << EOF\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n```\n\n\n\n\n\n```\n cat>/opt/kubernetes/kubelet.env<<EOF\n KUBELET_OPTIONS=\" --hostname-override=192.168.56.108 \\\n  --pod-infra-container-image=k8s.org/k8s/pause:3.4.1 \\\n  --bootstrap-kubeconfig=/opt/kubernetes/config/bootstrap.kubeconfig \\\n  --kubeconfig=/opt/kubernetes/config/kubelet.kubeconfig \\\n   --config=/opt/kubernetes/config/kubelet-conf.yaml   \\\n  --register-node=true \\\n  --cni-bin-dir=/opt/kubernetes/cni/bin --cni-conf-dir=/opt/kubernetes/cni/net.d --network-plugin=cni  \\\n   --runtime-cgroups=/systemd/system.slice  \\\n  --logtostderr=true \"\nEOF\n```\n\n\n\n\n\n\n\n```\n\tcat>/usr/lib/systemd/system/kubelet.service<<EOF\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=/var/lib/kubelet\nEnvironmentFile=/opt/kubernetes/kubelet.env\nExecStart=/opt/kubernetes/bin/kubelet  \\$KUBELET_OPTIONS\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n\n\n\n\n\n\n","tags":["etcd"],"categories":["linux","k8s"]},{"title":"redis集群","url":"/linux/k8s/redis/","content":"\n\n\n### pod\n\n```\nkubectl -n devops get pods\nNAME          READY   STATUS    RESTARTS   AGE\nredis-app-0   1/1     Running   0          50m\nredis-app-1   1/1     Running   0          50m\nredis-app-2   1/1     Running   0          44m\nredis-app-3   1/1     Running   0          38m\nredis-app-4   1/1     Running   0          38m\nredis-app-5   1/1     Running   0          38m\n\nkubectl -n devops exec -it redis-app-2 /bin/bash\nkubectl -n devops exec -it redis-app-4 /bin/bash\n```\n\nredis-cli -c -p 6379\n\n![](/pics/k8s-redis-c-set01.png)\n\n\n\n### svc ClusterIP\n\n两次认证?\n\n```\ncs@debian:~/oss/hexo$ kubectl get svc -n devops\nNAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)              AGE\njenkins                  ClusterIP   121.21.92.146    <none>        8081/TCP,50000/TCP   105d\nredis-headless-service   ClusterIP   None             <none>        6379/TCP             13d\nredis-service            ClusterIP   121.21.24.33     <none>        6379/TCP             13d\ntomcat                   ClusterIP   121.21.191.100   <none>        8082/TCP             105d\n\ncs@debian:~/oss/hexo$ kubectl exec -it redis-app-1 -n devops  /bin/bash\nkubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.\n.............\nroot@redis-app-1:/data# redis-cli  -c -h 121.21.24.33 -p 6379\n121.21.24.33:6379> auth 123456\nOK\n121.21.24.33:6379> ping\nPONG\n121.21.24.33:6379> get test21\n-> Redirected to slot [8530] located at 121.21.35.3:6379\n(error) NOAUTH Authentication required.  \n121.21.35.3:6379> auth 123456\nOK\n121.21.35.3:6379> get test21\n\"20220721cs\"\n```\n\n\n\n\n\n\n\ntraefik  deploay  配置 redis\n\n```\ncs@debian:/opt/kubernetes/yaml/k8s/tcp/redis$ redis-cli  -c  -p  6379\n127.0.0.1:6379> auth 123456\nOK\n127.0.0.1:6379> ping\nPONG\n```\n\n>127.0.0.1 - 192.168.56.103:6379, 192.168.56.101:6379, 192.168.56.102:6379 - [19/Jul/2022:22:10:12 +0800] 200 0, 0, 82\n\n\n\n### 不通超时\n\n![](/pics/k8s-redis-timeout.png)\n\n\n\n![](/pics/k8s-redis-c-set02.png)\n\n根据podip定位集群pod\n\n```\ncs@debian:~/oss/hexo$  kubectl  get pod --field-selector status.podIP=121.21.35.3 -o wide -n devops\nNAME          READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES\nredis-app-1   1/1     Running   1          9d    121.21.35.3   node04   <none>           <none>\n```\n\n","tags":["redis","redis-cluster"],"categories":["linux","k8s"]},{"title":"redis集群","url":"/services/database/redis/redis-cluster/","tags":["redis-cluster"],"categories":["services","database","redis"]},{"title":"mysql配置文件","url":"/services/database/mysql/my/","content":"\n\n\n## linux\n\n### my.cnf\n\n```\n[mysqld]\n#server-id                      = 224\nuser = mysql\nport                           = 3305\nmysqlx_port                    = 33060\nmysqlx_socket                  = /tmp/mysqlx.sock\ndatadir                        = /opt/mysql/data\nsocket                         = /tmp/mysql.sock\npid-file                       = /tmp/mysqld.pid\nauto_increment_offset          = 2\nauto_increment_increment       = 2 \nlog-error                      = /opt/mysql/log/error.log\nslow-query-log                 = 1\nslow-query-log-file            = /opt/mysql/log/slow.log\nlong_query_time                = 0.2\nlog-bin                        = bin.log\nrelay-log                      = relay.log\nbinlog_format                 =ROW\nrelay_log_recovery            = 1\ncharacter-set-client-handshake = FALSE\ncharacter-set-server           = utf8mb4\ncollation-server               = utf8mb4_unicode_ci\ninit_connect                   ='SET NAMES utf8mb4'\ninnodb_buffer_pool_size        = 1G\njoin_buffer_size               = 128M\nsort_buffer_size               = 2M\nread_rnd_buffer_size           = 2M\nlog_timestamps                 = SYSTEM\nlower_case_table_names         = 1\ndefault-authentication-plugin  =mysql_native_password\n```\n\n\n\n\n\n## win\n\n### my.ini\n\n```\n[client]\nport=3306\n\n[mysql]\ndefault-character-set=utf8mb4\n\n\n[mysqld]\nport=3306\n#password=123456\n#character-set-client-handshake=FALSE  \ncharacter-set-server=utf8mb4 \n#collation-server = utf8mb4_general_ci  \ninit_connect='SET NAMES utf8mb4'\n\n\nbasedir=\"D:/360Downloads/mysql-5.7.20-winx64\"\n#Path to the database root\ndatadir=\"D:/360Downloads/mysql-5.7.20-winx64/data\"\n\nlog-error=\"D:/360Downloads/mysql-5.7.20-winx64/log/mysqld_err.log\"\n#log-bin=\"D:/360Downloads/mysql-5.7.20-winx64/log/mysqld_bin.bin\"\n\ndefault-storage-engine=INNODB\n#从 5.6开始，timestamp 的默认行为已经是 deprecated 了\nexplicit_defaults_for_timestamp=true\n\nsql_mode=\"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\" \n\n```\n\n","tags":["mysql"],"categories":["services","database"]},{"title":"mysql安装","url":"/services/database/mysql/install/","content":"\n\n\n\n\n## linux\n\n下载  https://downloads.mysql.com/archives/community/\n\n**Compressed TAR Archive, Minimal Install** **不包含调试和测试工具**\n\n```\nxz -d mysql-8.0.28-linux-glibc2.17-x86_64-minimal.tar.xz\ntar -xvf mysql-8.0.28-linux-glibc2.17-x86_64-minimal.tar\n```\n\n\n\n用户组\n\n```\n# cs 换成mysql 或 ${USER}\nsudo groupadd mysql\nsudo useradd mysql -r -M -s /sbin/nologin\nsudo chown mysql:cs -R  /opt/mysql/*\n\n\ncs@debian:~/data/software$ cat /etc/group | grep mysql\nmysql:x:512:cs\ncs@debian:~/data/software$ cat /etc/passwd | grep mysql\nmysql:x:512:512::/home/mysql:/sbin/nologin\n```\n\n\n\n初始化数据库\n\n```\n$ sudo /opt/mysql/bin/mysqld  --initialize --user=mysql --console\n----2022-01-30T00:14:24.872326+08:00 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: bDB,fVSmt2/U\n```\n\n\n\n```\n url=/opt/mysql\n sed -n \"/^basedir=/s#=#==$url#\"p ./mysql.server\n sed -n \"/^datadir=/s#=#=$url/data#\"p ./mysql.server\n sed -n \"s#conf=.*#conf=$url/my.cnf#\"p ./mysql.server\n```\n\n\n\n开机启动\n\n```\nsudo cp /opt/mysql/support-files/mysql.server  /etc/init.d/mysql\n设置为开机自动运行\nsudo update-rc.d mysql defaults\n设置为取消开机自动运行\nsudo update-rc.d -f mysql remove\n```\n\n密码\n\n```\n##### 临时密码登录,执行语句提示 You must reset your password using ALTER USER statement before executing this statement.\n--- alter user user() identified by \"123456\";  ##密码字符串双引号\n\n---低于版本8---SET PASSWORD FOR root@localhost = '123456';\n---版本8以上---ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '123456'; \n\n##用户密码过期时间250天\nALTER USER ‘cs’@‘localhost' PASSWORD EXPIRE INTERVAL 250 DAY;\n###禁用过期     --恢复默认策略 PASSWORD EXPIRE DEFAULT----\nALTER USER 'cs'@'localhost' PASSWORD EXPIRE NEVER;\n\n###密码过期的策略\nshow variables like 'default_password_lifetime';\n---设置密码永不过期，需要把default_password_lifetime修改为 0\n---set global default_password_lifetime = 0;\n\n CREATE USER 'cs'@'localhost' IDENTIFIED BY '123456';\n\n\n###修改执行生效语句\nflush privileges;\n```\n\n\n\n## win\n\n[下载地址：http://dev.mysql.com/downloads/mysql/](http://dev.mysql.com/downloads/mysql/) \n\n管理员权限运行cmd\n\n```\nE:\\MySQL\\MySQL Server 5.7\\bin>mysqld install MySQL --defaults-file=\"E:\\MySQL\\MySQL Server 5.7\\my.ini\"\n```\n\ninstall/Remove of the Service Denied!  \n\n\n\n```\nbin>mysqld --initialize --user=mysql --console\n```\n\n启动服务\n\n```\nnet start MySQL\n```\n\n删除  \n\n```\nsc delete MySQL\n```\n\n","tags":["install","mysql"],"categories":["services","database"]},{"title":"pip包管理","url":"/lang/python/pip/","content":"\n\n\n## 安装\n\n```\ncs@debian:~/oss/typoraCracker$ sudo apt-get install python3-pip\ncs@debian:~/oss/typoraCracker$ pip3 -V\npip 20.3.4 from /usr/local/lib/python3.5/dist-packages/pip (python 3.5)\n```\n\n\n\n## 升级\n\n```\ncs@debian:~/oss/typoraCracker$ sudo pip3 install --upgrade pip\nCollecting pip\n  Downloading http://mirrors.aliyun.com/pypi/packages/27/79/8a850fe3496446ff0d584327ae44e7500daf6764ca1a382d2d02789accf7/pip-20.3.4-py2.py3-none-any.whl (1.5MB)\n    100% |████████████████████████████████| 1.5MB 5.8MB/s \nInstalling collected packages: pip\n  Found existing installation: pip 9.0.1\n    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\nSuccessfully installed pip-20.3.4\n```\n\n\n\n## 国内源\n\n```\n$ pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/\nWriting to ~/.config/pip/pip.conf\n\n```\npip.ini\n\n```\n[global]\ntimeout = 6000\nindex-url = https://pypi.tuna.tsinghua.edu.cn/simple\ntrusted-host = pypi.tuna.tsinghua.edu.cn\n```\n\n\n\n## 卸载\n\n```\nsudo apt-get remove python3-pip\n```\n\n","tags":["pip"],"categories":["lang","python"]},{"title":"tomcat优化","url":"/services/container/tomcat/","content":"\n\n\n\n\n## jvm参数\n\n\n\n```\nJAVA_OPTS=\"-server -XX:NewSize=256m -XX:MaxNewSize=256m -XX:PermSize=512M -XX:MaxPermSize=1024m -Xms2048m -Xmx2048m \"\n```\n\n\n\n>-Xms：Java虚拟机初始化时堆的最小内存，一般与 Xmx配置为相同值，这样的好处是GC不必再为扩展内存空间而消耗性能；\n>\n>-Xmx：Java虚拟机可使用堆的最大内存；\n>\n>-XX:PermSize：Java虚拟机永久代大小；\n>\n>-XX:MaxPermSize：Java虚拟机永久代大小最大值；\n>\n>-XX:NewSize=：新生代空间初始化大小 \n>\n>-XX:MaxNewSize=：新生代空间最大值\n\n## 配置优化\n\n### 连接属性\n\n/tomcat-8.5.38/conf/server.xml\n\n\n\nhttps://tomcat.apache.org/tomcat-8.5-doc/config/executor.html\n\n```\n<Executor   name=\"tomcatThreadPool\"\n  namePrefix=\"req-thead-exc\"\n  maxHttpHeaderSize=\"8192\" \n  maxThreads=\"1000\"\n  minSpareThreads=\"75\"\n  maxQueueSize=\"Integer.MAX_VALUE\"\n  maxIdleTime=\"60000\"\n  threadPriority=\"5\"\n  className=\"org.apache.catalina.core.StandardThreadExecutor\"\n />\n```\n\n> maxThreads:  服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量,压测计算,要排除单纯处理业务耗时方法,如果未指定，默认值为200\n>\n> minSpareThreads：线程的最小运行数目，这些始终保持运行。如果未指定，默认值为10。\n>\n> maxHttpHeaderSize：请求和响应的HTTP头的最大大小，以字节为单位指定。如果没有指定，这个属性被设置为8192（8 KB）。\n\n\n\n\n\n```\nsed -i '/connectionTimeout=/i\\  executor=\"tomcatThreadPool\"' /opt/apache/tomcat-8.5.38/conf/server.xml \n\n<Connector port=\"8080\" protocol=\"HTTP/1.1\" \n  executor=\"tomcatThreadPool\"\n  connectionTimeout=\"20000\"   \n  redirectPort=\"8443\" />  \n```\n\n> connectionTimeout代表连接超时时间，单位为毫秒,默认值为60000。通常情况下设置为30000。\n\nhttps://tomcat.apache.org/tomcat-8.5-doc/config/http.html\n\n\n\n###  cache\n\n/tomcat-8.5.38/conf/context.xml\n\ntomcat8以上对resource采取了cache，而默认的大小是10M\n\n\n\nconsider increasing the maximum size of the cache\n\n\n\n```\nsed -i '/^<\\/Context>/i\\<Resources cachingAllowed=\"true\"  cacheMaxSize=\"102400\" \\/>'  /opt/apache/tomcat-8.5.38/conf/context.xml\n```\n\n><Resources cachingAllowed=\"true\"  cacheMaxSize=\"102400\" />\n>\n>context.xml文件内添加到<Context>节点内</Context>\n>\n>cacheMaxSize值按需设置,单位K , ","tags":["tomcat"],"categories":["services","container"]},{"title":"apt","url":"/linux/debian/apt/","content":"\n\n\n## apt-get\n\n\n\n升级\n\n```\napt-get update\t\t\t   // 更新源文件，并不会做任何安装升级操作 \napt-get upgrade\t\t       // 升级所有已安装的包 \n```\n\n安装\n\n```\napt-get install packagename\t\t// 安装指定的包\n```\n\n查询包\n\n```\napt-cache depends packagename   //该包依赖哪些包\n```\n\n列出所有已经安装\n\n```\napt list --installed\n```\n\n\n\n删除\n\n```\napt-get autoremove packagename --purge  //删除包及其依赖的软件包+配置文件等\n```\n\n\n\n清理\n\n```\napt-get clean \t\t\t\t\t\t// 清理无用的包  \napt-get autoclean \t\t\t\t\t// 清理无用的包  \napt-get check \t\t\t\t\t\t// 检查是否有损坏的依赖\n```\n\n\n\n## apt-mark 标记\n\n系统中禁用 Chrome 更新\n\n```\ncs@debian:~$ sudo apt-mark  hold google-chrome-stable\ngoogle-chrome-stable 设置为保留。\n```\n\n> auto\t标记指定软件包为自动安装\n> manual\t标记指定软件包为手动安装\n> minimize-manual\t将 meta 包的所有依赖项标记为自动安装\n> hold\t标记指定软件包为保留（held back），阻止软件自动更新\n> unhold\t取消指定软件包的保留（held back）标记，解除阻止自动更新\n> showauto\t列出所有自动安装的软件包\n> showmanual\t列出所有手动安装的软件包\n> showhold\t列出设为保留的软件包\n\n\n\ncentos\n\n```\necho 'exclude=google-chrome-stable' >> /etc/yum.conf\n```\n\n","tags":["apt"],"categories":["linux","debian"]},{"title":"强弱类型语言","url":"/lang/sawtl/","content":"\n\n\n## 弱类型语言\n\n是一种弱类型定义的语言,某一个变量被定义类型,该变量可以根据环境变化自动进行转换,不需要经过显性强制转换 代表js,php,lua\n\n\n\njs\n\n![](/pics/was-1.png)\n\n+操作是将A的类型转化为了字符串，然后进行拼接\n\n-操作是将B的类型转化为了数字，然后进行减法\n\n\n\nlua\n\n```\n> a=5 \n> b=\"5\"\n> print(b+a)\n10.0\n> print(b-a)\n0.0\n> print(a==b)\nfalse\n\n```\n\n<!--more-->\n\n![](/pics/saw-2.png)\n\n\n\n## 强类型语言\n\njava\n\n```\npublic class Main{\n    public static void main(String []args) {\n    int a=5;\n    String b=\"5\";\n       System.out.println(a+b);//55\n       // System.out.println(a-b);//编译不通过,错误：二元运算符“-”的操作数类型错误\n    }\n} \n```\n\n\n\ngo\n\n```\npackage main\nvar a = 5\nvar b string = \"5\"\n\n\nfunc main(){\n    println(a+b) //无效操作：a + b（不匹配的类型 int 和 string）\n    println(a-b) //无效操作：a - b（不匹配的类型 int 和 string）\n}\n```\n\n","tags":["强弱类型"],"categories":["lang"]},{"title":"mongodb","url":"/database/mongo/","content":"\n\n\n# linux 环境\n\n## 下载 \n\nwget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-debian81-3.4.4.tgz\n\n```\ntar zxvf mongodb*.tar\nmv /opt/mongo*  /opt\ncd /opt/mongodb*  && touch  mongodb.conf\n```\n\n## 配置文件\n\n```\ndbpath=/home/cs/Download/mongodb/data #数据库路径\nlogpath=/home/cs/Download/mongodb/data/logs/mongodb.log #日志输出文件路径\nlogappend=true #错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\njournal=true #启用日志文件，默认启用\nquiet=true #这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nport=27017 #端口号 默认为27017\n```\n\n启动\n\n```\ncs@debian:/opt/mongodb-3.4.4/bin$ ./mongod  --config  /opt/mongodb-3.4.4/mongodb.conf\n```\n\n\n后台运行\n\n```\nmongo  -f   mongo.conf   & \n```\n\n\n使用 fork 必须加上logpath\n\n```\nmongo   --fork  --logpath=log/mongodb.log   \n\n```\n\n多条命令执行时 &&  可以把 fork配置到conf\n\n\n```\necho   { \\\n                echo 'dbpath=/data/db'; \\\n                echo 'port=27017'; \\\n                echo 'logpath=/data/mongo.log'; \\\n                echo 'logappend=true'; \\\n                echo 'fork=true'; \\\n             } > mongod.conf  \n```\n\n\n\n## 启动\n\nmongo-start.sh\n\n```\n#!/bin/bash\ncd /opt/mongodb-3.4.4/bin \n./mongod  --config  /opt/mongodb-3.4.4/mongodb.conf  &\nexit\n!\n```\n\n\n\n# win 环境\n\n下载  http://dl.mongodb.org/dl/win32/x86_64\nzip 免安装包\n\n\n\n启动\n\n```\nE:\\MongoDB\\Server\\bin>mongod.exe --config  E:\\MongoDB\\mongo.conf\n```\n\nmongo.conf\n\n```\ndbpath=E:\\MongoDB\\data #数据库路径\nlogpath=E:\\MongoDB\\logs\\mongodb.log #日志输出文件路径\nlogappend=true #错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\njournal=true #启用日志文件，默认启用\nquiet=true #这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nport=27017 #端口号 默认为27017\n```\n\n打开 http://127.0.0.1:27017/ \nIt looks like you are trying to access MongoDB over HTTP on the native driver port.\n\n## 安装服务\n\n管理员cmd\nE:\\MongoDB\\Server\\bin>`mongod --install --serviceName \"MongoDB\" --config` \"E:\\MongoDB\\mongo.conf\"\nE:\\MongoDB\\Server\\bin>  `net  start MongoDB`  \n\n## 删除服务\n\n`sc delete MongoDB`\n\n\n\n\n\nhttps://www.runoob.com/mongodb/mongodb-connections.html","tags":["mongodb"],"categories":["database"]},{"title":"singleton单例模式","url":"/design-pattern/singleton/","content":"\n\n\n## 懒汉  \n\n **第一次调用时实例化**\n\n```\npublic class LHanDanli {\n//定义一个私有类变量来存放单例，私有的目的是指外部无法直接获取这个变量，而要使用提供的公共方法来获取\nprivate static LHanDanli dl = null;\n//定义私有构造器，表示只在类内部使用，亦指单例的实例只能在单例类内部创建\nprivate LHanDanli(){}\n//定义一个公共的公开的方法来返回该类的实例，由于是懒汉式，需要在第一次使用时生成实例，所以为了线程安全，使用synchronized关键字来确保只会生成单例\npublic static synchronized LHanDanli getInstance(){\nif(dl == null){\ndl = new LHanDanli();\n}\nreturn dl;\n}\n}\n```\n## 双重判断  \n\n不用每次获取对象都加锁\nvolatile  屏蔽虚拟机代码优化(代码执行顺序)，运行效率会成问题\n\n```\npublic class SLHanDanli {\nprivate static volatile SLHanDanli dl = null;\nprivate SLHanDanli(){}\npublic static SLHanDanli getInstance(){\nif(dl == null){\n          synchronized (SLHanDanli.class) {\n       if(dl == null){\n    dl = new SLHanDanli();\n}\n}\n }\nreturn dl;\n}\n}\n`\n\n```\n\n## 饿汉   \n\n加载类内就实例化\n\n<!--more-->\n\n```\npublic class EHanDanli {\n//此处定义类变量实例并直接实例化，在类加载的时候就完成了实例化并保存在类中\nprivate static EHanDanli dl = new EHanDanli();\n//定义无参构造器，用于单例实例\nprivate EHanDanli(){}\n//定义公开方法，返回已创建的单例\npublic static EHanDanli getInstance(){\n    return dl;\n}\n}\n\n```\n会有占用空间的问题存在\n\n\n\n\n\n\n\n## 静态内部类 \n\n类加载机制   只有在调用时，才会加载实例，\n静态实例化``jvm线程安全``\n\n```\npublic class ClassInnerClassDanli {\n    public static class DanliHolder{\n        private static ClassInnerClassDanli dl = new ClassInnerClassDanli();\n    }\n    private ClassInnerClassDanli(){}\n        public static ClassInnerClassDanli getInstance(){\n                return DanliHolder.dl;\n        }\n    }\n}\n```\n","tags":["singleton"],"categories":["design-pattern"]},{"title":"常用语法","url":"/linux/k8s/docker1/","content":"\n\n\n\n\n```\n sudo  service docker status\n\n sudo service docker stop\n\n sudo service docker start\n```\n\n\n\n#### 搜索\n\n```\ndocker search Python\n\n```\n\n#### 拉取\n\n```\ndocker pull python:2.7\n\n```\n\n\n\n#### 查询\n\n镜像  `image`\n\n```\ndocker images\n\n```\n\n\n\n 容器 `container`\n\n```\ndocker ps  #run container\n\ndocker ps -a  #all container\n\n```\n\n##### 日志\n\n```\ndocker logs -f  <container or id>\n\n```\n\n##### 容器信息\n\n```\ndocker inspect  <id>\n\n#查看指定信息\ndocker inspect  <id>  --format '{{.Args}}'\n\ndocker inspect --format='{{.NetworkSettings.IPAddress}}' $CONTAINER_ID\n\n```\n\n<!--more-->\n\n#### 运行\n\n创建镜像  当前路径 **.** 英文点表示\n\n```\ndocker build -t  <镜像名> <Dockerfile路径>\n\n```\n\n修改名字,版本\n\n```\ndocker tag <IMAGE ID>  <名称:版本号>\n\n```\n\n容器安装程序\n\n```\ndocker run python:3.5.3 pip -V\n\n#指定源更新\ndocker run python:3.5.3 pip -i https://mirrors.aliyun.com/pypi/simple/ numpy\n\ndocker run <镜像名> apt-get install -y <程序>  \n\n```\n\n`-y` 交互\n\n\n\n```\n# tomcat 后台运行  p local port:container port     4452镜像id前4位\n\n docker run -d -p 8080:8080 4452\n\n```\n\n 保存容器\n\n```\ndocker commit  <id> <镜像名:版本号>\n\n```\n\n\n\n##### 进入容器\n\n```\n# /bin/bash\ndocker run -i -t  python:3.5.3  /bin/bash\n\n```\n\n##### 共享目录\n\n```\ndocker run -it -v <宿主机绝对路径目录>:<容器目录>  <镜像id>    /bin/bash\n\n```\n\n`-e` 环境变量\n\n```\ndocker run  -e \"MYSQL_ROOT_PASSWORD=19930221\" -it 797e57bb4fea\n\n```\n\n#### 停止\n\n```\ndocker stop <CONTAINER ID>\n\n```\n\n#### 删除\n\n要先停止运行容器stop id\n\n```\ndocker rmi <tag>:<no>\n\n```\n\n所有镜像\n\n```\ndocker rmi $(docker images  -q)\n\n```\n\n\n\n所有容器\n\n```\ndocker rm $(docker ps -a -q)\n\n```\n\n#### 迁移\n\n备份\n\n```\ndocker save <镜像名>  -o  ~/save.tar  \n\n```\n\n还原\n\n```\ndocker load  -i  ~/docker/save.tar\n\n```\n\n\n\n**Ctrl + P + Q** 退出容器\n\n\n\n\n\n#### 性能限制\n\n\n\n容器使用状态\n\n```\ndocker stats  containerId  \n```\n\nk,b,m,g内存\n\ndoc https://docs.docker.com/engine/reference/run/#runtime-constraints-on-resources\n\n\n\nnginx代理\n\n\n\n```\ntinkle-style-dev:\n  restart: always\n  ports:\n    - '18082:8080/tcp'\n  environment:\n    - TZ=Asia/Shanghai\n    - TERM=xterm\n  memswap_limit: 0\n  labels:\n    aliyun.scale: '1'\n  shm_size: 0\n  image: >-\n    registry-internal.cn-shenzhen.aliyuncs.com/tinkle/docker-registry:centos7-lite-1.0\n  memswap_reservation: 0\n  volumes:\n    - >-\n      /mnt/acs_mnt/nas/21ac64b65d/baopinghui/style-service:/app/0.0.1-SNAPSHOT/style-service/:rw\n    - '/home/data/tmpfile/style-service:/tmp:rw'\n    - /mnt/acs_mnt/nas/21ac64b65d/baopinghui/style-service/tinkle-style.conf:/etc/supervisor.conf.d/tinkle-style.conf:rw\n  kernel_memory: 0\n  mem_limit: 0\n```\n\n\n\n/tinkle-style-dev/docker-compose.yml  不指明`container_name`容器名\n\n`docker-compose up -d` 默认 tinkle-style-dev_tinkle-style-dev_1\n\n```\nupstream backend {\n    server tinkle-core-dev_tinkle-core-dev_1:8080;\n}\nupstream style{\n    server tinkle-style-dev_tinkle-style-dev_1:8080;\n}\nupstream ocr{\n    server tinkle-ocr-dev_tinkle-ocr-dev_1:8080;\n}\n log_format  main1  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"'\n                       '$upstream_addr $upstream_response_time $request_time ';\nserver {\n\tlisten       80;\n\tserver_name  api.baopinghui.com;\n\tcharset utf-8;\n\taccess_log  logs/host.access.log  main1;\n      \n      \n\tlocation / {\n\t\t#root   html;\n\t\t#index  index.html index.htm;\n\t\tif ( $request_uri ~* /fastNeuralStyleController ) {\n  \t\t\tproxy_pass http://style;\n\t\t }\n\t\tif ( $request_uri ~* /(style)/(.*) ){\n\t\t\tproxy_pass http://style/$2;\n\t\t}\n\t\tproxy_pass http://backend/;\n\t\tproxy_set_header   Host    $host;\n\t\tproxy_set_header   Cookie $http_cookie; \n\t\tproxy_set_header   X-Real-IP        $remote_addr;\n\t\tproxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n\t\tadd_header From localhost;\n\t\tproxy_cookie_path / /; \n\t}\n}\n```\n\n\n\n#### GPU\n\n\n\n```\nlspci | grep -i vga\n```\n\n支持列表 https://developer.nvidia.com/cuda-gpus\n\n下载 http://www.geforce.cn/drivers\n\n\n\n驱动版本\n\n```\ncat /proc/driver/nvidia/version\n```\n\n本机显卡\n\n```\nls -l /dev/nvidia*\n```\n\n\n\n```\nsudo nvidia-smi\n```\n\n![](/pics/nvidia.png)\n\n\n\n温度\n\n```\nsudo nvidia-smi -q -d TEMPERATURE\n```\n\n10s 一次\n\n```\nwatch -n 10 nvidia-smi\n```\n\n\n\n\n\n```\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"`\nexport CUDA_HOME=/usr/local/cuda`\n```\n\n> Check failed: s.ok() could not find cudnnCreate in cudnn DSO xxxxx undefined symbol: cudnnCreate\n\n\n\n\n\n#### 错误\n\nNo `command` specified\n\n```\ndocker run -it   xidx  /bin/bash  -c \"ls\"\n```\n\n\n\nOCI runtime create failed: container_linux.go:344: starting container process caused \"exec: \\\"/bin/bash\\\": stat `/bin/bash: no such file or directory`\": unknown.  \n\n```\ndocker run -it   xidx  sh\n```\n\n\n\n","tags":["docker"],"categories":["linux","k8s"]},{"title":"sed替换查找","url":"/linux/shell/sed/","content":"\n### 参数\n\n```\nsed [options] 'command' file(s) \n\nsed [options] -f scriptfile file(s)\n\n\ng 表示行内全面替换。     global 全局   \np 表示打印行。 P 打印模板第一行\nr 读文件\n-n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 \n-e ：直接在命令列模式上进行 sed 的动作编辑； \n-f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；\n-r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法) -i ：直接修改读取的文件内容，而不是输出到终端   \n w 表示把行写入一个文件。\n x 表示互换模板块中的文本和缓冲区中的文本。\n y 表示把一个字符翻译为另外的字符（但是不用于正则表达式）\n \\1 子串匹配标记 \n& 已匹配字符串标记元字符集\n^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 \n$ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。\n . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。\n * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。\n [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。\n [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。\n \\(..\\) 匹配子串，保存匹配的字符，如s/\\(love\\)able/\\1rs，loveable被替换成lovers。\n & 保存搜索字符用来替换其他字符，如s/love/**&**/，love这成**love**。\n \\< 匹配单词的开始，如:/\\ 匹配单词的结束，如/love\\>/匹配包含以love结尾的单词的行。\n x\\{m\\} 重复字符x，m次，如：/0\\{5\\}/匹配包含5个0的行。\n x\\{m,\\} 重复字符x，至少m次，如：/0\\{5,\\}/匹配至少有5个0的行。\n x\\{m,n\\} 重复字符x，至少m次，不多于n次，如：/0\\{5,10\\}/匹配5~10个0的行。\n```\n\n \n\n### 批量替换\n\n把目录下所有格式文件内容进行批量替换\n\n```shell\nsed -n \"s#$src#$dest#g\"p `grep $src -rl --include=\\*.{yaml,md} $path`\n```\n\n>扫描path路径对应格式的文件,把src替换成dest,\n\n>**sed** \n>\n>-n p  结合打印改变内容,不执行变更\n>\n>**grep**\n>\n>-r 表示查找当前目录以及所有子目录\n>\n>-l 表示仅列出符合条件的文件名\n>\n>--include=\"*.[ch]\" 表示仅查找.c、.h文件\n>\n>上面不适用大多数情况,推荐下面\n>\n>--include=*.{yaml,md}\n\n<!--more-->\n\n​           \n\n样本1 test.txt   (cat -n 显示行号)\n\n```\n111111111 \n222222222   \n```\n\n \n\n#### **a\\ ** 追加\n\n在当前行下面插入文本。  append  追加\n\nN;2a  指定第二行后追加append\n\n```shell\ncs@debian:~/～$ sed -i 'N;2a这是a' test.txt \ncs@debian:~/～$ cat -n test.txt    \n1\t11111111    \n2\t22222222    \n3\t这是a      \n```\n\n​        \n\n/匹配/  不确定行数 a\\ **反斜杠可以不要** a\n\n```shell\n cs@debian:~/～$ sed -i \"/这是a/a\\匹配追加\" test.txt \n cs@debian:~/～$ cat -n test.txt    \n 1\t这是i    \n 2\t11111111    \n 3\t22222222    \n 4\t这是a    \n 5  匹配追加      \n```\n\n​        \n\n####  **i\\ **  插入\n\n在当前行上面插入文本。 insert 插入\n\n N;2i 指定第二行前插入insert  'N;2i\\这是i' （\\省略）\n\n```\ncs@debian:~/～$ sed -i 'N;2i这是i' test.txt\ncs@debian:~/～$ cat -n test.txt    \n1\t这是i    \n2\t11111111    \n3\t22222222    \n```\n\n​          \n\n/匹配/  不确定行数\n\n```\ncs@debian:~/～$ sed -i \"/这是i/i\\匹配插入\" test.txt \ncs@debian:~/～$ cat -n test.txt    \n1\t匹配插入    \n2\t这是i    \n3\t11111111    \n4\t22222222    \n5\t这是a      \n```\n\n​        \n\n匹配多个---》 批量插入\n\n```\n cs@debian:~/～$ sed -i \"/这是/i\\匹配多个\" test.txt \n cs@debian:~/～$ cat -n test.txt    \n 1\t匹配多个    \n 2\t这是i    \n 3\t11111111    \n 4\t22222222    \n 5\t匹配多个    \n 6\t这是a   \n```\n\n​           \n\n c\\ 把选定的行改为新的文本。 \n\n\n\n#### d 删除\n\n删除选择的行。\n\n确定行数\n\n```\ncs@debian:~/～$  sed '2,5d' test.txt\n```\n\n> #2-5行删除  \n>\n>  '2d' 第2行\n>\n>   '10,$d' 10到最后一行\n\n​             \n\n匹配删除 删除匹配下一行  d删除 p打印  #加 -i 直接修改 \n\n\n\n样本2\n\n```\ncs@debian:~/～$ cat -n test.txt     \n1\t11111111     \n2\t这是i     \n3\t22222222     \n4\t这是a     \n5\t33333333             \n```\n\n\n\n#### n N p\n\n```shell\ncs@debian:~/～$ sed '/这是i/{n;d;p}' test.txt\n11111111     \n这是i     \n这是a     \n33333333\ncs@debian:~/～$ sed '/这是i/{N;d;p}' test.txt \n11111111     \n这是a     \n33333333\n```\n\n>n匹配下一行  \n>\n>N匹配当前行和下一行\n\n\n\nn命令-->移动到匹配行的下一行  {n;操作;}\n\n```\n$ sed -i '/^ZOOKEEPER_PREFIX/{n;s#$#JAVA_HOME=/opt/jdk/jdk-11.0.12#;}' ./zkEnv.sh\n```\n\n>ZOOKEEPER_PREFIX=\"${ZOOBINDIR}/..\"\n>\n>JAVA_HOME=/opt/jdk/jdk-11.0.12\n>\n>#check to see if the conf dir is given as an optional argument\n\n\n\n上一行 (提供多的特征匹配)\n\n```\nsed -n '/^if.*JAVA_HOME/i\\JAVA_HOME=/opt/jdk/jdk-11.0.12' ./zkEnv.sh \n```\n\n>JAVA_HOME=/opt/jdk/jdk-11.0.12\n>\n>if [[ -n \"$JAVA_HOME\" ]] && [[ -x \"$JAVA_HOME/bin/java\" ]];  then\n>\n>​    JAVA=\"$JAVA_HOME/bin/java\"\n>\n>elif type -p java; then\n\n\n\n\n\n N 将下一行读入并附加到当前行后面放到当前空间模式\n\n 最后一行结束\n\n```shell\ncs@debian:~/～$ echo -e \"11111\\n2222222\\n3333\" | sed 'N;p'\n11111\n2222222\n11111\n2222222\n333\n```\n\n\n\n P模式空间第一行 N再次执行就到了3 ，隔行  \n\n```shell\ncs@debian:~/～$ echo -e \"11111\\n2222222\\n3333\\n44\\n55\\n6\" | sed 'N;P'\n1111111111\n2222222\n33333333\n44\n5555\n6\n```\n\n\n\n```\ncs@debian:~$ cat /etc/hosts\n127.0.0.1\tlocalhost\n192.168.56.1  master01 ui.k8s.cn k8s.org jenkins.k8s.cn  gogs.k8s.cn\n192.168.56.101  node01\n192.168.56.108  node02 \ncs@debian:/ip$ ip=192.168.56.108\ncs@debian:/ip$ cat hosts | sed -e  \"s/^\\(${ip}\\)\\([[:space:]]*\\)\\(.*\\)/\\3/g\" p\nnode01\n```\n\n\n\n```\ncs@debian:/ip$ ip=node02\ncs@debian:/ip$ cat hosts | sed -n \"s/\\(.*\\)\\([[:space:]]*\\)\\(${ip}\\)/\\1/g\"p\n192.168.56.108  \n```\n\n\n\n```shell\nzookeeper.connect=localhost:2181\n cat ./config/server.properties | sed -n 's/^zookeeper\\.connect=\\(.*\\)/\\1/'p\nlocalhost:2181\ncat ./config/server.properties | sed -n \"s#^listeners=PLAINTEXT://\\(.*\\)#\\1#\"p\n127.0.0.1:9092\n```\n\n\n\n​         \n\n\n\n####  D\n\n 删除模板块的第一行。\n\n\n\n####  s 替换\n\ns/指定字符/替换字符/\n\nrelative/directory/  改为/etc/supervisor.conf.d/\n\n```shell\ncs@debian:~/～$ sed -n   's/relative\\/directory\\//\\/etc\\/supervisor.conf.d\\//'p /etc/supervisord.conf\n```\n\n> -n选项和p命令一起使用表示只打印发生替换的行\n\n  \n\n 防火墙关闭\n\n```\ncat /etc/selinux/config | grep ^SELINUX= | sed  's/^SELINUX=.*/SELINUX=disabled/'\nsed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config\n```\n\n\n\n替换整行\n\n  ```shell\ncs@debian:~/～$  sed  -i  '2s/^.*$/xxxxx/'  file  \n  ```\n\n\n\n\n\n#### 截取 \n\n```shell\ncs@debian:~/～$ echo \"tinkle-app-style-0.0.1-SNAPSHOT.jar\" | sed 's/\\([a-z]-*\\)-[0-9].*/\\1/'\n```\n\n\n\n```shell\ncs@debian:~/～$  echo \"abcdef-shea-df\" | sed 's/\\(.*\\)-\\(.*\\)-\\(.*\\)/\\2/g'\n命令解释\n\\(.*\\)- : 表示第一个引号前的内容\n-\\(.*\\)-：表示两引号之间的内容\n-\\(.*\\)：表示引号后的内容\n\\2: 表示第二对括号里面的内容\n括号里的表达式匹配的内容，可以用\\1，\\2等进行引用，第n个括号对内的内容，就用\\n引用。\n这个命令的意思是：\n用\\2代表的第二个括号的内容（shea）去替换整个字符串，这样就得到了我们所需要的子字符串了。\n```\n\n\n\n```shell\ncs@debian:~$ echo \"etch-master.sh\" | sed 's/\\(.*\\)-\\(.*\\)\\.\\(.*\\)/\\2/g'\nmaster\ncs@debian:~$ echo \"gen-flanneld.sh\" | sed 's/^gen-\\(.*\\)\\..*/\\1/g'\nflanneld\n```\n\n\n\n```shell\ncs@debian:~$ systemctl status flanneld.service\n● flanneld.service - Flanneld overlay address etcd agent\n   Loaded: loaded (/opt/kubernetes/flanneld/flanneld.service; disabled; vendor p\n   Active: inactive (dead)\ncs@debian:~$ systemctl status flanneld.service | grep Active: | sed 's/.*(\\([a-z]*\\)).*/\\1/g'\ndead\ncs@debian:~$ systemctl status nginx | grep Active | sed 's/.*(\\(.*\\)).*/\\1/g'\nrunning\ncs@debian:~$ systemctl status kube-scheduler  |  sed -n 's/.*ctive:.*(\\(.*\\)).*/\\1/g'p\ndead\n```\n\n\n\n### 标记跳转\n\n删除前一行  (:a  ;ta) a标记，ta执行成功在跳转，类似循环\n\n   ```shell\ncs@debian:~/～$ sed -e :a -e '$!N;s/.*\\n\\(.*是.*\\)/\\1/;ta' -e 'P;D'  test.txt\n这是i\n这是a\n33333333 \n   ```\n\n\n\n前置 s/正则/\\1/    $最后一行 ！不进行 \n\n```shell\ncs@debian:~/～$ sed -e   '$!N;s/.*\\n\\(.*是i\\)/\\1/' -e 'p;d'  test.txt\n这是i\n22222222\n这是a\n33333333\ncs@debian:~/～$ sed -e   '$!N;s/.*\\n\\(.*是i\\)/\\1/' -e 'P;D'  test.txt\n这是i\n22222222\n这是a\n33333333\ncs@debian:~/～$ sed -e :a -e '$!N;s/.*\\n\\(.*是.*\\)/\\1/;ta' -e 'P;D'  test.txt\n这是i\n这是a\n33333333\n```\n\n\n\n\n\ntest\n\n```\n3d5f\n<Proxy>\n这是i\n<P>\n22222222\n</Proxy>\nabcde\n```\n\n替换Proxy 标签中间部分\n\n```shell\nsed '/<P/{:a;N;/<\\//!ba;s/>[^<].*</>\\n替换你们\\n</}'  test\n\n<p  :a;N;/<\\//!ba\n匹配<Proxy  :a标记  </ 结束匹配标记  !b （匹配不了，执行下句命令）\ns/>[^<]*</>\\n1234567\\n</\n>把中间内容<  替换指定内容\n```\n\n\n\n\n\n\n\n\n\n### 注释       \n\njoin.yaml\n\n```\n#kind: JoinConfiguration\n\nnodeRegistration:\n  name: debian  #节点名,master要能解析\n```\n\n#### 添加\n\n```\nsed -n '/debian/s/^/#/'p ./join.yaml\n```\n\n> \\#  name: debian  #节点名,master要能解析\n\n```\nsed -n 's/debian/#&/'p ./join.yaml\n```\n\n>  name: #debian  #节点名,master要能解析\n\n\n\n```\ncs@debian:~$ cat /etc/fstab | grep swap | sed '/swap/s/^/#/' \n## swap was on /dev/sda5 during installation\n##UUID=0fd6cee8-fdfa-459b-a7c6-1898ea2ade8e none            swap    sw              0       0\n[vagrant@master03 ~]$ cat /etc/fstab | grep swap | sed '/swap/s/^/#/' \n##/swapfile none swap defaults 0 0\n```\n\n\n\n```\nsed -i '/匹配字符串/,+4 s/^/#/' 文件名   #匹配行和下面4行\n```\n\n> +4表示匹配行和下面4行，一共5行注释\n\n\n\n\n\n#### 删除\n\n```\n#去掉所有行注释\nsed -n '/^#.*$/s/^#//'p ./join.yaml\n#去匹配行注释\nsed -n '/^#.*debian.*$/s/^#//'p ./join.yaml\n```\n\n>  name: debian  #节点名,master要能解析\n\n\n\n```shell\nsed 's/^#.*\\(en_US.UTF-8\\)/\\1/' test\n```\n\n\n\n\n\n```\n#去注释行\nsed -i '/^#/d' ./join.yaml\n#去空行和注释行\nsed -i '/^$/d;/^#/' ./join.yaml\n```\n\n\n\n```\nsed -i '/匹配字符串/,+4 s/^#*//' 文件名\n\n[vagrant@node06 ~]$ grep 'HOME'  /etc/profile\nexport JAVA_HOME=/opt/mq/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n# echo $(sed -n  '/export\\ JAVA_HOME/,+2 s/export/#/'p /etc/profile)\n# sed -i '/export\\ JAVA_HOME/,+2 s/export/#/' /etc/profile\n```\n\n","tags":["sed"],"categories":["linux","shell"]},{"title":"磁盘或Inode使用率高","url":"/linux/shell/usage_high/","content":"\n\n\n## Inode\n\n**一个文件占用一个inode ，且inode是固定的，小文件过多就可能造成磁盘空间剩余挺多，但是inode耗尽的情况。**\n\n### df -i\n\n查看当前系统inode使用情况\n\n\n\n![](/pics/inode-1-2848.png)\n\n一级一级往下，统计inode文件数量。数字大就表示占用inode多\n\n<!--more-->\n\n如果命令在那个目录卡住,表示该目录,文件特多,ctrl+c停止,从该目录开始排查\n\n![](/pics/inode-3-4837.png)\n\n\n\n### wc  -l \n\n```\nfor i in /home/* ; do echo $i; find $i | wc -l; done\n```\n\n![](/pics/inode-2-4723.png)\n\n删除\n\n```\n find  /home/go/test/  -maxdepth 1  -type f   -mtime +0   -exec  rm  -rf  {} \\;\n```\n\n>+1 内表示 1 * 24 +24小时以外..\n>+0 才表示 0 * 24 +24小时以外\n>1 表示 1*24 + 24 到 24 之间..\n>0 表示 0*24 + 24 到 0 之间..\n\n\n\n修改大小\n\n```\n#卸载\numount /home/cs/go \n#建立文件系统，指定inode节点数 \nmkfs.ext3 /dev/sda6 -N 18276352 \n#修改fstab文件 \nvim /etc/fstab \n/dev/sda6 /home/cs/go ext3 defaults 1 2 \n#重新加载并检查挂载文件 \nmount -a \n#查看修改后的inode参数 \ndumpe2fs -h /dev/sda6 | grep node\n\n```\n\n\n\n\n\n多核cpu生成百万文件\n\n```\ncd ~/go/test\nseq 1000000 | xargs -i  -P 0 dd if=/dev/urandom of={}.txt bs=1024 count=1\n```\n\n\n\n## disk\n\n### df  -h\n\n排查目录\n\ndu -sh * | sort  -nr | head -5\n\n\n\n查找大于1G的文件\n\n```console-bash\nfind /  -type f -size +1G\n```\n\n\n\n 没有大文件,查看已经删除的文件\n\n```\nlsof -n |grep deleted\n```\n\n删除的文件有程序在使用,一直没有释放掉,kill掉pid\n\n\n\n## cpu\n\nps -aux | sort -k3nr | head -5\n\n\n\n### top  \n\n shift+p    切到cpu排序高到低\n\n### tid\n\nps -Lfp pid或者ps -mp pid -o THREAD，tid，time或者top -Hp pid\n\n```\nps -mp $pid -o THREAD，tid，time | sort -nr\n```\n\n\n\n#线程ID转成16进制用于查询\n\n```\n$ printf \"%x\\n\"  $tid\na221\n```\n\n### jstack\n\n```\njstack $pid | grep \"a221\"  -A  30\n```\n\n> -A  -B -C(大写)  后面都跟阿拉伯数字 \n>-A是显示匹配后和它后面的n行。after \n>-B是显示匹配行和它前面的n行。 before\n>-C是匹配行和它前后各n行。 context\n\n\n\n```\nps -ef | grep $name\njstack $pid >> ./dump.log\n```\n\n\n\n### Thread Dump\n\n***\\*kill -3 PID命令只能打印那一瞬间java进程的堆栈信息\\****，适合在服务器响应慢，cpu、内存快速飙升等异常情况下使用，可以方便地定位到导致异常发生的java类，解决如死锁、连接超时等原因导致的系统异常问题。**该命令不会杀死进程。**\n\n- tomcat  堆栈信息会打印在catalina.out\n- nohup启动 堆栈信息会在nohup.out\n\n\n\n## mem\n\n\n\n### free -m\n\n\n\nps -aux | sort -k4nr | head -5\n\n\n\n\n\n## 工具\n\narthas  \n\n下载 https://github.com/alibaba/arthas/releases\n\n文档 https://arthas.aliyun.com/doc/advanced-use.html\n\n\n\njvisualvm\n\n${JDK_HOME}\\bin\\jvisualvm\n\nhttps://www.cnblogs.com/mzq123/p/11166640.html","tags":["usage_high"],"categories":["linux","shell"]},{"title":"网络概念介绍","url":"/network/network/","content":"\n\n\n## http 应用层\n\n在两台计算机相互传递信息时，HTTP规定了每段数据以什么形式表达才是能够被另外一台计算机理解\n\n\n\n第一步：在浏览器输入内容（网址）\n\n第二步：浏览器把 域名 发送到DNS上 ，进行解析 得到IP之后链接到指定\n\n​    服务器 （服务器地址110,102.13.32:80 从浏览器到服务器使用底层TCP/IP）\n\n第三步：实现TCP/IP协议用Socket 用Socket套接字\n\n第四步：服务器端口80监听客户端链接（客户端到服务器端链接）\n\n\n\nHTTP 1.0 一个链接发送一个请求\n\nHTTP 1.1 一个链接发送多个请求\n\n\n\nget  向服务器 【索取】 数据的一种 请求\n\n  一般用于 获取/查询  资源信息\n\n  get用于信息获取，而且应该是安全（指非修改信息）和幂等\n\n  如：新闻头版不断更新，该操作被认为安全和幂等，从自身角度来看没有改变资源\n\n\n\npost  向服务器 【提交】 数据的一种 请求\n\n  一般用于 更新 资源信息\n\n​\tpost表示可能修改服务器上的资源请求\n\n​\t如：评论新闻，提交后站点资源不同，资源被修改\n\n\n\n表面现象\n\n​\tget请求数据附在URL上； post提交数据放在http包体中\n\n​\tget字节限制（1024） 实质是浏览器（和服务器）的限制 ； post理论没有限制\n\n​\tpost 安全（security）性比 get安全（security）性高\n\n\n\n\n\n## tpc/udp 传输层\n\n规定的是数据应该怎么传输才能稳定且高效的传递与计算机之间。\n\n\n\n| \\          | TCP                                    | UDP                                  |\n| ---------- | -------------------------------------- | ------------------------------------ |\n| 是否连接   | 面向连接                               | 面向非连接                           |\n| 传输可靠性 | 可靠                                   | 不可靠                               |\n| 应用场合   | 传输大量的数据，对可靠性要求较高的场合 | 传送少量数据、对可靠性要求不高的场景 |\n| 速度       | 慢                                     | 快                                   |\n\n\n\n## https\n\nHTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议","tags":["tcp","http"],"categories":["network"]},{"title":"npm初始","url":"/lang/npm/npm初始/","content":"\n\n\n## 源加速\n\n设置\n\n```\necho \"registry = https://registry.npm.taobao.org\">>~/.npmrc\n```\n\n查看当前源\n\n```\nnpm config get registry\n```\n\n<!--more-->\n\n## 使用\n\n### 全局安装(-g)\n\n typescript\n\n```\nnpm install -g typescript\n```\n\n>/opt/node/bin/tsc -> /opt/node/lib/node_modules/typescript/bin/tsc\n>/opt/node/bin/tsserver -> /opt/node/lib/node_modules/typescript/bin/tsserver\n>+ typescript@4.7.3\n>added 1 package from 1 contributor in 2.252s\n>\n\n\n\n### 卸载\n\n```\nnpm uninstall -g  typescript\n```\n\n\n\n- **`i`** 是 **`install`** 的简写\n- **`-g`** 是全局安装，不带 **`-g`** 会安装在个人文件夹\n- **`-S`** 与 **`--save`** 的简写，安装包信息会写入 **`dependencies`** 中;生产阶段,项目运行时的依赖\n- **`-D`** 与 **`--save-dev`** 的简写，安装包写入 **`devDependencies`** 中;开发阶段,只在开发阶段起作用,例如代码提示工具\n","tags":["源"],"categories":["lang","npm"]},{"title":"vi/vim基本命令","url":"/linux/shell/vim/","content":"\n\n\n![](/pics/vim-4855.png)\n\necs 退出 **编辑状态**  到  **命令状态** \n\n### 插入\n\n在光标前 `i`\n\n移到在行首 `I`\n\n光标后 `a`\n\n当前行尾 `A`\n\n当前行之下另起一行 `o` 进入编辑状态\n\n当前行之上另起一行 `O`\n\n##### 替换\n\n当前字符 `r`\n<!--more-->\n\n当前及其后,直到按Esc `R`\n\n#####  粘贴\n\n 剪切  `dd`当前行  ,移动到目标行 `p`粘贴\n\n复制  `yy`当前行  ,`p`粘贴  \n\n复制2个单词 `y2w`  向下2行 `y2j`  向上2行 `y2k`\n\n寄存器 `:reg [args]`  **+**剪切板\n\n复制当前行 `\"+yy`   `\"+nyy`\n\n剪切板内容粘贴到光标后 `\"+p`\n\n\n\n##### 搜索\n\n跳到指定行(21行) `:21`  或 `21G`   \n\n返回原光标处 ` ``  `\n\n##### 移动\n\n左`j` 下`j` 上`k` 右`l`\n\n单词末尾 `e`\n\n2个单词   前移  `2b`  后移 `2w`\n\n行首  `0` 或 `^`           行尾 `$`  2行行尾 `2$`\n\n上行(减号)  `-`   下行  `+`\n\n\n\n跳到对应括号(代码块)  `%`\n\n### 恢复\n\n撤销(本次编辑模式没有改动) `u`\n\n恢复上一步撤销  `ctrl+r`\n\n### 删除\n\n删除字符 `x`\n\n删除当前行及后面n-1行  `ndd` \n\n\n\n### 退出\n\n保存 `:wq` 或 `:x`\n\n强制退出 `:q!`\n\n\n\n\n\n### 编辑压缩包内文件\n\n 打开压缩包 进入文件可以编辑  （/name ）  **待验证**\n\n\n\n\n\nLANG=”Zn_CN.UTF-8”  #临时设置语言\n\necho $LANG #当前系统设置编码 \n","tags":["vim"],"categories":["linux","shell"]},{"title":"find查找搜索","url":"/linux/shell/find/","content":"\n\n\n查找\n\n> find [OPTIONS] [查找起始路径] [查找条件] [处理动作]\n\n[OPTIONS]  忽略\n\n\n\n#### 路径\n\n  相对    `./`\n\n  绝对   `/`\n\n#### 条件\n\n名称\n\n**name**    `find  /  -name   mysql`\n\n**iname**   `find  /  -iname  cmake`   *忽略大小写*\n\n**regex**  `find / -regex  /docker*`  正则模糊查询\n\n大小\n<!--more-->\n\n**size**   `find  / -size  +20M` \n\n *+* 大于    *-*小于    *K*  *M*  *G*\n\n`   20M`       (20-1,20]\n\n`-  20M`    [0,20-1]\n\n`+ 20M`    (20,+∞]\n\n时间\n\n**atime**  文件最后访问  \n\n*  [#, #-1) ：最后访问时间在#天前（大于等于#天前，小于#-1天前）\n\n  等价于最后访问时间与当前的时间差 大于 (#-1)*24小时，小于等于 #*24小时\n\n\n*  (#, 0] ：最后访问时间在#天以内，不包括24小时前的那一刻。\n\n等价于最后访问时间与当前的时间差小于 #*24小时\n\n*  (oo, #-1] ：最后访问时间在#-1天以前的。包括#-1天前\n\n等价于最后访问时间与当前的时间差大于等于 #*24小时\n\n```\n#查找最近10天内被访问过的所有文件\n[root@centos7 ~]# find . -type f -atime -10\n \n#查找超过10天内被访问过的所有文件\n[root@centos7 ~]# find . -type f -atime +10\n \n#查找访问时间超过20分钟的所有文件\n[root@centos7 ~]# find . -type f -amin +20\n \n#找出比mingongge修改时间更长的所有文件\n[root@centos7 ~]# find . -type f -newer mingongge\n```\n\n**mtime**  文件最后修改\n\n**ctime**  文件最后改变\n\n\n\n```\n\nsudo find /boot/burg/themes/  -name '[^Metro]*' | xargs rm -rf\n\n```\n\n-path  排除路径\n\n-type  类型  d 目录  f文件     \n\n-o  or \n\n-a and\n\n-prune 配备到path路径，则跳过该目录\n\n```\n\nsudo find  /  -path \"/home/cs/lua-5.3.4\"  -prune -o -type f    -name  lua*\n\n```","tags":["find"],"categories":["linux","shell"]},{"title":"top排查服务器","url":"/linux/shell/top/","content":"\n\n\ntop -M  \n\ntop -c \n\ntop -p $pid\n\n![](/pics/top-4834.png)\n\n>排序默认从大到小,R反向排序\n>\n>M：根据内存排序\n>\n>P：根据CPU使用排序\n>\n>T：根据使用时间排序\n>\n>\\>：向右移动一列排序\n>\n><:向左移动一列排序\n\n界面shift+m (根据内存排序)\n\n![](/pics/top-M-5210.png)\n\n\n\n### 第一行top\n\n等同命令uptime\n\n```\ncs@debian:~/go$ uptime\n 22:00:22 up  8:59,  1 user,  load average: 0.13, 0.32, 0.36\n```\n\n<!--more-->\n\n>系统当前时间 up 系统到目前为止运行的时间，\n>\n> 当前系统的登陆用户数量，\n>\n>load average后面的三个数字分别表示距离现在一分钟，五分钟，十五分钟的负载情况\n\nload average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了\n\n\n\n\n\n\n\n### 第二行 Tasks\n\n```\nTasks: 241 total,   1 running, 240 sleeping,   0 stopped,   0 zombie\n```\n\n>tasks表示任务（进程），214则表示现在有241个进程，\n>\n>running  其中处于运行中的有1个，\n>\n>sleeping  240个在休眠(挂起)，\n>\n>stopped  停止的进程数为0，\n>\n>zombie   僵尸的进程数为0个\n\n\n\n### 第三行%Cpu\n\n```\n%Cpu(s):  3.6 us,  0.6 sy,  0.0 ni, 95.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n```\n\n>us——用户空间(user)占用cpu的百分比\n>sy——内核空间(system)占用cpu的百分比\n>ni——改变过优先级(niced)的进程占用cpu的百分比\n>id——空闲（idolt）CPU百分比\n>wa——IO等待(wait)占用cpu的百分比\n>hi——IRQ 硬中断(Hardware)占用cpu的百分比\n>si——软中断（software）占用cpu的百分比\n>st——被hypervisor偷去的时间\n\n\n\n### 第四五行 kib内存\n\n```\nKiB Mem : 16257204 total, 12933272 free,  1288736 used,  2035196 buff/cache\nKiB Swap:  7812092 total,  7812092 free,        0 used. 14425716 avail Mem \n```\n\n>Mem：物理内存总量（16G）\n>free: 空闲内存总量(1G)\n>used: 使用中的内存总量\n>buff/cache: 用作内核缓存的内存量\n\n>Swap： 交换区总量\n>free：空闲交换区总量\n>used： 使用的交换区总量\n>avail Mem：表示可用于进程下一次分配的物理内存数量，这个大小一般比free大一点，因为除了free的空间外，系统还能立即释放出一些空间来\n\n\n\n\n\n### 第七行 进程信息区\n\n```\n PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND  \n```\n\n>PID — 进程id\n>USER — 进程所有者\n>PR — 进程优先级\n>NI — nice值。负值表示高优先级，正值表示低优先级\n>VIRT — 进程使用的`虚拟内存`总量，单位kb。VIRT=SWAP+RES\n>RES — `常驻内存`,进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\n>SHR — `共享内存`大小，单位kb\n>S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程\n>%CPU — 上次更新到现在的CPU时间占用百分比\n>%MEM — 进程使用的物理内存百分比\n>TIME+ — 进程使用的CPU时间总计，单位1/100秒\n>COMMAND — 进程名称（命令名/命令行）\n\n\n\n### 其他\n\n```\ncs@debian:~/go$ sudo netstat -anp|grep 12347\ntcp        0      0 0.0.0.0:4000            0.0.0.0:*               LISTEN      12347/hexo \n```\n\n\n\n```\ncs@debian:~/go$ lsof -i:4000\nCOMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nhexo    12347   cs   21u  IPv4 324187      0t0  TCP *:4000 (LISTEN)\ncs@debian:~/go$ ps -ef|grep 12347\ncs       12347  1640  0 21:56 pts/2    00:00:03 hexo\ncs       13306  1622  0 22:23 pts/0    00:00:00 grep 12347\n```\n\n\n\n列出所有正在运行的java进程\n\n```\ncs@debian:~/go$ jps\n13600 Jps\n```\n\n>| 参数 | 说明                            |\n>| ---- | ------------------------------- |\n>| `-l` | 输出主类全名或jar路径           |\n>| `-q` | 只输出LVMID                     |\n>| `-m` | 输出JVM启动时传递给main()的参数 |\n>| `-v` | 输出JVM启动时显示指定的JVM参数  |\n\n\n\n\n\n\n","tags":["shell"],"categories":["linux","shell"]},{"title":"初识jvm","url":"/lang/gc/","content":"\n## 调优参数\n\n选项 Xms,Xmx,newSize,MaxSize ,PermSize, MaxPermSize\n\nXms(young和old区使用大小)\n\nXmx(young和old区最大承受大小)\n\nnewSize(young区使用大小)\n\nMaxSize(young区最大承受大小)\n\nPermSize(持久区使用大小)\n\nMaxPermSize(持久区最大使用大小)\n\n<!--more-->\n\nsuivivorRatio(设置Eden和survivor比例  默认是8:1)\n\n-Xms：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。\n-Xmx：表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。\n\n-XX:newSize：表示新生代初始内存的大小，应该小于-Xms的值；\n-XX:MaxnewSize：表示新生代可被分配的内存的最大上限；当然这个值应该小于-Xmx的值；\n\n-XX:PermSize：表示非堆区初始内存分配大小（方法区）\n-XX:MaxPermSize：表示对非堆区分配的内存的最大上限（方法区）。\n\n\n\n## 工作流程\n\n![](/pics/jvm-work-4037.png)\n\n1、编译阶段：首先.java经过javac编译成.class文件\n\n2、加载阶段：然后.class文件经过类的加载器加载到JVM内存。(装载、连接、初始化)\n\n-  先把class的信息读到内存来\n-  会对class的信息进行验证、为类变量分配内存空间并对其赋默认值\n-  执行初始化静态块内容，并且为静态变量进行真正的赋值操作\n\n3、解释阶段：class字节码经过字节码解释器解释成系统可识别的指令码。\n\n4、执行阶段：系统再向硬件设备发送指令码执行操作。\n\n\n\n\n\n## 数据区域\n\n![](/pics/jvm-area-4346.png)\n\n Matespace(元空间)在本地内存区域\n\n> -XX:MetaspaceSize，初始空间大小\n>\n> -XX:MaxMetaspaceSize，最大空间，默认是没有限制的\n\n\n\n## 垃圾回收区域\n\n![](/pics/gc-area-4008.png)\n\n### Yong Generation\n\n负责新接收的对象\n\n默认区域划分8:1\n\n#### Eden   80%\n\nEden区域触发第一次GC\n\n#### Survivor \n\n##### From 10%\n\n上一次MinorGC存活者,等待下次扫描\n\n##### To 10%\n\n一次MinorGC过程后的存活者\n\nMinorGC过程\n\n1. eden,survivorFrom复制到survivorTo,年龄加1\n2. 清空(eden,survivorFrom) \n3. survivorTo 与survivorFrom互换\n\nGC过程中to区满后(或者达到年龄标准,无法储存的某个对象)就移到old区\n\n### Old Generation\n\n存放yong多次GC后仍存活的对象\n\nold空间不足时会触发MajorGC(Full GC)\n\nMajorGC过程\n\n- 先扫描全部,标记存活对象,清除没有标记的对象\n\n### Permanent Generation\n\n静态文件(java类,方法,元数据)\n\n\n\n## 垃圾回收算法\n\n![](/pics/gc-yg-3223.png)\n\n\n\nhttps://zhuanlan.zhihu.com/p/343746128\n\n\n\n\n\n\n\n![](/pics/new-area-3239.png)\n\n","tags":["jvm"],"categories":["lang","gc"]},{"title":"md流程图","url":"/markdown/flow/","content":"\n```flow\nstart=>start: 接收到消息\ninfo=>operation: 读取信息\ncd=>condition: 是否存在\nsetC=>subroutine: 设置缓存\ngetC=>operation: 读取缓存\nxx=>inputoutput: 返回信息\nend=>end: 处理结束\n\nstart->info->cd\ncd(yes)->getC->xx\ncd(no)->setC->xx\nxx->end\n```\n\n<!--more-->\n\n![md_flow](/pics/md_flow.png)\n\n\n>基本语法：定义模块 id=>关键字: 描述 （“描述”的前面必须有空格，“=>” 两端不能有空格）\n>\n>关键字：\n>\n>start 流程开始，以圆角矩形绘制\n>\n>operation 操作，以直角矩形绘制\n>\n>condition 判断，以菱形绘制\n>\n>subroutine 子流程，以左右带空白框的矩形绘制\n>\n>inputoutput 输入输出，以平行四边形绘制\n>\n>end 流程结束，以圆角矩形绘制\n>\n>定义模块间的流向：\n>\n>模块1 id->模块2 id ：\n>\n>一般的箭头指向条件模块id (描述)->模块id(direction) ：条件模块跳转到对应的执行模块，并指定对应分支的布局方向\n\n\n","tags":["流程图","flow"],"categories":["markdown"]},{"title":"zk选举","url":"/services/zookeeper/选举机制/","content":"\n#### 核心机制\n\n- 逻辑时间 epoch ,判断是否是同一轮投票(网络原因导致投票广播信息滞后)\n- 事物ID(Zxid),事物ID最大的数据最新  \n- 服务器ID(myid),数值大的权重大  \n\n<!--more-->\n\n```flow\nstart=>start: 选self\ninfo=>operation: 广播信息\nj1=>condition: 投票结果状态\n\nj2=>condition:  是否过时\nyj2=>operation: 清空投票信息\nnj2=>operation: 更新投票信息\n\nj3=>condition: 是否同一轮\nyj3=>operation: 比较投票信息\nnj3=>operation: 已完成投票信息\n\nj=>condition:  是否形成共识\nend=>end: 退出\n\nstart->info->j1\nj1(yes)->j3\nj1(no)->j2\n\nj2(yes)->yj2(right)->nj2\nj2(no)->nj2\n\nj3(yes)->yj3->j\nj3(no)->nj3->j\n\nnj2->yj3->j\nj(no)->info\nj(yes)->end\n\n```\n\n\n\n\n\n####  比较逻辑\n\n![](/pics/zk_flow_2232.png)\n\n\n\n同一轮,对投票信息(epoch,zxid,myid)进行比较(zxid,myid)\n\n是否过时:\n\n*过时*(小于),更新使用self信息(epoch,zxid,myid)\n\n非过时(大于),清空信息,更新(epoch)进行比较(zxid,myid)\n\n  \n\n根据以下规则,超过半数收到相同投票选出leader\n\n> 逻辑时钟小的选举结果被忽略，重新投票\n>\n> 统一逻辑时钟后，事物ID大的胜出\n>\n> 事物ID相同的情况下，服务器ID大的胜出\n\n","tags":["服务发现","选举"],"categories":["services","zookeeper"]},{"title":"stream写法","url":"/lang/java/stream/","content":"\n\n\n\n\n\n\n\n\n\n\n```\n  public static void main(String[] args) {\n    ArrayList<String> list = new ArrayList<>(Arrays.asList(\"I\", \"love\", \"you\", \"too\"));\n    for(String str : list){\n        if(str.length()>3)\n            System.out.println(str);\n    }\n    list.forEach(str->System.out.println(str));\n    list.stream().filter(str->str.length()>3).forEach(System.out::println);\n  }\n```\n\n>用stream的filter来替代if/else业务逻辑\n\n\n\n```\nfor(int i=0;i<10;i++){\n    if(....){\n      //...........\n    }else{\n        //.......\n    }\n}\n\nlist.stream().filter().limit(10).foreach();\n```\n\n\n\n## Stream\n\n![](/pics/stream-1.png)\n\n<!--more-->\n\n### 流创建\n\n```\n\nList<String> list = Arrays.asList(\"hello\",\"world\",\"stream\");\n//创建顺序流\nStream<String> stream = list.stream();\n//创建并行流\nStream<String> parallelStream = list.parallelStream();\n```\n\n\n\n#### 静态方法\n\n**`of()、iterate()、generate()`**\n\n```\nStream<String> stream1 = Stream.of(\"I\", \"love\", \"you\", \"too\");\nstream1.forEach(System.out::println);\n\nStream<Integer> stream2 = Stream.iterate(0, i -> i + 2).limit(3);\nstream2.forEach(System.out::println);\n\nStream<Boolean> stream3 = Stream.generate(new Random()::nextBoolean).limit(3);\nstream3.forEach(System.out::println);\n```\n\n\n\n并行流  多线程  把一个内容分成多个数据块 不同线程分别处理每个数据块的流,最后合并(*无序数据处理*)\n\n```\nOptional<Integer> findFirst = list.stream().parallel().filter( x -> x>4 ).findFirst();\n```\n\n> 可以通过`parallel()`把顺序流转换成并行流\n\n![](/pics/stream-type2.png)\n\n\n\n### 中间操作\n\n#### 无状态（Stateless）\n\n指元素的处理不受之前元素的影响\n\n##### filter\n\n**筛选，是按照一定的规则校验流中的元素，将符合条件的元素提取到新的流中的操作**\n\n```\nlist.stream().filter(str->str.length()>3).forEach(System.out::println);\n```\n\n相当于if\n\n##### 映射(map、flatMap、peek)\n\n###### map\n\n```\n List<String> out =  list.stream().\n        map(String::toUpperCase).\n        collect(Collectors.toList());\n System.out.println(out);//[I, LOVE, YOU, TOO]\n```\n\n\n\n```\n    List<Product> list = new ArrayList<>();\n    Test t = new Test();\n\n    list.add(t.new Product(1, \"domestic phone\", new BigDecimal(6899.99)));\n    list.add(t.new Product(2, \"overseas notebook\", new BigDecimal(14989.98)));\n\n    String out =  list.stream().\n     //map(a->a.name.split(\" \")[1]).//phone&&notebook\n    map(a->a.name.replaceAll(\" \", \"-\")).//domestic-phone&&overseas-notebook\n    collect(Collectors.joining(\"&&\"));\n    System.out.println(out);\n```\n\n###### flatMap\n\n```\n    List<String> list = Arrays.asList(\"a:b:c\", \"1:3:5\");\n    List<String> listNew = list.stream().\n            flatMap(s -> Arrays.stream(s.split(\":\")) ).\n            collect(Collectors.toList());\n \n    System.out.println(\"处理前的集合：\" + list);\n    System.out.println(\"处理后的集合：\" + listNew);\n```\n\n>处理前的集合：[a:b:c, 1:3:5]\n>处理后的集合：[a, b, c, 1, 3, 5]\n\n\n\n###### peek\n\n```\n    Stream<String> stream = Stream.of(\"hello\", \"world\");\n    stream.peek(System.out::println).collect(Collectors.toList());\n```\n\n\n\n终端操作。通常分为 **最终的消费** （`foreach` 之类的）和 **归纳** （`collect`）两类。\n\n\n\n#### 有状态（Stateful）\n\n指该操作只有拿到所有元素之后才能继续下去\n\n###### distinct\n\n使用hashCode（）和equals（）方法来获取不同的元素\n\n```\nStream<String> stream = Stream.of(\"1\", \"3\",\"4\",\"10\",\"4\",\"6\",\"23\",\"3\");\nstream.distinct().forEach(System.out::println);\n\n```\n\n\n\n###### sorted\n\n```\n    HashMap<Integer, String> map = new HashMap<>();\n    map.put(1,\"phone\");\n    map.put(2,\"notebook\");\n    map.entrySet().stream().sorted(\n                    Collections.reverseOrder(Map.Entry.comparingByKey())//倒序\n                    //Comparator.comparing(e -> e.getKey())//正序\n            ).forEach(System.out::println);\n```\n\n\n\n###### skip\n\n```\n    Stream<Integer> stream = Stream.of(3,1,10,16,8,4,9);\n    stream.limit(3).skip(2).forEach(System.out::print);\n```\n\n>limit(3)  Iloveyou\n>\n>skip(2)  you\n\n\n\n### 终结操作\n\n#### 短路（Short-circuiting）\n\n指遇到某些符合条件的元素就可以得到最终结果\n\n\n\n###### anyMatch\n\nStream 中只要有一个元素符合传入的 predicate，返回 true\n\n```\nstream.anyMatch(s->s==2)\n```\n\n###### allMatch\n\nStream 中全部元素符合传入的 predicate，返回 true\n\n\n\n###### noneMatch\n\nStream 中没有一个元素符合传入的 predicate，返回 true\n\n\n\n###### findFirst\n\n用于返回满足条件的第一个元素\n\n```\nArrayList<String> list = new ArrayList<>(Arrays.asList(\"I\", \"love\", \"you\", \"too\"));\nSystem.out.println(\n\tlist.stream().filter(s-> s.length()>2).findFirst().get()\n);\n\n```\n\n###### findAny\n\n返回流中的任意元素\n\n```\n    System.out.println(\n            list.parallelStream().filter(s-> s.length()>2).findAny().get()\n    );\n```\n\n>love 或 you\n\n并行数据多返回满足第一个\n\n\n\n#### 非短路（Unshort-circuiting）\n\n指必须处理完所有元素才能得到最终结果\n\n\n\n###### reduce\n\nreduce操作效率不高，因为它创建了大量的中间`String`和`StringBuilder`\n\n```\n list.stream().\n \t \tmap(a->a.name.replaceAll(\" \", \"-\")).\n\t\treduce((str1, str2) -> str1 + \"&&\" + str2).get();\n```\n\n>等价 collect(Collectors.joining(\"&&\"))\n\n\n\n###### toArray\n\n```\n    Product[] array = list.stream().toArray(Product[]::new);\n   //Arrays.stream(array).sorted(Comparator.comparing(s>s.getId())).forEach(System.out::println);\n    Arrays.stream(array).filter(s->s.id>1).forEach(System.out::println);\n```\n\n","tags":["stream"],"categories":["lang","java"]},{"title":"go语法规则","url":"/lang/go/","content":"\n\n\n###  声明赋值\n\n**:=**  临时,局部变量\n\n###  方法首字母\n\n类似java,不等同(private 只能当前类访问)\n\n**public** 大写 跨包调用\n\n**private**小写 包内调用\n\n<!--more-->\n\n```go\n##f2.go\npackage t1\n\nimport (\n\t\"fmt\"\n)\n\nvar gloal string = \" 全局\"\n//...可变参函数\nfunc Tfun2(a ...string) (string, string) {\n\ttemp := \" 局部\"\n\tnf(a)\n\treturn a[0] + gloal, a[1] + temp\n}\n\nfunc nf(a []string) {\n    //for i := range a \n    //for _, v := range a \n\tfor i, v := range a {\n\t\tif a[i] == \"dd\" {\n\t\t\tfmt.Println(a, v)\n\t\t}\n\t}\n}\n##f1.go\npackage t1\n\nimport (\n\t\"fmt\"\n)\n\nfunc Tfun1() {\n\ta, b := Tfun2(\"a is\", \"b is\", \"dd\")\n\tfmt.Println(a, b)\n}\n\n##main.go\npackage main\n\nimport (\n\t\"fmt\"\n\tt1 \"go_learn/test\"\n)\n\nfunc main() {\n\tmf()\n}\n\nfunc mf() {\n\tfmt.Println(\"main调用包test fun1\")\n\tt1.Tfun1() //两个返回值\n}\n```\n\n\n\n","tags":["规则","语法"],"categories":["lang","go"]},{"title":"ps","url":"/linux/shell/ps/","content":"\nps (process status) 命令用于显示当前进程的状态，类似于 windows 的任务管理器\n\n\n\n### 查找指定进程\n\n```\n$ ps -ef | grep  key\ncs        4565  4533  0 21:14 pts/2    00:00:00 /opt/ELK/elasticsearch-7.17.1/modules/x-pack-ml/platform/linux-x86_64/bin/controller\n```\n\n> key 运行进程的关键字 (如:ps -ef | grep  tomcat)\n>\n> UID 启动进程的用户名\n>\n> PID  进程pid\n>\n> PPID \n>\n> C \n>\n> STIME 开始启动时间 \n>\n> TTY  终端号\n>\n> TIME  运行时间\n>\n> CMD   启动进程的命令\n\n<!--more-->\n\n### 查找进程使用情况\n\n```\nps -aux | grep Typora\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\ncs  7458  1.2  0.8 4913400 139224 ?      Sl   15:11   0:08 /usr/share/typora/Typora /home/cs/go/ps.md\n\n```\n\n- USER: 行程拥有者\n- PID: pid\n- %CPU: 占用的 CPU 使用率\n- %MEM: 占用的记忆体使用率\n- VSZ: 占用的虚拟记忆体大小\n- RSS: 占用的记忆体大小\n- TTY: 终端的次要装置号码 (minor device number of tty)\n- STAT: 该行程的状态:\n  - D: 无法中断的休眠状态 (通常 IO 的进程)\n  - R: 正在执行中\n  - S: 静止状态\n  - T: 暂停执行\n  - Z: 不存在但暂时无法消除\n  - W: 没有足够的记忆体分页可分配\n  - <: 高优先序的行程\n  - N: 低优先序的行程\n  - L: 有记忆体分页分配并锁在记忆体内 (实时系统或捱A I/O)\n- START: 行程开始时间\n- TIME: 执行的时间\n- COMMAND:所执行的指令\n\n\n\n#### 内存\n\n```\n$ ps -aux | sort -k4nr | head -3\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\ncs   2119  4.8  1.6 1183553740 265420 ?   Sl   14:02   4:06 /opt/google/chrome/chrome -- ...\ncs   1660  5.1  1.5 34393500 254380 ?     SLl  13:59   4:30 /opt/google/chrome/chrome --...\ncs   1753  1.0  1.4 1179343396 242272 ?   Sl   13:59   0:57 /opt/google/chrome/chrome --...\n```\n\n>a all所有\n>\n>u userid,该进程用户id\n>\n>x 所有程序,不已终端区分\n>\n>sort 排序\n>\n>k 代表从第几列开始\n>\n>4n 4列(%MEM)开始\n>\n>r 反向(reverse) ,默认从小到大\n>\n>head  头几列(-3 ,显示前3列)\n\n\n\n#### cpu\n\n```\n$ ps -aux | sort -k3nr | head -3\n```\n\n","tags":["shell"],"categories":["linux","shell"]},{"title":"md语法","url":"/markdown/mdgrammar/","content":"\n\n\n/hexo/_config.yml<a id=\"id-sample\" style=\"display:none\"/>\n\n```\npermalink: :title/\n```\n\n### 站内文章链接\n\n#### 绝对路径\n\n/_posts\n\n```\n$ tree -L 2 ./_posts/\n./_posts/\n├── linux\n│   ├── debian\n│   ├── k8s\n│   └── shell\n├── markdown\n│   ├── flow.md\n│   ├── formula.md\n│   └── mdgrammar.md\n\n```\n\n\n\n```\n[点击查看md写flow文章](/markdown/flow)\n```\n\n>[点击查看md写flow文章](/markdown/flow)\n>\n>[] 自定义链接标题\n>\n>()绝对地址,permalink的值\n\n#### post_link\n\n```\n{% post_link markdown/flow '点击查看md写flow文章' %}\n```\n\n> {% post_link markdown/flow '点击查看md写flow文章' %}\n>\n> post_link 相对路径 '标题' \n\n\n\n### 跳转\n\n#### 页内跳转指定位置\n\n锚点链接\n\n```\n[跳到本页的开头](#id-sample)\n```\n\n[跳到开头](#id-sample)\n\n#### 其他页面跳转到指定位置\n\n锚点链接\n\n```\n[跳到其他页指定位置](permalink的值#id-sample)\n```\n\n\n\n#### 设置锚点\n\n```\n锚点<a id=\"id-sample\" style=\"display:none\"/>\n```\n\n","tags":["grammar"],"categories":["markdown"]},{"title":"初识K8S","url":"/linux/k8s/初识K8S/","content":"\n### Master服务\n\n#### 安装kubernetes\n\n[官网下载kubernetes](https://kubernetes.io/docs/setup/release/notes/)\n\n```\ntar -xvf kubernetes.tar.gz  -C /opt/\n```\n\n下载 Client Binaries，Server Binaries\n\n```\nuname -s -m  #获取版本官网下载或执行下面命令下载\nbash /opt/kubernetes/cluster/get-kube-binaries.sh\n```\n\n <!--more--> \n\n> Kubernetes release: v1.11.0\n>\n> Server: linux/amd64 (to override, set KUBERNETES_SERVER_ARCH)\n>\n> Client: linux/amd64 (autodetected)\n>\n> Will download **kubernetes-server-linux-amd64.tar.gz** from https://dl.k8s.io/v1.11.0\n>\n> Will download and extract **kubernetes-client-linux-amd64.tar.gz** from https://dl.k8s.io/v1.11.0\n>\n> Is this ok? [Y]/n\n\nkubernetes-server\n\n```\ntar -tf   kubernetes-server-linux-amd64.tar.gz  #查看文件\ntar -xvf   kubernetes-server-linux-amd64.tar.gz  -C /opt/kubernetes/   --strip-components 1\n```\n\n\n\nkubernetes-client\n\n```\ntar -tf   kubernetes-client-linux-amd64.tar.gz\ntar -xvf   kubernetes-client-linux-amd64.tar.gz  -C /opt/kubernetes/   --strip-components 1\n```\n\n\n\n执行文件(配置文件可以直接路径)\n\n```\nsudo ln -s /opt/kubernetes/server/bin/kube-apiserver  /usr/bin/\nsudo ln -s /opt/kubernetes/server/bin/kube-controller-manager  /usr/bin/\nsudo ln -s /opt/kubernetes/server/bin/kube-scheduler  /usr/bin/\n```\n\n\n\n#### 准备依赖服务 etcd\n\n[etcd releases下载](https://github.com/etcd-io/etcd/releases) 如果s3.amazonaws.com下不动。。。\n\n被墙了 被墙了 被墙了\n\ngo 编译\n\n```\n#mkdir -p $GOPATH/src/go.etcd.io/ \n#cd $GOPATH/src/go.etcd.io/\n#git https://github.com/etcd-io/etcd.git\ncs@debian:~/gopath/etcd$ ./bulid\n```\n\n\n\n> can’t load package: package go.etcd.io/etcd: cannot find package “go.etcd.io/etcd” in any of:\n>\n> /opt/go/src/go.etcd.io/etcd (from $GOROOT)\n>\n> /home/cs/gopath/src/go.etcd.io/etcd (from $GOPATH)\n\n```\n$GOPATH/bin/etcd   #运行\n$ ETCDCTL_API=3 ./bin/etcdctl put foo bar\nOK\n```\n\n##### 创建用户\n\n```\nsudo groupadd  -g 995 etcd\nsudo useradd -s /sbin/nologin -M -c \"etcd user\" -u 995 etcd -g  etcd\nsduo mkdir -p /etc/etcd \nsudo mkdir -p /var/lib/etcd \nsudo chown -R etcd.etcd /var/lib/etcd\n```\n\n##### etcd.service\n\n```\n[Unit] \nDescription=Etcd Server \nAfter=network.target \nAfter=network-online.target \nWants=network-online.target \n \n[Service] \nType=notify \nWorkingDirectory=/var/lib/etcd/ \nEnvironmentFile=-/etc/etcd/etcd.conf \nUser=etcd \n# set GOMAXPROCS to number of processors \nExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\" --listen-client-urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\"\" \nRestart=on-failure \nLimitNOFILE=65536 \n \n[Install] \nWantedBy=multi-user.target\n```\n\n> sudo systemctl start etcd.service\n>\n> 该命令启动不了 /bin/bash -c “GOMAXPROCS=$(nproc) /usr/bin/etcd –name=\\”${ETCD_NAME}\\” –data-dir=\\”${ETCD_DATA_DIR}\\” –listen-client-urls=\\”${ETCD_LISTEN_CLIENT_URLS}\\””\n>\n> sudo systemctl status etcd.service\n>\n> **bash[9841]: run the stateless etcd v3 gRPC L7 reverse proxy\n>\n> debian systemd[1]: etcd.service: main process exited, code=exited, status=2/INVALIDARGUMENT\n>\n> debian systemd[1]: Failed to start Etcd Server.\n> **\n\n设置etcd\nExecStart=/opt/etcd-v3.3.9/etcd\n\n##### 启动etcd服务\n\n```\ntemp=\"etcd.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● etcd.service - Etcd Server\n>\n> Loaded: loaded (/lib/systemd/system/etcd.service; enabled)\n>\n> Active: active (running) since 六 2018-09-08 14:53:26 CST; 5min ago\n> Main PID: 804 (etcd)\n>\n> CGroup: /system.slice/etcd.service\n>\n> └─804 /opt/etcd-v3.3.9/etcd\n\n```\n./etcdctl cluster-health\n```\n\n> member 8e9e05c52164694d is healthy: got healthy result from [http://localhost:2379](http://localhost:2379/)\n>\n> cluster is healthy\n\n#### kube-apiserver\n\n##### 创建用户\n\n```\nsudo groupadd -g 996 kube\nsudo useradd -s /sbin/nologin -M -c \"kube user\" -u 996 kube -g kube\nsudo mkdir -p /etc/kubernetes\nsudo mkdir -p /usr/libexec/kubernetes\nsudo chown -R kube.kube /usr/libexec/kubernetes\nsudo chown -R kube.kube /var/run/kubernetes\n```\n\n##### kube-apiserver.service\n\n```\n[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes\n#Dependent service\nAfter=etcd.service\n\n[Service]\nEnvironmentFile=-/etc/kubernetes/apiserver\nExecStart=/opt/kubernetes/server/bin/kube-apiserver $KUBE_API_ARGS\nRestart=on-failure\nType=notify\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n> 1.error creating self-signed certificates: mkdir /var/run/kubernetes: permission denied\n>\n> 2.error: –[etcd](https://chengshea.github.io/linux/debian/docker/install-kubernetes/#etcd)-servers must be specified\n\n配置\n\n```\nsudo cat>/etc/kubernetes/apiserver<<EOF\nKUBE_API_ARGS=\"--etcd-servers=http://localhost:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=169.169.0.0/16 --service-node-port-range=1-65535 --admission-control=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ResourceQuota --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n> –etcd-servers：就是etcd的地址。\n>\n> –insecure-bind-address：apiserver绑定主机的非安全IP地址，设置0.0.0.0表示绑定所有IP地址。\n>\n> –insecure-port：apiserver绑定主机的非安全端口，默认为8080。\n>\n> –service-cluster-ip-range：Kubernetes集群中Service的虚拟IP地址段范围，以CIDR格式表示，该IP范围不能与物理机真实IP段有重合。\n>\n> -service-node-port-range：Kubernetes集群中Service可映射的物理机端口范围，默认为30000~32767.\n>\n> –admission-control： Kubernetes集群的准入控制设置，各控制模块以插件形式依次生效。\n>\n> –logtostderr：设置为false表示将日志写入文件，不写入stderr。\n>\n> –log-dir： 日志目录。\n>\n> –v：日志级别。\n>\n> [更多参数查看官方文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/)\n\n##### 启动\n\n```\ntemp=\"kube-apiserver.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kube-apiserver.service - Kubernetes API Server\n>\n> Loaded: loaded (/lib/systemd/system/kube-apiserver.service; disabled)\n>\n> Active: active (running) since 六 2018-09-08 15:42:02 CST; 2s ago\n> Docs: https://github.com/GoogleCloudPlatform/kubernetes\n>\n> Main PID: 3560 (kube-apiserver)\n>\n> CGroup: /system.slice/kube-apiserver.service\n>\n> └─3560 /opt/kubernetes/server/bin/kube-apiserver –etcd-servers=[http://localhost:2379](http://localhost:2379/) …….\n\n#### kube-controller-manager\n\n##### kube-controller-manager.service\n\n```\n[Unit]\nDescription=Kubernetes Scheduler Plugin\nDocumentation=https://github.com/GoogleCloudPlatform/kubernetes\nAfter=kube-apiserver.service\nRequires=kube-apiserver.service\n\n[Service]\nEnvironmentFile=-/etc/kubernetes/controller-manager\nUser=kube\nExecStart=/opt/kubernetes/server/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_ARGS\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n配置\n\n```\nsudo touch /etc/kubernetes/controller-manager && sudo  chmod 757 /etc/kubernetes/controller-manager\ncat>/etc/kubernetes/controller-manager<<EOF\nKUBE_CONTROLLER_MANAGER_ARGS=\"--master=http://192.168.56.101:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2\" \nEOF\n```\n\n\n\n##### 启动\n\n```\ntemp=\"kube-controller-manager.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kube-controller-manager.service - Kubernetes Scheduler Plugin\n>\n> Loaded: loaded (/lib/systemd/system/kube-controller-manager.service; disabled)\n>\n> Active: active (running) since 六 2018-09-08 16:54:32 CST; 2s ago\n>\n> Docs: https://github.com/GoogleCloudPlatform/kubernetes\n>\n> Main PID: 5980 (kube-controller)\n>\n> CGroup: /system.slice/kube-controller-manager.service\n>\n> └─5980 /opt/kubernetes/server/bin/kube-controller-manager –master=[http://localhost:8080](http://localhost:8080/) ……\n\n#### kube-scheduler\n\n##### kube-scheduler.service\n\n```\n[Unit]\nDescription=Kubernetes Scheduler Manager\nDocumentation=https://github.com/kubernetes\nAfter=kube-apiserver.service\nRequires=kube-apiserver.service\n\n[Service]\nEnvironmentFile=/etc/kubernetes/scheduler\nExecStart=/opt/kubernetes/server/bin/kube-scheduler $KUBE_SCHEDULER_ARGS\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n配置\n\n```\nsudo touch /etc/kubernetes/scheduler && sudo  chmod 757 /etc/kubernetes/scheduler\ncat>/etc/kubernetes/scheduler<<EOF\nKUBE_SCHEDULER_ARGS=\"--master=http://localhost:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n##### 启动\n\n```\ntemp=\"kube-scheduler.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kube-scheduler.service - Kubernetes Scheduler Manager\n>\n> Loaded: loaded (/lib/systemd/system/kube-scheduler.service; disabled)\n>\n> Active: active (running) since 六 2018-09-08 17:02:09 CST; 7s ago\n>\n> Docs: https://github.com/kubernetes\n> Main PID: 6340 (kube-scheduler)\n>\n> CGroup: /system.slice/kube-scheduler.service\n>\n> └─6340 /opt/kubernetes/server/bin/kube-scheduler –master=[http://localhost:8080](http://localhost:8080/) ……\n\n### Node节点服务\n\n#### kubelet\n\n##### kubelet.service\n\n```\n[Unit]\nDescription=Kubernetes Kubelet Server\nDocumentation=https://github.com/kubernetes\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nWorkingDirectory=-/var/lib/kubelet\nEnvironmentFile=-/etc/kubernetes/kubelet\nExecStart=/opt/kubernetes/server/bin/kubelet $KUBELET_ARGS  \nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n```\n\n> kubelet.service holdoff time over, scheduling restart\n\n配置\n\n```\nsudo mkdir -p /var/lib/kubelet\nsudo touch /etc/kubernetes/kubelet && sudo  chmod 757 /etc/kubernetes/kubelet\ncat>/etc/kubernetes/kubelet<<EOF\nKUBELET_ARGS=\"--kubeconfig=/etc/kubernetes/kubeconfig --hostname-override=127.0.0.1 --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n> [–kubeconfig代替了–api-servers](https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/)\n>\n> \n> –[require-kubeconfig 1.7版开始默认true ](https://github.com/kubernetes/kubernetes/issues/36745)\n>\n> Kubernetes 1.8开始要求关闭系统的Swap\n\n##### 启动\n\n```\ntemp=\"kubelet.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n```\n\n> ● kubelet.service - Kubernetes Kubelet Server\n>\n> Loaded: loaded (/lib/systemd/system/kubelet.service; disabled)\n>\n> Active: active (running) since 二 2018-09-11 18:34:48 CST; 29ms ago\n>\n> Docs: https://github.com/kubernetes\n> Main PID: 9018 (kubelet)\n>\n> CGroup: /system.slice/kubelet.service\n>\n> └─9018 /opt/kubernetes/server/bin/kubelet –kubeconfig=/etc/kubernetes/kubeconfig –hostname-override=127.0.0.1 –logtostderr=false –log-dir=/var/log/kubernetes –v=2 –cgroup-driver=systemd\n\n#### kube-proxy\n\n##### kube-proxy.service\n\n```\n[Unit]\nDescription=Kubernetes Kube-Proxt Server\nDocumentation=https://github.com/kubernetes\nAfter=network.target\nRequires=network.target\n\n[Service]\nEnvironmentFile=-/etc/kubernetes/proxy\nExecStart=/opt/kubernetes/server/bin/kube-proxy $KUBE_PROXY_ARGS\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n```\n\n配置\n\n```\nsudo touch /etc/kubernetes/proxy && sudo  chmod 757 /etc/kubernetes/proxy\ncat>/etc/kubernetes/proxy<<EOF\nKUBE_PROXY_ARGS=\"--master=http://localhost:8080  --logtostderr=false --log-dir=/var/log/kubernetes --v=2\"\nEOF\n```\n\n\n\n##### 启动\n\n```\ntemp=\"kube-proxy.service\"\nsudo cp $temp /lib/systemd/system\nsudo systemctl daemon-reload\nsudo systemctl enable $temp\nsudo systemctl start $temp\nsudo systemctl status $temp\n./kubectl get cs\n./kubectl get node\n```","tags":["docker","k8s"],"categories":["linux","docker"]},{"title":"内网穿透","url":"/network/内网穿透/","content":"\n### ngrok\n\n提供内网穿透服务，可以在自己主机部署服务供外网访问\n\n同类产品： [花生壳](https://hsk.oray.com/download/) ，[nat123](http://www.nat123.com/Pages_2_32.jsp)\n\n官网 https://ngrok.com/\n\ngithub https://github.com/inconshreveable/ngrok\n\n### 安装\n\n官网注册[获取authtoken](https://dashboard.ngrok.com/get-started)\n\n生成配置\n\n```\n./ngrok authtoken   ********\n`\n```\n\n <!--more--> \n\n> Authtoken saved to configuration file:***.ngrok2/ngrok.yml\n>\n> 默认路径 https://ngrok.com/docs#default-config-location\n>\n> 运行\n>\n> ```\n> ./ngrok http 8010\n> ```\n>\n> \n>\n> 访问 http://localhost:4040/\n\n### 自定义\n\n隧道定义参数详解 https://ngrok.com/docs#tunnel-definitions\n\n每个隧道都必须定义\n\n- proto 需要 所有 隧道协议名称，中的一个http，tcp，tls\n- addr 需要 所有 转发流量到这个本地端口号或网络地址\n\n示例配置 https://ngrok.com/docs#config-examples\n\n**ngrok.cfg**\n\n```\nauthtoken: **************\ntunnels:\n  httpbin:\n    proto: http\n    addr: 8090\n    #subdomain: dev.com #子域名请求 收费\n```\n\n\n\n启动\n\n```\n#默认配置\n./ngrok start httpbin\n#指定额外配置文件\n./ngrok start  -config ./ngrok.cfg   httpbin\n```","tags":["ngrok","内网穿透"],"categories":["other","network"]},{"title":"评论","url":"/lang/node/npm/hexo/评论/","content":"\n### 由来\n\n[gitment](https://github.com/imsun/gitment)使用 **github issue** 保存评论\n\n### 准备\n\n右键新标签页打开 https://github.com/settings/applications/new\n\n创建\n![app-id](http://ojtd6k176.bkt.clouddn.com/github-new-app.png)\n\n获取 id secret\n![参数](http://ojtd6k176.bkt.clouddn.com/github-app-id.png)\n\n### hexo Theme\n\n根据 *个人主题* 添加\n\n#### 样式\n\nsource/css/gitment.css\n\n- css [详情右键新标签页](https://github.com/chengshea/record/blob/master/issue/gitment.css)\n\nsource/js/gitment.js\n\n- js [详情右键新标签页](https://github.com/chengshea/record/blob/master/issue/gitment.js)\n\n#### 布局调用\n <!--more--> \n调用认证\n/layout/_partial/comments/gitment.ejs\n\n```\n<div id=\"gitment\"></div>\n<!-- 主页不要加载gitment -->\n<%if (!index){ %>\n<script>\nvar gitment = new Gitment({\nowner: 'chengshea',\nrepo: 'chengshea.github.io',\noauth: {\nclient_id: '3478952f5e3ade06xxxxx',\nclient_secret: '3ca8b3ada58c7993cbb385839f83ba8xxxxxx',\n },\n})\ngitment.render('gitment')\n</script>\n<% } %>\n```\n\n\n\n添加评论\n/layout/_partial/article.ejs\n\n```\n<% if (!index && post.comments){ %>\n    <%  if (theme.gitment.on) { %>\n        <%- partial('comments/gitment') %>\n    <% } else if (theme.disqus.on) { %>\n        <%- partial('comments/disqus', {\n            shortname: theme.disqus.shortname\n          }) %>\n    <% } else if (config.disqus_shortname) { %>\n        <%- partial('comments/disqus', {\n            shortname: config.disqus_shortname\n          }) %>\n    <% } %>\n<% } %>\n```\n\n\n\n**_config.yml** 配置添加gitment开启\n\n```\ngitment:\n       on: true\n       enable: true\n       owner: chengshea\n       repo: chengshea.github.io\n       client_id: 3478952f5e3adexxxxx\n       client_secret: 3ca8b3ada58c7993cbb385839f83bxxxxx\n```\n\n\n\n管理OAuth Apps\n\nhttps://github.com/settings/developers","tags":["issues"],"categories":["other"]},{"title":"上网","url":"/network/on-line/","content":"\n### 准备\n  有时候因工作需要，查询资料，下载，就需要上网\n\n  **linux 环境下**\n  * pip \n  * shadowsocks\n\n\n### 安装\npip\n```\nwget https://bootstrap.pypa.io/get-pip.py\npython get-pip.py\n```\nshadowsocks\n```\n$sudo pip install shadowsocks \n```\n <!--more--> \n### 配置\n####  服务端\nss.json\n```json\n{\n    \"server\":\"server_ip\",\n    \"server_port\":8888,\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\":1080,\n    \"password\":\"mypassword\",\n    \"timeout\":300,\n    \"method\":\"aes-256-cfb\",\n    \"fast_open\": false\n}\n```\n多号\n```json\n{\n    \"server\": \"server_ip\",\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\": 1080,\n    \"port_password\": {\n        \"8881\": \"aaaa81\",  \n        \"8882\": \"aaaa82\",\n        \"8883\": \"aaaa83\",\n        \"8884\": \"aaa84\"\n    },\n    \"timeout\": 300,\n    \"method\": \"aes-256-cfb\",\n    \"fast_open\": false\n}\n```\n\n\n**ssserver --help**\n\n` -d start/stop/restart`\n```\nssserver  -c  /xx/ss.json  -d start\n```\n\n#### 客户端\nss.json\n```\n$cat  /xx/ss.json\n{\n    \"server\": \"server_ip\",\n    \"server_port\": 443,\n    \"password\": \"mypassword\",\n    \"method\": \"aes-256-cfb\",\n    \"remarks\": \"\"\n}\n```\n\n**sslocal --help**\n```\nsslocal -c  /xx/ss.json\n```\n\n### 运行原理\n![proxy](http://ojtd6k176.bkt.clouddn.com/proxy-12.56.png)\n* 首先通过SS Local和VPS进行通信，通过Socks5协议进行通信 <br/>\n* SS Local连接到VPS， 并对Socks5中传输的数据进行对称加密传输，传输的数据格式是SS的协议\n* SS Server收到请求后，对数据解密，按照SS协议来解析数据。\n* SS Server根据协议内容转发请求。\n* SS Server获取请求结果后回传给SS Local\n* SS Local获取结果回传给应用程序\n下面2者必须同时满足\n\n1.代理服务器本地可以访问到;\n\n2.代理服务器可以访问目标网站。\n\n### 启动\n小脚本，再次吐槽qt客户端，太重了\n```\n#!/bin/bash\n\nvar=''\ncd /opt/Shadowsocks\nname=`whoami`\n\nif [ ! -d '/home/$name/ss' ];then\n   mkdir ~/ss\nfi\n \nfunction state(){\n  var=$(ps -ef | grep sslocal | grep -v grep | awk '{print $2}')\n}\n\nstate\n\nif test -z $var ;then\n  sslocal -c  $PWD/ss.json >>~/ss/log 2>&1 &\nelse\n  echo \"kill ---$var\"\n  kill -9 $var\n  state\n  if test -z $var ;then rm -r ~/ss ;fi\nfi  \n```\n\n","tags":["online"],"categories":["other"]},{"title":"shield","url":"/services/elk/es-shield/","content":"\n### 简介\n  **Shield**拦截所有对ElasticSearch的请求，并加上认证与加密，保障ElasticSearch及相关系统的安全性\n  \n  [<span id='top'>安装 doc</span>]( https://www.elastic.co/guide/en/shield/2.4/installing-shield.html)\n \n### 准备\n\n版本2.4.2{% post_link 安装ElasticSearch 安装ElasticSearch %}\n <!--more--> \n**以下操作需要你安装了elasticsearch为前提**\n\n\n\n* [license-2.4.2](https://download.elastic.co/elasticsearch/release/org/elasticsearch/plugin/license/2.4.2/license-2.4.2.zip)\n* [shield-2.4.2](https://download.elastic.co/elasticsearch/release/org/elasticsearch/plugin/shield/2.4.2/shield-2.4.2.zip)\n\n### 安装\n**以es，插件为<span id='custom'>自定义</span>目录为背景**\n\nes自定义目录**/opt/elasticsearch**\n\n安装脚本**plugin**注意下面变量值\n\n* CONF_DIR (elasticsearch.yml目录)\n `CONF_DIR=\"/opt/elasticsearch/config\"`\n* ES_ENV_FILE (elasticsearch目录)\n `ES_ENV_FILE=\"/opt/elasticsearch/config/default/elasticsearch\"`\n\nlicense\n```\ncs@debian:/opt/elasticsearch$ bin/plugin install file:///home/cs/Download/license-2.4.2.zip\n```\n>Installed license into /home/cs/Download/es/plugins/license\n\n\nshield\n```\ncs@debian:/opt/elasticsearch$ bin/plugin install file:///home/cs/Download/shield-2.4.2.zip\n```\n >Installed license into /home/cs/Download/es/plugins/shield\n \n安装成功目录（部分）\n```\ncs@debian:/opt/elasticsearch$ tree -L 3 /opt/elasticsearch\n/opt/elasticsearch\n├── bin\n│   ├── elasticsearch\n│   ├── elasticsearch.in.sh\n│   ├── elasticsearch-systemd-pre-exec\n│   ├── plugin\n│   ├── shield\n│   │   ├── esusers  添加角色密码脚本\n│   │   ├── esusers.bat\n│   │   ├── migrate\n│   │   ├── migrate.bat\n│   │   ├── syskeygen\n│   │   └── syskeygen.bat\n│   └── watcher\n│       ├── croneval\n│       └── croneval.bat\n├── config\n│   ├── default\n│   │   └── elasticsearch\n│   ├── elasticsearch.yml\n│   ├── logging.yml\n│   ├── scripts\n│   └── shield\n│       ├── logging.yml\n│       ├── role_mapping.yml\n│       ├── roles.yml\n│       ├── users\n│       └── users_roles\n├── lib\n```\n\n### 添加新用户\n\n执行脚本**esusers**需要注意参数\n* CONF_DIR ( 判断 $CONF_DIR/shield 目录)\n   后面密码会写入到配置文件（usersusers_roles）内\n* ES_CLASSPATH (shield 生成密码的执行类)\n  ```\n  java -cp org.elasticsearch.shield.authc.esusers.tool.ESUsersTool\n  ```\n  \nESUsersTool类在shield插件目录**shield-2.4.2.jar**\n  \n  **注意** [自定义目录](#custom)即 *plugins* 不再 *ES_HOME* 目录下，执行脚本需要确认**ES_CLASSPATH**位置正确\n  \n  1.添加变量 ES_PLUGIN\n  ```shell\n  ES_PLUGIN=`dirname $(sed -n 's/path.plugins://p'  $ES_HOME/config/elasticsearch.yml)`\n```\n   2.修改\n  ```shell\n#ES_CLASSPATH=\"$ES_CLASSPATH:$ES_HOME/plugins/shield/*\"\nES_CLASSPATH=\"$ES_CLASSPATH:$ES_PLUGIN/plugins/shield/*\"  \n```\n\n<br/>\n\n执行添加命令[文档](#top)\n```\ncs@debian:/opt/elasticsearch$ ./bin/shield/esusers useradd cs -p cs@121 -r admin\n```\n>useradd 添加的新用户名 cs <br/>\n-p  密码   cs@121    <br/>\n-r  角色（role） admin  <br/>\n\n启动\n```\ncs@debian:/opt/elasticsearch$ ./bin/elasticsearch -d\n```\n>cs@debian:`$ curl -u cs  \"http://localhost:9200/?pretty\"  <br/>\nEnter host password for user 'cs': <br/>\n{ <br/>\n  \"name\" : \"Sepulchre\",<br/>\n  \"cluster_name\" : \"elasticsearch\",<br/>\n  \"cluster_uuid\" : \"Ey7sWEIPRZGstn2LSKCCTQ\",<br/>\n  \"version\" : {<br/>\n    \"number\" : \"2.4.2\",<br/>\n    \"build_hash\" : \"161c65a337d4b422ac0c805f284565cf2014bb84\",<br/>\n    \"build_timestamp\" : \"2016-11-17T11:51:03Z\",<br/>\n    \"build_snapshot\" : false,<br/>\n    \"lucene_version\" : \"5.5.2\"<br/>\n  },<br/>\n  \"tagline\" : \"You Know, for Search\"<br/>\n}\n\n\n### 总结\n注意脚本运行，主要参数（变量）值\n","tags":["auth","safe"],"categories":["ELK","elasticsearch"]},{"title":"git server 搭建","url":"/tool/git-server/","content":"## 准备\n*    ssh\n*    git \n\n\n## gitosis\n### 添加用户\n仓库服务器执行\n```\nuseradd git\nmkdir -p /home/git\nchown -R git:git /home/git\n```\n\n密钥\n```\ncp  ~/.ssh/id_rsa.pub   /tmp/git.pub\n```\n <!--more--> \n### 安装\n\n```\ngit clone git://github.com/res0nat0r/gitosis.git\ncd gitosis\npython setup.py install\n```\n\n初始化\n```\nsu  git\ngitosis-init < ~/.ssh/id_rsa.pub\n```\n\n### 管理\n拉取\n```\n$git clone git@192.168.16.232:repositories/gitosis-admin.git\n$ tree -L 2 gitosis-admin\ngitosis-admin\n├── gitosis.conf\n└── keydir\n    └── git@ubuntu.pub\n```\n配置密钥\n```\ncp ~/.ssh/id_rsa.pub  gitosis-admin/keydir/cs.pub\n```\n添加权限 **gitosis.conf**\n```\n[group dev]  \nmembers = cs #这里的cs对上面公匙cs.pub文件名cs  \nwritable = test #项目名test\n```\n\n### <span id=\"pull\">测试拉取</span>\n\n```\nmkdir  test && cd test\necho \"测试test仓库\">rep\ngit init\ngit add .\ngit  commit -am \"add test\"\ngit remote add origin git@192.168.16.232:test.git\ngit  push origin master\n```\n> 提示要密码 <br />\n设置密码（root用户操作）\n```\npasswd gits\n2次 123456\n```\n或\n```\nsu gits\necho \"你的密钥\">>~/.ssh/authorized_keys\n```\n\n\n## gitolite\n### 添加用户\n仓库服务器执行\n```\nuseradd gits\nmkdir -p /home/gits\nchown -R gits:gits  /home/gits\n```\n\n初始化\n```\n$ cp  ~/.ssh/id_rsa.pub   /tmp/git.pub\n$ su gits\n$ git clone https://github.com/sitaramc/gitolite\n$ gitolite/install -to $HOME/bin\n$ ~/bin/gitolite setup -pk /tmp/git.pub\n```\n\n**密码**\n\n见gitosis测试[拉取](#pull)的操作\n\n\n### 管理\n本地拉取\n```shell\ngit clone gits@192.168.16.232:repositories/gitolite-admin\n```\n> 正克隆到 'gitolite-admin'...  <br />\ngits@192.168.16.232's password:  <br />\nremote: Counting objects: 6, done. <br />\nremote: Compressing objects: 100% (4/4), done. <br />\nremote: Total 6 (delta 0), reused 0 (delta 0)\n接收对象中: 100% (6/6), 完成. <br />\n检查连接... 完成。 <br />\n\n查看目录\n```\n$ tree -L 2  gitolite-admin\ngitolite-admin\n├── conf\n│   └── gitolite.conf\n└── keydir\n    └── git.pub\n```\ncp密钥，配置权限\n```\n$ cat  gitolite-admin/conf/gitolite.conf \nrepo gitolite-admin\n    RW+     =   git\n\nrepo testing\n    RW+     =   @all\n```\n> RW+  所有权限  <br />\ndoc: https://github.com/sitaramc/gitolite#access-rule-examples <br />\n\n\n最后\n```\ngit add .\ngit commit -am \"add new user xx\"\ngit push origin master\n```\n>更多高级配置在/home/gits/.gitolite.rc\n\n\n## gogs\n官网 https://try.gogs.io/\n\n带**UI**的服务，部署方便，轻量级\n\ngitlab太占内存了，云服务器跑成本高呀\n```\n# Pull image from Docker Hub.\n$ docker pull gogs/gogs\n\n# Create local directory for volume.\n$ mkdir -p /var/gogs\n\n# Use `docker run` for the first time.\n$ docker run --name=gogs -p 10022:22 -p 10080:3000 -v /var/gogs:/data gogs/gogs\n\n# Use `docker start` if you have stopped it.\n$ docker start gogs\n```\n>doc https://github.com/gogits/gogs/tree/master/docker#usage\n","tags":["git"],"categories":["tools"]},{"title":"git pull","url":"/tool/git-pull/","content":"### pull\n稀疏检出*sparse checkout*\n <!--more--> \n```\n#!/bin/bash\n\nprint_help() {\n  cat <<EOF\n  use params \n   -h , --help   说明   不支持分支\n   -u , --url   *必须，下载文件的链接（如https:://github.io/xx/tree/master/a/b ,下载b）\n  \n\nEOF\n}\n\nfunction src(){\n   if [[ \"$1\" =~ \"github.com\" ]] || [[ \"$1\" =~ \"gitee.com\" ]];then\n     echo \"downloadUrl--> $1\"\n   else \n     echo \"不支持\"\n     exit 1\n   fi\n}\n\nwhile [ $# -ge 0 ]; do\n    case $1 in\n        -h|--help)\n           print_help  \n           exit 1\n            ;;\n        -u|--url)\n              src $2\n              break \n            ;;\n         *  )\n           echo \"use param -h or --help !\"  \n           exit 1\n            ;;\n    esac\ndone\nfunction type(){\n   uri=$(echo $1 | grep \"/tree/master/\" | grep -v grep)\n   echo \"---$uri\"\n   if [[ $uri != \"\" ]];then\n     echo \"-------/tree/master\"\n     uri=${url%/tree/master*}\".git\"\n     down=${url#*/tree/master/}\n   else\n     echo \"-------/blob/master\"\n     uri=$(echo $1 |grep -v grep | grep \"/blob/master/\")\n     if [[ $uri != \"\" ]];then\n       uri=${url%/blob/master*}\".git\"\n       down=${url#*/blob/master/}\n     else\n       echo \"只支持拉取master文件下载\"\n       exit 1\n     fi\n   fi \n}\n\nurl=$2\n\nfile=${url##*/}\n\nuri=\ndown=\ntype $2\n \n\nif [ ! -f \"$file\" ];then\n\tmkdir $file\nfi\ncd $file\n\ngit init\necho \"==================添加 源===================\"\ngit remote add -f origin $uri \n#稀疏检出\ngit config core.sparsecheckout true\n#拉取文件\necho \"$down\">>.git/info/sparse-checkout\necho \"==================开始拉取===================\"\ngit pull origin master\n \nrm -rf .git\nmv $file/*  . && rm -r $file\n\n\necho \"==================$PWD===================\"\t\n```\n>利用git稀疏检出拉取部分文件\n\n### js实现下载\n[kinolien gitzip ](http://kinolien.github.io/gitzip/)","tags":["git"],"categories":["tools"]},{"title":"avd","url":"/other/avd/","content":"\n### 创建AVD失败\n \n see log 查看日志\n ```\n WARN - vdmanager.AvdManagerConnection - Failed to create the SD card. \n WARN - vdmanager.AvdManagerConnection - Failed to create sdcard in the     AVD folder.\n ```\n \n#### 目录权限\n```\ncs@debian:~/repository/Android/sdk$ chmod +x tools/*\ncs@debian:~/repository/Android/sdk$ chmod +x platform-tools/*\n```\n\n#### 安装\n```\nsudo apt-get install  lib32z1 lib32ncurses5 #代替ia32-libs  \n```\n创建提示\n>/sdk/emulator/mksdcard: error while loading shared libraries: libgcc_s.so.1: cannot open shared object file: No such file or directory \n\n```\ncs@debian:~$ locate libgcc_s.so.1\n/lib/x86_64-linux-gnu/libgcc_s.so.1\n```\n 可以看到系统x86_64 不支持32\n> WARN - vdmanager.AvdManagerConnection - /home/cs/repository/Android/sdk/emulator/mksdcard: error while loading shared libraries: libgcc_s.so.1: cannot open shared object file: No such file or directory \nerror while loading shared libraries: libgcc_s.so.1: wrong ELF class: ELFCLASS64 \n\n <!--more--> \n\n搜索[libgcc_s.so.1](https://pkgs.org/download/libgcc_s.so.1)\n\n没有找到deb,下载的rpm\n```\nrpm2cpio  libgcc-4.1.2-55.el5.i386.rpm  | cpio -div\n```\n解压后\n```\nsudo ln -s /home/cs/repository/Android/sdk/lib32/libgcc_s.so.1  /lib/\n```\n创建AVD成功**等待近2分钟后出现**\n>Error while waiting for device: Timed out after 300seconds waiting for emulator to come online.\n\n#### 最终解决方法\n**SDK tools > SDK Tools** 勾选 **Android Emulator** \n\n**虚拟化应用** *VirtualBox* *docker* 等，与avd不能同时开启\n\n **Tools - Android** 勾选取消 *Enable ADB Integration* （对我无用）\n \nGraphics选项，**Software**而不是Automatic或Hardware","tags":["android","Simulator"],"categories":["linux","install"]},{"title":"docker-compose","url":"/linux/k8s/compose/","content":"#### 安装 \ngit下载地址:https://github.com/docker/compose/releases\n\n推荐pip安装\n```\nsudo pip install -U docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose -version\n```\n  <!--more--> \n#### 使用\n>build\n\n指定Dockerfile 文件,compose会利用它自动构建\n```\nbuild: /path\n```\n> command\n\n覆盖容器启动后默认命令\n```\ncommand:\n       - \"python\" \n       - \"neural_style.py\" \n       - \"--content\" \n       - \"/neural/input.jpg\" \n```\n> links\n\n链接其它服务的容器\n```\nlinks:\n    - redis\n```\n> ports\n\n暴露端口信息给宿主机,使用(host:container) 必须字符串格式,yaml解析涉及进制\n```\nports:\n      - \"8888:8888\"\n      - \"127.0.0.1:8001:8001\"\n```\n\n> volumes\n\n挂载路径,宿主机(host:container);上访模式(host:container:ro)\n``` \nvolumes:\n    - ~/tmp:/tmp/dir\n    - \n```\n> volumes_from\n\n挂载容器或服务\n```\nvolumes_from:\n    - jupyter\n    - service_name\n```\n> devices\n\n设配映射列表\n```\ndevices:\n    - \"/dev/nivida0:/dev/nivida0\"\n    - \"/dev/nivida1:/dev/nivida1\"\n```\n> depends_on\n\nexpress之间依赖关系,\n * `docker-compose up` 按照依赖顺序启动\n\n```\n depends_on:\n     - elasticsearch\n```\n\n> labels\n\n向docker容器添加元数据\n```\nlabels:\n   - aliyun.gpu=2\n\n```\n>其它\n\ndocker run 支持\n```\ncpu_shares: 73\n#指定工作目录\nworking_dir: /code  \n\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nhostname: foo\ndomainname: foo.com\nmem_limit: 1000000000\nprivileged: true\nrestart: always\nstdin_open: true\ntty: true\n```\n\n#### 示例\n\n\n\n```\nversion: '2'\nservices:\n  jupyter:\n    image: registry.cn-hangzhou.aliyuncs.com/denverdino/tensorflow:1.0.0\n    container_name: jupyter\n    ports:\n      - \"8888:8888\"\n    environment:\n      - PASSWORD=tensorflow\n    volumes:\n      - \"/tmp/tensorflow_logs\"\n      - \"./notebooks:/root/notebooks\"\n    command:\n      - \"/run_jupyter.sh\"\n      - \"/root/notebooks\"\n  tensorboard:\n    image: registry.cn-hangzhou.aliyuncs.com/denverdino/tensorflow:1.0.0\n    container_name: tensorboard\n    ports:\n      - \"6006:6006\"\n    volumes_from:\n      - jupyter\n    command:\n      - \"tensorboard\"\n      - \"--logdir\"\n      - \"/tmp/tensorflow_logs\"\n      - \"--host\"\n      - \"0.0.0.0\"\n```\n\n\n\nlogstash\n\n```\nlogstash:\n  image: logstash:2.4.1\n  command: /opt/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf\n  privileged: false\n  restart: always\n  ports:\n  - 21020:21020\n  volumes:\n  - /mnt/tinkle_data/logstash/logstash.conf:/etc/logstash/conf.d/logstash.conf\n```\n\nkibana\n\n```\nkibana:\n  image: daocloud.io/library/kibana:4.6.1\n  privileged: false\n  restart: always\n  ports:\n  - 5601:5601\n  volumes:\n  - /mnt/tinkle_data/kibana/kibana.yml:/opt/kibana/config/kibana.yml\n```\n\nelasticsearch\n\n```\nes:\n  restart: always\n  ports:\n    - '9200:9200/tcp'\n    - '9300:9300/tcp'\n  environment:\n    - LANG=C.UTF-8\n    - JAVA_HOME=/docker-java-home/jre\n    - TZ=Asia/ShangHai\n  memswap_limit: 0\n  labels:\n    aliyun.scale: '1'\n  shm_size: 0\n  image: 'elasticsearch:2.4.1'\n  memswap_reservation: 0\n  volumes:\n    - '/home/data/es:/usr/share/elasticsearch/data:rw'\n    - '/mnt/elasticsearch/plugins:/usr/share/elasticsearch/plugins:rw'\n  kernel_memory: 0\n  mem_limit: 0\n```\n\nredis\n\n```\nredis:\n  image: redis:3.2.5\n  command: \n     -  /etc/redis/6379.conf\n  privileged: false\n  restart: always\n  ports:\n  - 6379:6379\n  volumes:\n  - /mnt/tinkle_data/redis/data:/data/\n  - /mnt/tinkle_data/redis/conf/6379.conf:/etc/redis/6379.conf\n```\n\n\n\n```\nmysql:\n  image: 'mysql:5.7.17'\n  ports:\n    - '3306:3306'\n  restart: always\n  environment:\n    - MYSQL_ROOT_PASSWORD=19930221\n  labels:\n    aliyun.scale: '1'\n  volumes:\n    - '/home/data/mysql/mysql:/var/lib/mysql'\n    - '/home/data/mysql/conf/mysql.cnf:/etc/mysql/conf.d/mysql.cnf'\n```\n\n\n\n```\n#docker-compose services  mysql的服务名\njdbc_url=jdbc:mysql://服务名:3306/databasename\n```\n\n","tags":["install","docker-engine","docker compose"],"categories":["linux","k8s","docker"]},{"title":"docker","url":"/linux/k8s/docker/","content":"#### 安装 engine\n卸载旧版\n`sudo apt-get purge docker.io*`\n\n编辑 ` /etc/apt/sources.list.d/docker.list`\n```\necho 'deb https://apt.dockerproject.org/repo debian-jessie main'> /etc/apt/sources.list.d/docker.list\n```\n安装依赖：` apt-transport-https`\n\n```\nsudo apt-get install docker-engine\ndocker version\n...permission问题\n```\n创建组\n```\n cat /etc/group | grep ^docker  #不存在\n sudo groupadd docker  #存在忽略，创建组\nsudo gpasswd -a ${USER} docker   #添加当前用户到组\nsudo restart  #重启生效\n```\n <!--more--> \n#### 安装 compose\n官方文档 https://docs.docker.com/compose/install/#alternative-install-options\n\n##### 方法一\ncurl 安装\n```\nsudo apt-get install curl\n```\n/usr/local/bin 需要权限\n```\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.11.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n..... \ncurl: (56) SSL read: error:00000000:lib(0):func(0):reason(0), errno 104\n网络中断n次，推荐离线\n```\n[离线下载](https://dl.bintray.com/docker-compose/master/)\n```\nsudo mv docker-compose-Linux-x86_64 /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose --version\n```\n\n##### 方法二\npip安装`pip install docker-compose`\n**强烈建议您使用 virtualenv，因为许多操作系统有python系统包与docker-compose依赖关系冲突**\n\n\n####  国内源\n`docker search  xxxx` \n**error response from daemon: Get https://index.docker.io**\n被 GFW强了\nDocker配置文件`/etc/default/docker`\n```\nsudo mousepad /etc/default/docker\n\n#添加 阿里源\nDOCKER_OPTS=\"--registry-mirror=http://mirrors.aliyun.com\"\n```\n加速地址\n```\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://自己专属.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n#### docker-compose.yml\n常用配置{% post_link  compose %}\n\n#### 卸载\n```\n#docker-engine\nsudo apt-get remove docker-engine\n\n# docker-compose \n#curl\n$ rm /usr/local/bin/docker-compose\n# pip\n$ pip uninstall docker-compose\n```\n\n\n\ndocker.service\n\n```\ncat >/usr/lib/systemd/system/docker.service <<EOF\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=http://docs.docker.com\nAfter=network.target docker.socket\n[Service]\nType=notify\nEnvironmentFile=$BASE/flanneld/subnet.env\nWorkingDirectory=/usr/local/bin\nExecStart=/usr/bin/dockerd \\\n                \\$DOCKER_NETWORK_OPTIONS \\\n                -H unix:///var/run/docker.sock \nExecReload=/bin/kill -s HUP $MAINPID\n# Having non-zero Limit*s causes performance problems due to accounting overhead\n# in the kernel. We recommend using cgroups to do container-local accounting.\nLimitNOFILE=infinity\nLimitNPROC=infinity\nLimitCORE=infinity\nTimeoutStartSec=0\n# set delegate yes so that systemd does not reset the cgroups of docker containers\nDelegate=yes\n# kill only the docker process, not all processes in the cgroup\nKillMode=process\nRestart=on-failure\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\n","tags":["install","docker-engine","docker compose"],"categories":["linux","debian","docker"]},{"title":"dpkg","url":"/linux/debian/dpkg/","content":"#### dpkg\n\n\n\n```\napt-get install xxx\n....\nCould not exec dpkg!\nE: Sub-process /usr/bin/dpkg returned an error code (100)\n```\n\n\n```\n ls -l /usr/bin/dpkg #什么没有呀！！！\n find /usr -type f -name dpkg\n .....\n```\n  <!--more--> \n 那执行\n```\n apt-get install dpkg  \n ....\n 显示已安装 **使用方法一**\n```\n\n 搜索 **dpkg debian download **\n [download](https://packages.debian.org/jessie/dpkg)\n\n\n##### 方法一\n```\n ar x  ~/文档/dpkg_1.17.27_amd64.deb data.tar.gz\n \n mkdir /tmp/dpkg\n cp data.tar.gz /tmp/dpkg\n cd /tmp/dpkg\n \n tar xfvz data.tar.gz ./usr/bin/dpkg\n \nsudo cp ./usr/bin/dpkg /usr/bin/\nsudo apt-get update\n```\n#####  方法二\n\n`./configure`\nconfigure: error: libbz2 library or header not found\nSee `config.log' for more details\n安装 **libbz2**\nhttps://packages.debian.org/jessie/libbz2-1.0\n\nconfigure: error: liblzma library or header not found\nSee `config.log' for more details\n安装 **liblzma**\nhttps://packages.debian.org/jessie/liblzma5\n\nconfigure: error: no curses library found\n安装 ** curses  **\nhttps://packages.debian.org/jessie/libncurses5-dev\n\n\n\n#### 解压deb\n\n \n\n```\nar x   fileName.deb\n```\n\n\n\n```\nxz -d  data.tar.xz\n```\n\n\n\n```\ntar -zxvf   data.tar.gz\ntar -xvf   data.tar\n```\n\n","tags":["install","dpkg"],"categories":["linux","debian","tools"]},{"title":"live","url":"/tool/redis-live/","content":"Redis live\n Redis Live是一个用来监控redis实例,分析查询语句并且有web界面的监控工具,使用python编写\n#### Install Dependencies\n* **tornado** pip install tornado\n* **redis.py** pip install redis\n* **python-dateutil** pip install python-dateutil\n if you're running Python < 2.7:\n*  ** argparse** pip install argparse\n官方说明： http://www.nkrode.com/article/real-time-dashboard-for-redis\n <!--more--> \n#### pip\n下载地址:  https://pypi.python.org/pypi/pip#downloads\npip 依赖 setuptools\nFinished processing dependencies for setuptools==32.3.1\n\n```bash\n$tar -zxvf  pip-9.0.1.tar.gz\n$python setup.py build \n$sudo python setup.py install\nFinished processing dependencies for pip==9.0.1\n```\n\n\n\nFinished processing dependencies for python-dateutil==2.6.0\n\n\nFinished processing dependencies for redis==2.10.5\n\n```\n$sudo apt-get install build-essential python-dev\n```\nDpkg: Warning: ** ldconfig ** could not be found in the PATH environment variable or no executable privileges\nTip: The root PATH environment variable should normally contain ** / usr / local / sbin, / usr / sbin, and / sbin **\n```bash\n$locate ldconfig   #sbin目录存在 ldconfig\n$sudo mousepad ~/.bashrc\nexport PATH=/usr/loca/sbin:/usr/sbin:/sbin:$PATH\n$source ~/.bashrc\n```\n\nFinished processing dependencies for tornado==4.5.dev1\n\n列出安装的packages\n```\n$ sudo pip freeze\n```\n\n####  redislive\n```\ngit clone https://github.com/kumarnitin/RedisLive.git\n```\n配置文件**redis-live.conf**【redis-live.conf.example】\n```\n{\n\t\"RedisServers\":\n\t[ \n\t\t{\n  \t\t\t\"server\": \"154.17.59.99\",\n  \t\t\t\"port\" : 6379\n\t\t},\n\t\t\n\t\t{\n  \t\t\t\"server\": \"localhost\",\n  \t\t\t\"port\" : 6380,\n  \t\t\t\"password\" : \"some-password\"\n\t\t}\t\t\n\t],\n\n\t\"DataStoreType\" : \"redis\",\n\n\t\"RedisStatsServer\":\n\t{\n\t\t\"server\" : \"ec2-184-72-166-144.compute-1.amazonaws.com\",\n\t\t\"port\" : 6385\n\t},\n\t\n\t\"SqliteStatsStore\" :\n\t{\n\t\t\"path\":  \"to your sql lite file\"\n\t}\n}\n```\n启动服务\n```\n./redis-monitor.py --duration=30     //启动监控，duration是心跳时间\n./redis-live.py                    //启动web服务，默认监听8888端口\n```\n**env: ...py 权限不够**\n给予执行权\n```\nchmod +x  redis-monitor.py\nchmod +x  redis-live.py \n```\n打开 http://localhost:8888/index.html","tags":["redis","监控工具","install"],"categories":["nosql","redis"]},{"title":"kibana","url":"/services/elk/kibana/","content":"\n#### debian\n```\n$>sudo dpkg -i kibana-4.6.1-amd64.deb\n$>dpkg -L  kibana \n```\n \n#### win\n[nssm](#)\n\n#### 创建索引\n** logstash.conf **  \n <!--more--> \n```\noutput {\n    elasticsearch {\n        hosts => [\"127.0.0.1:9200\"]\n        index => \"logstash-nginx-json-%{+YYYY.MM}\"\n    }\n   stdout {codec => rubydebug}\n}\n```\n* 只有日志输入到es，才会触发创建索引","tags":["install","win"],"categories":["ELK","kibana"]},{"title":"logstash","url":"/services/elk/logstash/","content":"\n#### debian安装\n```\n $>sudo dpkg -i logstash-2.4.1_all.deb\n$> dpkg -L  logstash\n```\n#### win安装\nservice工具 [nssm](#)\n <!--more--> \n#### 配置\nlogstash.conf\n```\ninput {\n    file {\n        path => [ \"F:/ELK/nginx-1.10.2/logs/access.log\" ]\n\t\ttype => \"nginx_access\"\n        start_position => \"beginning\"\n        ignore_older => 0\n    }\n\tfile {\n        path => [ \"F:/ELK/nginx-1.10.2/logs/access_json.log\" ]\n\t\t#codec => \"json\"\n\t\ttype => \"nginx_json\"\n        start_position => \"beginning\"\n        ignore_older => 0\n    }\n}\n\nfilter {\n if [type] == \"nginx_access\" {\n    grok {\n\t    patterns_dir => \"F:/ELK/logstash-2.4.1/patterns\"        #设置自定义正则路径\n        match => { \"message\" => \"%{NGINXACCESS}\" }\n    }\n\n\n    date {\n      match => [ \"log_timestamp\",\"dd/MMM/yyyy:HH:mm:ss Z\"]\n\n    }\n   \n  }\n  \n  if [type] == \"nginx_json\" {\n        json {\n            source => \"message\"\n            #target => \"doc\"\n            remove_field => [\"message\"]\n        }\n\t\tif [@fields][ip] != \"-\" {\n\t\t\tgeoip {\n\t\t\t\t\tsource => \"[@fields][ip]\"\n \t\t\t\t\ttarget => \"geoip\"\n\t\t\t\t\tfields => [\"city_name\", \"continent_code\", \"country_code3\", \"country_name\", \"ip\", \"postal_code\", \"region_name\"]\n\t\t\t\t\tdatabase => \"F:/ELK/logstash-2.4.1/ip/GeoLiteCity.dat\"\n\t\t\t\t\tadd_field => [ \"[geoip][coordinates]\", \"%{[geoip][longitude]}\" ]\n\t\t\t\t\tadd_field => [ \"[geoip][coordinates]\", \"%{[geoip][latitude]}\"  ]\n\t\t\t}\n\t\t\n\t\t\tmutate {\n\t\t\t\t\tconvert => [ \"[geoip][coordinates]\", \"float\"]\n\t\t\t\t\t\n\t\t\t}\n   \n\t\t}\n \t}\n \n}\noutput {\n if [type] == \"nginx_access\" {\n    elasticsearch {\n        hosts => [\"127.0.0.1:9200\"]\n        index => \"logstash-nginx-access-%{+YYYY.MM}\"\n    }\n   stdout {codec => rubydebug}\n  }\n  if [type] == \"nginx_json\" {\n    elasticsearch {\n        hosts => [\"127.0.0.1:9200\"]\n        index => \"logstash-nginx-json-%{+YYYY.MM}\"\n    }\n   stdout {codec => rubydebug}\n  }\n \n}\n```","tags":["install","win","log"],"categories":["ELK","logstash"]},{"title":"安装elasticsearch","url":"/services/elk/安装ElasticSearch/","content":"## elasticsearch 目录结构\n\n|type | description | location |\n|-------|---------------------|-------|\n|home | Home of elasticsearch installation |\t/usr/share/elasticsearch \n| bin\t| Binary scripts including elasticsearch to start a node |\t/usr/share/elasticsearch/bin\n|conf\t| Configuration files elasticsearch.yml and logging.yml\t|/etc/elasticsearch\n|conf |Environment variables including heap size,file descriptors\t|/etc/default/elasticsearch\n|data\t| The location of the data files\t|/var/lib/elasticsearch/\n|logs\t| Log files location\t|/var/log/elasticsearch\n|plugins\t| Plugin files location\t|/usr/share/elasticsearch/plugins\n\n下载地址\n\n####  window7\nbin目录执行安装\n```\nF:\\ELK\\elasticsearch-2.4.1\\bin>service install\nInstalling service      :  \"elasticsearch-service-x64\"\nUsing JAVA_HOME (64-bit):  \"F:\\java\\jdk8\"\nThe service 'elasticsearch-service-x64' has been installed.\n```\n安装成功，如果启动失败（进logs目录，查看错误信息）\n <!--more--> \n```\n[error] [ 6376] Failed creating java %JAVA_HOME%\\jre\\bin\\server\\jvm.dll\n [error] [ 6376] 系统找不到指定的路径。\n ```\n 直接利用管理服务\n ```\n #运行 service manager 会弹出服务管理界面 修改jvm指定路径\nF:\\ELK\\elasticsearch-2.4.1\\bin>service manager\n```\n\n#### debian8\n```\nsudo dpkg -i  elasticsearch-2.4.2.deb\nbin$> ./elasticsearch   #启动提示没有权限\n```\n需要授权执行命令** chmod +x bin/elasticsearch  ** \n再次执行** ./elasticsearch -d **即可后台启动 \n使用** ps aux|grep elasticsearch **可以查看是否启动\n\n**设置开机启动**\n创建脚本 start.sh\n```\n#!bin/bash\nexport JAVA_HOME=/usr/bin/java\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n #切换到cs用户（带环境变量）\nsu -cs<<!\ncd /opt/elasticsearch/bin\n./elasticsearch &\nexit\n!\n```\n修改启动文件 mousepad /etc/init.d/elasticsearch\n```\n#!bin/bash\n### BEGIN INIT INFO\n# Provides:          elasticsearch\n# Required-Start:    $all\n# Required-Stop:     $all\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-De.ion: starts the elasticsearch  server\n# De.ion:       starts elasticsearch using start-stop-daemon\n### END INIT INFO\nsh /opt/elasticsearch/start.sh\n```\n","tags":["install","win","search"],"categories":["ELK","elasticsearch"]},{"title":"搭建hexo","url":"/lang/node/npm/hexo/搭建hexo/","content":"\n\n\n\n\n### 准备工具\n\nnode\ngit\nhexo\n\n### node 安装\n``` bash\n$tar  -zxvf  node.tar.gz\n$cd node\n$./config  --prefix=/opt/node\n$sudo make\n$sudo make install\n```\n添加环境变量\n```bash\n#set nodejs\nexport NODE_HOME=/opt/node\nexport PATH=$NODE_HOME/bin:$PATH\n$node -v #显示版本号\n$sudo node -v #当用root执行，commond not found\n#mousepad  ~/.bashrc\nalias sudo='sudo env PATH=$PATH'\n```\n <!--more--> \n### git\n\n\n``` bash\n$cd ~/.ssh #查看没有密钥\n$ ssh-keygen -t rsa -C \"你git的user.email\"\n```\n路径默认 最好输入密码\n最后得到两个文件：id_rsa和id_rsa.pub\n\n``` bash\n$ cat ~/.ssh/id_rsa.pub #复制到github ssh key \n$ssh git@github.com  \n```\n\n### hexo\n在指定目录下执行终端\n```bash\n$sudo npm install hexo-cli -g #安装在当前目录\n#忽略warn\n$sudo npm install hexo --save\n$hexo -v\n```\n给予文件夹权限\n初始化 ，安装组件\n```\n$hexo init\n$npm install\n```\n### 部署\n本地部署\n```\n$hexo g  #generate 简写\n$hexo s #server  默认端口4000\n```\npush \n\n```\n$hexo d #deploy\n```\n\n\n\n### themes\n\n部分主题是18,19年,node版本太高,**版本不一致**\n\n会导致hexo server 正常,但hexo generate 生成的public目录文件**全为为0kb**\n\n会导致\"<%= config.root %>\"写法只能获取到/,跳转链接不正常\n\n等一系列问题,**注意版本**\n\n\n\nnode版本问题https://nodejs.org/zh-cn/download/releases/\n\nhttps://www.npmjs.com/package/hexo-cli\n\n```\nnpm ls --depth 0\n\nhexo g --debug\n```\n\n","tags":["install","hexo"],"categories":["other"]},{"title":"https签名","url":"/network/https自己签名/","content":"#### 为服务器端和客户端准备公钥、私钥\n```\n#私钥\n>openssl genrsa -out server.key 1024 -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n```\n#公钥\n>openssl rsa -in server.key -pubout -out server.pem\n```\n#### 生成 CA 证书\n```\n <!--more--> \n#ca私钥\n>openssl genrsa -out ca.key 1024 -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n **第一次填写信息**\n```\n>openssl req -new -key ca.key -out ca.csr -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n\nCountry Name (2 letter code) [AU]:\nState or Province Name (full name) [Some-State]:\nLocality Name (eg, city) []:\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:\nOrganizational Unit Name (eg, section) []:\n**Common Name** (e.g. server FQDN or YOUR name) []:localhost\nEmail Address []:\n\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:12345678\nAn optional company name []:cs\n\n```\n>openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt -days 365\n```\n\n#### 生成服务器端证书\n服务器端需要向 CA 机构申请签名证书，在申请签名证书之前依然是创建自己的 CSR 文件  **与第一次信息填写一样**\n```\n>openssl req -new -key server.key -out server.csr -config E:\\Git\\mingw64\\ssl\\openssl.cnf\n```\n向自己的 CA 机构申请证书，签名过程需要 CA 的证书和私钥参与，最终颁发一个带有 CA 签名的证书\n```\n>openssl x509 -req -CA ca.crt -CAkey ca.key -CAcreateserial -in server.csr -out server.crt\n```\nSignature ok\nsubject=/C=AU/ST=Some-State/O=Internet Widgits Pty Ltd/CN=localhost\nGetting CA Private Key\n\n\n#### 生成cer文件\n使用openssl 进行转换\n```\n>openssl x509 -in server.crt -out server.cer -outform der\n```\n\n 生成p12\n```\nF:\\logs\\http>openssl pkcs12 -export -clcerts -in server.crt -inkey server.key -out client.p12\nWARNING: can't open config file: /usr/local/ssl/openssl.cnf\nLoading 'screen' into random state - done\nEnter Export Password:12345678\nVerifying - Enter Export Password:12345678\n```\n\n","tags":["https","签名"],"categories":["http协议","https"]},{"title":"404","url":"/404.html","content":"<html>\n<head>\n<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset=\"utf-8\">\n<title>404页面</title>\n<style>\n*{margin:0;padding:0;outline:none;font-family:\\5FAE\\8F6F\\96C5\\9ED1,宋体;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-khtml-user-select:none;user-select:none;cursor:default;font-weight:lighter;}\n.center{margin:0 auto;}\n.whole{width:100%;height:100%;line-height:100%;position:fixed;bottom:0;left:0;z-index:-1000;overflow:hidden;}\n.whole img{width:100%;height:100%;}\n.mask{width:100%;height:100%;position:absolute;top:0;left:0;background:#000;opacity:0.6;filter:alpha(opacity=60);}\n.b{width:100%;text-align:center;height:400px;position:absolute;top:50%;margin-top:-230px}.a{width:150px;height:50px;margin-top:30px}.a a{display:block;float:left;width:150px;height:50px;background:#fff;text-align:center;line-height:50px;font-size:18px;border-radius:25px;color:#333}.a a:hover{color:#000;box-shadow:#fff 0 0 20px}\np{color:#fff;margin-top:40px;font-size:24px;}\n#num{margin:0 5px;font-weight:bold;}\n</style>\n<script type=\"text/javascript\">\n\tvar num=4;\n\tfunction redirect(){\n\t\tnum--;\n\t\tdocument.getElementById(\"num\").innerHTML=num;\n\t\tif(num<0){\n\t\t\tdocument.getElementById(\"num\").innerHTML=0;\n\t\t\tlocation.href=\"https://cheng.vercel.app\";\n\t\t\t}\n\t\t}\n\tsetInterval(\"redirect()\", 1000);\n</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n</head>\n\n<body onload=\"redirect();\">\n<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class=\"whole\">\n\t<img src=\"http://7xowaa.com1.z0.glb.clouddn.com/back.jpg\">\n    <div class=\"mask\"></div>\n</div>\n<div class=\"b\">\n\t\t<img src=\"http://7xowaa.com1.z0.glb.clouddn.com/404.png\" class=\"center\">\n\t\t<p>\n\t\t\t暂时未能找到您查找的页面<br>\n\t\t\t可能输入的网址错误或此页面不存在<br>\n            <span id=\"num\"></span>秒后自动跳转到主页\n\t\t</p>\n\t</div><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n\n</body>\n</html> "},{"title":"categories","url":"/categories/index.html"},{"title":"分类 & 标签","url":"/tags/index.html"},{"title":"其他","url":"/other/index.html"}]
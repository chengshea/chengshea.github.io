---
title: k8s集群
permalink: linux/k8s/k8s01/
tags:
  - kubernetes
  - kubectl
categories:
  - linux
  - k8s
date: 2022-07-21 20:24:46
---







### 常用命令

缩写

```
certificatesigningrequests (缩写 csr)
componentstatuses (缩写 cs)
configmaps (缩写 cm)
customresourcedefinition (缩写 crd)
daemonsets (缩写 ds)
deployments (缩写 deploy)
endpoints (缩写 ep)
events (缩写 ev)
horizontalpodautoscalers (缩写 hpa)
ingresses (缩写 ing)
limitranges (缩写 limits)
namespaces (缩写 ns)
networkpolicies (缩写 netpol)
nodes (缩写 no)
persistentvolumeclaims (缩写 pvc)
persistentvolumes (缩写 pv)
poddisruptionbudgets (缩写 pdb)
pods (缩写 po)
podsecuritypolicies (缩写 psp)
replicasets (缩写 rs)
replicationcontrollers (缩写 rc)
resourcequotas (缩写 quota)
serviceaccounts (缩写 sa)
services (缩写 svc)
statefulsets (缩写 sts)
storageclasses (缩写 sc)
```



#### 自动补全

```
sudo apt install bash-completion

source /usr/share/bash-completion/bash_completion
source <(kubectl completion bash)

echo "source <(kubectl completion bash)" >> ~/.bashrc
```

> /usr/bin/zsh   /usr/bin/bash



#### cs(master节点)

componentstatuses

```
cs@debian:~$ kubectl get cs
NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok                   
controller-manager   Healthy   ok                   
etcd-2               Healthy   {"health": "true"}   
etcd-0               Healthy   {"health": "true"}   
etcd-1               Healthy   {"health": "true"}  
```



#### node节点

```
cs@debian:~$ kubectl  get node
NAME       STATUS   ROLES    AGE    VERSION
master02   Ready    <none>   101d   v1.18.8
master03   Ready    <none>   101d   v1.18.8
node04     Ready    <none>   101d   v1.18.8
node05     Ready    <none>   101d   v1.18.8
node06     Ready    <none>   101d   v1.18.8

kubectl get node -o wide
```

<!--more-->

空间

```
cs@debian:~$ kubectl get namespaces 
NAME                   STATUS   AGE
default                Active   101d
devops                 Active   100d
kube-node-lease        Active   101d
kube-public            Active   101d
kube-system            Active   101d
kubernetes-dashboard   Active   92d
```



#### pod

```
cs@debian:~$ kubectl get pod
No resources found in default namespace.

cs@debian:~$ kubectl get pod -n kube-system 
NAME                                         READY   STATUS    RESTARTS   AGE
coredns-56ff7bc666-prc6l                     1/1     Running   4          11d
coredns-56ff7bc666-qwdsh                     1/1     Running   8          92d
traefik-ingress-controller-7769cb875-x76rs   1/1     Running   1          46h
```

>-n  接namespaces的NAME值,省略为default



```
kubectl get pods -o wide
kubectl get pods -A -o wide
```





#### describe

 ingress **Tab提示**

```
cs@debian:~$ kubectl get ingress -n devops 
ingressclasses.networking.k8s.io      ingresses.networking.k8s.io           ingressroutetcps.traefik.containo.us  
ingresses.extensions                  ingressroutes.traefik.containo.us     ingressrouteudps.traefik.containo.us  

cs@debian:~$ kubectl get ingressroutetcps.traefik.containo.us -n devops 
NAME    AGE
redis   47h

cs@debian:~$ kubectl describe ingressroutetcps.traefik.containo.us redis -n devops 
Name:         redis
Namespace:    devops
Labels:       <none>
Annotations:  API Version:  traefik.containo.us/v1alpha1
Kind:         IngressRouteTCP
Metadata:
  Creation Timestamp:  2022-07-19T13:01:37Z
  Generation:          1
  Managed Fields:
    API Version:  traefik.containo.us/v1alpha1
    Fields Type:  FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .:
          f:kubectl.kubernetes.io/last-applied-configuration:
      f:spec:
        .:
        f:entryPoints:
        f:routes:
    Manager:         kubectl
    Operation:       Update
    Time:            2022-07-19T13:01:37Z
  Resource Version:  261095
  Self Link:         /apis/traefik.containo.us/v1alpha1/namespaces/devops/ingressroutetcps/redis
  UID:               c79681ee-1bf1-4843-9666-457970d78f27
Spec:
  Entry Points:
    redis
  Routes:
    Match:  HostSNI(`*`)
    Services:
      Name:  redis-service
      Port:  6379
Events:      <none>
```





#### log



```
cs@debian:~$ kubectl logs  --tail=5 redis-app-1 -n devops
63:M 21 Jul 2022 12:15:34.720 * Synchronization with replica 121.21.25.3:6379 succeeded
63:M 21 Jul 2022 12:15:36.469 # Cluster state changed: ok
63:M 21 Jul 2022 12:15:40.604 * FAIL message received from 67f931358b8004268db0b57932293602ab3de629 about b49a123e2764b665ee898c21f983b9cda70cda00
63:M 21 Jul 2022 12:15:42.635 * Marking node a0e2f50ba382870da1ce4d23b66a1375826d6dc8 as failing (quorum reached).
63:M 21 Jul 2022 12:15:42.635 # Cluster state changed: fail

cs@debian:~$ kubectl logs  -f  --tail=5 redis-app-1 -n devops
63:M 21 Jul 2022 12:15:34.720 * Synchronization with replica 121.21.25.3:6379 succeeded
63:M 21 Jul 2022 12:15:36.469 # Cluster state changed: ok
63:M 21 Jul 2022 12:15:40.604 * FAIL message received from 67f931358b8004268db0b57932293602ab3de629 about b49a123e2764b665ee898c21f983b9cda70cda00
63:M 21 Jul 2022 12:15:42.635 * Marking node a0e2f50ba382870da1ce4d23b66a1375826d6dc8 as failing (quorum reached).
63:M 21 Jul 2022 12:15:42.635 # Cluster state changed: fail
^C
```

>-f   类似 **tail -f** 
>
>-p,  --previous[=false]: 如果为true，输出pod中曾经运行过，但目前已终止的容器的日志
>       --since=0: 仅返回相对时间范围，如5s、2m或3h，之内的日志。默认返回所有日志。只能同时使用since 和since-time中的一种
>      --since-time="": 仅返回指定时间（RFC3339格式）之后的日志。默认返回所有日志。只能同时使用since和since-time中的一种
>      --tail=-1: 要显示的最新的日志条数。默认为-1，显示所有的日志



#### patch

更新容器的镜像

```
kubectl patch pod valid-pod -p '{"spec":{"containers":[{"name":"kubernetes-serve-hostname","image":"new image"}]}}'
或
kubectl patch pod valid-pod --type='json' -p='[{"op": "replace", "path": "/spec/containers/0/image", "value":"new image"}]'
```

设置服务对外的IP

```
kubectl patch svc <svc-name> -n <namespace> -p '{"spec": {"type": "LoadBalancer", "externalIPs":["192.168.31.241"]}}'
```



#### scale

对副本数进行扩展或缩小



前提条件校验 ；当前副本数量或 `--resource-version`



缩减副本数到2

```
kubectl scale rc rc-nginx-3 —replicas=2
```



当前副本数为2，则将其扩展至3

```
kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
```





#### 重启

```
kubectl rollout restart deployment <deployment_name> -n <namespace>
```



#### 选择器

--field-selector

`status.podIP`

```
cs@debian:~/oss/hexo$  kubectl  get pod --field-selector status.podIP=121.21.35.3 -o wide -n devops
NAME          READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES
redis-app-1   1/1     Running   1          9d    121.21.35.3   node04   <none>           <none>
```

>1. metadata.name=my-service
>2. metadata.namespace!=default
>3. status.phase=Pending
>
>

选择了所有**`status.phase`**不为**`Running`**且`spec.restartPolicy`为**`Always`**的Pod.

```
kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always
```



#### events

显示集群内的详细事件，如果最近出现故障，你可以查看集群事件以了解故障前后发生的情况。如果你知道只有特定名称空间中存在问题，你可以将事件过滤到该名称空间。

```
$ kubectl get events 
LAST SEEN   TYPE     REASON                    OBJECT     MESSAGE
2d18h       Normal   Starting                  node/k8s   Starting kubelet.
2d18h       Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory
2d18h       Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure
2d18h       Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID
2d18h       Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods
2d18h       Normal   Starting                  node/k8s   Starting kubelet.
2d18h       Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory
2d18h       Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure
2d18h       Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID
2d18h       Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods
2d18h       Normal   NodeReady                 node/k8s   Node k8s status is now: NodeReady
2d18h       Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller
2d18h       Normal   Starting                  node/k8s   Starting kube-proxy.
2d18h       Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller
23m         Normal   Starting                  node/k8s   Starting kubelet.
23m         Normal   NodeHasSufficientMemory   node/k8s   Node k8s status is now: NodeHasSufficientMemory
23m         Normal   NodeHasNoDiskPressure     node/k8s   Node k8s status is now: NodeHasNoDiskPressure
23m         Normal   NodeHasSufficientPID      node/k8s   Node k8s status is now: NodeHasSufficientPID
23m         Normal   NodeAllocatableEnforced   node/k8s   Updated Node Allocatable limit across pods
23m         Normal   Starting                  node/k8s   Starting kube-proxy.
22m         Normal   RegisteredNode            node/k8s   Node k8s event: Registered Node k8s in Controller
```



#### api-resources

```
kubectl api-resources -o wide --sort-by name
```



#### 调试

启动参数`--feature-gates=EphemeralContainers=true`配置到kube-api和kubelet服务上重启

```
# 查看pod所在宿主及pod name
$ kubectl get po -o wide
# 根据pod name查看对应的docker 容器
$ docker ps | grep centos-687ff6c787-47gvh
# 根据输出的容器id，挂载容器网络并运行一个debug容器，使用 nicolaka/netshoot 这个镜像。这个镜像里集成了很多网络调试工具。
$ docker run -it --rm --name=debug --network=container:bb009aab414f nicolaka/netshoot bash
接下来就进入了与这个pod的相同的网络namespace，可以进行网络相关的调试了
```



```
for pod in $(kubectl get -o name pod  -n kube-system); 
do
    kubectl debug --image security/pod_scanner -p $pod /sanner.sh
done
```

> 批量跑某个命名空间下的安全扫描的脚本而不用干扰原容器





##### 没有开启Ephemeral Containers

```
kubectl debug mypod -it \
--container=debug \
--image=busybox \
--copy-to=my-debugger \
--same-node=true \
--share-processes=true
```

>--copy-to   指定新pod的名称
>--replace=true   是否删除原容器
>--same-node=true  是否调度到和原容器一样的node上
>--share-processes=true  是否共享容器pid空间



##### 利用Ephemeral Containers

```
kubectl run ephemeral-demo --image=k8s.gcr.io/pause:3.1 --restart=Never
```



```
kubectl debug ephemeral-demo -it --image=busybox  --target=ephemeral-demo
```

> 容器运行时必须支持--target参数。 如果不支持，则临时容器可能不会启动，或者可能使用隔离的进程命名空间启动。



```
kubectl delete pod ephemeral-demo
```

##### nsenter

```
 sudo yum install -y util-linux
```



```
$ docker inspect -f {{.State.Pid}} nginx
#nsenter命令进入该容器的网络命令空间
$ nsenter -n -t6700
```

